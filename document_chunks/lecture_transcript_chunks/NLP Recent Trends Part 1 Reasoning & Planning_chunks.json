{
  "source_file": "NLP Recent Trends Part 1 Reasoning & Planning.json",
  "lecture_name": "NLP Recent Trends Part 1 Reasoning & Planning",
  "course": "NLP",
  "total_chunks": 19,
  "chunks": [
    {
      "id": "transcript_nlp_nlp_recent_trends_part_1_reaso_c000_8eb6c3",
      "content": "[강의 녹취록] 과목: NLP | 제목: NLP Recent Trends Part 1 Reasoning & Planning\n\n안녕하세요. 여러분 저는 이번에 NLP 리센드 트렌드 강좌를 맡게 된 조준 박사과정생이라고 합니다. 이번 강의부터 여러분들께 최신 NLP 트렌드하고 어 요즘의 연구 현황 현황들을 좀 공유하는 시간을 좀 가질까 생각을 하고 있습니다. 그래서 그 첫 번째 강좌로서 한번 nap에서 가장 요즘에 핫한 주제인 리즈닝 앤 플래닝 관련 이야기를 좀 해보도록 하겠습니다. 네 목차는 이렇게 구성이 되고요. 그래서 우선 첫 번째로 NLP는 여러분들이 생각을 하는지에 대해서 한번 고찰을 해보고 그리고 실제로 LLM들이 어떻게 뭔가 생각을 할 수 있는지 생각하게 된다면 어떠한 방식으로 뭔가 이것을 구체화 할 수 있고 고도화를 할 수 있는지에 대해서 얘기해 보도록 하겠습니다. 우선 첫 번째로 얘기해 보고 싶은 주제는 실제로 LLM이 생각할까 그러니까 여러분들이 아마도 이전 강의에서 되게 거대 언어 모델들에 대한 강의들을 많이 들었을 거예요. 뭐 챗지피티라든가 뭐 최근에 나온 구글에서 나온 제미나이 이런 친구들을 여러분들이 한번 써보신 분들도 있을 거고 안 써보신 분들도 있을 건데 써보신 분들 아마 챗gpt는 아마 또 써보신 분들이 되게 많을 거라고 생각이 들어요. 근데 그러한 인공지능 등과 한번 대화를 해보시면 알겠지만 되게 얘네들이 똑똑하다는 생각이 들 겁니다. 그래서 실제로 여러분들이 만약 챗gpt한테 이렇게 물어보는 거죠. 요즘에 내가 개인적인 걱정이 많은데 뭔가 좋은 방법이 있을까 뭐 이런 개인적인 질문도 할 수도 있고 아니면 뭐 그냥 내일 점심 어떠냐 점심 뭐 먹는 게 좋을까 같은 뭐 그런 사적인 질문들 내가 요즘 연애를 하고 있는데 혹시 조언을 줄 수 있냐 뭐 그러한 다양한 질문들을 여러분들이 많이 물어봤을 겁니다. 그리고 물어보시면 알겠지만 대개 이 챗gpt가 아주 똑똑하다는 것을 여러분들도 많이 느꼈을 거예요. 이 사이트 같은 경우에는 어 여러분들이 실제로 많이 보이는 보시는 뭐 챗지피티 사이트는 아니긴 한데 실제로 그 뭔가 여러분들이 이거 챗지피티 에피아를 통해 가지고 실제로 여러분들의 쿼리를 날리고 실제로 결과물을 받아볼 수 있는 그러한 사이트라고 생각하시면 좋을 것 같습니다. 그래서 실제로 저희가 이 LLM의 카우션 랭귀지 모델링 그러니까 다음 단어를 맞추는 형태로 해가지고 컴플렉션을 해보게 된다면 이렇게 우선 걱정의 원인부터 찾는 것이 좋다 하면서 되게 아주 상세하게 여러분들에게 도움이 될 만한 글을 쓴다는 것을 확인해 볼 수가 있죠. 어 그렇다면 여러분들이 이런 LLM들과 대화를 해 보시면 아 정말 똑똑하고 사고를 하는 것 같다 생각을 하고 정말 인간과 비슷하다구나 라고 생각할 수도 있겠지만 사실 그렇지가 않습니다. 그래서 여러분들께 좀 몇 가지 예시를 좀 보여드리도록 하겠습니다. 그래서 간단하게 수학 문제 하나 풀어보도록 하죠. 해치피티한테 그래서 저희가 예시를 보면 철수는 테니스 공을 5개 들고 있고 철수가 테니스공 묶음 2개를 샀고 그리고 각 묶음에는 3개의 테니스 공이 있다. 이때 철수의 테니스 공이 몇 개 있는가 해가지고 저희가 이렇게 질문했다고 합시다. 이 경우에는 저희가 결국에는 각 묶음에 3개의 테니스 공 그리고 아 묶음을 2개 샀으니까 2개 그러니까 이 총 6개의 테니스공을 샀고 원래 5개를 들고 있었으니까 총 개수는 11개가 될 거예요. 그래서 이걸 생성하는 건 아니고요. 저희가 하고 싶은 것은 이걸 예시로 줄 겁니다. 아마도 이전 강의에서 아마도 여러분들은 이미 퓨샤주시라든가 원샷으로 이러한 LNN들을 인퍼런스 하는 것 자체는 좀 배웠을 겁니다. 그래서 이렇게 저희가 이것을 예시를 하나 줘 가지고 아 이런 형태로 답변을 해라 같은 형태로 저희가 이 채집피티한테 한번 제공을 해보도록 하겠습니다. 그래서 저희는 답은 11개 해가지고 이렇게 답을 준 상태이죠. 자 그다음에 이제 실제로 물어보고 싶은 것을 하나 물어보도록 합시",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "NLP Recent Trends Part 1 Reasoning & Planning.json",
        "lecture_name": "NLP Recent Trends Part 1 Reasoning & Planning",
        "course": "NLP",
        "lecture_num": "",
        "lecture_title": "NLP Recent Trends Part 1 Reasoning & Planning",
        "chunk_idx": 0,
        "total_chunks": 19,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:16397b31c981b01f4896a180b6afb60691dae1a3ddb8e74b654627d26a186523"
      },
      "token_estimate": 1051,
      "char_count": 1970
    },
    {
      "id": "transcript_nlp_nlp_recent_trends_part_1_reaso_c001_704f7f",
      "content": "[NLP] NLP Recent Trends Part 1 Reasoning & Planning\n\n다. 아마도 이전 강의에서 아마도 여러분들은 이미 퓨샤주시라든가 원샷으로 이러한 LNN들을 인퍼런스 하는 것 자체는 좀 배웠을 겁니다. 그래서 이렇게 저희가 이것을 예시를 하나 줘 가지고 아 이런 형태로 답변을 해라 같은 형태로 저희가 이 채집피티한테 한번 제공을 해보도록 하겠습니다. 그래서 저희는 답은 11개 해가지고 이렇게 답을 준 상태이죠. 자 그다음에 이제 실제로 물어보고 싶은 것을 하나 물어보도록 합시다. 그래서 식당에 사과가 232개가 있고 어 점심을 위해서 197개를 썼고 37개를 추가로 구매했어 그럼 사과가 몇 개 남았니? 그래서 이렇게 해가지고 그 답을 생성하게 된다면 답이 어 이것이 틀리게 돼요 어 이거 같은 경우에는 어 좀 옛날 모델이라서 그런 거 아니냐 라고 생각이 들 수 있는데 실제로 이것이 돌아가는 것을 좀 보여주도록 하겠습니다. 네 제가 방금 전에 보여드렸던 실제 그 사이트인데요 어 아마 이 사이트는 아마도 그 오픈 AI에서 제공하는 플레이 그라운드라는 그 프레임워크인데 어 이거는 아마도 여러분들이 좀 제대로 이 챗지피티 관련 애플리케이션 만든다든가 그런 경우에는 꽤 유용하게 사용할 수 있는 그러한 플랫폼이다라고 생각하시면 좋을 것 같습니다. 그래서 여러분들이 실제로 XGPT라든가 그런 것은 결국에는 이전 학습에서는 다 cos 랭귀지 모델링 결국에는 다음 단어를 예측하는 모델이다 라고 배웠을 텐데 실제로 여러분들이 실제로 활용하신 챗gpt는 뭔가 채팅 형태가 되게 많았죠 하지만 저희가 이것을 실제로 그 다음 단어를 예측하는 컴플렉션 모델로서 실제로 테스트해 볼 수 있는 공간도 존재합니다. 그래서 지금 보시면 여러분들이 이렇게 지피티 3.5를 모델을 골랐고요. 어 템포처라든가 뭔가 맥시멈 랭스 같은 뭔가 생성 관련 파라 하이퍼 파라미터가 여기 들어가 있다는 것을 확인해 볼 수가 있습니다. 그 외에도 뭐 타피라든가 프리퀀시 패널티 해가지고 같은 단어가 덜 나오게 하는 그러한 각종 하이퍼 파라미터들을 조절하면서 실제로 생성 관련 뭔가 그 응용 프로그램 만들 때 이걸로 뭔가 프롬프트로 테스트하는 뭐 그러한 용도로 뭔가 많이 쌓인 많이 사용하는 그러한 사이트다라고 생각하시면 좋을 것 같네요. 그래서 똑같은 저희가 질문을 이번에는 0으로 준 겁니다. 지금 내용을 보시면 지금 보시면 로저가 우리가 5개의 페니스 공을 가지고 있고 어 두 개의 테니스 우리가 두 캔을 샀으며 각 캔에는 3개의 공이 들었다. 그렇다면 이제 테니스 공 몇 개 남았냐 했을 때 11개 주고요. 질문이 좀 다르긴 한데 비슷합니다. 325개를 우리가 325개의 사과를 들고 있고 우리가 점심으로 23개를 주고 그리고 저녁으로 37개를 쓴다 매일 그렇다면 3일 뒤에 몇 개 남았는가? 자 이거 답 같은 경우에는 어떻게 될까요? 저희가 매일 점심 23개 저녁 37개니까 하루에 60개를 쓸 거고 3일 동안 180개를 쓸 겁니다. 그래서 180개니까 325 빼기 180으로 한다면 당연히 145가 나오는 것이 정상이겠죠. 하지만 저희가 이것을 컴플리션 해가지고 서브잇을 눌러보면 답이 201 애플 해가지고 완전 틀린 답이 나왔다는 것을 확인해 볼 수가 있습니다. 이처럼 완전히 그 챗지피티가 완전히 틀린 답을 뱉는 것을 확인해 볼 수 있는 건데요. 사실 가만히 생각하면 당연합니다. 왜냐하면 챗츠 PD도 결국에는 다음 단어를 맞추는 모델이기 때문입니다. 이건 마치 여러분들께 이런 질문을 드리는 것과 동일합니다. 여러분들이 사고를 전혀 하지 않고 저희 질문에 대해서 답변하는 겁니다. 제가 어제 신발 한 켤레를 샀는데 그게 3만 9천 원이었고 10% 할인이 붙었어가지고 좀 싸게 샀습니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "NLP Recent Trends Part 1 Reasoning & Planning.json",
        "lecture_name": "NLP Recent Trends Part 1 Reasoning & Planning",
        "course": "NLP",
        "lecture_num": "",
        "lecture_title": "NLP Recent Trends Part 1 Reasoning & Planning",
        "chunk_idx": 1,
        "total_chunks": 19,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:16397b31c981b01f4896a180b6afb60691dae1a3ddb8e74b654627d26a186523"
      },
      "token_estimate": 972,
      "char_count": 1843
    },
    {
      "id": "transcript_nlp_nlp_recent_trends_part_1_reaso_c002_f34e1a",
      "content": "[NLP] NLP Recent Trends Part 1 Reasoning & Planning\n\n다. 이처럼 완전히 그 챗지피티가 완전히 틀린 답을 뱉는 것을 확인해 볼 수 있는 건데요. 사실 가만히 생각하면 당연합니다. 왜냐하면 챗츠 PD도 결국에는 다음 단어를 맞추는 모델이기 때문입니다. 이건 마치 여러분들께 이런 질문을 드리는 것과 동일합니다. 여러분들이 사고를 전혀 하지 않고 저희 질문에 대해서 답변하는 겁니다. 제가 어제 신발 한 켤레를 샀는데 그게 3만 9천 원이었고 10% 할인이 붙었어가지고 좀 싸게 샀습니다. 하지만 뭔가 그 신발에 뭔가 실밥이 풀어진 걸 확인해 가지고 환불을 한 다음에 그 남은 값으로 6천 원짜리 아이스크림 샀을 때 남은 금액이 얼마인가 이러한 되게 아주 길고 복잡한 질문을 받았을 때 여러분들이 이것들이 아무 생각 없이 바로 그 다음으로 답을 말하라라고 한다면 여러분들이 그냥 적당하게 흘려 듣다가 그냥 가장 그럴듯한 숫자를 하나 받게 될 거예요. 근데 그것이 실제로 정답이냐라고 한다면 좀 별개의 문제겠죠. 틀릴 확률도 되게 높고요. 따라서 이러한 사고가 사고라는 것이 전혀 이 챗지피티에는 들어가 있지 않기 때문에 단순히 가장 많이 나올 만한 다음 단어를 그을 통계적으로 혹은 뭔가 모델링적으로 그냥 예측한 거기 때문에 결국에는 바로 다음 단어 이 98이라는 숫자가 나오게 되는 것은 사실 이것 자체가 값을 생각해서 나왔다기보다 그냥 통계적으로 그 단어가 나올 확률이 높았기 때문에 라고 생각하시는 것이 좋을 것 같습니다. 자 그럼 이런 생각이 들 겁니다. 어 그럼 챗치피티는 사고를 아예 할 수 없는 것일까? 챗지피티는 그렇다면 아예 멍청한 걸까 이런 수학 계산을 할 수 없는 걸까라는 생각이 들 겁니다. 하지만 저희가 이것을 프롬프트 엔지니어링을 통해 가지고 저희가 엘에이 혹은 뭐 챗지피티라든가 그런 친구들이 사고를 하게 만들 수가 있습니다. 그래서 결국에는 LLM 자체는 사고하는 능력이 없고요. LLM도 결국에는 오토 리그레시브 모델 다음 단어를 낮추는 모델이기 때문에 뭔가 출력했다면 이것은 뭐 다음 값을 계산하고 생각해서 출력하는 것이 아니고 72가 가장 다음 단어로 가장 그럴 듯했다라는 것을 당정에서 여기서도 확인해 볼 수가 있죠. 그래 가지고 이제는 LNM이 생각을 하는 것을 뭔가 모사하고 그리고 생각하는 과정들을 함으로써 뭔가 더 정답에 대한 정답률을 좀 더 올릴 수 있는 그러한 방법론에 대해서 소개해 드리도록 하겠습니다. 그래서 첫 번째로 제가 얘기할 내용은 차근차근 생각해 보는 이야기 이걸 영어로 하면 LST 스텝바이 스텝인데요 어 이게 되게 유명한 문장이라서 NLP 쪽에서는 이것도 나중에 한번 얘기해 보면 좋을 것 같습니다. LLM이 어떻게 하면 사고를 저희가 모사할 수 있을까요? 이걸 사과하는 못 사는 방법은 저희가 가장 쉬운 거는 그냥 사고하는 과정 자체를 저희가 한번 프롬프터에 넣어보면 어떨까라는 생각이 좀 들어보실 겁니다. 이런 식으로 넣어준 겁니다. 방금 전에 봤던 그 예시 그대로입니다. 지금 우리 로저가 테니스 공 5개를 사고 그리고 저희가 캔이 2개 있을 때 캔 안에 3개씩 들어 있고 했던 그 예시가 그대로 들어 있다는 것을 확인해 볼 수 있죠. 그래서 이것을 우리가 일반적으로 얘기하는 스탠다드 프롬프팅 혹은 뭐 나이브 프롬프팅이라고 얘기를 해보도록 합시다. 그래서 실제로 답을 보게 된다면 저희가 27개 나와가지고 이게 완전 답이 틀렸다는 것을 확인해 볼 수가 있죠. 그래서 저희가 방금 전에 말했던 것처럼 이 사고하는 과정을 한번 묘사해 보자 하는 것이 이 체인 오브 소트 한국어로는 사고 연쇄적 사고 뭐 그렇게 불렀던 걸로 기억합니다. 그래서 교육 프럼프팅을 어떻게 쓰냐 간단합니다. 저희가 이러한 예시를 줄 때 로저가 테니스 공을 산 이야기를 했을 때 이것을 푸는 과정 자체를 프롬프트에서 동시에 주는 것이죠. 그래서 원래는 바로 더 앤서이즈 11이라고 줬었는데 저희가 로저가 5개의 공을 들고 있었고 어 테니스공 3개가 든 두 캔은 우리가 6볼이 들어있",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "NLP Recent Trends Part 1 Reasoning & Planning.json",
        "lecture_name": "NLP Recent Trends Part 1 Reasoning & Planning",
        "course": "NLP",
        "lecture_num": "",
        "lecture_title": "NLP Recent Trends Part 1 Reasoning & Planning",
        "chunk_idx": 2,
        "total_chunks": 19,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:16397b31c981b01f4896a180b6afb60691dae1a3ddb8e74b654627d26a186523"
      },
      "token_estimate": 1063,
      "char_count": 1992
    },
    {
      "id": "transcript_nlp_nlp_recent_trends_part_1_reaso_c003_1eb715",
      "content": "[NLP] NLP Recent Trends Part 1 Reasoning & Planning\n\n다. 그래서 교육 프럼프팅을 어떻게 쓰냐 간단합니다. 저희가 이러한 예시를 줄 때 로저가 테니스 공을 산 이야기를 했을 때 이것을 푸는 과정 자체를 프롬프트에서 동시에 주는 것이죠. 그래서 원래는 바로 더 앤서이즈 11이라고 줬었는데 저희가 로저가 5개의 공을 들고 있었고 어 테니스공 3개가 든 두 캔은 우리가 6볼이 들어있다. 따라서 5 플러스 6은 11이다라는 이러한 우리가 일반적으로 말로 풀어 쓰는 거죠. 이러한 사고 과정을 프롬프트로 주고 저희가 이제 이러한 예시를 통해 가지고 LLM도 역시 사고를 할 수 있게끔 하는 것이 목표입니다. 그래서 똑같은 질문을 준 겁니다. 해서 저희가 23개의 카페테리아가 23개의 애플을 주고 있고 어 20개를 런치로 썼으며 우리가 6개를 더 샀다 이런 질문이 들어가 있다는 것을 확인해 볼 수 있죠. 근데 이제 좀 차이점은 스탠다드 프롬프팅에서는 결국에는 이렇게 바로 답이 나오는 것이 좀 더 모델 입장에서 되게 그럴 듯했기 때문에 바로 답이 나왔지만 체인 오브 서트에서는 예시에서 본 것처럼 뭔가 사고의 흐름을 적는 것이 좀 더 모델 입장에서는 편안하다고 느낄 수가 있기 때문에 당연히 왜냐하면 예시에 있었으니까요. 사고의 흐름을 그것이 맞냐 안 맞냐는 둘째 치고서 뭔가 하나씩 하나씩 뱉기 시작할 겁니다. 그런데 이러한 사고 흐름 자체는 대개 단순한 리스닝이 이루어져 있습니다. 훨씬 이 어려운 조금 더 어려운 복합적 리즈닝보다는 여러분들이 하나하나 단계를 밟아서 생각하는 것처럼 되게 간단한 스텝들을 밟아 가지고 이것들이 결국에는 복잡한 문제를 풀게 되는 과정인 거죠. 그래서 실제로 모델은 이 사고의 흐름을 묘사하기 위해서 뭔가 간단한 스텝들을 밟기 시작합니다. 그래서 카페테리아는 23개를 가지고 있었고 그리고 20개를 우리가 점심을 위해 사용하였고 그래서 이제 3개가 남았고 6개를 다 썼으니까 답은 6 36 3 플러스 6 해서 구야라고 이렇게 어 사고의 흐름을 모사하다 보니까 자기 자신의 논리를 쌓아나가다 보니까 결국에는 이 그 생성된 논리에 의해서 좀 더 정답률을 올리게 되고 결국에는 원래 되게 복잡했던 문제도 이렇게 풀 수 있다는 것을 확인할 수가 있습니다. 그래서 실제로 이것이 작동되는 모습을 좀 보여주도록 하겠습니다. 지금 보시면 방금 전에 봤던 예시랑 동일하게 들어가 있습니다. 그래서 로저가 테니스 공사하는 이야기가 여기 적혀 있고요. 더 앤서이지 11 에어 값도 똑같죠. 그리고 저희가 들어가는 질문도 동일하게 들어가 있다는 것을 확인해 볼 수 있습니다. 그래서 사과를 300개 사 가지고 점심 저녁에 동안 3일 동안 먹는 이야기가 적혀 있다는 것을 확인해 볼 수 있죠. 단 하나의 차이점이 무엇이냐 한다면 여기 이 사고의 흐름 또 로저가 우리가 5개를 샀고 2 곱하기 3은 6개니까 따라서 우리가 로저가 들고 있는 테니스 공은 11개다라는 이러한 간단한 스텝들을 밟아 가지고 이런 복잡한 문제를 푸는 리스닝 스텝이 들어갔다는 것을 확인해 볼 수가 있습니다. 그래서 방금 전에 이러한 사고 흐름이 예시로 들어가 있고 그래서 이 여기서 저희가 서브 빗스 눌러가지고 실제로 생성 결과물을 보게 된다면 저희가 실제로 이제 한 루가 지나면 이제 60개의 애플이 소모됐으니까 665개가 남았고 이틀 뒤에는 또 60개가 소모됐으니까 205개 그리고 3일 뒤에는 60개가 소모됐으니까 145개다. 그래서 더 엔서이즈 145 해가지고 이러한 결과값을 정확하게 풀어냈다는 것을 확실히 확인해 볼 수가 있습니다. 네 이런 사고 흐름을 넣는 것은 단순히 산수 문제뿐만 아니고 되게 다양한 과제에 대해서도 이것은 이러한 체인업소트 연쇄적 사고를 적용해 볼 수가 있는데요. 실제로 이 체인 오소트 논문 같은 경우에는 이 체인 오소트가 되게 잘 작동하는 3개의 테스크에 대해서 얘기를 합니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "NLP Recent Trends Part 1 Reasoning & Planning.json",
        "lecture_name": "NLP Recent Trends Part 1 Reasoning & Planning",
        "course": "NLP",
        "lecture_num": "",
        "lecture_title": "NLP Recent Trends Part 1 Reasoning & Planning",
        "chunk_idx": 3,
        "total_chunks": 19,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:16397b31c981b01f4896a180b6afb60691dae1a3ddb8e74b654627d26a186523"
      },
      "token_estimate": 1020,
      "char_count": 1923
    },
    {
      "id": "transcript_nlp_nlp_recent_trends_part_1_reaso_c004_2f7689",
      "content": "[NLP] NLP Recent Trends Part 1 Reasoning & Planning\n\n다. 그래서 더 엔서이즈 145 해가지고 이러한 결과값을 정확하게 풀어냈다는 것을 확실히 확인해 볼 수가 있습니다. 네 이런 사고 흐름을 넣는 것은 단순히 산수 문제뿐만 아니고 되게 다양한 과제에 대해서도 이것은 이러한 체인업소트 연쇄적 사고를 적용해 볼 수가 있는데요. 실제로 이 체인 오소트 논문 같은 경우에는 이 체인 오소트가 되게 잘 작동하는 3개의 테스크에 대해서 얘기를 합니다. 첫 번째가 이 산수연산 방금 전에 봤던 뭔가 테니스 공을 사고 그러한 간단한 사고 연산부터 되게 복잡한 산수 연산까지 하는 그러한 리즈닝 사고력이 필요한 문제부터 이러한 커먼센스 리즈닝 해서 상식적 추론이라고 하는데 이거 같은 경우에는 사실 여러분들이 챗gpt랑 대화 하다 보면 할루시네이션이라고 하든가 뭐 그러한 환각 현상들 그러니까 어 완전한 헛소리를 많이 뱉는 것을 확인해 볼 수가 있었을 겁니다. 그래서 LLM 자체가 사실 그렇게 사고가 깊지 않다 사고가 깊지 않다 보니까 뭔가 상식 자체가 결여된 모습을 많이 보이는데요. 이러한 상식적 추론 그러니까 상식적인 질문을 했을 때 지금 우리가 만약 배가 이러한 물에 빠지는가 그러니까 배가 물에 뜨는지 안 뜨는지 이러한 상식을 물어봤을 때 단순히 이것을 대답하는 것보다 이렇게 체인업소트를 생성해가지고 넣어주게 된다면 저희가 체인 오브 소프트를 통해 가지고 이 상식적인 문제들도 되게 정답률이 오른다라는 것을 확인합니다. 그리고 챗치피티가 이러한 체인 오브 소프트에서 큰 정확도 향상을 볼 수 있는 것이 이 기호 추론 혹은 뭐 심볼링 리즈니 쪽인데 이거 같은 경우에는 어 설명을 하자면 조금 어려울 수 있는데 예를 들어 어 이런 문제 봅시다. 어 이 레이디 가가에서의 라스트 레더 그러니까 마지막 글자를 합치는 그러한 해스크를 줬다는 것을 확인해 볼 수 있습니다. 그래서 실제로는 간단하죠. 실제로는 레이디에서 와를 붙이고 가가에서 a를 붙이니까 야가 나오면 되는 거 아니냐라고 생각하면 될 겁니다. 그래서 저희 인간 입장에서는 되게 쉬운 문제이지만 이게 사실 이게 모델 입장에서는 그렇게 이게 쉬운 문제가 아닙니다. 그 이유에 대해서 말씀을 드리자면 엘앤엠도 결국에는 랭귀지 모델링이다 보니까 토크라이징 하는 과정이 있을 거고 결국에는 이것이 토큰화 돼 가지고 숫자로 변환되는 과정이 있을 건데 문제는 무엇이냐 이 레이디라는 것이 하나의 토큰 예를 들어 뭐 90번 토큰으로 바뀌고 가가라는 것도 뭔가 다른 토큰으로 바뀔 겁니다. 예를 들어 130번 토큰 해가지고 바뀔 거고 문제는 이제 야라는 토큰도 완전 다르겠죠. 그래서 이게 152번 뭐 이렇게 숫자가 나왔다고 합시다. 그렇다면 실제로 이 LLM이 풀어야 되는 문제는 아 90번 90번의 마지막 글자하고 102 30번의 마지막 글자를 뽑아 가지고 그것을 합쳐 가지고 152번이라는 숫자를 뱉어라라는 테스크가 되는데요. 이것 자체가 사실 이 90번이라는 것은 이 레이디라는 뭔가 어 레이디에서 와라는 되게 심볼릭한 문제 결국에는 그 이것이 레이디라는 글자하고 90번이라는 숫자가 연관 관계가 그렇게 많지가 않기 때문에 이러한 그 뭔가 심볼릭한 리즈닝이 필요한 것도 되게 에엠에게 아주 어려운 문제 중 하나입니다. 그래서 이러한 체인업소트를 적용해 가지고 저희가 심볼링 문제를 풀게 된다면 이 체인업소트 논문에서 밝힌 바에 따르면 되게 이러한 심볼링 문제도 되게 잘 풀 수 있다는 것을 확인해 볼 수가 있습니다. 그래서 실제로 저희가 생각해 볼 수 있는 베이스 라인으로는 뭔가 파인 튜닝 하는 것도 생각해 볼 수 있겠죠. 저희가 이런 질문들이 있을 때 이것 자체를 LLM에다 직접 넣어가지고 되게 데이터셋을 많이 써가지고 파인튜닝 하는 방법론이 하나 있을 거고요. 혹은 프롬프트 스탠다드 프롬프팅 하는 것도 생각해 볼 수가 있을 겁니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "NLP Recent Trends Part 1 Reasoning & Planning.json",
        "lecture_name": "NLP Recent Trends Part 1 Reasoning & Planning",
        "course": "NLP",
        "lecture_num": "",
        "lecture_title": "NLP Recent Trends Part 1 Reasoning & Planning",
        "chunk_idx": 4,
        "total_chunks": 19,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:16397b31c981b01f4896a180b6afb60691dae1a3ddb8e74b654627d26a186523"
      },
      "token_estimate": 1027,
      "char_count": 1916
    },
    {
      "id": "transcript_nlp_nlp_recent_trends_part_1_reaso_c005_5a7cac",
      "content": "[NLP] NLP Recent Trends Part 1 Reasoning & Planning\n\n다. 그래서 이러한 체인업소트를 적용해 가지고 저희가 심볼링 문제를 풀게 된다면 이 체인업소트 논문에서 밝힌 바에 따르면 되게 이러한 심볼링 문제도 되게 잘 풀 수 있다는 것을 확인해 볼 수가 있습니다. 그래서 실제로 저희가 생각해 볼 수 있는 베이스 라인으로는 뭔가 파인 튜닝 하는 것도 생각해 볼 수 있겠죠. 저희가 이런 질문들이 있을 때 이것 자체를 LLM에다 직접 넣어가지고 되게 데이터셋을 많이 써가지고 파인튜닝 하는 방법론이 하나 있을 거고요. 혹은 프롬프트 스탠다드 프롬프팅 하는 것도 생각해 볼 수가 있을 겁니다. 아니면 뭔가 LLM을 쓰지 않고 뭔가 프라이어 베스트 프라이어 베스트라는 것이 뭔가 고전적인 방법으로든 뭔가 LST이든 뭔가 되게 이 테스크만을 위해서 디자인된 그러한 모델들이 있을 때 보시면 알겠지만 이 파인 튜닝 모델 그리고 기존에 있던 슈퍼바이저드 모델 그리고 스탠다드 프롬포팅보다 이 체인 오브 소트 프롬프팅 해 가지고 따로 저희가 파인튜닝 하지 않고 단순히 이런 사고 과정을 넣어 준 것만으로도 기존에 있던 시크바이저 모델보다도 더 좋은 성능 그리고 기존에 이 스탠다드 프롬프팅으로는 거의 못 풀었던 문제를 아주 높은 정확도로 풀 수 있다는 것을 확인해 볼 수가 있습니다. 자 이 cot 관련해서는 조금 주의할 점 혹은 저희가 확인해 볼 점인데요. 우선 첫 번째로 cot 같은 경우에는 자연어 형태일 때 가장 효과적으로 작동합니다. 그럴 수밖에 없는 게 이 LLM 자체가 이 자연어 기반으로 많이 사전 학습되었다 보니까 저희가 뭔가 수식으로 푸는 것보다는 직접 말로 설명하면서 푸는 것이 좀 더 엘에게 친숙한 형태겠죠. 따라서 뭔가 식만 적거나 여기 보시면 이콥션 원리 해 가지고 5 더하기 2 곱하기 3은 11 이런 식으로 식만 적거나 혹은 변수 계산만 사과는 사과는 5 어 뭐 이런 식으로 변수만 적은 경우에는 거의 효과가 그렇게 많지는 않았다라고 보고를 합니다. 그리고 또 확인해 볼 만한 점은 당연히 저희가 결국에는 이 체인 오브 소프트라는 것은 저희가 앞서 앞쪽에서 이 리스닝 스텝을 차근차근 밟고 나아가다가 결국에는 복잡한 문제를 하나 풀어 풀어내는 그런 과정이기 때문에 복잡한 문제를 먼저 답을 뱉고 나서 리즈닝 스텝으로 하는 것은 효과가 없습니다. 그래서 결국엔 이것도 오토 리그래식 모델 다음 단어를 맞추는 모델이기 때문에 리즈닝 엔서 다음에 리즈닝 하는 것은 당연히 효과를 볼 수가 없겠죠. 실제로 성과가 거의 안 나타난다는 것을 확인해 볼 수가 있습니다. 그리고 이 체인 오브 서트를 하게 된다면 다른 것들은 거의 효과가 없는데 이 체인업소트를 통해서 이렇게 성확도가 많이 올라갔다라는 것을 확인해 볼 수가 있죠. 참고로 데이터셋은 gsm8k가 이것이 앞서 말했던 산수 산수 연산 데이터셋이라고 생각하면 좋을 것 같고요. 이 람다나 팜 같은 경우에는 엘엠이라고 생각하시면 좋을 것 같습니다. 저게 람다하고 팜 자체 팜이 아마도 구글에서 나온 그 엘엠으로 알고 있네요. 자 그리고 하나 중요한 점이 있는데요. 체인 오소트는 이멀전트 어빌리티입니다. 이멀전트 어빌리티는 아마도 앞쪽 강의에서 설명이 됐을 수도 있는데요. 이멀전트 어빌리티가 뭐냐 결국에는 큰 모델 그러니까 gpt2라든가 그런 데서 나타나지 않고 라지 랭귀지 모델에서 모델이 커짐으로써 갑자기 나타나는 능력을 이머전트 어빌리티라고 부릅니다. 그래서 이 cot 그러한 이머전트 어빌리티가 몇 가지가 있는데요. dapp cot가 그러니까 이 체인 오브 서트 자체도 아주 유명한 이머전트 어빌리티의 예제 중 하나입니다. 그래서 실제로 지금 보시면 이 x축 부분이 이게 모델 크기 부분인데요. 모델 크기가 작은 부분에서는 거의 모든 모델에서 잘 작동이 안 되는 것을 확인해 볼 수 있지만 만약 저희가 모델 크기를 키우게 되면 어느 순간부터 이것을 잘 풀기 시작해 가지고 되게 기존에 있는 프라이어 슈퍼바이저 베스트에 따라 잡는 그러한 성능이 나온다는 것을 확인해 볼 수가 있습니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "NLP Recent Trends Part 1 Reasoning & Planning.json",
        "lecture_name": "NLP Recent Trends Part 1 Reasoning & Planning",
        "course": "NLP",
        "lecture_num": "",
        "lecture_title": "NLP Recent Trends Part 1 Reasoning & Planning",
        "chunk_idx": 5,
        "total_chunks": 19,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:16397b31c981b01f4896a180b6afb60691dae1a3ddb8e74b654627d26a186523"
      },
      "token_estimate": 1071,
      "char_count": 2006
    },
    {
      "id": "transcript_nlp_nlp_recent_trends_part_1_reaso_c006_02245e",
      "content": "[NLP] NLP Recent Trends Part 1 Reasoning & Planning\n\n다. 그래서 이 cot 그러한 이머전트 어빌리티가 몇 가지가 있는데요. dapp cot가 그러니까 이 체인 오브 서트 자체도 아주 유명한 이머전트 어빌리티의 예제 중 하나입니다. 그래서 실제로 지금 보시면 이 x축 부분이 이게 모델 크기 부분인데요. 모델 크기가 작은 부분에서는 거의 모든 모델에서 잘 작동이 안 되는 것을 확인해 볼 수 있지만 만약 저희가 모델 크기를 키우게 되면 어느 순간부터 이것을 잘 풀기 시작해 가지고 되게 기존에 있는 프라이어 슈퍼바이저 베스트에 따라 잡는 그러한 성능이 나온다는 것을 확인해 볼 수가 있습니다. 또 하나 더 확인해 볼 만한 점은 이 리스닝 자체가 이러한 사고 능력 자체가 코드 데이터에 대해서 사전 학습된 경우에만 작동하는 게 아니냐라는 보고도 존재합니다. 저희가 실제로 뭔가 사전 학습할 때 뭔가 단순히 자연어만 쓰지 않고 코드 데이터 해가지고 기타에 있는 덤프를 쓴다든가 그런 식으로 해가지고 사전 학습을 하는 편인데요. 하지만 지피티3 같은 옛날 l은 같은 경우에는 사실 코드 데이터를 활용하지 않고 자연어만 활용해 가지고 사전 학습하는 경우가 되게 많았습니다. 하지만 그런 모델들과 그리고 우리가 현재 쓰고 있는 뭔가 코드 학습된 모델들과 비교했을 때 이 체인 오브 소트 성능 자체가 조금 차이가 나는 것 같다라는 얘기를 합니다. 이건 뭐 별개인 이야기이긴 한데 뭐 이거에 대해서 뭐 가설이라든가 뭐 알려진 정확하게 실험적으로 증명된 바는 없긴 한데요. 몇 가지 이야기하는 바에 따르면 뭔가 이 절차 지향적 프로그래밍이 그런 절차 지향적 코드들이 문제의 흐름을 풀어가는 데 도움이 되고 뭔가 객체 지향 프로그램이 문제를 구조화하는 데 도움이 되는 것 아니냐 뭐 이런 이야기가 있긴 하지만 지금은 아직 좀 더 이 관련해서는 아직은 이 NLP 업계에서 말이 많은 상태고요. 우선은 기본적으로 관찰된 것 자체는 이 리즈닝 자체가 코드 데이터에 대해서 사전 학습의 경우에 되게 잘 작동하는 것 같다라고 많이 알려져 있습니다. 네 앞서 봤던 체인 오브 소트 같은 경우에는 하지만 하나의 단점이 있는데요 어 그 단점 중 하나는 바로 이 예시가 하나는 필요하다는 단점이 존재합니다. 어 지금 보시면 알겠지만 결국에는 체인 오브 소프트에서 저희는 항상 이 예시 이 더 앤서이즈 혹은 이런 사고 흐름들을 하나씩 넣어줬다는 것을 확인해 볼 수가 있습니다. 그럴 수밖에 없는 것이 결국에는 저희가 이 사고의 흐름 모델이 사고의 흐름을 뱉게 하기 위해서는 결국에는 이 예시를 통해 가지고 모델이 네가 이제 이 예시 보였지 아 넌 이제 지금부터 사고의 흐름을 뱉어내야 돼 이런 식으로 저희가 데몬스트레이션을 줄 수 있었기 때문에 이것이 작동되는 거였죠. 하지만 저희는 일반적으로 이러한 사고 흐름 자체는 사실 되게 휴먼 그러니까 사람이 디자인을 하는 경우가 많고 되게 임의적인 경우도 많다 보니까 이런 것을 뭔가 만드는 것도 만들고 어떠한 그 예제를 주는가도 되게 중요한 문제가 되다 보니 이것을 뭔가 제로 샷으로 볼 수 없을까에 대한 당연히 고민이 나타나게 됩니다. 그래서 앞쪽에서 봤던 것처럼 이렇게 예시를 주지 않고 더 ansis 한 다음에 실제로 아웃풋을 보게 된다면 8 나오는 이러한 것을 der SA 롬프팅 이런 식으로 많이 얘기를 하는데요. 그래서 저희가 앞서 봤던 것처럼 결국에는 이 예시를 통해서 저희가 이 모델이 사고 흐름이 나오게 유도했기 때문에 그렇다면 이것을 예시 없이 어떻게 하면 체인 오브 ot를 유도할 수 있을까가 좀 중요한 문제가 되게 됩니다. 그래서 이걸 어떻게 하느냐를 얘기했던 것이 이 NLP에서 가장 유명한 논문 중 하나인 이 레스팅 스텝바이 스텝에 얘기를 했던 이 제로샷 씨오티 논문입니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "NLP Recent Trends Part 1 Reasoning & Planning.json",
        "lecture_name": "NLP Recent Trends Part 1 Reasoning & Planning",
        "course": "NLP",
        "lecture_num": "",
        "lecture_title": "NLP Recent Trends Part 1 Reasoning & Planning",
        "chunk_idx": 6,
        "total_chunks": 19,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:16397b31c981b01f4896a180b6afb60691dae1a3ddb8e74b654627d26a186523"
      },
      "token_estimate": 1001,
      "char_count": 1875
    },
    {
      "id": "transcript_nlp_nlp_recent_trends_part_1_reaso_c007_51d50a",
      "content": "[NLP] NLP Recent Trends Part 1 Reasoning & Planning\n\n다. 그래서 이걸 어떻게 하느냐를 얘기했던 것이 이 NLP에서 가장 유명한 논문 중 하나인 이 레스팅 스텝바이 스텝에 얘기를 했던 이 제로샷 씨오티 논문입니다. 그래서 제로샷 cot 같은 경우에는 어 저희가 모델이 결국에는 하고 싶은 것은 사고의 흐름을 모델이 생성하게 하는 거니까 아 그렇다면 뭔가 예시를 통해 가지고 이러한 것을 유도하지 말고 우리가 모델이 사고 흐름을 뱉지 않으면 참을 수 없는 그러한 프롬프트를 넣어 가지고 예시를 한번 이 사고 흐름을 만들게 하겠다라고 생각해 보시면 좋을 것 같아요. 어떻게 하냐면 간단합니다. 저희가 질문을 넣고 그리고 앤서 시작하기 전에 하나 묻고 얘기하는 겁니다. 레스팅 스텝 바이 스텝 차근차근 생각해 봅시다. 자 이다음부터 만약 모델이 생성하기 시작한다면 어떻게 될까요? 당연히 우선은 lestin 스텝 바이 스텝이라는 것은 뭔가 사전 학습 과정이라든가 그런 데이터에서 되게 뭔가 이 다음을 차근차근 얘기해 주는 그런 예시들이 되게 데이터들이 되게 많았을 거예요. 따라서 이 레스팅 스텝바이 스텝이라는 센텐스 이러한 문장 자체는 모델이 이 다음부터는 이제 뭔가 흐름을 차근차근 얘기하지 않고는 뭔가 참을 수 없는 그런 유도감을 만들 수가 있는 겁니다. 그래서 실제로 레스팅 스텝바이 스텝 이후에 이제 이것을 스텝바이 스텝으로 설명을 하는 것을 확인해 볼 수가 있습니다. 그래서 설명하고 나서 이제 이렇게 하게 된다면 뭔가 차근차근 밟다 보니까 결국에는 답을 만들 수가 있겠죠. 다만 이렇게 답을 생성한 것 자체는 저희가 앞쪽 예시에서는 항상 모든 답이 더 앤서 이즈 다음에 나왔기 때문에 저희가 뭔가 이 답을 추출하는 거 그러니까 모델이 생성한 더 앤서이즈 8 혹은 이 아웃풋에 나온 그 사고 흐름과 더 앤서 이즈 4 했을 때 더 앤서 이즈 다음에 나오는 센텐스를 저희가 뭔가 레클로 익스프레션이라든가 정규 표현식 사용해 가지고 뽑아내는 것이 가능했었습니다. 하지만 이 제로 샷 시오티 같은 경우에는 저희가 이렇게 사고 흐름을 만드는 과정에서 뭔가 이 답을 어떻게 뱉을지에 대해서 얘기를 안 했기 때문에 실제 답은 뭔가 이 사고 흐름 과정 속에 숨어 있을 수 있어요. 그렇다면 이 안에서 그냥 단순히 숫자만 뽑아내면 되는 거 아닌가 생각할 수 있는데 애초에 이 사고 흐름 과정 중에 되게 숫자도 많다 보니까 도대체 이 중에서 무엇이 정답인가에 대한 뭔가 그러한 문제도 발생할 수 있죠. 그래서 아 되게 뭔가 룰 베이스로 해야 되나 뭐 그런 생각이 들 수 있는데 어 생각보다 이거에 대한 해결 방안은 간단합니다. 무엇이냐 그냥 이 다음에 그래서 정답은이라는 센텐스를 다시 붙여주는 것이죠. 그래서 375야 그리고 이 생성이 끝나고 나서 이 뒤에다가 다시 우리가 이러한 프로포트를 더 붙여주는 겁니다. 따라서 정답은 하고 난 다음에 이 다음부터 생성하게 된다면 이것이 자동적으로 이 정답인 375 위에 있는 저희가 모델 자신이 만들었던 이 그 사고의 흐름하고 그리고 문제를 보고 결국에는 모델이 답을 마지막에 어 더 앤서이즈 375 해서 이런 식으로 제로샷으로 맞출 수 있다는 것을 얘기하는 것이 이 제로샷 시오티에서 제안하는 방법론입니다. 네 이 제로샷 씨오티 같은 경우에는 이 나이브 제로 샷 그러니까 단순히 이 씨오티를 쓰지 않고 그냥 바로 제로 샷을 한 프롬프트보다 훨씬 다양한 분야에서 우월한 정확도를 보입니다. 이 다양한 분야라는 것은 앞서 얘기했던 뭔가 산수 연산이라든가 상식적 추론 커먼센스 리스닝 혹은 뭐 심볼릭 리스닝 같은 거여서 되게 높은 성능을 보였다는 것을 확인해 볼 수가 있죠. 실제로 지금 보시면 이것이 왼쪽 같은 표가 그것을 나타내는 표인데요. 그래서 제로 샷이 이것이 나이브 그러니까 우리가 씨오티를 안 넣은 것 제로샷 씨오티가 레스팅 스텝바이 스텝으로 뽑아낸 그러한 프롬프트라고 생각하면 좋을 것 같습니다. 그래서 어 지금 이거는 성능 별로 차이가 안 나는 것 같은데요 라고 생각할 수가 있는데 이 싱글 eq 같은 경우에는 되게 쉬운 데이터 셋입니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "NLP Recent Trends Part 1 Reasoning & Planning.json",
        "lecture_name": "NLP Recent Trends Part 1 Reasoning & Planning",
        "course": "NLP",
        "lecture_num": "",
        "lecture_title": "NLP Recent Trends Part 1 Reasoning & Planning",
        "chunk_idx": 7,
        "total_chunks": 19,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:16397b31c981b01f4896a180b6afb60691dae1a3ddb8e74b654627d26a186523"
      },
      "token_estimate": 1087,
      "char_count": 2027
    },
    {
      "id": "transcript_nlp_nlp_recent_trends_part_1_reaso_c008_3fc51f",
      "content": "[NLP] NLP Recent Trends Part 1 Reasoning & Planning\n\n다. 그래서 어 지금 이거는 성능 별로 차이가 안 나는 것 같은데요 라고 생각할 수가 있는데 이 싱글 eq 같은 경우에는 되게 쉬운 데이터 셋입니다. 단순히 3 더하기 2 뭐 이런 걸 물어보는 데이터셋이라고 생각하시면 좋을 것 같아요. 비슷하게 애드 서브도 비슷한 데이터셋이라서 오히려 이런 것에서는 사실상 제로 샷이나 제로 s cot나 따로 사고가 필요 없기 때문에 성능이 거의 비슷비슷한 것을 확인해 볼 수가 있지만 뒤에서 뭔가 gsm8k라든가 뭔가 멀티아리스 이러한 뭔가 되게 복잡한 사고 추론이 필요한 것에서는 이 제로4 cot가 단순히 이렇게 레스팅 스테타이 스텝을 붙여가지고 사고의 흐름을 넣어주는 것만으로도 되게 높은 성적을 달성했다는 것을 확인해 볼 수가 있죠. 비슷하게 이 커먼센스에서도 성능이 향상되었다는 것을 확인해 볼 수 있고 뭔가 심볼릭 테스크에서도 이렇게 정확도가 제로 샵보다 이 제로샷 시티가 더 좋았다는 것을 확인해 볼 수가 있습니다. 그래서 뭔가 이러한 쉬운 문제보다는 이렇게 복잡한 문제에서 더욱 두각을 드러내고요. 어 유사 cot 이와 비교한다면 뷰s cot보다 성능이 조금 낮긴 합니다. 지금 보시면 알겠지만 지금 어 제로s cot 대신에 저희가 실제로 사람이 만든 이 사고 흐름을 넣어주는 것을 제로 필샷으로 사고 흐름 넣어 가지고 해볼 수가 있는데요. 그거에 비해서 성능 자체는 뭐 조금 떨어지긴 하나 중요한 것은 결국에는 제로 샷으로 예시를 요구하지 않았다는 점에서 되게 큰 장점이다라고 생각하시면 좋을 것 같습니다. 그렇다면 이것을 제로 샷으로 뭔가 우리가 사고 흐름을 여러 개 만든 다음에 이것 자체를 활용할 수가 있는데요. 그래서 제로 샷으로 레스팅 스텝 바이 스텝 레스 띵크 스텝 바이 스텝 바이 스텝 하고 나서 이 뒤에 사고 흐름이 되게 많이 나올 건데 이 사고 흐름 자체를 샘플링을 통해서 여러 개 생성한 다음에 저희가 다시 또 이것을 뷰자 시오티로도 활용할 수가 있을 겁니다. 이렇게 했을 때는 성능이 아주 크게 오른다는 것을 확인해 볼 수 있죠. 그래서 이렇게 하면 저희가 이 파인튜드 한 그러니까 엘엠 자체를 파인튜닝 한 것보다 우리가 이 사고 흐름을 엘엘엠이 따라갈 수 있게끔 묘사할 수 있게끔 하는 방법론이 훨씬 더 성능이 더 좋았다는 것을 확인해 볼 수가 있습니다. 네 그렇다면 당연히 드는 생각이 레스팅 스텝바이 스텝 말고 다른 프롬프트를 쓸 수 있는가라고 생각이 들 건데요. 당연히 이거에 관련해서도 당연히 저자들이 여러 가지 실험을 해봤습니다. 지금 보시면 알겠지만 이 리즈닝 익스트랙션 이 사고를 익스트랙션 하기 위한 프롬프트로 뭔가 레스팅 스텝바이 스텝이라든가 아니면 뭐 퍼스트 어 아니면 이것을 로지컬하게 생각해 보자 해서 다양하게 해봤는데 어 우선은 어떤 걸 쓰든 간에 뭔가 이렇게 인스럭티브 실제로 이 사고 흐름을 유도하는 프롬프트를 쓰게 된다면 이렇게 에큐러시가 올랐다는 것을 확인해 볼 수가 있고요. 반대로 어 뭔가 미스리딩하는 프롬프트 그러니까 생각하지만 그냥 느껴 혹은 뭔가 아바다카다브라 같은 아예 관련이 없는 프롬프트 줬을 때는 이렇게 성능이 그렇게 오르지 않았다는 것을 확인해 볼 수가 있습니다. 따라서 이렇게 의미 없거나 잘못된 지시를 제시할 경우에는 이 사고 흐름이 나오지 않게 되므로 이것이 효과가 없다는 것을 확인해 볼 수가 있죠. 그리고 당연하게도 씨오티 자체가 이멀전트 어빌리티이기 때문에 이 제로샷 시오티도 이멀전트 어빌리티입니다. 그래서 어 거의 작은 모델에서는 거의 작동이 안 된다라고 보는 것이 좋을 것 같고요. 모델이 커짐으로써 이것이 갑자기 성능이 정확도가 크게 올라가지고 기존 모델에서 작은 모델에서는 절대 안 나타나다가 이렇게 큰 모델에서 그 나타난 것을 확인해 볼 수가 있습니다. 따라서 씨오티는 작은 모델에서는 작동하지 않으며 큰 모델에서 나타나는 이모전트 어빌리티라는 것을 확인해 볼 수가 있죠. 자 이 리즈닝에서 또 많이 쓰이는 방법론 중 하나가 이 셀프 컨시스턴시입니다. 그래서 방금 전에 제가 말씀했던 거 기억나실 겁니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "NLP Recent Trends Part 1 Reasoning & Planning.json",
        "lecture_name": "NLP Recent Trends Part 1 Reasoning & Planning",
        "course": "NLP",
        "lecture_num": "",
        "lecture_title": "NLP Recent Trends Part 1 Reasoning & Planning",
        "chunk_idx": 8,
        "total_chunks": 19,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:16397b31c981b01f4896a180b6afb60691dae1a3ddb8e74b654627d26a186523"
      },
      "token_estimate": 1096,
      "char_count": 2037
    },
    {
      "id": "transcript_nlp_nlp_recent_trends_part_1_reaso_c009_e21a66",
      "content": "[NLP] NLP Recent Trends Part 1 Reasoning & Planning\n\n다. 그래서 어 거의 작은 모델에서는 거의 작동이 안 된다라고 보는 것이 좋을 것 같고요. 모델이 커짐으로써 이것이 갑자기 성능이 정확도가 크게 올라가지고 기존 모델에서 작은 모델에서는 절대 안 나타나다가 이렇게 큰 모델에서 그 나타난 것을 확인해 볼 수가 있습니다. 따라서 씨오티는 작은 모델에서는 작동하지 않으며 큰 모델에서 나타나는 이모전트 어빌리티라는 것을 확인해 볼 수가 있죠. 자 이 리즈닝에서 또 많이 쓰이는 방법론 중 하나가 이 셀프 컨시스턴시입니다. 그래서 방금 전에 제가 말씀했던 거 기억나실 겁니다. 이 제로샷에서 뭔가 제로 샷에서 뭔가 리즈닝들을 여러 개 뽑아내 가지고 이걸로 뷰샷을 쓴다고 얘기했었는데 그거와 조금 유사하다고 생각할 수도 있습니다. 자 이거 같은 경우에는 사실 이 저희가 만들었던 제럴 체인 오브 소트 프롬프틴 같은 경우에는 문제점이 하나 있는데 저희가 이 사고 흐름 자체를 저희가 그리디 디코딩 그러니까 뭔가 이렇게 알그맥스로 통하고 뽑아내게 된다면 사실상 어느 순간 이것이 만약 중간에 저희가 사고의 흐름이 틀렸다 그러니까 3 더하기 7 하고 나서 뭔가 중간에 7이 아니고 뭔가 6을 뱉어냈다 이런 경우에는 이 중간에 실수 한 번으로 이 뒤에 있는 사고 흐름이 전반적으로 다 틀려버리다 보니까 답이 완전히 틀려버리는 문제가 있습니다. 그래서 뭔가 이렇게 리즈닝 과정에서 만약 치명적인 실수가 발생한다면 추론 결과가 완전히 틀리는 경우가 발생하게 되죠. 하지만 문제는 그리드 디코딩을 통해 가지고 저희가 그냥 알그맥스로 뽑아냈기 때문에 이런 것을 생성 과정 중에서는 뭔가 해당 실수로 알아내기는 되게 어렵습니다. 그렇다면 이러한 실수가 발생하더라도 뭔가 이것을 보완할 수 있는 그러한 아이디어가 없을까라고 고민을 하게 되는데요 거기에 대해서 어느 정도 해결책을 제시한 것이 셀프 컨시스턴시라고 생각하시면 좋을 것 같습니다. 그래서 하는 방법은 간단합니다. 우리가 사고 흐름 자체를 하다가 좀 틀릴 수 있다면 단순히 사고 흐름을 여러 개 뽑은 다음에 메저리티보트 그냥 다수결 투표하면 되는 거 아니냐 그냥 일종의 앙상블 하면 되는 거 아니냐라고 생각해 볼 수가 있습니다. 그래서 실제로 체인 오브 서트 같은 경우에는 이렇게 사고 흐름 자체를 단 한 번만 생성해 가지고 중간에 틀리면 되게 치명적인 결과가 나올 수 있지만 이 셀프 컨시스턴시 같은 경우에는 이렇게 질문에서 랭귀지 모델에서 이 사고의 흐름을 생성해 낼 때 이렇게 어 그냥 템포처를 다양하게 템포처를 줘 가지고 그리고 샘플링 과정을 통해서 리즈닝을 여러 개를 뽑아냅니다. 그래서 어떤 것에서는 이러한 형태로 리스닝을 할 수가 있을 거고요. 어떤 리즈닝은 또 틀렸을 수도 있겠죠 하지만 이게 일반적으로 정말 모델이 잘 풀 수가 있다면 많은 경우에서 이것을 정답을 맞출 수가 있습니다. 따라서 이 그 답을 뽑아낸 다음에 이 답에 대해서 최종 답계만 집계를 해 가지고 가장 많이 나온 답을 답변으로 뱉는 겁니다. 그래서 일종의 뭔가의 앙상블 하는 방법이라고 생각하면 좋을 것 같네요. 그래서 이러한 패스 자체를 여러 개 생성한 다음에 가장 많이 나온 방향으로 가장 가장 많은 답안으로 최종 답안을 결정하겠다라는 방법론이라 생각하시면 좋을 것 같습니다. 따라서 이거 같은 경우에는 사실 단점은 사실 계산량이 많다 정도밖에 없고요. 대부분의 경우에는 이 셀프 컨시턴시를 활용하게 된다면 아주 이 리즈닝 과정에서의 뭔가 실수나 그런 것들을 보완할 수 있기 때문에 정확도가 크게 오릅니다. 그래서 다양한 모델 다양한 과제에서도 일반적으로 많이 쓰이는 방법론 중 하나이고요. 그래서 live cot보다 ol 하다는 것을 확인해 볼 수가 있습니다. 그래서 이것이 단순히 cot grided 코딩을 뽑은 cot 성능이고요. 그리고 이 밑에 있는 것이 셀프 컨시턴시 그를 사용했을 때 성능이라고 생각해 주시면 좋을 것 같습니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "NLP Recent Trends Part 1 Reasoning & Planning.json",
        "lecture_name": "NLP Recent Trends Part 1 Reasoning & Planning",
        "course": "NLP",
        "lecture_num": "",
        "lecture_title": "NLP Recent Trends Part 1 Reasoning & Planning",
        "chunk_idx": 9,
        "total_chunks": 19,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:16397b31c981b01f4896a180b6afb60691dae1a3ddb8e74b654627d26a186523"
      },
      "token_estimate": 1056,
      "char_count": 1959
    },
    {
      "id": "transcript_nlp_nlp_recent_trends_part_1_reaso_c010_deb8dd",
      "content": "[NLP] NLP Recent Trends Part 1 Reasoning & Planning\n\n다. 그래서 다양한 모델 다양한 과제에서도 일반적으로 많이 쓰이는 방법론 중 하나이고요. 그래서 live cot보다 ol 하다는 것을 확인해 볼 수가 있습니다. 그래서 이것이 단순히 cot grided 코딩을 뽑은 cot 성능이고요. 그리고 이 밑에 있는 것이 셀프 컨시턴시 그를 사용했을 때 성능이라고 생각해 주시면 좋을 것 같습니다. 그리고 여기 쪽은 그냥 다양한 엘엠들이고요. 이쪽은 테스크별로 정리됐다고 생각하면 좋을 것 같네요. 그래서 보시면 알겠지만 대부분의 경우에는 다 플러스가 찍혀 있다는 것을 확인해 볼 수 있고 마이너스가 찍힌 경우는 거의 없다는 것을 확인해 볼 수 있습니다. 그래서 실제로 저희가 뭐 이렇게 셀프 컨시턴시라 하면 거의 이 멀사리스매틱을 완전하게 푸는 것도 가능하고 따라서 어 우리가 이 셀프 컨시턴시를 활용하게 된다면 대부분의 경우에서는 이렇게 성능 이득을 좀 챙길 수가 있습니다. 그래서 어 많이 쓰이긴 하는데 다만 이것이 방금 전에 봤던 것처럼 결국에는 이 추론 경로를 n개 샘플링 하다 보니까 계산량에 한계가 있어 가지고 이것은 좀 보완하는 용도로 많이 쓰고 있습니다. 단순히 저희가 이 셀프 컨시스턴시를 활용하는 방법은 뭔가 빔 서치를 통해 가지고 뭔가 그 하는 것보다 그러니까 댐 서치를 활용하게 된다면 저희도 비슷하게 뭔가 리즈닝 패스를 여러 개 뽑을 수가 있을 거잖아요. 하지만 이렇게 뭔가 가장 좋은 리즈닝 패스들로 추론하는 것보다 샘플링을 통해 가지고 다양한 리스닝 패스를 추론할 때 더 좋은 성능을 보인다라고 이 논문에서 얘기를 합니다. 그래서 실제로 저희가 빔 서치 그냥 빔 서치했을 거랑 뭔가 셀프 컨터치를 빔 서치를 엮었을 때 그리고 샘플링을 통해 가지고 다양한 패스를 했을 때를 비교하게 된다면 이 빔 사이즈가 어 커짐으로 커짐으로써 이거 성능이 올라간다는 것을 확인해 볼 수가 있고요. 실제로 뭔가 리즈닝을 빔 서치하는 것보다 그냥 다양하게 패스들을 뽑아 가지고 이것을 기반으로 메이저리티 포트는 포팅하는 것이 더 좋았다라는 얘기를 합니다. 따라서 결국엔 다양성 자체가 되게 중요하다 보니까 이게 템포처 그러니까 템포 하트가 낮게 되면 되게 저희가 이 모델이 생성할 수 있는 다양성 자체가 되게 낮아지게 되잖아요. 그래서 낮은 템포처는 단순 다양성으로 이어지고 결국에는 좀 낮은 정확도로 이어지게 됩니다. 그래서 실제로 지금 보시면 셀프 컨시턴시를 활용하겠다 그러한 경우를 경향을 저희가 이 그 피겨를 통해서 확인해 볼 수가 있는데요. 이 티가 템포츠라고 생각하시면 좋을 것 같고 케가 탑 케라고 생각하시면 좋을 것 같네요. 그래서 지금 보시면 알겠지만 이 템포츠가 높아짐에 따라 0.3에서 0.7로 올라감에 따라 성능이 올라간다는 것을 확인해 볼 수가 있고요. 다만 이것이 성능이 그래도 한 20을 넘어 가지고 40을 넘어가게 되면 40개를 넘어가게 된다면 성능이 어느 정도 이것이 그 그 추렴하는 것을 확인해 볼 수가 있습니다. 우리가 이 그리드 리코딩 했을 때보다 물론 초반에 만약 샘플을 하나만 하는 경우에는 당연히 성능이 템퍼처가 높은 것이 더 성능이 안 좋지만 이게 만약 우리가 다양한 패스를 통해서 셀프 컨시턴시를 할 수 있다면 저희가 어 되게 좋은 성능을 얻을 수 있다는 것을 확인해 볼 수가 있습니다. 저희가 샘플 개수가 늘어날수록 성능이 올라지는 경향 자체는 모든 데이터 셋에서 확인을 볼 수가 있고요. 다만 이것 자체가 결국에는 어느 정도 수렴하는 수렴하긴 한다라는 것만 확인해 보시면 좋을 것 같습니다. 그래서 모델 크기가 클수록 그리디 디코딩과 격차가 커지고 그리고 샘플 개수가 많을수록 정확도가 사스하다가 수렴하게 됩니다. 네 이제부터는 이 앞서 봤던 체인 오서트랑은 조금 다르게 이제 어려운 문제를 작은 문제로 분해한 다음에 이것을 풀어보는 그러한 방법론에 대해서 소개해 보려고 합니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "NLP Recent Trends Part 1 Reasoning & Planning.json",
        "lecture_name": "NLP Recent Trends Part 1 Reasoning & Planning",
        "course": "NLP",
        "lecture_num": "",
        "lecture_title": "NLP Recent Trends Part 1 Reasoning & Planning",
        "chunk_idx": 10,
        "total_chunks": 19,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:16397b31c981b01f4896a180b6afb60691dae1a3ddb8e74b654627d26a186523"
      },
      "token_estimate": 1041,
      "char_count": 1941
    },
    {
      "id": "transcript_nlp_nlp_recent_trends_part_1_reaso_c011_b44527",
      "content": "[NLP] NLP Recent Trends Part 1 Reasoning & Planning\n\n다. 저희가 샘플 개수가 늘어날수록 성능이 올라지는 경향 자체는 모든 데이터 셋에서 확인을 볼 수가 있고요. 다만 이것 자체가 결국에는 어느 정도 수렴하는 수렴하긴 한다라는 것만 확인해 보시면 좋을 것 같습니다. 그래서 모델 크기가 클수록 그리디 디코딩과 격차가 커지고 그리고 샘플 개수가 많을수록 정확도가 사스하다가 수렴하게 됩니다. 네 이제부터는 이 앞서 봤던 체인 오서트랑은 조금 다르게 이제 어려운 문제를 작은 문제로 분해한 다음에 이것을 풀어보는 그러한 방법론에 대해서 소개해 보려고 합니다. 여러분들도 뭔가 되게 어려운 문제를 푼다면 이것을 아예 바닥부터 차근차근 생각하는 경우보다 뭔가 어려운 문제를 작은 문제들을 사전에 분할한 다음에 이것을 작은 문제를 풀어나가는 경우가 되게 많을 겁니다. 그래서 앞선 체인 오브 서트에서 이런 것을 이러한 과정을 모델의 파인튜닝 없이 학습 없이 단순히 프론팅만으로도 우리가 해냈으니까 아 이러한 어려운 문제를 작은 문제로 분해하는 것도 뭔가 프롬프트를 잘 짜는 것만으로도 가능하지 않을까라는 생각이 들 겁니다. 그래서 이거에 관련된 이야기를 조금 진행해 볼까 생각합니다. 어 이러한 방법론 그러니까 큰 문제를 작은 문제를 분리하는 대표적인 프롬프팅 방법론 중 하나가 이 리스트 머스트 방법론입니다. 그래서 결국에 하고 싶은 것은 되게 어려운 문제를 쉽고 작은 문제로 분리하고 싶은 것이 목적입니다. 네 이러한 예시를 보도록 하겠습니다. 그래서 에이미가 우리가 슬라이드에 탑으로 올라가는 데 4분이 걸리는데 1 분 내려오는 데 1분이 걸리고 15분 뒤에 슬라이드가 문을 닫아 그렇다면 우리가 에이미는 이제 몇 분 동안 몇 번을 탈 수 있을까에 대한 이러한 문제가 있다고 합시다. 그래서 체인 오브 서트 같은 경우에는 여기서 뭔가 이 사고의 흐름을 했다면 여기 이 리스트도 머스트 프로틴 같은 경우에는 이 문제를 풀기 위해서 풀어야 될 서브 문제를 만든다고 생각하면 좋을 것 같습니다. 그래서 그녀가 슬라이드를 몇 번 탈 수 있는지를 확인하기 위해서는 먼저 각 슬라이드를 타는 데 몇 분이 걸리는가를 측정해야 된다. 그러니까 결국에는 큰 문제를 풀기 위해서 작은 문제를 먼저 구체화를 하는 것이죠. 아 이거는 실제로 어떻게 하냐면 앞쪽에 그러한 예시가 있다라고 생각하면 좋을 것 같습니다. 즉 이것은 퓨샵 프롬포팅이라고 생각하면 좋을 것 같네요. 보세요. 앞쪽 이 뒤에 있는 다양한 예시들 앞에서 나왔던 제로 샷이라든가 제로 샷 시오티 제외하고 지금부터 얘기하는 것들은 다 뷰 샷이 있다라고 생각하시면 좋을 것 같습니다. 그래서 똑같이 이렇게 어려운 문제가 있고 저희가 이렇게 엔서에서 이제 뭔가 이렇게 문제를 푸는 것이 앞쪽에 예시로 주어져 있고 똑같이 이제 문제를 풀 수 있게끔 이렇게 저희가 샷을 넣어 가지고 푸는 것을 과정이 들어가 있다라고 기본적으로 생각하시면 좋을 것 같습니다. 그래서 어쨌든 이러한 과정을 통하게 된다면 뭔가 우리가 문제를 분해하는 것도 가능할 겁니다. 자 이제 문제를 분해했다면 이 분해한 문제들을 순서대로 풀어 가지고 되게 어려운 문제를 푸는 것이 저희의 목적이 될 겁니다. 그래서 이 스테이지 2에서는 결국에는 이 문제를 풀기 전에 우리가 분해하였던 이 질문을 넣어가지고 여기에 대한 해답을 구한 다음 그다음에 최종적으로 뭔가 우리가 실제로 궁금했던 되게 복잡한 질문을 넣음으로써 우리가 이 최종적으로 이 어려운 문제에 대한 답안을 풀 수 있다는 것이 이 리스트 모스트 프롬프팅이라고 생각하시면 좋을 것 같습니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "NLP Recent Trends Part 1 Reasoning & Planning.json",
        "lecture_name": "NLP Recent Trends Part 1 Reasoning & Planning",
        "course": "NLP",
        "lecture_num": "",
        "lecture_title": "NLP Recent Trends Part 1 Reasoning & Planning",
        "chunk_idx": 11,
        "total_chunks": 19,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:16397b31c981b01f4896a180b6afb60691dae1a3ddb8e74b654627d26a186523"
      },
      "token_estimate": 967,
      "char_count": 1783
    },
    {
      "id": "transcript_nlp_nlp_recent_trends_part_1_reaso_c012_0246d7",
      "content": "[NLP] NLP Recent Trends Part 1 Reasoning & Planning\n\n다. 자 이제 문제를 분해했다면 이 분해한 문제들을 순서대로 풀어 가지고 되게 어려운 문제를 푸는 것이 저희의 목적이 될 겁니다. 그래서 이 스테이지 2에서는 결국에는 이 문제를 풀기 전에 우리가 분해하였던 이 질문을 넣어가지고 여기에 대한 해답을 구한 다음 그다음에 최종적으로 뭔가 우리가 실제로 궁금했던 되게 복잡한 질문을 넣음으로써 우리가 이 최종적으로 이 어려운 문제에 대한 답안을 풀 수 있다는 것이 이 리스트 모스트 프롬프팅이라고 생각하시면 좋을 것 같습니다. 그래서 이 리스트 투 모스트 프롬프팅 같은 경우에는 이 체인 오브 소트보다 산수유 현상이나 뭐 기호 추론 과제에서 되게 우월한 정확도를 기록했고요. 그래서 지금 보시면 알겠지만 제로 샷을 넣었을 때 하고 스탠다드 프롬프팅으로 샷을 몇 개 넣었을 때 예시를 몇 개 넣었을 때 그리고 체인업소트를 했을 때 리스트 드 머스트를 했을 때 이렇게 비교를 하게 된다면 이 리스트 드 모스트 그러니까 큰 문제를 먼저 작은 문제를 분해하고 나서 작은 문제를 순차적으로 푸는 것 자체가 어 이 체인 오소트보다 더 좋았다는 것을 확인해 볼 수가 있습니다. 특히 지금 보시면 알겠지만 지에스엠8k 같은 경우에는 성능이 별로 안 오른 게 아닌가라는 생각이 좀 들 수가 있는데요. 이것이 계산이 필요한 단계가 많을수록 라이브 시오티보다 더 높은 정확도를 보여요. 그래서 실제로 저희가 gsm8키에 의해서 각 문제마다 이것이 뭔가 이 문제를 풀기 위한 뭔가 예측 예상되는 뭔가 그러한 스텝 개수가 있을 건데요. 그래서 전체로 보면 리스트 모스가 거의 한 2%밖에 차이 안 나지만 저희가 만약 스텝 수가 많아지는 문제 스텝수 단위로 해가지고 저희가 이것을 좀 더 분석하게 된다면 스텝 수가 작을 때는 체인 오브 소트가 그러니까 되게 간단한 문제는 체인 오소트가 자라다가 스텝 수가 많아질수록 이 간격이 벌어져 가지고 결국에는 리스트 버스트가 이긴다는 것을 확인해 볼 수가 있습니다. 즉 계산 단계가 더 많을수록 이 그 리스트 버스를 통해 가지고 문제를 쉬운 문제로 분해하고 나서 푸는 것이 더 좋았다라고 생각해 볼 수가 있죠. 그리고 무엇보다도 이 퓨샷 예시가 뭔가 단계 수가 달라진다든가 뭔가 예시와 달라져 가지고 나이브 씨오티보다 이것이 일반화를 조금 더 잘합니다. 즉 라이브 시오티 같은 경우에는 앞쪽에 줬던 씨오티 예제들에 대해서 되게 민감한 상태인데요. 그에 비해서 리스트 드 모스트 같은 경우에는 예시에서의 단계는 뭔가 3단계 밖에 없었는데 3단계 그러니까 샷 자체 데모스트레이션 자체가 뭔가 3단계로 이루어져 있었는데 이것을 갑자기 문제가 4단계가 필요한 질문을 한다든가 그런 경우에서도 표시 예시에서 좀 달라지더라도 일반화를 좀 더 라이브 세오트보다 잘한다는 것이 알려져 있습니다. 그래서 실제로 보시면 알겠지만 이것이 기호 추론에서 길이가 길어질수록 지금 좀 더 리스트 모스가 성능이 떨어지는 폭이 더 약하다는 것을 확인해 볼 수가 있는데요. 이것 자체가 왜냐하면 예시에서 이 길이가 긴 경우 이 기호 추론에서 아마도 이 문제 같은 경우에 라스트 레더 컨커네이션 해 가지고 문 단어들이 있을 때 아이 러브 유 있을 때 첫 번째 단어들을 합쳐라 즉 아이엘유 이런 식으로 만들어내는 그런 테스크였을 겁니다. 했을 때 길이가 길어진 예시 자체가 아마 데몬스트레이션에는 없었을 거예요. 근데 이런 경우에서도 체인 홈 소트가 일반화를 되게 잘하기 때문에 문제를 그냥 체인 홈 소트보다 리스트 머스트가 더 잘 풀었다라는 것을 확인해 볼 수가 있습니다. 그리고 이것은 당연히 체용 소프트랑 또 비슷한 얘기인데 결국에는 이것도 데이 코드 데이터에서 학습된 LLM에서 더 좋은 정확도를 보인다라고 알려져 있고요. 실제로 보시면 알겠지만 이 텍스트 다빈치 002 랑 코드 다빈치 002 00원 혹은 뭐 코드 다빈치 002 이런 거랑 비교했을 때 어 코드 다빈치가 이거 기본적으로 코드에 대해서 학습된 지피티3라고 생각하시면 좋을 것 같고요. 텍스트 다빈치는 자연어를 위주로 학습된 gpt3라고 생각하면 좋을 것 같습니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "NLP Recent Trends Part 1 Reasoning & Planning.json",
        "lecture_name": "NLP Recent Trends Part 1 Reasoning & Planning",
        "course": "NLP",
        "lecture_num": "",
        "lecture_title": "NLP Recent Trends Part 1 Reasoning & Planning",
        "chunk_idx": 12,
        "total_chunks": 19,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:16397b31c981b01f4896a180b6afb60691dae1a3ddb8e74b654627d26a186523"
      },
      "token_estimate": 1100,
      "char_count": 2046
    },
    {
      "id": "transcript_nlp_nlp_recent_trends_part_1_reaso_c013_4e5268",
      "content": "[NLP] NLP Recent Trends Part 1 Reasoning & Planning\n\n다. 그리고 이것은 당연히 체용 소프트랑 또 비슷한 얘기인데 결국에는 이것도 데이 코드 데이터에서 학습된 LLM에서 더 좋은 정확도를 보인다라고 알려져 있고요. 실제로 보시면 알겠지만 이 텍스트 다빈치 002 랑 코드 다빈치 002 00원 혹은 뭐 코드 다빈치 002 이런 거랑 비교했을 때 어 코드 다빈치가 이거 기본적으로 코드에 대해서 학습된 지피티3라고 생각하시면 좋을 것 같고요. 텍스트 다빈치는 자연어를 위주로 학습된 gpt3라고 생각하면 좋을 것 같습니다. 했을 때 비교하면 확실하게 리스트 드 버스트가 뭔가 이 코드 쪽에서 학습된 모델이 좀 더 더 잘하는 것 같다 이 논문에서 얘기를 합니다. 리스트 투 모스트를 통해 가지고 저희가 이 엘엔 자체가 이 어려운 문제를 작은 문제로 분해할 수 있는 능력이 있다는 것은 저희가 이제 방금 전에 확인하였습니다. 그렇다면 이런 생각이 들 겁니다. 아 우리가 어 문제 같은 경우에는 작은 문제를 애초에 LLM이 정의를 했었지만 그러지 말고 우리가 뭔가 작은 문제를 사전에 정의하고 이제 이 작은 문제들을 알아서 이 모델이 조합해 가지고 적절한 순간에 이것을 호출하는 형태로 만들 수 있지 않을까 즉 원래라면 저희가 에르뎀 자체가 큰 문제를 보고 큰 문제를 보고 이것을 자기 자신이 알아서 작은 문제를 풀었다면 문제를 풀었다면 이 디커버스 프롬프틴 같은 경우에는 그러지 말고 우리가 작은 문제를 풀 수 있는 그러한 도구 혹은 서브 테스크 핸들러 그래서 그러한 핸들러들이 이렇게 잔뜩 있을 때 이제 어 에드램이 이 큰 문제를 풀기 위해서 이 작은 태스크들을 엮는 그런 역할을 할 수 있지 않을까라고 생각하게 해서 제안하게 된 것이 이 디컴포즈드 프롬프팅이라고 생각하시면 좋을 것 같습니다. 그래서 방금 전에 보았던 그 라스 레더 콤큐네이션이랑 비슷한 테스크를 합니다. 실제로 어떤 느낌이냐면 결국에는 저희가 존 스미스라는 것을 세컨드 레더 두 번째 글자를 뽑아가지고 두 것을 스페이스를 통해서 합쳐라 그러니까 합치게 된다면 o 공백 m이겠죠 이런 문제를 푸는 건데 list mot 머스트 같은 경우에는 결국에는 이 문제를 풀기 위해 풀기 위해서 작은 문제들을 뭔가 만들고 그렇게 되지만 그러지 않고 여기서는 우리가 이 디콘버s 프롬프틴 같은 경우에는 이렇게 사전에 정의된 뭔가 도구들을 얘기를 사용해 가지고 풀도록 합니다. 그래서 이 사전에 정의된 도구들은 무엇이냐 한다면 어 이건 결국에는 디자인 초이스예요. 이건 사람이 정해주는 거긴 합니다. 하지만 이 도구를 저희는 이 이 테스크를 풀기 위해서 적절한 도구가 적절한 뭔가 도구를 정해 갈 수 있고 그걸 통해가지고 LNM이 이걸 활용할 수 있게 하고 있다는 것이 기본적인 아이디어라고 생각하시면 좋을 것 같아요. 그래서 스플리스 같은 경우에는 뭔가 이러한 존 스미스에서 글자를 뽑아내라 글자를 분할하라 해가지고 존 하고 스미스 해가지고 리스트 형태로 뽑아내고 그리고 뭔가 존에서 또 앞서 있던 이러한 존 스미스에서 두 번째 글자를 뽑아내는 것을 하기 위해서는 저희가 결국에는 이 캐릭터 단위에서 뭔가 뽑아내는 그러한 메서드도 필요할 겁니다. 그래서 이렇게 존에서 두 번째 글자는 무엇이냐 하면 오 그리고 스미스에서 두 번째 글자는 무엇이냐 이런 것을 푸는 뭔가 그런 도구도 정의할 수가 있겠죠. 그리고 결국에는 저희가 이것을 공백을 통해 가지고 합쳐야 되기 때문에 그것을 합치는 뭔가 멀지라는 함수도 만들 수가 있을 겁니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "NLP Recent Trends Part 1 Reasoning & Planning.json",
        "lecture_name": "NLP Recent Trends Part 1 Reasoning & Planning",
        "course": "NLP",
        "lecture_num": "",
        "lecture_title": "NLP Recent Trends Part 1 Reasoning & Planning",
        "chunk_idx": 13,
        "total_chunks": 19,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:16397b31c981b01f4896a180b6afb60691dae1a3ddb8e74b654627d26a186523"
      },
      "token_estimate": 932,
      "char_count": 1745
    },
    {
      "id": "transcript_nlp_nlp_recent_trends_part_1_reaso_c014_726266",
      "content": "[NLP] NLP Recent Trends Part 1 Reasoning & Planning\n\n다. 그래서 이렇게 존에서 두 번째 글자는 무엇이냐 하면 오 그리고 스미스에서 두 번째 글자는 무엇이냐 이런 것을 푸는 뭔가 그런 도구도 정의할 수가 있겠죠. 그리고 결국에는 저희가 이것을 공백을 통해 가지고 합쳐야 되기 때문에 그것을 합치는 뭔가 멀지라는 함수도 만들 수가 있을 겁니다. 그래서 이러한 함수들이 있고 결국에는 하는 것은 조민 스미스가 풀기 위해서는 이것을 스플릿을 해가지고 이렇게 풀어야 되고 그리고 이제 그 이 앞서 나왔던 것에서 각각의 두 번째 글자가 무엇인가 푸는 것을 이제 오엠 해서 방금 전에 보았던 것처럼 이렇게 도구가 정의가 돼 있고 그렇다면 이제 이 엘 우리가 이 앞서 나왔던 이 엘램 자체가 하는 것이 무엇이냐 한다면 이제 어떤 도구에 대해서 어떠한 입력을 넣어야 되는가를 하는 것 그 생성하는 것이 이 디컴포스 포팅이라고 생각하시면 좋을 것 같아요. 그래서 어 결국에는 생성하는 것이 이 퀘스천 부분을 생성한다라고 생각하시면 좋을 것 같아요. 이거는 이 밑에 있는 아웃풋들 어 이 밑에 있는 아웃풋들 같은 경우에는 실제로 저희가 이 입력 값을 받아 가지고 이제 LM 자체가 LM 자체가 이러한 뭔가 함수 이름과 그리고 거기에 해당하는 아규먼트를 넣어주게 된다면 실제로 우리가 서브 테스크 핸들러에게 전달해 가지고 결과값을 받게 된다면 직접 넣어 준다라고 생각하시면 좋을 것 같습니다. 그래서 이 밑에 있는 것들은 이 모델에 대한 이 밑에 서브 테스크 핸들러에서 나온 그러한 결과 값이라고 생각하시면 좋을 것 같습니다. 그래서 그럴 경우에는 이 LLM 자체가 하는 건 뭐냐 결국에는 이 위에 있는 값들을 보고 이제 이 밑에 있는 것들을 이 프롬프트를 생성해 가지고 네 결국에는 이 엘엠 자체가 생성하는 것은 이렇게 멀지 나는 멀지라는 함수를 사용할 거야. 그리고 이 콘크네이트 그 두 번째 나온 결과물을 이제 위스페이스를 하겠다 이런 식으로 결과물 뭔가 이런 디컴포스 프롬프트를 짜가지고 이런 도구하고 그리고 거기에 들어가야 될 뭔가 알규먼트들을 이렇게 LM 자체가 생성하는 것이 가능하다라는 것을 보이는 논문이라 생각하시면 좋을 것 같습니다. 그래서 실제로 보시면 물론 이것도 다 뷰샵 프로트로 다 들어가고요. 이러한 예시들 이러한 콘크리이트 하는 예시들이 이쪽에 퓨샷으로 좀 들어가 있다라고 생각하시면 좋을 것 같습니다. 참고로 이 논문 같은 경우에는 이 스플릿이라든가 STR 포지션 MG 같은 경우에는 사실 파이썬 코드로 짠다면 뭐 한 줄로 짤 수 있지만 이것도 역시 뭔가 LLM 써가지고 이 테스크를 풀었다라고 생각하시면 좋을 것 같아요. 그래서 스플릿 같은 경우에도 이 위에 있는 에다가 샷을 넣어 가지고 이것 자체를 그냥 이 스플릿 자체를 하는 뭔가 LLM을 만들고 STR 포지션도 그러한 LLM을 하나 만들고 멀티도 그러한 ll을 만들었다 생각하면 좋을 것 같은데 기본적으로 중요한 것은 이렇게 뭔가 작은 문제를 사전에 정의하고 이 디컴포저 그러니까 문제를 분해하는 애하고 이 서브 스테스크 핸들러가 상호 작용하는 것이 핵심이라고 생각하시면 좋을 것 같습니다. 이게 결국에는 이 리스트 드 버스트와 가장 큰 차이점이 무엇이냐 한다면 저희가 리스트 투 머스트 같은 경우에는 결국에는 어떠한 어려운 문제를 풀기 위해서 작은 문제를 분해하고 나서 작은 문제를 먼저 다 사전에 다 분리를 하고 그리고 이 순서대로 작은 문제를 풀고 큰 문제를 푸는 형태였다면 이 컴퍼스 프롬프트 같은 경우에는 큰 문제를 풀기 위해서 작은 문제를 하나 만들고 그리고 작은 문제를 풀고 나서 그리고 다시 이 큰 문제를 다시 조금 분해해 가지고 또 작은 문제 하나 만들고 해가지고 이렇게 인터랙티브 상호 작용 자체가 되게 중요한 그러한 프로모팅 방법론이라고 생각하시면 좋을 것 같습니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "NLP Recent Trends Part 1 Reasoning & Planning.json",
        "lecture_name": "NLP Recent Trends Part 1 Reasoning & Planning",
        "course": "NLP",
        "lecture_num": "",
        "lecture_title": "NLP Recent Trends Part 1 Reasoning & Planning",
        "chunk_idx": 14,
        "total_chunks": 19,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:16397b31c981b01f4896a180b6afb60691dae1a3ddb8e74b654627d26a186523"
      },
      "token_estimate": 1020,
      "char_count": 1900
    },
    {
      "id": "transcript_nlp_nlp_recent_trends_part_1_reaso_c015_b3e903",
      "content": "[NLP] NLP Recent Trends Part 1 Reasoning & Planning\n\n다. 그래서 이거 같은 경우에도 지금 앞쪽에서 나왔던 예시를 또 또 도식화를 한 건데요. 결국에는 저희가 큐씨 개션 컴플리케이드 어려운 것을 풀었을 때 이렇게 스플릿 멀지 이러한 서브 테스크 핸들러가 있고 결국에는 이것들을 저희가 큐원에서 생성하는 것들을 생성하는 부분이 결국에는 이 q1 부분 스프릿 와라 더 월즈 인 잭 라이언 하게 된다면 결국에는 이 스프 우리가 이 이 스플릿이라는 함수에다가 스플릿이라는 함수에다가 이 와 rd 월드 잭 라이언이라는 것 자체가 이렇게 들어가서 인풋으로 들어갔다는 것을 비슷하게 인풋으로 들어갈 겁니다. 그래서 이것의 결과값 자체가 바로 인터랙티브 상호작용 을 통해 가지고 그냥 바로 나와 들어와서 이렇게 잭 라이언으로 분해가 되고 비슷하게 이 뒤에 있는 멀지라든가 뭐 에디알 포지션 이런 것들도 이렇게 프롬프트화를 해 가지고 저희가 이 적절한 함수들을 호출할 수 있게끔 만들어 주었다라고 생각하시면 좋을 것 같습니다. 그래서 지금 보시면 결국에는 스탠다드 프롬프팅이 이렇게 나오고 체인 홈 소트가 이렇게 단계별로 나가는 형태였다면 디컴포즈 프롬프트 같은 경우에는 이렇게 서브 테스크 핸들러가 그 체인 홈 소트 하는 순간 순간마다 이 다음 리즈닝 스텝 갈 때마다 하나씩 호출돼 가지고 넘어간다라고 생각하시면 좋을 것 같네요. 그래서 되게 다양한 테스크에 대해서 해보는데요. 그래서 방금 전에 봤던 뭔가 케이스 레더 콤큐네이션 그러니까 엠번제 레더를 콤큐네이션하는 방법론 같은 경우에는 이 단순히 체인 오브 소트라든가 리스트 모스트 이런 것보다 이 디 컴퍼스 프롬프트 하는 것이 더 성능이 좋았다라는 것을 확인해 볼 수가 있고요. 그 무엇보다도 사실 정확도는 그렇다 치더라도 어 좀 더 중요하게 볼 만한 부분은 일반화를 잘했다라고 생각하시면 좋을 것 같습니다. 그래서 실제로 이 예시 단순히 이 뭔가 이 케이 번째 레더를 합치는 예시가 앞쪽에 있는 디콤버스 프롬프트에서 저희가 캐샷으로 들어간다고 했었는데 이 샷 같은 경우에는 실제로 글자를 글자 혹은 워드가 정확히는 단어겠죠. 단어가 3개씩만 3개씩 분해하는 그러니까 단어가 뭔가 잭 라이언 어쩌고저쩌고 해가지고 그렇게 3개씩만 들어간 예시만 주었는데도 어 그래서 인도메인 디스뷰션이고 그리고 실제로 푸는 것은 엔이 4짜리 앤이 5짜리 이렇게 했을 때 이 체인 오브 소트 같은 경우에는 실제로 성능이 조금 떨어지는 것을 확인해 볼 수가 있지만 리스트 버스도 비슷하게 떨어지는 것을 확인해 볼 수가 있죠. 하지만 디크모스 프롬프트 같은 경우에는 거의 성능이 크게 떨어지지 않았다라는 것을 확인해 볼 수 있습니다. 그래서 단순히 저희가 이 디코머트 프롬프트 같은 경우에는 뭔가 이러한 계층적인 분해도 가능하고요. 혹은 저희가 이것을 뭔가 재귀적으로 문제를 분해하는 것도 가능할 겁니다. 그래서 이것은 또 다시 시퀀스 리버싱 해 가지고 뭔가 이것을 심볼릭한 테스크 중 하나인데 간단합니다. 그냥 그 워드가 하나 있을 때 이거 워드를 워드를 그냥 거꾸로 뒤집는 거라고 생각하면 좋을 것 같아요. dorw 이런 식으로 바꾸는 테스크라고 생각하시면 좋을 것 같아요. 이런 테스크 같은 경우에는 만약 저희가 인도인 디스비션을 가지고 4개 이렇게 줬을 경우에는 인도메인은 뭐 체인업소트나 디코머스 프롬프트나 그렇게 차이가 없지만 저희가 만약 10개씩 부르게 된다면 어 저희가 이 체인업소트 같은 경우에는 잘 작동되지 않지만 디커머스 프롬프트는 이것이 일반화를 어느 정도 해서 잘 돌아간다는 것을 확인해 볼 수가 있고요. 무엇보다도 이것을 뭔가 재귀적으로 호출해 가지고 결국에는 이거 어떻게 푸냐면 저희가 안에 밑에 있는 예시를 보면 알겠지만 결국에는 이것을 그 모드들이 이렇게 뉴스페이퍼 글래시스 레타 포트 있을 때 이것을 뒤집는 시퀀스 같은 경우에는 결국에는 뉴스페이퍼 앤 리 클래스를 이걸 뒤집어 가지고 다시 이것을 뒤집고 해가지고 이런 식으로 뭔가 재귀적으로 호출하는 것도 가능합니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "NLP Recent Trends Part 1 Reasoning & Planning.json",
        "lecture_name": "NLP Recent Trends Part 1 Reasoning & Planning",
        "course": "NLP",
        "lecture_num": "",
        "lecture_title": "NLP Recent Trends Part 1 Reasoning & Planning",
        "chunk_idx": 15,
        "total_chunks": 19,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:16397b31c981b01f4896a180b6afb60691dae1a3ddb8e74b654627d26a186523"
      },
      "token_estimate": 1083,
      "char_count": 1990
    },
    {
      "id": "transcript_nlp_nlp_recent_trends_part_1_reaso_c016_d3f0c7",
      "content": "[NLP] NLP Recent Trends Part 1 Reasoning & Planning\n\n다. 이거 같은 경우에는 리스트 버트 같은 경우에는 이것을 뭔가 재귀적으로 구매하는 것은 조금 어려웠겠죠 왜냐하면 문제를 맨 처음에 다 풀어놓고 시작하기 때문에 그게 좀 어려운 반면에 이것은 상호작용을 통해 가지고 분해를 하기 때문에 이런 재귀적인 분해도 가능하다라고 생각하시면 좋을 것 같습니다. 다만 이런 생각이 들 겁니다. 아 도대체 이게 무슨 의미가 있지라는 생각이 들 거예요. 디코퍼터 프롬프트여가지고 결국 이런 프롬포팅 방법론을 풀 수 있는 거는 결국에는 뭔가 단어를 단어에서 글자를 뽑아내는 뭔가 이런 캐스 케이스 레이라 그러니까 세 번째 글자 합치기 혹은 뭔가 시퀀스를 뒤집는다던가 이런 것밖에 이런 건 단순히 파이썬으로 세 줄만 짤 수 있는 건데 왜 굳이 디컴퍼스 펌프팅을 써야 되는가라는 생각이 들 거예요. 사실 이 논문에서 말하고자 하는 바는 그게 좀 핵심은 아니긴 해요. 제가 보기에는 그래서 실제로 뭐 그런 것은 굳이 파이썬으로 짤 필요 굳이 LLM을 쓸 필요 없이 파이썬으로 짜도 되는데 이 논문에서 보여주고 싶었던 바는 이렇게 문제 자체를 저희가 사전에 정의하고 그리고 모델이 그것을 이제 큰 문제를 해결하기 위해서 엮어가지고 큰 문제를 해결할 수 있다는 그러한 능력을 보여줬다라고 생각하시면 좋을 것 같습니다. 그래서 그런데 이 사전 테스크라는 것은 저희가 정의하기 나름이거든요. 결국엔 앞쪽에 봤었던 뭔가 케이스 레더 같은 경우는 케번째 글자를 뽑아내는 함수 이런 것도 저희가 사전에 정의하는 함수였고 그리고 그것 자체가 뭔가 모델에 의존적이라든가 그런 건 아니었습니다. 따라서 이런 생각을 해볼 수 있어요. 저희가 뭔가 리트라이브 같은 해 가지고 뭔가 도큐먼트를 뽑아오는 그러한 서브 테스크 핸들러를 정의하는 것도 가능할 겁니다. 그래서 로스트 그래비티는 어느 컴퍼뉴가 제조하였나 아마도 제 기억에는 로스트 그래비티 저게 롤러코스터 이름일 거예요. 하지만 이런 것을 뭔가 LNM에게 물어보기보다 LNM에게 바로 생성하는 것보다 당연히 뭔가 인터넷 문서를 뒤져가지고 하는 것이 좀 더 도움이 될 겁니다. 그래서 이것을 하기 위해서 저희가 리트라이브라는 함수를 뭔가 이렇게 서브 테스크로 정의를 하고 그리고 위치 컴퍼니 mann prettald los gravity 하게 된다면 저희가 이 검색 결과 자체를 리트라이브라는 거 써요. 실제로 굳이 LLM을 쓸 필요는 없잖아요. 이거 이 서브 테스크를 그래서 실제로 인터넷 검사를 검색을 한 다음에 그 결과값 자체를 넘겨주는 형태로 하는 것도 가능합니다. 그래서 이런 식으로 뭔가 외부 기능 자체를 활용한 형태로 이 서브 테스크 핸들러를 활용을 할 수가 있고요. 그래서 이걸 기반으로 대게 아주 복잡한 문제들 그래 인터넷 검색이 없으면 못하는 문제들 혹은 뭐 계산기를 쓰지 않으면 풀기 어려운 문제들 이런 것들도 어 풀 수 있지 않을까라는 생각을 해볼 수가 있을 겁니다. 그래서 이런 외부 기능을 활용해서 작은 문제를 해결하는 것 중에서 가장 대표적인 프롬포팅 방법론 중 하나가 이 리액트 프롬포팅입니다. 리액트 프럼프틴 같은 경우에는 간단합니다. 어떤 걸 하냐 내가 뭔가 어떤 복잡한 문제를 풀 때 현재에 대해서 생각을 하고 현재의 상황에 대해서 생각을 하고 그리고 실제로 at 행동을 하고 그리고 그의 행동에 대한 옵조베이션을 관측합니다. 옵조베이션이라는 것은 뭔가 이것은 인터넷 검색 결과가 될 수도 있을 거고요. 아니면 뭔가 어쨌든 이 액션으로 액션으로 인해 발생된 뭔가 결과물들을 확인해 볼 수가 있을 겁니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "NLP Recent Trends Part 1 Reasoning & Planning.json",
        "lecture_name": "NLP Recent Trends Part 1 Reasoning & Planning",
        "course": "NLP",
        "lecture_num": "",
        "lecture_title": "NLP Recent Trends Part 1 Reasoning & Planning",
        "chunk_idx": 16,
        "total_chunks": 19,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:16397b31c981b01f4896a180b6afb60691dae1a3ddb8e74b654627d26a186523"
      },
      "token_estimate": 955,
      "char_count": 1783
    },
    {
      "id": "transcript_nlp_nlp_recent_trends_part_1_reaso_c017_b83325",
      "content": "[NLP] NLP Recent Trends Part 1 Reasoning & Planning\n\n다. 리액트 프럼프틴 같은 경우에는 간단합니다. 어떤 걸 하냐 내가 뭔가 어떤 복잡한 문제를 풀 때 현재에 대해서 생각을 하고 현재의 상황에 대해서 생각을 하고 그리고 실제로 at 행동을 하고 그리고 그의 행동에 대한 옵조베이션을 관측합니다. 옵조베이션이라는 것은 뭔가 이것은 인터넷 검색 결과가 될 수도 있을 거고요. 아니면 뭔가 어쨌든 이 액션으로 액션으로 인해 발생된 뭔가 결과물들을 확인해 볼 수가 있을 겁니다. 그래서 거기서 이렇게 받은 다음에 또 다시 이것을 지금 상태에서 또다시 생각을 하고 그리고 액트를 고르고 이런 식으로 반복되는 것이 이 리액트 방법론 이러한 프롬프팅이라고 생각하시면 좋을 것 같아요. 그래서 이 액트 같은 경우에 그러니까 행동 같은 경우에는 결국엔 이것은 저희가 정의하기 나름이에요. 이 보시면 알겠지만 예를 들어 설치 이런 식의 뭔가 액트를 정의할 수 있고요. 이 설치 같은 경우에는 뭔가 엔티티의 위키 페이지의 첫 다섯 문장을 반환하는 그러한 함수로 정의하고 또 뭐 룩업 같은 형태로 룩업 같은 뭔가 함수를 정의해 가지고 컨트롤 프랑 유사하게 뭔가 이 다음에 나오는 스트링을 포함하는 그 다음 문장을 출력하게 한다든가 혹은 뭔가 답이 나왔으면 이제 BNC 해가지고 BNC nce를 반환하고 현재 과제를 종료한다든가 이런 식으로 우리가 사전에 이런 LLM이 쓸 수 있는 도구들을 정의를 할 수가 있을 겁니다. 그리고 그 도구에 대해서 뭔가 설명을 넣는다든가 데모 스트레이션을 넣어 가지고 저희가 이 엘엠이 되게 어려운 문제를 풀 때 이러한 도구들을 활용할 수 있게끔 저희가 정의하는 것이 가능할 겁니다. 그래서 어 기존에 뭔가 핫스팟 큐에이 가지고 이 핫스팟 큐에 데이터 셋 같은 경우에는 저희가 그 인터넷 검색 없이는 되게 풀기가 어려운 문제인데요. 근데 이 스탠다드 같은 경우에는 결국에는 나이브하게 그냥 퓨샷 형태로 물어본 거라고 생각하시면 좋을 것 같습니다. 그래서 이 경우에는 틀렸다는 걸 확인해 볼 수 있죠. 비슷하게 cot로 하더라도 결국에는 이 씨ot 자체가 인터넷 검색 능력이 없다 보니까 리즈닝만 가능하다 보니까 답 자체가 되게 할루시네이션 그러니까 환각 현상이 많이 일어난 거고 그 결과 모델에 내재돼 있는 정보만으로 뭔가 답변을 하려다 보니까 되게 틀리는 경우가 많이 발생합니다. 그리고 액트 올리 해가지고 리즈닝 사우스를 안 하고 단순히 액션만 골라서 하는 거 액션하고 옵저베이션하고 액션하고 옵조베이션 하는 거 이런 경우에는 저희가 체인 홈 소트 그러니까 이 모델이 이 다음 액션 현재 상황을 보았을 때 어떠한 액션을 골라야 될까에 대한 이러한 사고 흐름 과정이 없기 때문에 이런 것도 되게 잘 작동하지 않습니다. 하지만 리액트 같은 경우에는 결국에는 이렇게 뭔가 액션을 하기 전에 뭔가 사고를 해 가지고 내가 지금 어떠한 행동을 취해야 되는가를 뭔가 뱉어내게 되고 그리고 그거에 대한 관측 결과를 받은 다음에 거기서 또다시 그 사고를 하는 그러한 프롬프팅이라고 생각하시면 좋을 것 같네요. 다만 이 리액트 같은 경우에는 지금 이 리액트 프롬프트를 뭔가 챗gpt라든가 혹은 뭔가 gpt4 이러한 친구들에게 뭔가 한번 활용해 보시면 어 꽤 잘 작동하는데 당시에는 사실 LLM 성능 자체가 그렇게 좋은 편은 아니었기 때문에 우선 리액트 단독으로 그 당시에는 이게 리액트 단독으로는 정확도가 그렇게 좋지 않았습니다. 그래서 모델에 내재돼 있는 뭔가 정보를 활용하는 이 셀프 컨시스턴시는 뭔가 같이 함께 사용하는 것이 일반적이었어요. 그래서 저희가 위에서 보이는 게 우선 베이스라인으로 비교해 볼 만한 것이 스탠다드라든가 cot cot 셀프 컨시선시 여기 보이는 sc가 셀프 컨시전시라고 생각하시면 좋을 것 같아요. 그래서 이런과 비교했을 때 리액트하고 액트 자체가 그렇게 막 성능이 뛰어나다는 아니라는 것을 확인해 볼 수가 있습니다. 단순히 액션 자체를 골라서 하지만 문제는 뭐냐 하면 이 리액트 같은 경우에는 결국에는 같은 검색을 반복하거나 뭔가 잘못된 검색 결과로 추론이 틀리는 경우가 되게 많았다라고 합니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "NLP Recent Trends Part 1 Reasoning & Planning.json",
        "lecture_name": "NLP Recent Trends Part 1 Reasoning & Planning",
        "course": "NLP",
        "lecture_num": "",
        "lecture_title": "NLP Recent Trends Part 1 Reasoning & Planning",
        "chunk_idx": 17,
        "total_chunks": 19,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:16397b31c981b01f4896a180b6afb60691dae1a3ddb8e74b654627d26a186523"
      },
      "token_estimate": 1102,
      "char_count": 2050
    },
    {
      "id": "transcript_nlp_nlp_recent_trends_part_1_reaso_c018_10b239",
      "content": "[NLP] NLP Recent Trends Part 1 Reasoning & Planning\n\n다. 단순히 액션 자체를 골라서 하지만 문제는 뭐냐 하면 이 리액트 같은 경우에는 결국에는 같은 검색을 반복하거나 뭔가 잘못된 검색 결과로 추론이 틀리는 경우가 되게 많았다라고 합니다. 결국에는 이것이 모델이 있는 내재된 정보만으로 얘기를 하다 보니까 이것이 뭔가 리즈닝적으로 틀리기 보다는 뭔가 활로시네이션 환광 현상 자체에 발생해 가지고 이것이 추론이 틀리는 경우가 많았다고 합니다. 그래서 이 리액트 논문에서는 뭔가 셀프 그 뭔가 씨오티를 하고 나서 뭔가 씨오티에서 앙상블 할 때 다수 다방이었다 그러니까 메이저리티를 못 넘었다 하면 리액트를 진행하고 또 리액트를 진행하고 뭔가 리액트를 뭔가 몇 번 이상 반복해 가지고 어디서 뺑뺑 돈다든가 그런 경우에는 cot로 추론하고 이렇게 했을 때 기존에 있는 방법론보다 더 좋았다라고 얘기를 합니다. 그래서 실제로 cot를 하고 리액트를 한 경우 리액트를 하고 cot를 하는 경우 했을 때 기존 방법론에 비해서 성능이 많이 올랐다라는 것을 확인해 볼 수가 있죠. 다만 물론 하나 고민해 볼 만한 점은 이렇게 쓰더라도 우선 슈퍼바이스 소타 그러니까 이 테스크만을 위해서 뭔가 디자인의 소타 모델보다는 다소 성능이 떨어지는 것을 확인해 볼 수 있습니다. 하지만 이거 이거에 중요한 점은 이 슈퍼바이즈 소타 같은 경우에는 결국에는 다량의 데이터셋 이러한 문제를 풀기 위한 그러한 데이터 셋을 많이 요구하는데 저희가 앞서 얘기했던 이 리액트 방법론 혹은 뭐 cot 방법론 이런 것들은 다 결국엔 퓨샷이기 때문에 되게 적은 시나리오만으로도 어느 정도 이러한 성능을 유지할 수 있다라고 생각하시면 좋을 것 같습니다. 네 그리고 이 리액트 논문에서 얘기하는 바가 또 하나가 있는데요. 바로 어 앞쪽에서 얘기했던 것처럼 제가 뷰 샷으로 넣는 것도 가능하다 했지만 사실 리액트의 진짜 본질은 이것을 파인튜닝 했을 때 성능이 더 좋다라고 얘기합니다. 그러니까 결국에는 인컨텍스트 러닝으로 저희가 예시를 줘 가지고 저희가 리액트를 실제로 돌리게 될 텐데요. 저희가 이러한 시나리오를 한 3천 개 정도만 모을 수 있다면 어 저희가 이것을 파인튜닝 하게 된다면 기존에 있는 씨오티라든가 보시면 이것이 인컨텍스 러닝 그러니까 프롬프트를 통해 가지고 씨오티를 하든가 그 리액트를 돌렸을 때 결과고요. 오른쪽 결과가 저희가 이 시나리오 데이터를 조금 모아 가지고 한 3k 정도 모아가지고 파인튜닝 했을 때 성능인데 그렇게 하게 된다면 이 파인튜닝 한 리액트 자체가 성능이 크게 오르는 것을 확인해 볼 수가 있고 지금 보시면 성능 차가 여기서는 거의 차이가 안 나는 것을 확인해 볼 수 있지만 여기서는 확실하게 파인 튜닝 했을 때 리액트가 기존 모델보다 기존 cot라든가 그런 것을 그런 것보다 더 좋은 성능이 나왔다는 것을 확인해 볼 수가 있습니다. 그래서 사실 리액트는 사실 인컨덱스 러닝보다 파인 튜닝 방식이 더 좋은 방식이고 다만 요즘에는 리액트로 프롬프팅해도 워낙 엘엠 자체가 머리가 되게 좋기 때문에 이 생각보다 그런 것들을 돌려보게 된다 잘 돌아가는 것을 아마 관측할 수가 있을 겁니다. 네 이상으로 1강에서 리즈닝 엠플래닝에 대해서 얘기를 해보았고요. 이제는 다음 강의에서는 이걸 활용한 엘앤엠 애플리케이션들 그러니까 엘앤엠 응용 프로그램에 대해서 한번 얘기해 보도록 하겠습니다. 네 강의를 마치겠습니다. 감사합니다.",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "NLP Recent Trends Part 1 Reasoning & Planning.json",
        "lecture_name": "NLP Recent Trends Part 1 Reasoning & Planning",
        "course": "NLP",
        "lecture_num": "",
        "lecture_title": "NLP Recent Trends Part 1 Reasoning & Planning",
        "chunk_idx": 18,
        "total_chunks": 19,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:16397b31c981b01f4896a180b6afb60691dae1a3ddb8e74b654627d26a186523"
      },
      "token_estimate": 920,
      "char_count": 1704
    }
  ]
}