{
  "source_file": "[MRC] (8강)Reducing Training Bias.json",
  "lecture_name": "[MRC] (8강)Reducing Training Bias",
  "course": "MRC",
  "total_chunks": 8,
  "chunks": [
    {
      "id": "transcript_mrc_mrc_8강reducing_training_bias_c000_900f45",
      "content": "[강의 녹취록] 과목: MRC | 강의: 8강 | 제목: Reducing Training Bias\n\n네 안녕하세요. 8강 시작하도록 하겠습니다. 오늘 다뤄볼 주제는 위듀싱 트레이닝 바이어스입니다. 그래서 바이러스가 뭘까요? 라고 좀 질문을 하시는 분도 계실 것 같은데요. 그래서 저희가 먼저 바이러스의 정의에 대해서 먼저 섹션 1에서 짚고 넘어가고요. 그다음에 이런 바이러스가 일반적인 개념이긴 하지만 오픈 도메인 QA에서는 어떤 바이러스가 있는지 섹션 2에서 다뤄보도록 하겠습니다. 마지막 섹션에서는 저희가 데이터셋에서 발생하는 애노테이션 바이러스에 대해 좀 더 자세하게 들여다보도록 하겠습니다. 네 먼저 바이러스의 정의입니다. 바이러스는 여러 가지 종류가 있습니다. 그중 하나는 러닝에서 바이러스가 생기는 경우인데요. 학습할 때 과적합을 막거나 사전 지식을 주입하기 위해 특정 형태의 함수를 선호하는 것 또는 인덕티브 바이러스라 불려지는 바이러스가 있고요. 여러분이 모델을 만드실 때 예를 들면은 아 이런 모델은 이런 이런 종류의 인풋과 이런 종류의 아웃풋이 들어온 이런 종류의 아웃풋을 저희가 내보내야 하니까 이런 식으로 모델을 만들면 좋겠다라고 생각하는 것 자체가 바이러스라는 거죠. 어떤 걸 선호하는 현상 그 특정 모델을 선호함으로써 실제로 그 모델이 그렇게 작동하도록 유도하는 것 나쁘다는 것은 아니고요. 다만 저희가 바이러스가 있다는 것을 인지하고 넘어가야 한다는 것입니다. 왜냐하면 모델이 그런 방식으로 디자인이 됐기 때문에 실제로 데이터가 주어지면 여러분이 의도하신 대로 모델이 학습이 되겠죠. 그 의도가 사실은 근데 좋은 건지 나쁜 건지는 사실은 아무도 모르는 것이니까 이 바이러스라고 볼 수가 있고요. 또한 바이어스 월드라는 개념이 있는데요. 간단하게는 예를 들면은 히스토리컬 바이어스라고 불리는 현실 세계가 편향되어 있기 때문에 모델이 원치 않는 속성이 학습되는 현상이 있습니다. 그리고 성별과 직업 간 관계 등 표면적인 상관관계 때문에 원치 않는 속성이 학습되는 또 코어 클랜스 바이러스가 있고요. 마지막으로는 데이터 제너레이션 단계에 생기는 바이러스들이 있는데요. 입력과 출력을 정의한 방식 때문에 생기는 편향 스피피케이션 바이러스라고 불리고요. 데이터를 샘플링한 방식 때문에 생기는 편향 샘플링 바이러스라고 불리고 에노테이터들의 특성 때문에 생기는 편향 에노테이터 바이러스라 불리는 바이러스들이 있습니다. 저희가 모든 바이러스를 들여다보지는 않겠지만 여기서 몇 가지 좀 이그잼플로 드리면서 이해를 돕도록 하겠습니다. 예를 들면 사회에서 많은 문제가 되고 있는 젠더 바이러스가 있죠 이 대표적인 바이러스의 예시인데요. 즉 특별 특정 성별과 행동을 연관시켜서 예측 오류가 발생하는 경우입니다. 자 예를 들어볼까요? 보시다시피 이제 쿠킹이라는 어떤 개념을 봤었을 때는 사실 쿠킹이라는 게 항상 사실 여자만 쿠킹을 하지는 않죠 사실 남자도 쿠킹을 해야 되는데 근데 저희가 어떤 모델은 항상 여자가 쿠킹을 한다고 데이터를 통해서든 그렇게 많이 보다 보니까 즉 많이 발생하다 보니까 보시다시피 남자가 쿠킹을 하고 있는 경우에도 에이전트가 우먼으로 착각을 하는 경우가 발생을 합니다. 이런 경우를 바이스라고 보시면 되는데 또 다른 대표적인 예는 사실 벌써 머신 트랜슬레이션에서도 많이 보여지고 있는데요. 구글 트랜슬레이 가셔서 어떤 좀 트랜슬레이을 해보시게 되면은 어떤 사람이 의사다 라는 것을 만약에 영어로 트랜스라잇트 하게 좀 어 구글 트랜스라잇 넣게 되면은 그러니까 저기 그 위에 있는 털키시는 사실은 저게 성별을 지칭하지 않는 그 사람이라고 보시면 돼요. 그 사람은 의사다 의사다라고 이렇게 저희가 인풋을 넣어줬지만 영어로는 his docter 이렇게 나오는 걸 보실 수가 있습니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "[MRC] (8강)Reducing Training Bias.json",
        "lecture_name": "[MRC] (8강)Reducing Training Bias",
        "course": "MRC",
        "lecture_num": "8강",
        "lecture_title": "Reducing Training Bias",
        "chunk_idx": 0,
        "total_chunks": 8,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:f9489eb5149a0b40edcef87b33503df5683ae2893e0ea5ea27841c3f3b105557"
      },
      "token_estimate": 1016,
      "char_count": 1848
    },
    {
      "id": "transcript_mrc_mrc_8강reducing_training_bias_c001_fc7de6",
      "content": "[MRC] [MRC] (8강)Reducing Training Bias\n\n다. 이런 경우를 바이스라고 보시면 되는데 또 다른 대표적인 예는 사실 벌써 머신 트랜슬레이션에서도 많이 보여지고 있는데요. 구글 트랜슬레이 가셔서 어떤 좀 트랜슬레이을 해보시게 되면은 어떤 사람이 의사다 라는 것을 만약에 영어로 트랜스라잇트 하게 좀 어 구글 트랜스라잇 넣게 되면은 그러니까 저기 그 위에 있는 털키시는 사실은 저게 성별을 지칭하지 않는 그 사람이라고 보시면 돼요. 그 사람은 의사다 의사다라고 이렇게 저희가 인풋을 넣어줬지만 영어로는 his docter 이렇게 나오는 걸 보실 수가 있습니다. 자 왜 그럴까요? 이것도 마찬가지로 뭐 당연히 그 구글이 의사가 항상 남자로 생각한다 이거는 좀 잘못된 방식이고요. 그것보다는 저희가 학습한 데이터에서 실제로 닥터가 남자인 경우가 많다 보니까 모델은 닥터가 닥터라는 표현이 있었으면 아마도 남자이지 않을까라고 어떻게 보면 좀 어음을 해버린 거죠. 하지만 상당히 큰 문제죠. 이런 걸 통해서 실제로 구글이 이걸 의도하지 않았다 하더라도 사람들의 머릿속에 사실 이런 거를 심어주기 때문에 의사는 남자다라는 것을 심어주고 이런 바이러스들이 결국에는 소셜이 좀 사회적으로 문제가 있다고 보기 때문에 이런 부분들을 해결하기 위해서 많은 노력이 있습니다. 또 다른 대표적인 예로는 샘플링 바이러스가 있을 텐데요. 예를 들면 1936년에 있었던 여론조사에 대해 좀 말씀을 드려볼게요. 상당히 유명한 여론조사인데 리터러시 다이제스트라는 회사에서 사실 엄청난 큰 표본으로 당시에 누가 대통령이 될 것 같은지에 대한 여론조사를 했습니다. 표본 크기는 240만 명으로 사상 최대였고 사실 당시에 미국 인구를 생각하면 특히나 엄청난 크기의 여론조사였던 거죠. 그리고 그 여론조사에서 루즈벨트가 43%, 알프 랜던이 57%로 알파 랜던이 압도적으로 이기는 것으로 예측을 했던 거죠. 하지만 실제로 결과를 까보니 대선 때는 루즈베이트가 62%를 받고 알프레드가 38%를 받는 완전히 반대의 결과가 나왔었는데요. 이렇게 됐던 이유가 나중에 살펴보니 설문 대상을 잡지 정기 구독자와 자동차 자동차 등록 명부 그리고 사교 클럽 인명부 등을 활용을 했는데 사실 이런 사람들은 미국 내에서 중산층 이상인 표본이거든요. 즉 왜곡이 된 거죠. 240만 명을 샘플링을 할 때 페어하게 상당히 랜덤하게 샘플링을 했어야 되는데 상당히 편향된 형태로 샘플링을 하다 보니까 중산층 이상의 사람들로 샘플링이 됐고 이 사람들은 조금 더 알프레드를 선호하는 그런 이제 좀 표본이었던 거죠. 하지만 실제로 전체의 미국 인구를 봤을 때는 조금 더 루즈벨트를 선호했던 것이고 완전히 결과를 잘못 맞춤으로써 물론 이것만이 이유는 아니었겠지만 실제로 2년 후에 리터러시 다이제스트가 파산을 하게 됩니다. 이처럼 어쨌든 바이러스라는 것은 특히 이제 보시다시피 샘플링 바이러스나 젠더 바이러스 같은 경우는 사실 저희가 좀 피해야 되는 바이러스들이고요. 물론 인덕트 바이러스와 같이 사실 바이러스라는 의미가 항상 나쁘다고 느끼실 필요는 없을 것 같습니다. 하지만 보통으로는 바이러스는 아 일단은 뭔가 문제가 있고 그걸 해결해야 되는구나라고 생각을 해 주시면 좋을 것 같아요. 그래서 두 번째 섹션에서는 저희가 오픈 도메인 퀘스트 엔서링에서 어떤 바이러스가 존재를 하는지를 좀 살펴보도록 하겠습니다. 익숙한 리트리버 리더 파이프라인인데요. 보시다시피 저희가 리트리버에서 문서를 가져와서 가져온 문서를 통해서 뒤에 MRC 모델이 퀘스천 엔서링하는 그런 파이프라인입니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "[MRC] (8강)Reducing Training Bias.json",
        "lecture_name": "[MRC] (8강)Reducing Training Bias",
        "course": "MRC",
        "lecture_num": "8강",
        "lecture_title": "Reducing Training Bias",
        "chunk_idx": 1,
        "total_chunks": 8,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:f9489eb5149a0b40edcef87b33503df5683ae2893e0ea5ea27841c3f3b105557"
      },
      "token_estimate": 953,
      "char_count": 1752
    },
    {
      "id": "transcript_mrc_mrc_8강reducing_training_bias_c002_dc6956",
      "content": "[MRC] [MRC] (8강)Reducing Training Bias\n\n다. 하지만 보통으로는 바이러스는 아 일단은 뭔가 문제가 있고 그걸 해결해야 되는구나라고 생각을 해 주시면 좋을 것 같아요. 그래서 두 번째 섹션에서는 저희가 오픈 도메인 퀘스트 엔서링에서 어떤 바이러스가 존재를 하는지를 좀 살펴보도록 하겠습니다. 익숙한 리트리버 리더 파이프라인인데요. 보시다시피 저희가 리트리버에서 문서를 가져와서 가져온 문서를 통해서 뒤에 MRC 모델이 퀘스천 엔서링하는 그런 파이프라인입니다. 여기서 저희가 좀 포커스 할 부분은 위트리버 쪽은 아니고 위더 쪽의 바이러스를 좀 보도록 할게요. 이제 학습할 때 바이러스가 많이 발생을 하는데요. 만약에 리더 모델이 한정된 데이터 셋에서만 학습이 된다면 미드 모델은 항상 정답이 문서 내에 포함된 데이터 쌍만 보게 되겠죠. 즉 특히 스쿼드 같은 경우는 컨텍스트 쿼리 앤서가 모두 포함된 데이터를 완전 positive라고 보는 고정되어 있는 형태라 인퍼런스의 만약에 데이터 내에서 찾아볼 수 없었던 새로운 형태의 문서가 나오거나 또는 이런 경우는 리더 모델의 문서에 대한 독해 능력이 매우 떨어지겠죠. 그리고 결과적으로 정답을 내지 못할 것입니다. 그래서 예를 들면은 저희가 학습할 때는 소설이나 수필 또는 비문학만 봤다가 갑자기 인퍼런스 때 완전히 의학이나 공학이나 자연과학 같은 다른 종류의 문서를 보게 된다면은 모델이 보지 못했던 형태의 글 아무래도 소설 같은 경우는 조금 더 메타 포라나 이런 상당히 좀 문학적인 용어 또는 문장 형태를 많이 쓰게 될 것이고 의학이나 공학은 조금 더 간결하고 직접적인 문장을 많이 쓰게 될 것이기 때문에 신 모델 머신러닝 모델이 많이 힘들어 하겠죠. 이제 이런 것들이 사실 바이러스라고 보시면 됩니다. 저희가 학습할 때 너무 한쪽에 편향돼 가지고 학습을 시켜줬다 보니 좀 더 일반적인 문서들을 다루는 것을 모델이 학습하지 못한 것이죠. 이런 문제들을 어떻게 저희가 해결을 해야 될까요? 몇 가지 방법들이 있는데 예를 들면은 저희가 좀 네이티브 샘플들을 좀 잘 보여주는 방법이 있겠습니다. 그래서 보시면은 훈련할 때 잘못된 예시를 보여줘야 리트리버가 네이티브한 내용들을 먼 곳에 배치를 할 수 있겠죠. 그렇지 않으면 이게 틀린 문장인지 아닌지를 학습 때 잘 알 수가 없을 테니까요. 다만 negative 샘플을 어떻게 잘 가져올지에 대한 고려는 필요하겠고요. 또한 답변이 문서 내에 없는 경우에 노우 앤서를 줄 수 있도록 학습하는 그런 방법론도 필요하겠습니다. 뭐 그 그중 하나의 방법론은 now 엔서 바이어스라는 걸 추가하는 것인데요. 입력 시퀀스의 길이가 n일 때 시퀀스 길이 외에 1개의 토큰이 더 있다고 생각을 하고 훈련 모델의 마지막 레이어 웨이트에 훈련 가능한 바이러스를 하나 더 추가하는 방법이 있겠습니다. 이런 경우 소프트맥스로 최종 프리딕션을 수행을 할 때 스타트 엔드 확률이 해당 바이러스 위치에 있는 경우가 가장 확률이 높으면 이는 대답을 할 수 없다 또는 답변이 없다로 취급할 수가 있겠죠. negative 샘플 관련해서 좀 더 들여다보면요. 어떻게 좋은 negative 샘플을 만들 수 있을까가 사실 중요한 문제인데요. 저희가 5강에서 다뤘던 문제고요. 사실 이것이 그때 당시에는 저희가 그냥 좀 더 단순하게 네이트 샘플을 잘 가져오는 거 중요하다고 말씀을 드렸지만 실제로는 이런 것들이 바이러스랑도 밀접한 관련이 있고요. 저희가 콜퍼스 내에서 랜덤하게 뽑을 수도 있겠지만 좀 더 헷갈리는 즉 좀 더 답변 같지만 얼핏 보면은 실제로는 답변이 아닌 답변을 포함하고 있지 않은 샘플들을 가져오면 사람도 그렇듯이 좀 더 어려운 멀티플 초이스들을 줘야 더 학습을 잘 할 수 있겠죠. 모델도 마찬가지로 좀 더 어려운 negative 샘플들을 줘야 학습을 잘 할 수가 있고, 예를 들면은 bm25나 tfidf 매칭 스코어는 높지만 실제 답을 포함하지 않는 샘플이라거나 또는 같은 문서에서 나오는 다른 패시지를 선택하는 방법이 있겠습니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "[MRC] (8강)Reducing Training Bias.json",
        "lecture_name": "[MRC] (8강)Reducing Training Bias",
        "course": "MRC",
        "lecture_num": "8강",
        "lecture_title": "Reducing Training Bias",
        "chunk_idx": 2,
        "total_chunks": 8,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:f9489eb5149a0b40edcef87b33503df5683ae2893e0ea5ea27841c3f3b105557"
      },
      "token_estimate": 1056,
      "char_count": 1971
    },
    {
      "id": "transcript_mrc_mrc_8강reducing_training_bias_c003_cbe564",
      "content": "[MRC] [MRC] (8강)Reducing Training Bias\n\n다. 네 저희가 마지막으로는 데이터셋 상에 존재하는 애노테이션 바이러스에 대해 좀 더 자세히 알아보도록 할게요. 사실 가장 여기서 큰 문제는 저희가 데이터셋을 제작을 할 때 생기는 바이러스 이슈인 건데요. 이게 그래서 에메테이션 바이어스라고 불리는 거죠. odqa를 저희가 학습할 때 이제 기존의 MRC 데이터셋을 활용하죠. 리트리버도 그렇고 저희가 MRC 모델을 만들 때는 더더욱 그렇고요. 하지만 이게 odqa 세팅에서는 적합하지 않은 바이어스가 발생할 수가 있습니다. 이제 아래 표에서 보시는 것처럼 사실 질문을 하는 사람이 답을 알고 있지 않는 게 실제 유저의 퀘스천 앤서링 시나리오겠죠. 여러분이 어떤 질문을 에이전트한테 물어볼 때는 답을 모르니까 물어보잖아요. 그렇기 때문에 그 경우를 최대한 시뮬레이션을 해야 저희가 올바른 바이러스가 없는 데이터 셋을 확보할 수가 있는데 이제 문제점은 실제로 데이터 셋을 만들 때 그렇게 하기가 쉽지가 않다 보니 아래와 같이 질문을 하는 사람이 답을 알고 있으면서 질문을 하게 되는 편향이 발생하게 되는 거죠. 이런 편향 때문에 원치 않는 어떤 그런 아티팩트가 질문에 이나 답에 들어가는 경우가 발생을 합니다. 실제로 이런 게 좀 심한 경우가 트리비아 큐에이랑 스쿼드라고 볼 수가 있겠는데요. 보시다시피 질문을 하는 사람이 답을 알고 있기 때문에 질문과 에비던스 문단 사이에 많은 단어가 겹치는 바이러스가 발생할 수 있습니다. 즉 너무 질문이 쉬워지는 거죠. 그래서 예를 들면 위에와 같이 저런 툴에서 질문을 쓰고 답을 내라고 한다면 이미 벌써 문서를 보고 있기 때문에 문서를 보면서 질문을 작성을 하게 되겠죠. 그러면 거의 PR 프레이징이나 어떤 그런 다른 단어를 활용하지 않게 되고 질문이 상당히 지문에 디펜던트한 바이러스가 발생하게 됩니다. 그리고 사실 스쿼드 같은 경우는 500개의 문서만 활용을 하고 있기 때문에 학습 데이터의 분포 자체가 이미 좀 바이러스가 있습니다. 이 500개의 문서는 가장 사람들이 많이 보는 문서들 중에서 골랐거든요. 하지만 저희가 질의응답을 하는 경우에는 꼭 사람들이 많이 보는 문서뿐만이 아니라 사람들이 덜 보는 문서도 가야 될 수도 있겠죠. 즉 랜덤리 샘플 된 게 아니다 보니 바이스가 존재를 하게 되는 것입니다. 그래서 아까 보여드린 것처럼 TV와 QA랑 스쿼드 같은 경우는 이런 게 좀 심한 편이고 위에 보시다시피 퀘스천을 쓰는 사람이 답을 알고 있는 것뿐만이 아니라 스쿼드 같은 경우는 실제로 그 답이 어디 어느 문단에서 어떤 페어 그래프에서 나오는지까지도 알고 있기 때문에 바이러스가 더 심해지게 됩니다. 그럼 이런 바이러스 때문에 어떤 문제가 생길까요? 실제로는 데이터 셋별 성능 차이가 모델이나 또는 사실 다른 중요한 팩터에 의한 차이가 아니라 이런 바이러스 때문에 발생할 수 있습니다. 예를 들면은 그 저희 표에서 보시다시피 스쿼드에서 어떤 모델을 돌렸었을 때 비엠 25가 디피알보다 훨씬 잘 되는 걸 볼 수가 있어요. 비엠25는 68.8점을 내보내 주고 DPR 같은 경우 DPR이 댄스 패시스 리트리벌 즉 댄스 인베딩을 통해서 가져오는 실질적으로는 많은 벤치마크에서 비엠 투니5보다 저희가 5강에서 다뤘듯이 더 성능이 잘 나오는 모델인데 보시다시피 68.8 대 63.2처럼 비엠 트니 5가 더 점수가 스쿼드에서 높게 나오는 걸 볼 수가 있습니다. 이런 현상이 다른 데이터셋 특히나 엔큐 같은 경우 완전 반대인데요. 비엠25는 점수가 잘 안 나오는 반면에 59.1 dpi 같은 경우는 78.4가 나오는 것을 보실 수가 있습니다. 이런 현상이 발생한 이유는 스쿼드의 어노테이션 바이어스가 이 단어의 오버랩을 유도를 하게 되고요. 이 오버랩은 실제로 비엠 투니5가 훨씬 더 유리한 셋업이죠. 왜냐하면 비엠프 투니5는 스파스한 단어 기반의 임베딩이기 때문에 리트리벌이기 때문에 단어가 겹치면 상당히 가져오기가 쉬워지고요. 디피알은 반대로 댄스 인베딩 스페이스에서 리트리벌 하기 때문에 그렇지가 않겠죠. 그래서 스쿼드만 반대 양상을 보여줍니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "[MRC] (8강)Reducing Training Bias.json",
        "lecture_name": "[MRC] (8강)Reducing Training Bias",
        "course": "MRC",
        "lecture_num": "8강",
        "lecture_title": "Reducing Training Bias",
        "chunk_idx": 3,
        "total_chunks": 8,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:f9489eb5149a0b40edcef87b33503df5683ae2893e0ea5ea27841c3f3b105557"
      },
      "token_estimate": 1079,
      "char_count": 2017
    },
    {
      "id": "transcript_mrc_mrc_8강reducing_training_bias_c004_230bd2",
      "content": "[MRC] [MRC] (8강)Reducing Training Bias\n\n다. 이런 현상이 발생한 이유는 스쿼드의 어노테이션 바이어스가 이 단어의 오버랩을 유도를 하게 되고요. 이 오버랩은 실제로 비엠 투니5가 훨씬 더 유리한 셋업이죠. 왜냐하면 비엠프 투니5는 스파스한 단어 기반의 임베딩이기 때문에 리트리벌이기 때문에 단어가 겹치면 상당히 가져오기가 쉬워지고요. 디피알은 반대로 댄스 인베딩 스페이스에서 리트리벌 하기 때문에 그렇지가 않겠죠. 그래서 스쿼드만 반대 양상을 보여줍니다. 다른 데이터셋 같은 경우 전부 다 디피알이 더 높죠. 하지만 이 두 개를 합치면 더 점수가 올라갈 수도 있는 것을 아실 수가 있습니다. 즉 어느 정도 상호보완적인 부분도 있는 거죠. 스쿼드에서 특히나 다른 부분에서는 근데 그렇지가 않은 걸 알 수가 있죠. 엔큐만 해도 두 개를 합쳤을 때 DPR보다 더 성능이 내려가는 걸 보실 수가 있고 트리비아 큐에이 같은 경우는 조금은 올라가긴 하지만 큰 차이가 없는 걸 알 수가 있고 더블 웹 퀘스천스나 이쪽은 성능이 오히려 내려가고요. 트랙은 조금 더 올라가긴 하지만 스쿼드만큼 올라가지 않는 걸 알 수가 있습니다. 따라서 이런 바이러스를 없애는 것이 좋은 퀘스천 엔서링 데이터셋, 좋은 MRC 데이터셋 만들 때 정말 중요하다고 좀 다시 한 번 강조를 드리고 싶은데요. 물론 이게 항상 가능하지는 않을 수 있고 또 이런 데이터셋을 활용하는 것 자체가 나쁘다는 것은 아닙니다. 하지만 뭐 가능하다면 저희가 이런 바이러스를 피해 가는 게 좋겠죠. 그래서 예를 들면 내추럴 퀘스천스 같은 경우는 이런 바이러스를 좀 피해가기 위해서 실제로 서퍼링 에비던스가 주어지지 않은 상황에서 실제 유저의 쿼리 이 경우는 사실 구글에서 유저들이 썼던 구글 서치 엔진에 썼던 쿼리를 가져와서 에노테이터들이 답을 찾는 방식으로 툴을 활용해서 애노테이션을 진행을 했고 이런 방식이 결국은 실제로 오디큐에 세팅과 상당히 유사하다고 볼 수 있기 때문에 비교적 바이러스가 적다고 할 수가 있겠습니다. 그리고 또 다른 바이러스가 있는데요. 이 경우 어떤 바이러스가 있냐면 사실 스쿼드 같은 경우는 패시지가 주어지고 주어진 패시지 내에서 질문과 답을 생성하다 보니까 사실 오디qa 오픈 도메인 퀘스천 엔서링의 어플리케브 하지 않은 질문들이 존재를 합니다. 아까 지난 렉처에서 드렸던 그런 질문과 비슷하죠. 미국의 대통령이 누구인가라는 질문을 했을 때 사실 이 질문은 오디qa에서는 상당히 적합하지가 않죠. 지금 대통령인가 5년 전 대통령 또는 10년 전 대통령 언제 때 대통령을 얘기하는 것인가에 대한 좀 스피스피케이션이 필요한데 패시지가 주어진 상태에서는 어쩌면은 스피스 파이가 돼 있기 때문에 이런 특정하는 프로세스가 필요가 없을 수도 있겠죠. 그러다 보니 이런 odqa에서 특정하기 힘든 질문들이 나오는 경우가 많아지고 이런 예제 같은 경우도 투 데이 이런 질문은 사실은 오디큐에에선 전혀 의미가 없는 질문이죠. 희가 누굴까요? 여기서 사실 알 수가 없죠. 그거 당연한 얘기겠지만 희가 누군지 안다 하더라도 사실 2달러로 뭘 하는지까지 특정하기도 쉽지가 않고요. 오디큐에 의해서 따라서 이런 바이러스도 존재를 한다는 점 말씀을 드립니다. 네 8강 본강을 마치도록 하겠습니다. 8강 실습 시작하도록 하겠습니다. 사실 오늘 실습은 저희가 8강 본강 때 나왔던 내용하고는 조금 관련보다는 사실 7강에서 미처 못 다뤘던 댄스 인베딩과 MRC를 연결하는 방법론에 대해서 다루도록 할게요. 그래서 댄스 인베딩은 잘 기억하실지 모르겠지만 저희가 5강에서 다뤘던 리트리벌 방법론이고요. 스파스보다 좀 더 나은 방식의 그리고 MRC 모델은 마찬가지로 똑같이 2강에서 활용했던 MRC 모델을 그대로 불러와서 사용하도록 하겠습니다. 자 여느 때와 같이 다시 런 타임에 가셔서 지피로 연결해 주시고요. 네 커넥트를 해주도록 하겠습니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "[MRC] (8강)Reducing Training Bias.json",
        "lecture_name": "[MRC] (8강)Reducing Training Bias",
        "course": "MRC",
        "lecture_num": "8강",
        "lecture_title": "Reducing Training Bias",
        "chunk_idx": 4,
        "total_chunks": 8,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:f9489eb5149a0b40edcef87b33503df5683ae2893e0ea5ea27841c3f3b105557"
      },
      "token_estimate": 1031,
      "char_count": 1908
    },
    {
      "id": "transcript_mrc_mrc_8강reducing_training_bias_c005_648df7",
      "content": "[MRC] [MRC] (8강)Reducing Training Bias\n\n다. 사실 오늘 실습은 저희가 8강 본강 때 나왔던 내용하고는 조금 관련보다는 사실 7강에서 미처 못 다뤘던 댄스 인베딩과 MRC를 연결하는 방법론에 대해서 다루도록 할게요. 그래서 댄스 인베딩은 잘 기억하실지 모르겠지만 저희가 5강에서 다뤘던 리트리벌 방법론이고요. 스파스보다 좀 더 나은 방식의 그리고 MRC 모델은 마찬가지로 똑같이 2강에서 활용했던 MRC 모델을 그대로 불러와서 사용하도록 하겠습니다. 자 여느 때와 같이 다시 런 타임에 가셔서 지피로 연결해 주시고요. 네 커넥트를 해주도록 하겠습니다. 네 먼저 설치를 똑같이 패키지를 설치해 주도록 할게요. 네 다음으로는 몇 개 필요한 중요한 라이브러리들을 가져오도록 하고요. 똑같죠 다음으로 저희 프리체인 더 댄스 인코더 모델을 밑에 쿠키에 가져오도록 할게요. 그래서 저희가 다운로드를 받고요. 이 파일을 여기서 이런 프리트윈 된 모델 저희가 학습을 다 하기에는 너무 시간이 오래 걸려 가지고 가져오는 거고요. 그다음에 이거를 타일로 익스트랙트 하도록 하겠습니다. 네 앞쪽이 다 풀렸습니다. 그래서 이 인코더 같은 경우는 결국 기억하시겠지만 어떤 문서가 들어왔을 때 문서에 해당되는 벡터를 아웃풋 해주는 그런 역할을 해주고요. 다음으로는 저희가 뭐 필요한 패키지들을 트랜스포머에서 가져와서 인코더를 클래스를 저희 여기 내부에서 정해 주도록 할게요. 그래서 먼저 버튼 모델과 토크나이저를 가져오고요. 그다음에 클래스를 정의해 주도록 하겠습니다. 그래서 보시면은 뭐 아주 디피크한 방법으로 클래스를 정의를 해 주고 포워드 쪽에 보시면은 버튼을 그냥 돌려주죠. 인풋 아이디랑 어텐션 마스크 토큰 아이디로 돌려주고 다만 저희는 인베딩을 뽑아내는 것이다 보니까 이제 아웃풋에서 이제 인덱스 첫 번째에 있는 인베딩을 가져와서 리턴을 해주도록 합니다. 그리고 실제로 이 클래스를 이용을 해서 모델을 불러오도록 할게요. 한번 정리를 해주고 보시면 아까 체크 포인트 에서 가져오는데 그래서 저희가 먼저 대부분의 것들은 버터 베이스 멀티링고 케이스를 활용하기 때문에 가져올 수 있지만 실제로 저희가 그 모델에 있는 파라미터들은 다운 받았던 걸 활용하는 거고요. 그다음에 실제로 다운받았던 걸 로딩하기 위해서 이런 방식으로 인코드를 각각 로딩을 해주고요. 모델 넥트 내에 있는 그래서 보시면 저희가 인코더 2개를 만들죠. 피 인코더랑 큐 인코더인데 피가 패시지 즉 지문 쪽 인코더고 큐 인코더가 퀘스천 쪽 인코더고 둘 다 따로 지금 존재하고 있습니다. 그래서 이 모델 딕트라는 파일은 딕셔널인 거고 2개 안에 바이너리가 2개가 있는데 하나는 피코더 하나는 키인 코더 이렇게 보시면 될 것 같아요. 저희가 다운받은 파일이죠. 다시 한 번 그다음에 토크나이저는 사실은 버트 베이스 머티링골 케이스와 똑같은 걸 사용하기 때문에 거기서 가져오도록 하겠습니다. 이러면은 로딩이 완료가 되고 다운을 받겠죠 버트 베이스 멀티 링고 모델을 확인 베이스에서요. 네 참고로 현재 진행 중인 곳은 저 초록색 화살표를 보실 수 있습니다. 이쪽에 보이죠. 지금은 모델 로딩 중인 거죠. 아까 다운받았던 파일에서 네 완료가 됐습니다. 자 그 여느 때와 같이 바로 스쿼드 콜 비1 데이터 셋을 다운 받는 걸로 시작을 해보도록 할게요. 익숙하시죠? 이건 그다음에 쿠다로 보내주는 펑션을 정의를 유틸리티 차원에서 해주도록 하고요. 그리고 저희가 지난 실습 때 만들었던 겟 웰레벤 다글 펑션을 또 정리를 할 텐데 이번에는 조금 다르죠. 저희가 이제 그 tfidf를 활용해서 문서를 가져오는 것이 아닌 저희가 지금 방금 만들었던 q인 코드와 피인 코드를 활용해서 가져오는 것이기 때문에 보시다시피 비슷하지만 좀 다릅니다. 이제 먼저 핀 코더를 먼저 이발 모드로 바꿔주고요. 그다음에 쿼리가 들어왔을 때 이거를 토크나이즈를 해 줍니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "[MRC] (8강)Reducing Training Bias.json",
        "lecture_name": "[MRC] (8강)Reducing Training Bias",
        "course": "MRC",
        "lecture_num": "8강",
        "lecture_title": "Reducing Training Bias",
        "chunk_idx": 5,
        "total_chunks": 8,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:f9489eb5149a0b40edcef87b33503df5683ae2893e0ea5ea27841c3f3b105557"
      },
      "token_estimate": 1035,
      "char_count": 1908
    },
    {
      "id": "transcript_mrc_mrc_8강reducing_training_bias_c006_d59484",
      "content": "[MRC] [MRC] (8강)Reducing Training Bias\n\n다. 이제 먼저 핀 코더를 먼저 이발 모드로 바꿔주고요. 그다음에 쿼리가 들어왔을 때 이거를 토크나이즈를 해 줍니다. 원래 저희가 활용한 토크나이저로 멀티링골 버트 포크나이저죠. 그다음에 퀘스천 인베딩을 큐인 코더에 이 토큰 라이스 된 인풋을 넣음으로써 인베딩을 갖고 오고요. 일단 저희가 이걸 계산한 다음에 지표 상에 있는 인베딩을 CPU로 가져옵니다. 편의상 그다음에 패세지 인베딩 같은 경우는 저희 코퍼스에 있는 모든 패시지를 다 들여다보면서 퀘스천과 똑같은 방식으로 저희가 토크나이즈를 해 주고 인베딩은 피인 코드를 써서 옵테인 해 주고 그다음에 인베딩들을 전부 다 어펜드를 해줍니다. 그다음에 이 인베딩들을 전부 다 결국에는 저희가 하나로 모아가지고 하나의 매트릭스로 만들어주는 거죠. 이 매트릭스는 결국은 폐쇄제의 개수와 인베딩 디멘션의 크기로 돼 있다고 보시면 되고 이거를 퀘션 인베딩과 매트릭스 애플리케이션을 해서 즉 각각 인베딩에 대해 다 프로덕트를 해가지고 스코어를 구해줍니다. 그다음에 저희가 이제 마지막으로 똑같은 방식으로 랭킹을 하는 거죠. 스코어에 따라서 가장 높은 문서가 뭔지를 찾는 거고 하나 이제 좀 주의하실 점은 보시다시피 이제 큐 인베딩 같은 경우는 저희가 퀘스천이 여러 개 있을 수 있다고 가정을 하고 넘 쿼리 디멘션을 하나 만들어 줬어요. 하지만 저희가 위에 보시면은 쿼리는 하나죠. 그러니까 즉 이 브레켓을 통해서 쿼리가 하나지만 그 브레킷을 하나 넣어줌으로써 디멘션이 하나 더 추가가 된 거죠. 그래서 저희가 만약에 쿼리를 여러 개를 한 번에 하고 싶다 하면은 쿼리가 이렇게 넣어줄 수 있겠죠. 그러면은 넘 쿼리는 두 개가 되겠죠. 어 저희가 여기서는 쿼리가 하나니까 하나로 진행을 하고 실제로 효율적으로 계산을 하기 위해서는 저기서 넘 쿼리를 추가해 주는 방식이 이 겟 웰레벤 닥을 여러 번 해주는 것보다 더 빠릅니다. 저희가 퀘스천이 2개가 있을 때 이 겟 웰레벤 d을 두 번 돌려주는 방식도 있겠지만 또는 쿼리를 아예 2개를 처음부터 받아 가지고 여기서 쿼리 2개를 받는 거죠. 또는 쿼리 리스트로 받은 다음에 여기 밑에서 브레켓을 없애주고 이렇게 해주는 것도 방법이겠죠. 이거는 사실 그 챌린지를 하실 때 편하신 방법대로 하시면 되고 한 번에 여러 개를 쿼리를 날리고 싶다 하시면 이런 방식을 추천을 드립니다. 네 이렇게 한 다음에 랭크를 해서 똑같은 방식으로 스파스 인베딩 쪽과 티드 비슷한 방식으로 아웃풋을 내보내 주게 됩니다. 네 펑션을 정의를 했고요. 디프네션 자 그다음에는 이제 똑같은 저희가 방식으로 실험을 해보면 되겠죠. 그래서 일단은 간단하게 랜덤 시드를 하나 정해 놓을게요. 왜냐하면 저희가 내분마다 다른 것들을 랜덤하게 하면은 좀 위패도스가 힘드니까요. 그래서 이건 항상 습관을 들이시는 게 좋고요. 랜덤 시드를 해주는 게 저희가 발리드 콜퍼스 같은 경우는 그냥 카페인 페스트를 할게요. 저희가 모든 콜퍼스를 가져오는 예전에 많이 봤던 코드죠. 그리고 여기서 하나의 샘플 idx를 랜덤하게 고르게 됩니다. 그다음에 해당되는 쿼리도 가져오겠죠. 샘플 아dx에 해당되는 쿼리를 가져오고 그리고 이게 잘 됐을 때 이 쿼리랑 관련이 있는 문서가 정답이 무엇이어야 되는지 즉 그라운트 로스를 정의를 하고요. 당연히 이제 그라운트스가 발리드 콜퍼슨이 없다고 한다면 이때는 더해주도록 하고 좀 심플하게 하는 방법이죠. 그다음에 저희가 한번 프린트를 해볼게요. 어떤 그라운트로스가 저기 나왔는지를 한번 보죠. 실제로 보시면 질문은 북한의 무장 공비에게 살해당한 김영삼의 어머니 이름은 이었고 이거에 저희가 잘 리트을 한다면 나와야 되는 문서는 제14대 대통령 선거에서 김영삼으로 시작하는 문서입니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "[MRC] (8강)Reducing Training Bias.json",
        "lecture_name": "[MRC] (8강)Reducing Training Bias",
        "course": "MRC",
        "lecture_num": "8강",
        "lecture_title": "Reducing Training Bias",
        "chunk_idx": 6,
        "total_chunks": 8,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:f9489eb5149a0b40edcef87b33503df5683ae2893e0ea5ea27841c3f3b105557"
      },
      "token_estimate": 1010,
      "char_count": 1858
    },
    {
      "id": "transcript_mrc_mrc_8강reducing_training_bias_c007_918b03",
      "content": "[MRC] [MRC] (8강)Reducing Training Bias\n\n다. 자 그럼 실제로 저희가 한번 이거를 문서 셋 내에서 한번 가져와 보도록 할게요. 실제로 저희가 하는 방식은 간단하죠. 아까 보셨다시피 예전 실습과 마찬가지로 닭 아이디어를 가져오는데 피인 코더와 큐 인코더 그리고 쿼리와 케이는 1로 해줘서 답변을 가져오고 이 각 아이디에 대한 문서를 프린트를 해보도록 할게요. 이거는 제가 카페 페이스트를 해보고 이건 프린트 펑션입니다. 단순하게 답변을 추출하게 되면은 보시다시피 올바른 답이 14대 대통령 선거에서 김영삼 김대중의 단어들로 시작하는 문서가 올바르게 RTV 된 것을 볼 수가 있습니다. 저희가 또 그리고 상위 5개의 문서 폐쇄지를 추출해서 점수를 확인할 수도 있는데요. 예를 들면은 이런 식으로 해주면 케를 5로 해주면은 5개 문서가 나오겠죠 그다음에 이제 이거에 대해서 점수를 한번 보면서 각각 가장 높은 것부터 낮은 것까지 어떤 문서인지 한번 살펴볼게요. 간단한 FLF를 통해서 실제 랭크랑 패시지의 점수랑 패시지의 내용을 볼 수 있겠죠. 보시게 되면은 가장 첫 번째 나왔던 문서는 아까 봤던 14대 대통령 선거에서로 시작하는 문서고요. 점수가 187점인 걸 알 수가 있고 이게 이널 프로덕트 스코어죠 퀘스천 인베딩과 패세지 인베딩 사이의 이너 프로덕트의 그 크기고 두 번째 패시지 같은 경우는 관련이 좀 덜해 보이죠. 북한 북방 한계선 NLL에 대한 얘기고 세 번째도 그렇고 좀 아래쪽에 있는 문서들은 확실히 좀 관련성이 적어 보입니다. 자 이제는 이 댄스 리트리벌 모델을 활용하고 엠알씨 모델을 똑같은 걸 가져와서 한번 오픈 도메인 큐에이를 최종적으로 다시 한번 연결을 해볼게요. 엠알씨 쪽은 지난 액체에서 다뤘기 때문에 좀 빠르게 넘어갈게요. 이제 엠알씨 쪽인데 자 똑같이 정리를 해 주고요. 저희가 똑같은 모델을 불러오도록 하겠습니다. 그리고 다운 받는 데 좀 시간이 걸리고요. 더 큰 나이저도 마찬가지로 정의를 해주도록 할게요. 네 그다음에 MRC 모델은 저희는 항상 이발 모드일 테니까 학습을 추가적으로 안 하기 때문에 2발 모드로 바꿔주고 그리고 똑같은 펑션을 가져옵니다. 지난번에 저희가 썼던 앤서를 가져오는 펑션이요. 그리고 잘 되는지 한번 확인해 볼까요? 한번 네 저희가 확인해 보면 잘 되는 걸 확인해 봤고요. 그러면 이제 odqa를 연결시켜 보겠습니다. odqa 펑션은 똑같죠 거의 살짝 다른 거는 그 인풋이 피인 코더와 큐인 코더가 들어온다는 것만 다르고 저희가 지난번에 봤던 스파스 인베딩 리트리버를 활용한 모델과 동일합니다. 설명은 생략하도록 할게요. 그리고 이제 다시 저희가 오디qa를 다 했으니 한번 질문을 넣어보도록 할게요. 쿼리는 대한민국의 대통령은 누구인가 이렇게 질문을 똑같이 넣어보고요. 마찬가지로 오픈 도메인 이제 QA에서 쿼리와 바리드 콜퍼스를 넣어주고 피 인코더 인코더 그리고 MRC 모델 그리고 토크나이저 마지막으로 키는 1로 한번 저희가 여기서 보시면 보시다시피 지문을 특정해 주지 않고 질문이랑 질문에 답을 갖고 있는 큰 콜퍼스와 그리고 인코더만 넣어줬죠. 일반적인 odqa 모델이라고 보시면 될 것 같고 돌렸을 때 답이 보시면 김영삼으로 잘 나오는 것을 아실 수가 있습니다. 네 아까 그 지난 렉처처럼 이거를 데모 형태로 만들 수도 있고요. 인풋을 통해서 인풋이라는 펑션을 통해서 데모 형태로 만들 수 있고 어 또 이런 방식으로 저희가 오디qa를 만들 수 있는 거를 좀 오늘 확인해 봤고요. 실제로 여러분이 챌린지에서 좀 더 추천을 드리는 방법은 이런 그 댄스 리트리버를 활용을 하거나 또는 스파스 리트리버를 활용하는 것도 고려를 해보면 좋겠지만 댄스 리트리버를 꼭 활용을 해서 최종적인 오픈 도메인 퀘스천 엔서링 모델을 만드는 거를 추천을 드립니다. 네 오늘까지 내용으로 사실상 챌린지를 시작하실 수 있고요. 9강이랑 10강의 내용은 조금 더 추가적인 어떤 분들한테는 좀 도움이 될 수도 있는 내용을 다루고 있으니까 이제 챌린지를 이제 금방 시작하시면 좋을 것 같습니다. 네 그러면은 8강 실습 여기서 마치도록 하겠습니다. 감사합니다.",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "[MRC] (8강)Reducing Training Bias.json",
        "lecture_name": "[MRC] (8강)Reducing Training Bias",
        "course": "MRC",
        "lecture_num": "8강",
        "lecture_title": "Reducing Training Bias",
        "chunk_idx": 7,
        "total_chunks": 8,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:f9489eb5149a0b40edcef87b33503df5683ae2893e0ea5ea27841c3f3b105557"
      },
      "token_estimate": 1086,
      "char_count": 2026
    }
  ]
}