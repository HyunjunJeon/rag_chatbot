{
  "source_file": "[MLforRecSys] (9강) 인과성과 기계학습 I.json",
  "lecture_name": "[MLforRecSys] (9강) 인과성과 기계학습 I",
  "course": "MLforRecSys",
  "total_chunks": 17,
  "chunks": [
    {
      "id": "transcript_mlforrecsys_mlforrecsys_9강_인과성과_기계학습_i_c000_5b3580",
      "content": "[강의 녹취록] 과목: MLforRecSys | 강의: 9강 | 제목: 인과성과 기계학습 I\n\n네 안녕하세요 여러분 이번에는 저희 인과성과 기계 학습에 대해서 한번 살펴보도록 하겠습니다. 인과성이라는 말이 어쩌면 좀 친숙하지 않을 수도 있을 텐데요. 인과성이라는 게 무엇이고 그다음에 그러한 인과성을 추론하기 위한 알고리즘들이 무엇이고 그다음에 그러한 추론을 좀 더 심화적으로 기계 학습과 연관 지어서 할 수 있는 방법론에 대해서 살펴보도록 하겠습니다. 먼저 첫 번째로는 아무래도 인과성과 관련된 강의 내용은 여러분들께서 뭐 접하지 않았을 가능성이 크기 때문에 인과성이 무엇이고 왜 고려해야 되는 것인지 저희가 한번 요약해서 같이 한번 보도록 하겠습니다. 자 이러한 인과성은 의료 데이터에서 사실 굉장히 많이 활용되는 요소입니다. 즉 이러한 환자가 있다고 할 때 이러한 환자한테 우리가 약을 투약을 해야 될지 말아야 될지 결정을 한다든지 아니면 a라는 약을 주는 게 좋을지 아니면 b라는 약을 주는 게 좋을지 결국 우리가 결정을 함에 있어서 인과성을 고려해야 된다라는 뜻입니다. 그러한 인과성은 상관관계랑은 매우 상이합니다. 즉 다음과 같은 예시가 굉장히 유명한 예시인데요. y축은 피파 랭킹입니다. 그리고 스축은 코비디 랭킹이에요. 코비드가 이제 얼마나 많이 걸리거나 얼마나 많이 사망했는지 입니다. 자 그랬을 때 피파 랭킹과 코비드 랭킹은 아주 좋은 양의 상관관계를 갖고 있어요. 보시면 그렇죠 지금 무슨 말이에요? 코비드 랭킹이 1위에 가까워질수록 그렇죠 피파 랭킹도 1위에 가까워진다라는 겁니다. 즉 상관관계를 우리가 잘못 해석하면은 어 그러면은 축구를 잘하기 위해서는 우리 코비드 확진자 수가 많아야 되나 즉 코비드를 많이 걸리면 축구를 잘 해주나 아니면 축구를 못 해주면은 코비드가 점점 확진자 수가 줄어드나라는 잘못된 의사 결정을 하게 됩니다. 즉 이런 거는 우리가 코릴레이션이라고 부르는 것이죠. 그리고 그러한 코릴레이션은 커제이션 즉 인과성과는 다른 요소입니다. 자 인과성을 나타내는 중요한 예시 한 가지 또 한번 보도록 하겠습니다. 자 다음과 같은 환자 몸 상태가 있다고 하겠습니다. 몸 상태는 비교적 괜찮은 상황도 있고 아니면 극심하게 안 좋은 상황도 있습니다. 그때 치료약 a를 주거나 치료약 비를 주는 상황을 가정하겠습니다. 자 그리고 사망률 즉 1400명의 환자 몸이 괜찮은 환자에 대해서 우리가 a라는 약을 줬을 때 210명의 사망자가 발생한 상황이고요. 그다음에 몸이 좀 극심하게 안 좋은 환자에 대해서 100명에 대해서 우리가 30명이 사망했다는 뜻입니다. a라는 약을 투약하면 b라는 약을 투약하면 이렇다는 뜻이고 토탈로는 우리가 이 환자의 수를 합하면 1500명이고 총 240명이 a라는 약을 통해서 사망한 것을 우리가 확인할 수가 있습니다. 그랬을 때 우리가 어떠한 약이 과연 더 좋은 약인지 알고 싶은 거예요. 즉 에라는 약이 추천해 줘야 되는 건지 아니면 b라는 약을 추천해 줘야 되는 것인지 문제를 풀고 싶은 겁니다. 자 이러한 문제 상황은 추천 시스템에서도 굉장히 중요할 수가 있습니다. 특정한 영화 추천뿐만 아니라 이런 가격을 설정한다고 했을 때 즉 여기 컨디션에서는 아이템의 퀄리티가 올 수가 있을 것이고요. 그다음에 여기에는 가격을 올릴지 가격을 낮출지 그다음에 여기에는 이제 사망률이 아니라 실제로 유저가 그래서 구매를 할 건지 안 할 건지를 우리가 모델링 할 수 있겠죠. 그래서 유저가 많이 구매하기 위해서 또는 우리의 매출을 극대화하기 위해서 가격을 높이는 게 좋을지 가격을 낮추는 게 좋을지 결정하는 문제로 우리가 해석도 할 수가 있습니다. 자 이러한 문제를 또 다르게도 우리가 해석을 하면 컨디션을 뉴스 기사의 작성 시간으로 볼 수도 있겠죠. 뉴스를 밤에 썼는지 아침에 썼는지 또는 이제 밤에 기사가 나왔는지 기사가 뭐 아침에 나왔는지 그렇죠 또는 뭐 새벽에 나왔는지 그러면 새벽보다는 뭐 아침이나 밤이 더 클릭이 많을 겁니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "[MLforRecSys] (9강) 인과성과 기계학습 I.json",
        "lecture_name": "[MLforRecSys] (9강) 인과성과 기계학습 I",
        "course": "MLforRecSys",
        "lecture_num": "9강",
        "lecture_title": "인과성과 기계학습 I",
        "chunk_idx": 0,
        "total_chunks": 17,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:a5abe758db6c94e58a6adffe5521d462055b94444e49d3d70f1542f8a75fffb4"
      },
      "token_estimate": 1059,
      "char_count": 1949
    },
    {
      "id": "transcript_mlforrecsys_mlforrecsys_9강_인과성과_기계학습_i_c001_8e31a8",
      "content": "[MLforRecSys] [MLforRecSys] (9강) 인과성과 기계학습 I\n\n다. 자 이러한 문제를 또 다르게도 우리가 해석을 하면 컨디션을 뉴스 기사의 작성 시간으로 볼 수도 있겠죠. 뉴스를 밤에 썼는지 아침에 썼는지 또는 이제 밤에 기사가 나왔는지 기사가 뭐 아침에 나왔는지 그렇죠 또는 뭐 새벽에 나왔는지 그러면 새벽보다는 뭐 아침이나 밤이 더 클릭이 많을 겁니다. 자 그다음에 여기 나와 있는 트리트먼트는 우리가 어떤 뉴스를 과연 연예 뉴스를 쓰는 게 좋을지 정치 뉴스를 쓰는 게 좋을지 그리고 그때 실제로 클릭을 했는지 안 했는지 이런 요소로도 우리가 고려할 수 있습니다. 그래서 우리가 결국 뉴스 클릭을 맥시마이즈 하기 위해서는 과연 어떤 카테고리의 뉴스를 작성해야 되는가에 대한 문제가 되는 것이죠. 자 그러면 여러분 여기서 결론이 뭘까요? 그래서 에라는 약을 추천해야 될지 아니면 b라는 약을 추천해야 될지 우리가 한번 정해보자는 겁니다. 어떤 약을 추천하면 좋을지 자 여기서 아니 선생님 애초에 에라는 약을 투약한 사람은 1500명이고 그중에서 240명이 사망했다면서요 그러면 사망률은 16%지 않습니까? 그리고 b라는 약을 투약한 사람은 총 550명이고 그중에서 105명이 사망했다면서요 그러면 사망률은 19%이지 않습니까? 그러면 a라는 약이 사망률이 더 낮으니까 16% 사망률이 더 낮은 a라는 약이 더 좋은 약 아닌가요? 라고 왜 이런 쉬운 걸 물어보나요라고 생각할 수가 있습니다. 그렇죠 하지만 이걸 물어보는 이유는 쉬운 문제가 아니기 때문에 여러분한테 이제 물어보고 한번 고민을 해보라는 뜻이었습니다. 자 왜 또 여기만 보게 되면은 여기만 보게 되면 자 환자의 몸 상태만 봅시다. 환자의 몸 상태가 마일드 즉 비교적 괜찮은 사람들만 한번 놓고 보자는 거예요. 이때는 뭐예요? 뭐가 좋습니까? b라는 약이 더 좋죠 사망률이 더 낮잖아요. 그렇죠 또 몸 상태가 극심히 안 좋은 사람만 두고 봅시다. 그땐 또 무슨 약이 좋습니까? b라는 약이 좋아요. 사망률이 더 낮아요. 몸 상태가 괜찮은 사람이나 몸 상태가 안 좋은 사람이나 비약이 다 좋은 거예요. 뭐지 그러면 b가 a보다 더 좋나 이제부터 여러분은 어 자명하지 않은 문제라는 거를 알게 될 겁니다. 자 정해진 답은 사실 없습니다. 그때그때 정답이 다르다는 뜻입니다. 자 한번 봅시다. 우리가 지금 변수가 3개가 있습니다. 컨디션 트리트먼트 아웃컴 이렇게 변수가 3개가 존재합니다. 자 그러면 그랬을 때 만약에 다음과 같은 인과성을 가지고 있는 그래프라고 가정할게요. 즉 무슨 말이냐면 c가 t에 영향을 주고 c가 o에도 영향을 주고 t가 5에 영향을 준다라는 뜻입니다. 이 화살표는 영향을 준다라고 생각하시면 됩니다. 자 그랬을 때 이거는 뭐예요? 그러면 현재의 몸 상태가 그렇죠 현재의 몸 상태가 트리트먼트 치료약과 그다음에 아웃컴에 동시에 영향을 미친다는 겁니다. 한번 생각해 보면 현재의 몸 상태가 사망률에 영향을 미칠 수 있겠죠 왜 현재 몸 상태가 괜찮은지 아니면 극심히 좋지 않은지가 사망률에 영향을 줄 수가 있으니까 그다음에 현재의 몸 상태가 또 트리트먼트에도 영향을 줄 수가 있습니다. 왜 애초에 좀 그런 치료약이 굉장히 독한 치료약이라고 한다면 몸 상태가 괜찮아야지만 그 약을 투약할 수 있고 몸 상태가 좋지 못하면 그 약은 투약하지 못할 가능성이 있지 않습니까 그래서 이러한 몸 상태가 트리트먼트랑 아웃컴에 동시에 영향을 미치는 상황인 것이고요. 그다음에 여기는 지금 트리트먼트 즉 어떠한 약을 먹었느냐가 사망률에 영향을 미치는 상황을 가정하고 있는 겁니다. 자 이런 상황일 때는 이런 문제 상황이라고 한다면 비가 좋습니다. 자 그런데 이번에는 이런 상황을 한번 가정해 볼게요. 아까와 다른 거는 씨와 티의 위치가 달라졌습니다. 아까는 시가 트리트먼트랑 아웃컴을 이제 인과하는 거였는데 영향을 주는 거였는데 여기서는 트리트먼트가 컨디션과 아웃컴에 영향을 주고 있습니다. 그 말은 우리가 이러한 문제 상황에서는 에이라는 약이 더 좋다는 거예요 아니 뭐 이거는 트리트먼트가 컨디션에 영향을 줄 수가 있나요 라고 반문하는 분도 계실 수가 있습니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "[MLforRecSys] (9강) 인과성과 기계학습 I.json",
        "lecture_name": "[MLforRecSys] (9강) 인과성과 기계학습 I",
        "course": "MLforRecSys",
        "lecture_num": "9강",
        "lecture_title": "인과성과 기계학습 I",
        "chunk_idx": 1,
        "total_chunks": 17,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:a5abe758db6c94e58a6adffe5521d462055b94444e49d3d70f1542f8a75fffb4"
      },
      "token_estimate": 1095,
      "char_count": 2037
    },
    {
      "id": "transcript_mlforrecsys_mlforrecsys_9강_인과성과_기계학습_i_c002_bc7dcf",
      "content": "[MLforRecSys] [MLforRecSys] (9강) 인과성과 기계학습 I\n\n다. 자 이런 상황일 때는 이런 문제 상황이라고 한다면 비가 좋습니다. 자 그런데 이번에는 이런 상황을 한번 가정해 볼게요. 아까와 다른 거는 씨와 티의 위치가 달라졌습니다. 아까는 시가 트리트먼트랑 아웃컴을 이제 인과하는 거였는데 영향을 주는 거였는데 여기서는 트리트먼트가 컨디션과 아웃컴에 영향을 주고 있습니다. 그 말은 우리가 이러한 문제 상황에서는 에이라는 약이 더 좋다는 거예요 아니 뭐 이거는 트리트먼트가 컨디션에 영향을 줄 수가 있나요 라고 반문하는 분도 계실 수가 있습니다. 뭐 예를 들어서 이런 건 있겠죠 자 트리트먼트 우리가 a라는 비를 고르는데 a를 고를지 b를 고를지 정합니다. 자 근데 특정한 약은 만약 우리가 뭐 a라는 약을 골랐다고 하겠습니다 자 아니면 b라는 약을 골랐다고 할게요. b라는 약을 골랐는데 b라는 약이 저기 먼 나라에 있어 가지고 우리나라에 수입되기까지 좀 시간이 오래 걸려요. 그럼 b라는 양을 정하면 시간이 오래 걸리니까 몸 상태가 바뀔 수 있는 겁니다. 안 좋게 그래서 트리트먼트를 정하면 몸 상태가 바뀌고 그때 이 아웃컴에도 영향을 미치고 이런 인과관계 그래프도 그래서 말이 되는 그래프죠. 그렇죠 그때는 a가 좋다는 겁니다. 즉 정해진 게 없다 그러면 여기서 a가 좋은지 비가 좋은지 어떻게 우리가 알 수 있냐 라고 하면은 그거는 이제부터 저희가 베이지볼 알고리즘과 같은 내용을 기본적으로 보고 넘어가도록 하겠습니다. 우리가 이러한 변수들을 이렇게 동그라미로 표현을 하고 변수들 간의 관계를 화살표로 표현을 하겠습니다. 자 그리고 여기 색칠이 되어 있는 변수도 있어요. 얘는 뭐냐면 관측이 된 변수라고 생각을 합시다. 조건으로 주어진 변수라고 생각하셔도 됩니다. 그랬을 때 우리가 3개의 그래프가 있다고 치면 이 3개의 그래프가 이렇게 스에서 와이로 가고 와에서 지로 가고 이렇게 일자로 쭉 가는 그래프를 생각할 수가 있겠죠. 이런 거를 우리는 체인 스트럭처라고 부릅니다. 얘도 체인 스트럭처죠. 얘도 체인 스트럭처인데 가운데가 관측이 된 조건으로 주어진 체인 스트럭처입니다. 자 그다음에 또 다른 스트럭처로는 포크 스트럭처가 있습니다. 또는 커먼 커즈라고 부르기도 합니다. 하나의 변수가 두 개를 다 야기하니까 하나의 공통된 인자가 두 개를 다 야기하니까 커먼 커즈라고 부르기도 합니다. 또는 포크라고 부르기도 해요. 여기에다가 이제 포크 딱 막대기만 세우면은 이렇게 포크 형태 닮았죠 그쵸 그래서 이걸 우리가 포크라고 부르는데 또 여기에 관측된 가운데 관측된 걸 이렇게 색칠을 할 수 있겠죠. 이 두 가지 구조는 동일한 특징을 공유하는데요. 어떤 특징이냐면 스랑 지가 독립이 아니라는 겁니다. 그런데 가운데 와이가 만약에 관측이 되면 와가 조건으로 주어지면 그때는 스랑 지가 조건부 독립이 된다는 특징을 갖고 있습니다. 즉 이러한 체인 스트럭처든 이러한 포크 스트럭처든 얘가 만족하고 이러한 체인 스트럭처든 이런 포크 스트럭처든 얘가 만족한다는 겁니다. 아시겠죠? 그래서 동일하게 예를 들어서 이걸 한번 봅시다. 아니 왜 x랑 g는 독립이 아니라고 합니까라고 한번 보면은 독립이 되려면 PX 콤마 지가 피지 곱하기 피스 두개의 곱으로 분해가 돼야 됩니다. 근데 한번 해보면 분해가 안 되거든요. 그래서 우리는 얘를 독립이라고 볼 수가 없습니다. 다른 예시로 우리가 보면은 x를 우리가 뭐 과거라고 생각을 하고 y를 현재라고 생각하고 지를 미래라고 한번 비유하겠습니다. 자 그러면 지금은 뭐예요? 와라는 게 주어진 게 아니에요 와가 관측이 되지 않았습니다. y가 관측이 안 됐어요. 자 그럼 현재를 모르는 상황에서는 과거랑 미래는 연결이 되어 있는 거예요. 그렇죠 자 그리고 여기 나와 있는 것도 마찬가지입니다. 만약에 이거는 가장 유명한 구조가 나이브 베이즈 구조입니다. 자 와라는 거는 이미지에 대한 클래스입니다. 강아지인지 고양이인지 자 그랬을 때 스는 강아지라고 할게요. 그러면 만약에 y가 강아지라는 클래스입니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "[MLforRecSys] (9강) 인과성과 기계학습 I.json",
        "lecture_name": "[MLforRecSys] (9강) 인과성과 기계학습 I",
        "course": "MLforRecSys",
        "lecture_num": "9강",
        "lecture_title": "인과성과 기계학습 I",
        "chunk_idx": 2,
        "total_chunks": 17,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:a5abe758db6c94e58a6adffe5521d462055b94444e49d3d70f1542f8a75fffb4"
      },
      "token_estimate": 1078,
      "char_count": 1990
    },
    {
      "id": "transcript_mlforrecsys_mlforrecsys_9강_인과성과_기계학습_i_c003_4c5424",
      "content": "[MLforRecSys] [MLforRecSys] (9강) 인과성과 기계학습 I\n\n다. 자 그러면 지금은 뭐예요? 와라는 게 주어진 게 아니에요 와가 관측이 되지 않았습니다. y가 관측이 안 됐어요. 자 그럼 현재를 모르는 상황에서는 과거랑 미래는 연결이 되어 있는 거예요. 그렇죠 자 그리고 여기 나와 있는 것도 마찬가지입니다. 만약에 이거는 가장 유명한 구조가 나이브 베이즈 구조입니다. 자 와라는 거는 이미지에 대한 클래스입니다. 강아지인지 고양이인지 자 그랬을 때 스는 강아지라고 할게요. 그러면 만약에 y가 강아지라는 클래스입니다. 그러면 강아지라는 클래스에서 강아지 이미지가 이렇게 두 개가 나온 거예요. x랑 지로 자 그러면 우리가 그때 y라는 클래스를 만약에 모르면 이게 관측이 안 됐으면 스랑 지는 독립이 아니잖아요. 왜 y가 관측이 안 됐습니다. 그러면 스가 만약에 강아지예요. 그러면은 지도 강아지라는 걸 우리는 바로 알 수 있게 돼요. 그 까닭에 독립이 아니다. 근데 가운데가 관측됐다고 가정하겠습니다. 그러면 y가 주어졌을 때 x 콤마 z는 이렇게 y x by g b y 이렇게 두 개로 쪼개지게 됩니다. 그렇죠 여러분 여기 한번 보면 얘는 베이지 룰에 따라서 이렇게 py 분의 피스 콤마 지콤마 와이가 되는 것이고 그렇죠 그다음에 피스 있고 피와 바스가 있고 피지바 와이가 이렇게 있다고 볼 수가 있습니다. 그렇죠 그리고 여기서 마코 어썸션을 통해서 바로 직전 것만 고려하면 된다고 할게요. 그래서 지바 스콤마 와가 아니라 지바 와가 되는 겁니다. 왜 마코 어섬션에 의해서 최근 것만 있으면 과거는 몰라도 된다는 거니까 자 그럼 여기에서 우리가 얘를 다시 쓰면 PC바 y가 여기 있고 PX py 바x py 얘를 다시 쓰면 이렇게 써지게 되겠죠. 그래서 얘가 이렇게 되니까 우리는 조건부 독립이 되는 겁니다. 자 외우기 어렵다라고 하면 이렇게 비유해서 보자는 겁니다. 스는 과거 y는 현재 z는 미래 즉 현재가 만약에 관측됐으면 과거는 더 이상 미래에 영향을 주지 않는다는 거예요. 현재가 관직됐으면 현재가 관측됐으면 현재가 관측됐으면 과거와 미래는 독립이라는 겁니다. 조건부로 여기도 마찬가지 자 이 와이라는 게 애초에 고양이라는 뭐 아니면 강아지라는 클래스로 관측이 됐으면 지는 x를 알든 모르든 상관없이 지는 무조건 고양이잖아요. 그렇죠 이 와에서 나온 거니까 즉 y만 알아도 지를 바로 알 수 있게 됩니다. 그 까닭에 독립이라고 볼 수가 있는 것이죠. 자 이렇게 체인 스트럭처와 포크 스트럭처를 봤고 마지막 가장 중요한 스트럭처입니다. 이모럴리티라는 또는 브이 스트럭처 또는 인버티드 포크 포크를 뒤집어 놓은 거죠. 또는 컬라이더 여기를 이제 같이 충돌해 버리는 구조로 우리가 부르는 다 같은 말입니다. 자 얘는 좀 달라요. 얘는 이렇게 색칠이 안 되어 있을 때 두 개가 독립입니다. 색칠이 되어 있으면 독립이 아니에요. 앞에서 봤던 거랑 반대죠. 앞에서는 색칠이 되어 있으면 조건부 독립이고 색칠이 안 되어 있으면 독립이 아니었어요. 얘는 독립이고 색칠이 안 되어 있으면 독립이고 색칠이 되어 있으면 주고의 독립이 안 된다는 겁니다. 얘는 이렇게 기억하시면 쉬워요. 스는 남성 지는 여성 그다음에 와는 우리가 뭐 베이비가 됐든 뭐 같이 키우는 강아지가 됐든 그러한 이제 같이 뭔가를 함께 하는 요소로 생각을 하겠습니다. 자 그러면 우리가 y라는 존재가 없으면 x라는 z는 여전히 독립이에요. 뭐 비유하자면 뭐 어디까지 비유로 만약에 같이 같은 취미를 갖고 있거나 같이 강아지를 키우거나 같이 아기가 있거나 뭐 같이 식사를 많이 하거나 뭐 그런 게 만약에 없다고 치면 XR 지는 언제든지 헤어질 수 있는 독립 관계 반면에 x랑 지가 함께 아기를 낳았거나 같이 강아지나 고양이를 키우거나 아니면 같이 식사를 많이 하거나 같은 취미를 갖고 있거나 뭔가 같이 함께 하는 게 있다고 하면은 뭔가 이제는 뭔가 남성과 여성과 이제 두 명이 독립이라고 말하기 어려운 상황이 되는 것이죠. 이렇게 비유를 하면은 좀 비교적 쉽게 이해가 되시지 않을까 싶습니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "[MLforRecSys] (9강) 인과성과 기계학습 I.json",
        "lecture_name": "[MLforRecSys] (9강) 인과성과 기계학습 I",
        "course": "MLforRecSys",
        "lecture_num": "9강",
        "lecture_title": "인과성과 기계학습 I",
        "chunk_idx": 3,
        "total_chunks": 17,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:a5abe758db6c94e58a6adffe5521d462055b94444e49d3d70f1542f8a75fffb4"
      },
      "token_estimate": 1067,
      "char_count": 1999
    },
    {
      "id": "transcript_mlforrecsys_mlforrecsys_9강_인과성과_기계학습_i_c004_b122f6",
      "content": "[MLforRecSys] [MLforRecSys] (9강) 인과성과 기계학습 I\n\n다. 그러면 다시 돌아와서 이 문제 상황 한번 볼게요. 여기서 보면은 컨디션 c가 있고 그렇죠 트리트먼트 아웃컴이 있습니다. 여기서 컨디션 c가 트리트먼트로도 영향을 미치고 아웃컴으로도 지금 영향을 미치는 걸 볼 수가 있습니다. 이런 걸 우리는 컴파운더라고 부릅니다. 트리트먼트에서 영향을 미치고 결과에도 영향을 미치고 컴파운더 또는 뭐 교란 변수라고도 우리가 부릅니다. 자 이런 상황에서 결국 우리가 하고 싶은 건 뭔가요? 우리는 티에서 아웃컴으로 가는 커절 관계만 알고 싶은 겁니다. 그런데 즉 t에서 5로 가는 이 커절 관계만 알고 싶은 거예요. 정말 이 트리트먼트 a라는 약이 사망에 미치는 인과적인 관계가 얼마인지 알고 싶다는 거예요. 추천 시스템으로 비유하면 우리가 특정한 영화를 추천을 했기 때문에 얘가 정말 본 것인지 아니면 다른 것 때문에 얘가 본 것인지 우리가 알고 싶다는 겁니다. 반대로 우리가 마케팅을 했기 때문에 네이버에 배너 광고를 띄웠기 때문에 클릭을 한 것인지 아니면 뭐 다른 여러 가지 이유로 클릭을 한 것인지 우리는 알고 싶다는 거예요. 왜 그래야지 이 마케팅으로 인한 정말 인과적으로 몇 명이나 들어왔는지를 우리가 알아야지 마케팅의 효과를 정확하게 추산이 가능한 거니 그걸 우리가 어떻게 할까 즉 t에서 5로 가는 이 관계만 우리가 알고 싶은 거예요. 자 그런데 우리가 만약에 티에서 5로 가는 이 관계를 일단 생략하고 이것만 그래프를 보겠습니다. 자 그러면 어떻게 돼요? 티랑 오가 독립이라고 했나요? 독립이 아니라고 했나요? 여러분 앞에서 봤을 때 자 이런 씨 티5 이렇게 했을 때 자 포크 스트럭처죠 그리고 관측된 게 없습니다. 이때는 티랑 o가 독립이 아니라고 했습니다. 왜 이렇게 공이 굴러갈 수가 있다라고 생각하시면 됩니다. 즉 우리가 여기서 독립인지 아닌지는 공이 만약에 굴러갈 수 있으면 독립이 아닌 거예요. 그래서 우리가 베이지 볼 알고리즘이라고 부르는 겁니다. 이럴 때는 공이 막 굴러가고 공이 또 굴러갈 수 있어요. 공이 또 이렇게 굴러가고 공이 딱 굴러갈 수 있어요. 근데 여기서는 여기가 관측되면 공이 딱 가다가 막힌다는 겁니다. 또 공이 딱 가다가 막힌다는 겁니다. 그래서 스랑 니가 독립이다 y가 주어지면 반대로 이런 거는 여기서는 우리가 반대로 여기서는 공이 굴러갔다 다시 올 수 있습니다. 근데 관측이 되면 공이 이제 못 굴러가게 되는 상황이 죄송합니다. 이때는 우리가 공이 굴러갈 수 있는 상황이 되고 여기서는 공이 못 굴러가는 상황이 된다고 했습니다. 반대의 상황이라고 말씀드렸죠. 그래서 공이 못 굴러가면 우리가 독립 그렇죠 공이 굴러가면 독립이 아니다 입니다. 자 여기서는 CTO가 있을 때 t에서 5로 공이 굴러갈 수 있다고 했잖아요. 씨가 관측이 되면 그때 막히는 거지 아니면은 관측이 안 될 때는 t랑 5가 독립이 아니라고 했습니다. 즉 그 말은 t에서 5로 공이 굴러갈 수 있다는 거고 티에서 씨를 통해서 5로 영향을 주기도 한다는 겁니다. 즉 우리는 티에서 5로 가는 딱 이 영향력만 알고 싶은 건데 그게 어렵다는 거예요. 왜 이렇게 뒤로 가는 영향력도 있으니까 즉 영향력이 두 개가 있는 겁니다. t에서 5로 가는 거 t에서 c를 거쳐서 5로 가는 거 그래서 우리는 이러한 영향력을 줄이고 싶은 거예요. 없애고 싶은 겁니다. 이 영향력을 어떻게 없애면 될까요? 씨가 만약에 컨디션으로 주어지면 우리는 배웠죠. 씨가 컨디션으로 주어지면 티랑 오가 시가 주어지면 조건부 독립입니다. 즉 이렇게 못 간다는 말이에요. 그래서 이 패스가 막힙니다. 그래서 우리는 이 패스에 대한 영향 t에서 5로 가는 영향력만 수치화를 할 수가 있는 겁니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "[MLforRecSys] (9강) 인과성과 기계학습 I.json",
        "lecture_name": "[MLforRecSys] (9강) 인과성과 기계학습 I",
        "course": "MLforRecSys",
        "lecture_num": "9강",
        "lecture_title": "인과성과 기계학습 I",
        "chunk_idx": 4,
        "total_chunks": 17,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:a5abe758db6c94e58a6adffe5521d462055b94444e49d3d70f1542f8a75fffb4"
      },
      "token_estimate": 984,
      "char_count": 1844
    },
    {
      "id": "transcript_mlforrecsys_mlforrecsys_9강_인과성과_기계학습_i_c005_0b1e43",
      "content": "[MLforRecSys] [MLforRecSys] (9강) 인과성과 기계학습 I\n\n다. t에서 5로 가는 거 t에서 c를 거쳐서 5로 가는 거 그래서 우리는 이러한 영향력을 줄이고 싶은 거예요. 없애고 싶은 겁니다. 이 영향력을 어떻게 없애면 될까요? 씨가 만약에 컨디션으로 주어지면 우리는 배웠죠. 씨가 컨디션으로 주어지면 티랑 오가 시가 주어지면 조건부 독립입니다. 즉 이렇게 못 간다는 말이에요. 그래서 이 패스가 막힙니다. 그래서 우리는 이 패스에 대한 영향 t에서 5로 가는 영향력만 수치화를 할 수가 있는 겁니다. 시에 대해서 우리가 조건을 걸어주게 되면 자 그래서 우리는 결국 문제가 어떻게 바뀌게 되냐면요. 우리가 알고 싶은 건 여기 나와 있는 두 칼큘러스라고 부르는 건데요. 얘는 특별한 게 아니라 정말 인과적인 효과를 보고 싶다는 거예요. 자 나는 정말 에라는 약을 줬을 때 사망에 영향을 미치는 인과적인 효과를 보고 싶다 그냥 조건부 확률 그냥 컨디션 그냥 그 코릴레이션이 아니라 정말 인과적인 걸 보고 싶다라고 할 때 이런 조라고 나타납니다. 자 그러면 얘는 우리가 실제로 계산을 이걸 정말 정확하게 하려면 어떻게 할 수 있냐면 사람을 우리가 모아서 랜덤하게 야 이 사람은 a라는 약 주고 저 사람은 b라는 약을 주고 랜덤하게 다시 실험을 하는 거예요. 그러면 얘는 정확히 추정할 수 있는데 그거는 윤리적으로나 비용적으로나 불가능합니다. 그래서 우리가 많이 하는 게 다음과 같은 인과추론인 거예요. 정말 이 인과관계를 알고 싶으면 아까 어떻게 한다고 했습니까? t가 기본으로 주어지는 것뿐만 아니라 씨도 우리가 기분으로 주어지고 y에 가해지는 영향력을 보자는 거예요. 즉 씨를 기분으로 주자는 겁니다. 왜 c를 기분으로 줘야지 이렇게 뒤로 가는 패스가 막히고 커져 패스만 남게 되니까 그래서 t가 기분으로 주어지는 것뿐만 아니라 c까지 기분으로 주어져 버리자 색칠해버리자 그러면 우리가 c가 주어질 확률 곱하기 c까지 주어졌을 때 실제 사망률을 보게 되면 우리는 이렇게 뒤로 넘어가는 패스는 막히게 되고 티에서 5로 가는 정말 인과적인 효과만 추론할 수 있게 된다라는 뜻입니다. 자 그래서 한번 이거를 계산을 한번 해보면 자 시라는 거는 결국 마일드거나 그렇죠 아니면 시피어 하거나 두 개 중에 하나입니다. 그럼 a라는 약을 줬을 때는 한번 저희가 보도록 할게요. 그때는 우리가 컨디션이 비교적 괜찮은 경우 그렇죠 그다음에 비교적 괜찮지 않을 경우 이렇게 있겠죠 얘가 지금 여기에 대응된다라고 보면 되겠죠. 즉 컨디션도 주어지고 마일드로 그다음에 트리트먼트도 에라는 약으로 주어졌을 때 그때 와는 0.15입니다. 그래서 여기 0.15가 있는 거예요. 그다음에 씨일 확률은 즉 마일드일 확률은 얼마입니까? 마일 들 확률은 지금 한번 보시면 1450명 1550명 2050명 중에서 전체 2050명 중에서 마일드인 컨디션일 확률은 1450입니다. 그래서 이만큼 있는 거예요. 더하기 자 이번에는 몸 상태가 극심히 안 좋을 확률은 250명 중에 600명입니다. 그리고 그때 우리가 a라는 약을 주면 사망률은 0.3 이겁니다. 비도 똑같이 하시면 돼요. 그럼 어떻게 된다 실제 컨트롤 임팩트는 이렇게 나와요. a로 인해서 사망에 영향을 미치는 정도는 19.4%, 비로 인해서 사망에 영향을 미치는 정도는 12.9%가 나옵니다. 앞에서 봤던 이런 수치들과는 확연히 다른 수치가 나오죠. 즉 이런 식으로 우리가 커절 관계를 추론할 수 있게 된 겁니다. 그러면 이걸 우리가 어떻게 했냐 공이 굴러갈 수 있는 다른 패스는 다 막고 이렇게 t에서 5로 다이렉트로 가는 우리가 궁금한 게 정말 t에서 5로 가는 이 다이렉트 커절 관계니까 이게 정말 얼마나 영향을 미치는지인 거니까 나머지 패스는 우리가 막아두고 진행을 하면 이렇게 추론할 수 있다입니다. 자 이런 상황은 여러분들께서 한번 또 해보세요. 이런 상황이 돼서 한번 해보시면은 그때는 반대로 a가 좋다는 것을 우리가 알 수 있게 됩니다. 아시겠죠? 네 여러분 저희가 계속해서 보고 있는 것은 이렇게 코릴레이션과 커셜리티가 다르다라는 것입니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "[MLforRecSys] (9강) 인과성과 기계학습 I.json",
        "lecture_name": "[MLforRecSys] (9강) 인과성과 기계학습 I",
        "course": "MLforRecSys",
        "lecture_num": "9강",
        "lecture_title": "인과성과 기계학습 I",
        "chunk_idx": 5,
        "total_chunks": 17,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:a5abe758db6c94e58a6adffe5521d462055b94444e49d3d70f1542f8a75fffb4"
      },
      "token_estimate": 1068,
      "char_count": 2015
    },
    {
      "id": "transcript_mlforrecsys_mlforrecsys_9강_인과성과_기계학습_i_c006_dcbd07",
      "content": "[MLforRecSys] [MLforRecSys] (9강) 인과성과 기계학습 I\n\n다. 자 이런 상황은 여러분들께서 한번 또 해보세요. 이런 상황이 돼서 한번 해보시면은 그때는 반대로 a가 좋다는 것을 우리가 알 수 있게 됩니다. 아시겠죠? 네 여러분 저희가 계속해서 보고 있는 것은 이렇게 코릴레이션과 커셜리티가 다르다라는 것입니다. 즉 이러한 커셜 그래프가 있다고 할 때 물론 실제로는 이런 커셜 그래프뿐만 아니라 더 다양한 커셜 그래프가 있을 겁니다. 다만 저희는 우선 이러한 커셜 그래프에 대해서 먼저 우선적으로 생각을 해 보겠습니다. 자 이럴 때 우리가 앞에서 봤던 게 뭡니까 이 트리트먼트가 이 아웃컴에 미치는 영향을 우리는 보고 싶은데 어떠한 영향 인과적인 영향만 보고 싶은 겁니다. 그래서 이렇게 다른 패스 여기서는 우리가 뒤로 돌아간다고 해서 백도어 패스라고 부릅니다. 그래서 그러한 백도어 패스를 우리가 어떻게 좀 해결할 수 있는지 이러한 컨디션을 통해서 그렇죠 이런 컴파운더에다가 우리가 컨디션을 줌으로써 해결을 할 수 있다고 했습니다. 자 이렇게 백도어 패스를 우리가 어저스먼트 하는 방법이 있었고요. 실제로 가장 좋은 방법은 어떤 거냐면 다음과 같이 랜덤 마이스 컨트롤 트라이어를 하는 것입니다. 자 이거를 결국 보고 싶은 것인데요. 저희는 지금 하고 있는 게 뭐냐면 첫 번째는 콜릴레이션인 거죠. 왜 t에 대한 조건부 확률이지 않습니까 두 번째는 특정한 트리트먼트를 정말 우리가 가했을 때의 y 값입니다. 즉 인과적인 관계를 나타내는 게 여기 나와 있는 두 오퍼레이션이라고 한다고 했습니다. 지금 무슨 말이냐면 우리가 이미 관측된 테이블 값이 있습니다. 어떤 a라는 약을 먹은 사람들은 얼마큼 뭐 몸이 회복됐고 b라는 약을 먹은 사람은 몸이 얼마큼 회복됐고 그러한 테이블을 보고 우리가 조건부 확률을 계산하는 거는 코릴레이션이에요. 여기 아래에 있는 두라는 것은 그런 콜레이션이 아니라 커즐리티인 거고 이거를 계산하는 가장 쉽지만 어려운 방법은 랜덤 마이스 컨트롤 트라이어를 하는 것입니다. 즉 무슨 말이냐면 다음과 같이 우리가 다시 실험을 랜덤하게 하는 거예요. 자 앞에서 이미 관측된 테이블 값이 있다고 했습니다. a라는 약을 먹은 사람들은 얼마큼 났고 b라는 약을 먹은 사람은 얼마큼 났고 우리가 실험한 게 아니에요. 과거에 이미 실험되었던 결과인 겁니다. 자 그 실험에서는 a라는 약을 먹은 사람들과 b라는 약을 먹은 사람들이 정말 랜덤하게 나뉘어져 있는 건지 아니면은 뭐 에라는 약은 비싸기 때문에 좀 더 뭐 돈이 많고 건강한 분들이 에라는 약을 골랐는지 그런 것들에 대해서 우리는 정보가 없습니다. 그래서 우리가 그러한 관측값만 가지고 조건부 확률을 계산하면 CS리티라고 할 수 없는 겁니다. 그런데 우리가 만약에 실험을 다시 할 수 있다면 정말 우리한테 100명의 사람이 있는데 100명의 사람한테 우리가 동전을 던져서 안면이 나오면 그 사람은 a 약을 주고 뒷면이 나오면 비약을 주는 겁니다. 정말 랜덤하게 어떠한 트리트먼트를 줄 건지 우리가 정하는 겁니다. 그러면 어떻게 됩니까? 이 트리트먼트가 정말 랜덤이니까 이 컴파운더에서 트리트먼트로 가는 영향력이 없어지는 겁니다. 자 이 차이를 여러분 아시겠네요. 즉 일반적인 관측 데이터는 앞서 말씀드린 것처럼 우리가 a라는 약을 먹은 것과 b라는 약을 먹은 게 랜덤이 아닐 수 있다는 겁니다. 왜 몸 상태가 매우 극심하게 안 좋은 사람은 매우 위중하기 때문에 효과가 매우 강한 a라는 약을 우리가 선택하게 할 수도 있는 거고 또는 에라는 약이 굉장히 비싸기 때문에 소수의 몇 명만 그 사람의 경제적인 효과나 다른 부분을 우리가 고려해서 a라는 약을 그 사람이 선택했을 수도 있습니다. 자 그러한 랜덤성이 아니기 때문에 컴파운더가 이렇게 트리트먼트로 영향을 주는 게 있었죠. 그래서 우리가 여기에다가 트리트먼트를 결국 가하게 되면은 랜덤하게 가하게 되면 이렇게 연결 관계가 끊어져서 그럼 백토어 패스가 없어진 거죠. 여러분 그러면 우리가 t에서 5로 가는 인과관계를 고려할 수 있게 됩니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "[MLforRecSys] (9강) 인과성과 기계학습 I.json",
        "lecture_name": "[MLforRecSys] (9강) 인과성과 기계학습 I",
        "course": "MLforRecSys",
        "lecture_num": "9강",
        "lecture_title": "인과성과 기계학습 I",
        "chunk_idx": 6,
        "total_chunks": 17,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:a5abe758db6c94e58a6adffe5521d462055b94444e49d3d70f1542f8a75fffb4"
      },
      "token_estimate": 1082,
      "char_count": 2000
    },
    {
      "id": "transcript_mlforrecsys_mlforrecsys_9강_인과성과_기계학습_i_c007_955d19",
      "content": "[MLforRecSys] [MLforRecSys] (9강) 인과성과 기계학습 I\n\n다. 자 그러한 랜덤성이 아니기 때문에 컴파운더가 이렇게 트리트먼트로 영향을 주는 게 있었죠. 그래서 우리가 여기에다가 트리트먼트를 결국 가하게 되면은 랜덤하게 가하게 되면 이렇게 연결 관계가 끊어져서 그럼 백토어 패스가 없어진 거죠. 여러분 그러면 우리가 t에서 5로 가는 인과관계를 고려할 수 있게 됩니다. 얘가 첫 번째 해결책 우리가 정말 실험을 다시 한다라는 건데 사실상 얘는 불가능한 경우가 많겠죠. 왜 그러냐면 윤리적인 문제도 있고 정말 뭐 이 사람들 우리가 굉장히 위중한 사람들 모셔와서 최적의 트리트먼트를 가하는 게 아니라 랜덤하게 a라는 약 주고 b라는 약 주고 하고 있으면 안 되는 거죠. 그다음에 그러한 것을 만약에 할 수 있다고 하더라도 굉장히 많은 비용과 시간이 들어갑니다. 그 까닭에 저희는 앞서서 봤던 것처럼 우리가 이런 백토 오패스를 어저스먼트 하기 위해서 즉 막기 위해서 적절한 해결책을 우리가 찾았습니다. 여기서는 컨디션을 우리가 줌으로써 이렇게 뒤로 가는 패스를 방지하는 방법을 우리가 앞서서 배웠습니다. 마지막 세 번째 해결책은 또 포텐셜 아웃컴이라는 해결책이 있습니다. 포텐셜 아웃컴은 우리가 매칭 또는 웨이팅이라고도 많이 부릅니다. 자 무슨 말이냐면 앞서서 여기 c에서 티로 가는 영향력 때문에 우리가 t에서 5로 가는 것을 바로 인과할 수가 없다라고 말씀드렸습니다. 이게 왜 이런 현상이 발생했다고 말씀드렸나요? 이러한 트리트먼트가 랜덤하지 않기 때문입니다. 즉 예를 들어서 뭐 부자인 분들은 트리트먼트 에를 선택할 확률이 더 올라간다든지 또는 몸 상태가 매우 좋지 못한 분들은 에라는 약을 선택할 확률이 또 매우 올라간다든지 그렇죠 그렇게 몸 상태나 아니면 경제적 상황에 따라서 특정한 약을 선택할 확률이 높아지게 되기 때문에 이 트리트먼트를 선택하는 게 랜덤이 아니게 되는 것이고 우리는 이러한 커s 패스를 정확하게 추정하지 못하게 되는 겁니다. 자 그렇다면 우리가 여기서 매칭 또는 웨이팅을 시켜 줄 수 있으면 어떨까요? 즉 무슨 말이냐면 우리가 랜덤 마이스 컨트롤 트라이어를 하지 않더라도 부자인 사람이 a라는 약을 선택하는 비율과 그다음에 부자라는 사람이 또 b라는 약을 선택한 비율 그러한 비율들을 우리가 만약에 맞춰줄 수만 있다면 아까 매우 몸 상태가 안 좋은 사람은 a라는 약을 선택할 확률이 매우 높아진 상황을 가정했었는데 그분이 a라는 약을 선택할 확률과 b라는 약을 선택할 확률이 만약에 매칭되도록 우리가 비율을 조정해 줄 수 있다면 어떻게 될까라는 얘기를 지금 하고 있는 겁니다. 그러면 마찬가지로 이렇게 문제가 풀리지 않을까라는 얘기를 하고 있는 거죠. 자 그래서 지금 우리가 계속해서 보고 있는 거는 우리가 이러한 사람에게 어떠한 트리트먼트를 줄까 a라는 약을 줘야 될까 b라는 약을 줘야 될까 반대로 또 우리가 영화 추천으로 보게 되면 에라는 영화를 추천해 줘야 될까 아니면 b라는 약을 추천해 줘야 될까 지금 이러한 커셜리티가 아무래도 이제 의료 쪽에서 또는 이제 의학 분야 쪽에서 굉장히 중요한 분야라서 그쪽에서 많은 데이터들이 공개가 되어 있고 많은 실험들이 되어 있기 때문에 저희가 좀 이런 의료 쪽에서 약 추천이나 아니면 뭐 트리트먼트 추천으로 예시를 들어드리고 있지만 하지만 영화 추천으로 또는 광고 추천으로 바로 여러분들께서 비유해서 생각하셔도 전혀 무방한 문제가 없습니다. 결국 우리가 지금 풀고 싶은 거는 어떤 거냐면 커셜리티 즉 이런 에라는 약이 결국 아웃컴 몸 상태 회복 또는 사망률에 미치는 인과적인 효과를 알고 싶은 건데 얘를 우리가 알기 어려운 이유는 뭐다 앞에서 봤던 것처럼 컨디션에 따라서 또는 그 사람의 경제적인 상황에 따라서 또는 그 사람의 기타 상황에 따라서 트리트먼트가 달라지기 때문입니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "[MLforRecSys] (9강) 인과성과 기계학습 I.json",
        "lecture_name": "[MLforRecSys] (9강) 인과성과 기계학습 I",
        "course": "MLforRecSys",
        "lecture_num": "9강",
        "lecture_title": "인과성과 기계학습 I",
        "chunk_idx": 7,
        "total_chunks": 17,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:a5abe758db6c94e58a6adffe5521d462055b94444e49d3d70f1542f8a75fffb4"
      },
      "token_estimate": 1029,
      "char_count": 1888
    },
    {
      "id": "transcript_mlforrecsys_mlforrecsys_9강_인과성과_기계학습_i_c008_077c5f",
      "content": "[MLforRecSys] [MLforRecSys] (9강) 인과성과 기계학습 I\n\n다. 결국 우리가 지금 풀고 싶은 거는 어떤 거냐면 커셜리티 즉 이런 에라는 약이 결국 아웃컴 몸 상태 회복 또는 사망률에 미치는 인과적인 효과를 알고 싶은 건데 얘를 우리가 알기 어려운 이유는 뭐다 앞에서 봤던 것처럼 컨디션에 따라서 또는 그 사람의 경제적인 상황에 따라서 또는 그 사람의 기타 상황에 따라서 트리트먼트가 달라지기 때문입니다. 또 다른 예시로는 애초에 건강한 사람이면 우리가 어떤 약을 선택할지 결정이 되게 되는 것이고 또는 건강에 관심이 많은 사람은 이 약뿐만 아니라 애초에 건강 보조제나 굉장히 건강한 음식을 먹었기 때문에 이 약과는 무관하게 애초에 건강한 음식을 먹어서 건강해질 수도 있는 것이죠. 그러면 이 a라는 약이 실제로는 건강하게 만든 게 아니라 건강에 관심이 많아서 좋은 걸 많이 먹다 보니까 더 다른 약보다 더 건강해졌을 가능성도 있는 겁니다. 이런 거를 우리가 어떻게 해결할 수 있을까인 거예요. 그래서 앞서 말씀드렸던 방식 중의 하나가 이러한 포텐셜 아웃컴 방식이었습니다. 매칭을 시켜주는 거였습니다. 즉 이러한 매칭은 앞서 말씀드린 것처럼 건강에 관심을 받은 사람이 a라는 약을 선택할 확률이 높다고 하더라도 그동안 관측됐던 데이터 중에서 뭐 예를 들어서 운동을 하기 위해서 한강 근처에 집을 구했다고 하겠습니다. 자 그러면 그분들은 병원을 갈 때도 뭐 한강 근처에 있는 병원을 가게 될 가능성이 크겠죠. 그러면 한강 근처에 있는 병원에서 만약에 a라는 약을 주로 다룬다 그러면 a라는 약을 먹게 될 가능성이 큽니다. 자 그러면 한강 근처에 사는 사람들은 이제 건강에 관심이 많고 애초에 운동을 많이 합니다. 그렇게 가정을 한번 해볼게요. 자 그러면 운동을 많이 해서 이런 건강성에 굉장히 긍정적인 영향을 미칠 수가 있습니다. 이 a라는 약을 먹었기 때문이 아니라 이 사람들은 a라는 약을 먹든 b라는 약을 먹든 애초에 건강해질 사람이었을 거란 말입니다. 그러면 우리가 이러한 거를 잘 고려하지 않게 되면은 뭔가 a라는 약을 먹은 사람들이 건강해지는 비율이 높네 그러면 a라는 약이 좋나 보다라고 잘못된 콜리에이션을 얻게 된다는 거죠. 그렇죠 이러한 문제를 우리가 해결하기 위해서 우리는 어떤 걸 해야 됩니까? 앞서 말씀드린 것처럼 여러 가지 해결책이 있지만 지금 세 번째 해결책 포텐셜 아웃컴 해결책은 어떤 걸 하는 거다 여기 운동에 관심 많은 사람들이 에라는 약을 선택할 비중과 비라는 약을 선택할 비중을 우리가 매칭시켜 주자입니다. 그리고 그러한 비율을 우리가 프로펜서티 스코어라고 부르겠습니다. 즉 여기 보시면 이 x가 여기 존재하고 있죠 즉 이 여기 나와 있는 x는 그 앞에서 c로 표현됐던 컴파운더라고 생각해 주시면 됩니다. 즉 그 트리트먼트랑 아웃컴에 모두 다 영향을 미칠 수 있는 요소입니다. 그 사람의 거주 지역 그 사람의 운동 습관 그다음에 식습관 모든 것들을 다 포함한 것들입니다. 그걸 기반으로 했을 때 그 사람이 첫 번째 트리트먼트를 선택할 확률입니다. 즉 앞서 말씀드린 예시로 보면 운동에 관심이 많은 사람이 건강에 관심 많은 사람이 에라는 약을 선택할 비율이라고 볼 수가 있는 것이죠. 자 이 비율을 우리가 잘 맞춰주면은 이 비율을 잘 매칭시켜 주면 즉 운동에 관심 많은 사람이 a라는 약을 먹을 비율과 비라는 약을 먹을 비율을 우리가 잘 매칭시켜 주면 그때는 앞서서 우리가 백도어 어저스먼트를 했었죠 그것처럼 이렇게 뒤로 돌아가는 패스가 막히는 역할과 동일한 기능을 수행하게 됩니다. 자 얘를 이용해서 그러면 우리가 어떻게 또 인과 추론을 할 수 있는지 한번 보도록 하겠습니다. 에브레시 트리트먼트 이펙트라는 것을 한번 정의를 하고 넘어가겠습니다. 여기에 y의 괄호 1이라고 쓴 거는 다음과 같이 정의가 되는 요소로 생각하시면 되는데요. 인과적인 효과라고 생각하시면 됩니다. 인과적인 효과 즉 우리가 랜덤 마이스 컨트롤 트라이어를 정말 했을 때의 효과라고 생각하셔도 됩니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "[MLforRecSys] (9강) 인과성과 기계학습 I.json",
        "lecture_name": "[MLforRecSys] (9강) 인과성과 기계학습 I",
        "course": "MLforRecSys",
        "lecture_num": "9강",
        "lecture_title": "인과성과 기계학습 I",
        "chunk_idx": 8,
        "total_chunks": 17,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:a5abe758db6c94e58a6adffe5521d462055b94444e49d3d70f1542f8a75fffb4"
      },
      "token_estimate": 1069,
      "char_count": 1972
    },
    {
      "id": "transcript_mlforrecsys_mlforrecsys_9강_인과성과_기계학습_i_c009_87e8f1",
      "content": "[MLforRecSys] [MLforRecSys] (9강) 인과성과 기계학습 I\n\n다. 자 얘를 이용해서 그러면 우리가 어떻게 또 인과 추론을 할 수 있는지 한번 보도록 하겠습니다. 에브레시 트리트먼트 이펙트라는 것을 한번 정의를 하고 넘어가겠습니다. 여기에 y의 괄호 1이라고 쓴 거는 다음과 같이 정의가 되는 요소로 생각하시면 되는데요. 인과적인 효과라고 생각하시면 됩니다. 인과적인 효과 즉 우리가 랜덤 마이스 컨트롤 트라이어를 정말 했을 때의 효과라고 생각하셔도 됩니다. 쉽게 생각해서 즉 우리가 랜덤 마이스 컨트롤 트라이어를 해서 랜덤하게 그냥 트리트먼트를 1로 줬을 때 그다음에 0으로 줬을 때 두 개의 효과의 차이가 어떻게 되냐를 우리가 보고 싶은 겁니다. 근데 우리가 실제로는 랜덤 마이 트라이어를 우리가 사실은 할 수 없는 경우가 대부분이라고 말씀을 드렸습니다. 그 까닭에 우리는 얘를 이렇게 우리가 표현을 할 수도 있습니다. 즉 예를 한번 보게 되시면 얘는 뭐예요? 이 와 즉 사망할 것인지 아니면은 건강이 회복될 것인지 그러한 아웃컴에 대한 기댓값입니다. 아웃컴에 대한 기댓값인데 그냥 아웃컴에 대한 기댓값이 아니라 어떤 상황인가요? 이 트리트먼트를 우리가 한 사람들에 대한 아웃컴인 건데 그중에서 뭐다 여기 나와 있는 것처럼 우리가 특정한 트리트먼트를 할 확률값을 나눠주는 겁니다. 왜냐하면 보정해 주기 위해서 매칭시켜 주기 위해서입니다. 즉 여기서 한번 보게 되면은 자 이 위에 분자만 보게 되면 얘는 뭐예요? 조건부 확률이에요. 그냥 자 왼쪽은 우리가 인과적인 효과입니다. 조건부 확률 콜레이션이 아니라 커셜리티를 보는 게 목표예요. 정말 랜덤 아이즈 컨트롤 트라이얼로 트리트먼트 티를 했을 때 이 사람의 아웃컴이 어떻게 될 거냐 보는 겁니다. 그렇죠 근데 그게 이제 여러 명에 대한 아웃컴이니까 익스펙테이션을 그냥 취한 것뿐이에요. 여러 명이니까 그런데 여기 오른쪽으로 한번 보면 분자만 보면은 근데 우리가 이런 랜덤 마이스 컨트롤 트라이를 못 한다고 했잖아요. 그러면 이미 그냥 관측 실험이 끝난 인터넷에 올라와 있는 그런 데이터만 우리가 보고 관측된 데이터만 보고 우리가 정해야 됩니다. 굉장히 편향된 데이터가 되겠죠. 자 거기에서 트리트먼트 t를 한 환자들만 찾아가지고 그 환자들의 아웃풋만 본다는 거예요. 그러면 우리가 조건부 확률이죠. 분자만 보면 근데 그 사람이 트리트먼트 티를 선택했을 확률 값을 프로펜스의 스코어를 우리가 추정하게 되면 그거를 우리가 보정하게 되면 그게 인과적인 효과를 나타낸다라고 말하는 겁니다. 즉 무슨 말이냐면 프로펜스팅 스코어를 우리가 추정만 할 수 있다면 그때는 우리가 랜덤 마이스 컨트롤 트라이어를 하지 않더라도 문제를 풀 수 있게 된다라는 얘기가 됩니다. 자 그리고 이러한 이제 at는 에버리스 트리트먼트 이펙트를 말하는 것이고요. 여기서는 이 에브레스 스트리트먼트 이펙트는 뭐예요? 만약에 환자가 100명이 있다 그러면 50명은 트리트먼트 1을 주고 나머지 50명은 0을 줄 수 있겠죠. 그렇죠 그럼 50명 1을 준 트리트먼트 1을 준 50명에 대한 아웃컴 기댓값 그렇죠 또 50명이 0을 준 50명에 대한 아웃컴 기댓값을 의미하고 있습니다. 자 그다음에 컨디셔널 에버스트리트먼트 이펙트는 x가 기본으로 주어진 겁니다. 얘는 헤테로지니어스 트리트먼트 이펙트라고 해서 ht라고도 또 많이 불리기도 합니다. 또는 인디비주얼 트리트먼트 이펙트라고 해서 it라고 많이 부르기도 합니다. 그건 이제 분야마다 용어가 다른 것이고요. 자 여러분들께서는 여기 나오는 그 케이트를 어떻게 생각하시면 되냐면 전체에 대한 게 아니라 그룹별 at라고 생각하셔도 됩니다. 자 예를 들어서 뭐 남성 그룹이 있고 여성 그룹이 있다고 할게요. 자 그러면 에브로시트리트메이트 이펙트는 어떤 거냐면 자 여기가 첫 번째 트리트먼트를 했을 때 즉 0번째 트리트먼트를 했을 때의 아웃컴 여기는 1번째 첫 번째 트리트먼트를 했을 때의 아웃컴으로 우리가 생각해 주시면 되겠습니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "[MLforRecSys] (9강) 인과성과 기계학습 I.json",
        "lecture_name": "[MLforRecSys] (9강) 인과성과 기계학습 I",
        "course": "MLforRecSys",
        "lecture_num": "9강",
        "lecture_title": "인과성과 기계학습 I",
        "chunk_idx": 9,
        "total_chunks": 17,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:a5abe758db6c94e58a6adffe5521d462055b94444e49d3d70f1542f8a75fffb4"
      },
      "token_estimate": 1063,
      "char_count": 1963
    },
    {
      "id": "transcript_mlforrecsys_mlforrecsys_9강_인과성과_기계학습_i_c010_23b9af",
      "content": "[MLforRecSys] [MLforRecSys] (9강) 인과성과 기계학습 I\n\n다. 또는 인디비주얼 트리트먼트 이펙트라고 해서 it라고 많이 부르기도 합니다. 그건 이제 분야마다 용어가 다른 것이고요. 자 여러분들께서는 여기 나오는 그 케이트를 어떻게 생각하시면 되냐면 전체에 대한 게 아니라 그룹별 at라고 생각하셔도 됩니다. 자 예를 들어서 뭐 남성 그룹이 있고 여성 그룹이 있다고 할게요. 자 그러면 에브로시트리트메이트 이펙트는 어떤 거냐면 자 여기가 첫 번째 트리트먼트를 했을 때 즉 0번째 트리트먼트를 했을 때의 아웃컴 여기는 1번째 첫 번째 트리트먼트를 했을 때의 아웃컴으로 우리가 생각해 주시면 되겠습니다. 자 한번 보시면 전체에 대한 에브로 스트리트먼트 이펙트는 0에서 요거 에브 스트리트먼트 이펙트는 뭡니까? 이거는 001 1 그러면 더하면 2고 개수 나누면 2분의 1입니다. 얘도 2분의 1입니다. 빼면 0이 나옵니다. 그러면 에브리 스트리트먼트 이벤트는 0이라고 할 수 있는데 여기 나와 있는 KT는 그룹별입니다. 즉 남성 그룹에 대해서 우리가 에브리 스트리트먼트 이펙트를 구하면 자 0번째 트리트먼트를 선택한 것과 첫 번째 트리트먼트를 한 거는 차이가 나요 그렇죠 또 여성에 대해서도 0번째 트리트먼트를 한 거랑 첫 번째 트리트먼트를 한 게 차이가 나요 그러면은 이 KT는 0이 아니라는 거죠. 왜 남성이라는 그룹이 주어졌을 때 두 개는 0보다 또 0이 아니고 또 여성이라는 게 주어졌을 때 또 0이 아니고 그러면 KT는 0이 아닐 수도 있다는 겁니다. 좀 더 퍼스널라이즈가 된 그렇죠 우리가 효과를 보는 걸로 해석할 수 있습니다. x가 기본으로 주어진 즉 x가 기본이라는 말은 환자의 그러한 여러 가지 몸 상태나 식습관이나 그러한 것들을 우리가 인풋으로 넣어준다라는 뜻이 됩니다. 자 얘가 최근에는 뉴럴 네트워크랑 연결해서 많이 활용이 되고 있습니다. 왜 자 결국 이 케이트를 추정하기 위해서는 뭘 해야 됩니까? 엑스라는 것을 인풋으로 받아야 돼요 스가 뭐예요? 환자의 인풋입니다. 즉 무슨 말이냐면 그 환자의 식습관일 수도 있고 그 환자의 폐를 촬영한 사진 아니면 뭐 다른 엑스레이를 촬영한 사진 그런 이미지 정보일 수도 있어요. 어떠한 정보든 될 수 있는 겁니다. 아니면 그 의사가 그 환자에 대해서 소견서를 작성한 텍스트 데이터일 수도 있는 것이고요. 자 그런 상황에서 그러한 액스를 잘 반영하기 위해서는 즉 스가 컨디션이라는 말은 스가 뉴럴 네트워크에 엑스가 어쨌든 우리 머신 러닝 모델의 인풋으로 들어가야 되는 건데 그러면 그런 이미지 텍스트 테이블 데이터를 잘 고려할 수 있는 머신러닝 모델은 뭡니까? 결국 뉴럴 네트워크 기반이지 않습니까 좋은 피처를 뽑아낼 수 있는 그래서 이런 구조로 많이 연구가 되고 있습니다. 즉 우리한테 주어진 x를 기반으로 다음과 같이 뉴럴 네트워크를 통과시켜서 이 뉴로넬 토크는 뭐 뉴로넬 토크일 수도 있고 트랜스포머일 수도 있고 시일 수도 있고 어떤 거든 될 수 있겠죠 자 거기에서 우리가 뮤헤 제로와 뮤헤 원을 뽑아냅니다. 자 여기서 뮤햇 제로랑 뮤헤원은 뭐냐면 실제로 우리가 추정하고 싶은 건 지금 뭐예요? 다음과 같은 케이트입니다. 그렇죠 여러분 얘를 추정하고 싶은 거예요 즉 트리트먼트 0을 했을 때의 아웃컴과 트리트먼트 일을 했을 때의 아웃컴의 차이를 알고 싶은 겁니다. 실제 우리가 알고 싶은 게 이예요. 그래서 우리는 이 각각의 추정치를 해시라고 하겠습니다. 실제 그런 투루 얘를 알 수가 없으니까 얘를 추정하는 것을 뮤헤 제로 뮤헤 원이라고 하겠습니다. 자 그다음에 프로펜시 스코어도 우리가 추정하고 싶은 것 중에 하나입니다. 왜 얘를 우리가 알면은 뭔가 여러 가지 보정을 좀 할 수 있는 것들이 많다고 하지 않았습니까 그렇죠 그래서 이러한 프로펜스티 스코어도 우리가 뉴런 연습을 통해서 추정을 하도록 하겠습니다. 결국 우리가 알고 싶은 거는 이거예요. 타w입니다. 타우 근데 타우를 잘 알기 위해서 우리가 좀 추정을 할 거예요. 뮤제로랑 유언과 파일을 추정할 겁니다. 얘가 어떻게 쓰일지는 뒤에서 보도록 하겠습니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "[MLforRecSys] (9강) 인과성과 기계학습 I.json",
        "lecture_name": "[MLforRecSys] (9강) 인과성과 기계학습 I",
        "course": "MLforRecSys",
        "lecture_num": "9강",
        "lecture_title": "인과성과 기계학습 I",
        "chunk_idx": 10,
        "total_chunks": 17,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:a5abe758db6c94e58a6adffe5521d462055b94444e49d3d70f1542f8a75fffb4"
      },
      "token_estimate": 1082,
      "char_count": 2013
    },
    {
      "id": "transcript_mlforrecsys_mlforrecsys_9강_인과성과_기계학습_i_c011_3da964",
      "content": "[MLforRecSys] [MLforRecSys] (9강) 인과성과 기계학습 I\n\n다. 자 그다음에 프로펜시 스코어도 우리가 추정하고 싶은 것 중에 하나입니다. 왜 얘를 우리가 알면은 뭔가 여러 가지 보정을 좀 할 수 있는 것들이 많다고 하지 않았습니까 그렇죠 그래서 이러한 프로펜스티 스코어도 우리가 뉴런 연습을 통해서 추정을 하도록 하겠습니다. 결국 우리가 알고 싶은 거는 이거예요. 타w입니다. 타우 근데 타우를 잘 알기 위해서 우리가 좀 추정을 할 거예요. 뮤제로랑 유언과 파일을 추정할 겁니다. 얘가 어떻게 쓰일지는 뒤에서 보도록 하겠습니다. 자 그러면은 여기서 이 머신러닝 모델로 뭘 할 거냐 어떤 구조를 우리가 가져올 거냐라고 하면 이 구조가 여러 개가 있습니다. 자 다시 한 번 말씀드리면 뮤 h 제로라는 거는 0번째 트리트먼트를 했을 때의 아웃컴 예측값 첫 번째 트리트먼트를 했을 때의 아웃컴에 대한 예측 값입니다. 그렇죠 그다음에 파이 햇이라는 거는 이 환자가 여기 즉 트리트먼트 0을 선택할 확률 또는 트리트먼트 1을 선택할 확률을 우리가 나타내고 있는 것입니다. 그러면 티넷이라는 구조로 우리가 만약에 설계를 한다라는 말은 뮤제로엣과 뮤원 앱과 파이엣을 다 별도로 우리가 모델링 한다라는 뜻입니다. 그렇죠 무슨 말이냐면 그냥 여기서 x라는 정보가 있어요. x라는 정보 그 환자 정보가 되겠죠. 환자의 몸 상태 식습관 뭐 그런 것들 아니면 얘를 영화로 생각하셔도 돼요. 영화 같은 경우는 영화의 그 포스터 이미지 또는 줄거리 또는 영화의 감독 정보들이 되겠습니다. 그랬을 때 여기서 뮤헤 제로와 뮤엣 1 파이 햇을 우리가 따로 구성한 겁니다. 즉 여기에서 이런 네트워크가 3개 있다라고 생각하시면 되는 겁니다. 분리해서 딱딱딱 그 말은 뮤햇제로 뮤 햇 1 파이 h을 예측할 때 서로 뭔가 공통적인 도움이 되는 정보는 없을 것이다라고 가정을 하고 있는 거예요. 근데 얘가 처음 나오고 나서 그 뒤에 굉장히 많은 변형 연구들이 많이 나왔습니다. 자 그중에서 한 가지를 말씀드리면 자 여기서는 뮤헤 제로랑 뮤헤 원을 우리가 예측할 때 뭔가 공통적으로 도움이 되는 피처가 있을 거다라는 것이고요. 자 여기 드래곤 넷 같은 경우는 뮤엣 제로랑 뮤헷 원이랑 파이엣을 예측할 때 이 세 개에 다 공통적으로 도움이 되는 정보가 있을 것이다라는 얘기를 하는 겁니다. 뭐 예를 들어서 그 환자의 그 건강에 대한 관심도는 결국 또는 뭐 식습관은 어떠한 트리트먼트를 선택할지에 영향을 주기도 하고 그렇죠 그다음에 그 환자의 식습관이 어떠한 약을 선택할지 뿐만 아니라 어떠한 약을 선택했을 때 그에 대한 이펙트도 영향을 줄 수 있지 않겠냐 이렇게 공통적으로 주는 영향이 있지 않겠냐라는 차원에서 공통 쉐어링 되는 이런 네트워크가 나오고도 있습니다. 그리고 이렇게 뭐 2개만 쉐어링 되는 거 이렇게 3개 전체 쉐어링 되는 거 그리고 각각 독립적으로 되어 있는 거 그다음에 쉐어링 되어 있는 거 이 모든 걸 고려한 SNT이라는 것도 쉐어드 댓 의 약자겠죠 이러한 변형들도 나오고 있습니다. 자 그러면 이러한 머신러닝 모델들을 활용하면 결국 뮤 헷 제로 뮤 햇 원 파이 햇을 우리가 추정할 수 있게 되는 것입니다. 그렇죠 이거 각각에 대한 설명은 앞서서 말씀드렸고요. 이 각각 하나가 사실 논문 하나하나입니다. 하지만 모델 구조를 보시면 이 그림 하나로 모델 구조가 어떻게 발전해 왔는지 그 변천사를 비교적 쉽게 여러분들께서 아실 수 있을 거라 생각합니다. 그래서 지금 한번 보시면 여기서 뮤제로 헷 뮤어 햇 파이햇을 우리가 이런 다양한 방식으로 추정할 수 있다까지 봤습니다. 자 그러면 계속 강조드리지만 우리가 지금 하고 싶은 게 뭐예요? 케이트를 추정하는 겁니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "[MLforRecSys] (9강) 인과성과 기계학습 I.json",
        "lecture_name": "[MLforRecSys] (9강) 인과성과 기계학습 I",
        "course": "MLforRecSys",
        "lecture_num": "9강",
        "lecture_title": "인과성과 기계학습 I",
        "chunk_idx": 11,
        "total_chunks": 17,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:a5abe758db6c94e58a6adffe5521d462055b94444e49d3d70f1542f8a75fffb4"
      },
      "token_estimate": 980,
      "char_count": 1822
    },
    {
      "id": "transcript_mlforrecsys_mlforrecsys_9강_인과성과_기계학습_i_c012_1d7f02",
      "content": "[MLforRecSys] [MLforRecSys] (9강) 인과성과 기계학습 I\n\n다. 그렇죠 이거 각각에 대한 설명은 앞서서 말씀드렸고요. 이 각각 하나가 사실 논문 하나하나입니다. 하지만 모델 구조를 보시면 이 그림 하나로 모델 구조가 어떻게 발전해 왔는지 그 변천사를 비교적 쉽게 여러분들께서 아실 수 있을 거라 생각합니다. 그래서 지금 한번 보시면 여기서 뮤제로 헷 뮤어 햇 파이햇을 우리가 이런 다양한 방식으로 추정할 수 있다까지 봤습니다. 자 그러면 계속 강조드리지만 우리가 지금 하고 싶은 게 뭐예요? 케이트를 추정하는 겁니다. 케이트 그렇죠 결국 그 디퍼런스를 우리가 알고 싶은 거예요. 이 케이트라 함은 결국에 우리가 또 다르게 해석하면은 이 환자의 상태에서 이 약을 줬을 때 즉 특정한 연령 50대 이상의 환자에 대해서 이 약에 대한 효과를 본다든지 그렇죠 아니면 뭐 예를 들어서 부산에 사는 사람들을 대상으로 우리가 특정한 마케팅을 했을 때 그 마케팅 효과를 본다든지 또는 뭐 우리가 넷플릭스랑 유튜브를 동시에 보는 시청자분들에 대해서 우리가 특정한 영상을 추천해 줬을 때 그 효과가 어땠는지 클릭을 했는지 안 했는지 그거를 우리가 각 그룹별로 이런 차이를 예측하는 게 목표입니다. 그러면 지금 아직까지는 우리는 각각만 본 거예요. 그렇죠 이 각각에 대해서만 우리가 지금 본 것이고 아직 디퍼런스에 대해서는 보지 않았습니다. 그러면 이러한 디퍼런스를 우리가 좀 어떻게 실제로 할 수 있겠냐라고 하면은 방법이 두 개가 있습니다. 하나는 in 다이렉트 또는 플로그인 러더라고 부릅니다. 여기서 보시면 이 방법 중에 대표적인 방법은 에스 러너 또는 티 러너가 대표적인 인 다이렉트 또는 플로그인 러너의 대표적인 모델입니다. 자 얘는 우리가 특별한 방법 없이 결국 앞에서 뮤제로 핵과 미원이 잘 구해졌으면 그걸 이용해서 그냥 우리가 차이를 뺀다라는 뜻입니다. 자 그러면은 우리가 실제로 그 타워라는 값을 우리가 추정을 할 수가 있게 되는 것이죠. 이 에스트로노랑 티러노는 지금 한번 보시면 우리가 디퍼런스 자체를 추정하기보다는 각각을 추정해서 디퍼런스를 계산하는 것이기 때문에 인 다이렉트 러너라고 부르기도 합니다. 자 그리고 여기서는 한번 생각해 보시면 이 에스러너랑 티러너의 차이를 좀 잠깐만 말씀드리면 우리가 이 에스 러너는 싱글 러너의 약자거든요. 그래서 여기 앞에서는 우리가 뮤쉐르엣과 뮤어넷을 예측하기 위해서 각각의 뉴럴 네트워크를 이렇게 따로 쓰지 않았습니까? 그렇죠 따로 썼는데 이 방식으로 하면은 각각이 나오는 거고 그렇죠 이게 티러너 기반의 방법인 거고 에스트러너는 자 뮤제로 핵과 뮤원햇을 예측하기 위해서 뉴럴넷을 이렇게 두 개로 따로 구성하는 게 아니라 하나의 뉴럴넷인데 인풋으로 티 값을 같이 넣어주는 겁니다. 그러면 티가 0일 때는 그 뉴런에 대해서 0일 때의 아웃풋이 나오는 거고 티에 1을 넣어주면은 이 동일한 뉴런에서 1에 대한 아웃컴이 나오게 되는 구조입니다. 그래서 에스 러너는 우리가 싱글 러너 즉 뉴로 네트워크 구조가 하나로 된 거 티 러너는 이렇게 트리트먼트마다 뉴로 네트워크 구조가 따로 되어 있는 것을 의미합니다. 그래서 에스 러너는 보시면 트리트먼트 0 또는 1 값이 그냥 인풋에다가 같이 더해져서 같이 이제 그 추가돼서 들어가는 형태로 생각할 수가 있습니다. 자 그다음에 또 다른 러너로는 투 스텝 러너가 있습니다. 지금 우리가 뭘 보고 있냐면 앞에서 이 뉴런의 구조를 통해서 여기까지 나온 거예요. 그다음에 그 뒷단 그래서 정말 그 타월을 어떻게 계산할 건데 트리트먼트 이펙트를 어떻게 계산할 건데 그 뒷부분에 대한 얘기를 지금 하고 있는 것입니다. 그리고 그때 우리가 앞에서 봤던 에스 러너랑 틸 러너는 추가적인 학습 없이 그냥 바로 빼는 거고요. 그다음에 여기 나와 있는 방식은 우리가 어떻게 진행을 하는 것이냐면 약간의 변형을 가합니다. 즉 여기서 약간의 변형을 가해서 알레이 러너 피블 러너 디알 언어 이 세 가지 방식은 어떻게 하는 거냐면 이 세 가지를 가지고 재료를 조합해서 새로운 하나의 아웃풋을 하나 만들어요. 그리고 얘를 우리가 추정하는 형태로 진행됩니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "[MLforRecSys] (9강) 인과성과 기계학습 I.json",
        "lecture_name": "[MLforRecSys] (9강) 인과성과 기계학습 I",
        "course": "MLforRecSys",
        "lecture_num": "9강",
        "lecture_title": "인과성과 기계학습 I",
        "chunk_idx": 12,
        "total_chunks": 17,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:a5abe758db6c94e58a6adffe5521d462055b94444e49d3d70f1542f8a75fffb4"
      },
      "token_estimate": 1105,
      "char_count": 2032
    },
    {
      "id": "transcript_mlforrecsys_mlforrecsys_9강_인과성과_기계학습_i_c013_7e9d39",
      "content": "[MLforRecSys] [MLforRecSys] (9강) 인과성과 기계학습 I\n\n다. 그리고 그때 우리가 앞에서 봤던 에스 러너랑 틸 러너는 추가적인 학습 없이 그냥 바로 빼는 거고요. 그다음에 여기 나와 있는 방식은 우리가 어떻게 진행을 하는 것이냐면 약간의 변형을 가합니다. 즉 여기서 약간의 변형을 가해서 알레이 러너 피블 러너 디알 언어 이 세 가지 방식은 어떻게 하는 거냐면 이 세 가지를 가지고 재료를 조합해서 새로운 하나의 아웃풋을 하나 만들어요. 그리고 얘를 우리가 추정하는 형태로 진행됩니다. 즉 다시 무슨 말이냐면 뮤 엣 제로 뮤헤 원 파일이 나왔습니다. 얘를 가지고 새로운 하나의 가상의 레이블을 만듭니다. 이 가상의 레이블은 실제 우리가 추정해야 되는 그 타워 값이랑 매우 밀접하게 연결되어 있습니다. 그러면 얘를 잘 추정하면 되는 거예요. 그래서 얘를 추정하는 학습을 다시 한 번 진행합니다. 즉 아까 우리가 앞에서 이 데이터를 써 가지고 환자의 데이터를 써서 뮤엣 제로 뮤헤 1 파이 햇을 구했습니다. 그렇죠 그걸 기반으로 우리가 여기서는 와이틸리아를 구할 거예요. 이 세 가지 러너는 와이 틸리아를 구하고 그다음에 우리가 앞에서 썼던 그 환자의 데이터를 기반으로 이 와이틸리를 예측하는 뉴럴 네트워크를 한 번 더 학습할 겁니다. 그래서 우리가 투 스텝 러너라고 부르기도 합니다. 두 번 학습하니까 자 얘를 하나씩 보면 자 아레이 러너를 한번 보도록 하겠습니다. 자 아레일 러너는 이렇게 구성이 되어 있습니다. 지금 무슨 말이냐면 지금 뭘 얘기하고 있냐면 뮤엣 제로 뮤헤 1 파이 헤이 있는데 여기서 아레일 러너를 쓰면은 와 틸다를 이렇게 만들겠다는 뜻인 거고 그다음에 여기서 우리가 피를 피블 러너를 쓰게 되면 이 세 가지의 재료를 우리가 이용해서 다음과 같이 와 틸다를 만든다라는 얘기가 또 되는 겁니다. 자 그다음에 Dr 러너 더블 로버스트 러너는 앞에서 봤던 RA와 pw의 결합 버전인데 어찌 됐든 이 세 가지를 이용해서 와 틸다를 이렇게 만들겠다라는 뜻입니다. 아시겠죠? 여러분 자 그러면 각각의 이 우리가 와이 틸다를 만들고 나면 하나의 뭔가 새로운 아웃컴이 만들어진 거예요. 새로운 예측치가 만들어진 겁니다. 새로운 레이블이 만들어진 거라고 생각하시면 됩니다. 그 레이블을 잘 추정할 수 있도록 우리가 뉴럴 네트워크를 다시 하나 학습시킨다 그러면 얘가 실제로 그 타우 틸다가 된다 즉 우리가 추정해야 되는 그 케이트가 된다라는 말입니다. 자 각각에 대해서 저희가 조금만 더 한번 살펴보고 넘어가도록 하겠습니다. 자 아래 러너는 이렇게 만든다는 거예요. 즉 여기서 한번 보면은 뭐 t가 1일 때 스트레이트먼트를 1로 줬다라고 하면 어떻게 됩니까? 이 뒷부분 날아가고 이것만 남게 되겠죠 그렇죠 그럼 실제로 우리가 트리트먼트를 실제로 1로 준 환자였다고 한다면 즉 우리는 지금 어떤 데이터를 갖고 있어요? 환자 데이터인데 그 환자에 대해서 과거에 어떤 트리트먼트를 줬고 아웃컴이 어땠는지는 알고 있어요. 근데 우리가 추정하고 싶은 건 그 환자에 대해서 다른 트리트먼트를 줬다면 어땠을까 이걸 우리가 또 알고 싶은 거잖아요 그렇죠 그 까닭에 지금 우리가 이거를 보고 있는 겁니다. 그러면 트리트먼트 1을 이미 줬던 환자라고 한다면 그 환자에 대한 아웃컴이 이미 있는 겁니다. 그리고 우리가 예측한 uhu가 있어요. 0을 줬을 때의 그 트리트먼트 이펙트 아웃컴이 여기 나와 있는 겁니다. 그 차이가 나오게 되는 것이고 트리트먼트가 0이라는 0을 만약에 준 환자에 대해서는 얘가 0이니까 여기가 이제 켜지게 되는 것이고 그럼 트리트먼트 1을 준 기록은 없으니까 우리 모델의 예측치를 쓰는 것이고 그다음에 그 실제로 트리트먼트 0을 줬을 때의 아웃컴이 나오게 됩니다. 그렇죠 이렇게 구성이 되는 것이고 실제로 이거에 대한 익스펙테이션을 구하게 되면 얘가 나오게 돼요. 즉 정확한 기댓값으로는 정확한 트리트먼트 임팩트 케이트가 추정이 되는 겁니다. 언제 우리가 만약에 이것만 잘 추정했다면 실제로 얘가 쉽진 않겠죠. 근데 그렇죠 자 그다음에 피블 러너 같은 경우는 이렇게 구성이 됩니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "[MLforRecSys] (9강) 인과성과 기계학습 I.json",
        "lecture_name": "[MLforRecSys] (9강) 인과성과 기계학습 I",
        "course": "MLforRecSys",
        "lecture_num": "9강",
        "lecture_title": "인과성과 기계학습 I",
        "chunk_idx": 13,
        "total_chunks": 17,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:a5abe758db6c94e58a6adffe5521d462055b94444e49d3d70f1542f8a75fffb4"
      },
      "token_estimate": 1090,
      "char_count": 2021
    },
    {
      "id": "transcript_mlforrecsys_mlforrecsys_9강_인과성과_기계학습_i_c014_98b2e2",
      "content": "[MLforRecSys] [MLforRecSys] (9강) 인과성과 기계학습 I\n\n다. 그렇죠 이렇게 구성이 되는 것이고 실제로 이거에 대한 익스펙테이션을 구하게 되면 얘가 나오게 돼요. 즉 정확한 기댓값으로는 정확한 트리트먼트 임팩트 케이트가 추정이 되는 겁니다. 언제 우리가 만약에 이것만 잘 추정했다면 실제로 얘가 쉽진 않겠죠. 근데 그렇죠 자 그다음에 피블 러너 같은 경우는 이렇게 구성이 됩니다. 얘도 한번 보시면 익스펙테이션을 취하게 되면은 결국 이렇게 케이트가 나와요. 근데 언제 우리가 파이엣을 정확하게 추정했다면 즉 여기 파이는 뭐예요? 프로페스트 스코어 즉 현재의 몸 상태에서 어떠한 트리트먼트를 선택할 건지에 대한 얘기를 지금 하고 있는 겁니다. 즉 프로펜스틱 스코어만 잘 예측해도 우리가 이러한 케이트를 잘 추정할 수 있다는 거예요. 그렇죠 그러면 굉장히 재밌는 거죠. 자 우리가 뮤헤 제로를 우리가 추정하기 쉬울 때도 있고 그다음에 다음과 같이 프로페스티 스코어를 추정하기 쉬울 때도 있습니다. 그러면 그때그때 우리가 맞는 러너를 쓰면 된다는 겁니다. 그다음에 더블릿 러버스트 러너는 뭐 그럴 필요 없이 두 개 중에서 하나만 맞춰도 된다라는 얘기입니다. 즉 얘는 무슨 말이에요? RA 러너는 우리가 대신 얘는 무조건 맞춰야 되는 거예요. 그쵸 피블 러너는 무조건 얘를 맞춰야 되는 겁니다. 그래야지 정확한 케이티가 추정이 되는 거예요. 더블릿 러버스트 러너는 얘 또는 얘를 맞추면 된다라는 겁니다. 자 식은 약간 좀 복잡하게 써져 있습니다. 근데 한번 보시면 앞에서 봤던 아레이 러너의 폼과 피블 러너의 폼이 지금 합쳐져 있는 것을 볼 수가 있습니다. 얘에 대한 기댓값 이런 건 우리가 다 일일이 유도는 저희가 시간상 하지 않을 겁니다. 굉장히 심화된 버전이기 때문에 이건 하지 않을 거고 대신 여러분은 이 결과 이게 의미하는 바를 이해해 주시면 되겠습니다. 자 여기에 대해서 우리가 익스펙테이션을 취하게 되면은 그땐 이렇게 나오게 되고 그때 우리가 뮤 햄만 뮤를 잘 추정해도 정확한 케이트가 나오고 또는 파일을 잘 추정해도 정확한 케이트가 나옵니다. 즉 두 개 중에 하나만 해도 된다는 거예요. 잘 추정해도 그래서 로버스트하다는 겁니다. 대신에 둘 다 못 맞추게 되면은 그때는 좀 오히려 성능이 안 좋아질 수도 있게 됩니다. 그래서 여기 나와 있는 러너들 그다음에 이러한 모델 구조들이 어떤 모델 구조가 좋은지 지금 이 모델 구조가 5개 중에서 하나를 우리가 고를 수도 있고 또 새로운 모델 구조가 나올 수도 있고요. 그다음에 여기서도 에스트로노랑 테러노를 만약에 같은 걸로 생각한다면 4개의 모델 구조가 있습니다. 그렇죠 그러면은 조합으로 따지면 또 20가지의 조합이 나오게 되는 것인데요. 그러면 결국 어떤 모델 구조가 좋고 어떠한 러너가 좋은 것인지 좀 다양한 환경에서 실험을 우리가 해 볼 수가 있다는 겁니다. 가상의 데이터를 만들어서 예를 들어서 우리가 첫 번째 세팅 같은 경우는 여기 컴파운더가 우리가 5개가 있는 거예요. 5개의 디맨션으로 이루어진 건데 근데 컴파운더가 있는데 튜트먼트 이펙트는 우리가 동일하다고 하겠습니다. 뮤제로랑 m1이 동일하다 이런 상황 그다음에 두 번째 세팅은 그 두 개가 다른 상황으로 우리가 함수를 구성하는 겁니다. 그냥 가상의 데이터로 만드는 거예요. 가상으로 그다음에 세 번째는 컴파운드가 없습니다. 근데 뮤제로를 선택하는 애랑 미원을 선택하는 애가 다른 겁니다. 이렇게 다른 상황 마치 이런 상황에서는 어떤 게 유리할 거라고 기대할 수 있나요? 뮤제로와 뮤원이 만들어지는 케이스가 완전 다른 거예요. 지금 한번 보시면 여기서는 예를 들어서 환자의 건강 상태를 나타내는 게 25개가 있는데 0번째 트리트먼트에 대해서 영향을 미치는 거는 앞에 있는 뭐 우리가 13개인 거고 그다음에 이 뒤에 있는 12개는 위원에 대한 첫 번째 트리트먼트 이펙트에 대해서 영향을 미친다는 겁니다. 즉 뮤재료와 유원을 만드는 재료가 좀 많이 상이한 거죠. 이럴 때는 또 우리가 뭐 이런 티넥 구조가 비교적 더 좋을 수도 아주 약간이라도 좋을 수도 있다라고 기대를 할 수가 있는 상황입니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "[MLforRecSys] (9강) 인과성과 기계학습 I.json",
        "lecture_name": "[MLforRecSys] (9강) 인과성과 기계학습 I",
        "course": "MLforRecSys",
        "lecture_num": "9강",
        "lecture_title": "인과성과 기계학습 I",
        "chunk_idx": 14,
        "total_chunks": 17,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:a5abe758db6c94e58a6adffe5521d462055b94444e49d3d70f1542f8a75fffb4"
      },
      "token_estimate": 1100,
      "char_count": 2034
    },
    {
      "id": "transcript_mlforrecsys_mlforrecsys_9강_인과성과_기계학습_i_c015_4b4bde",
      "content": "[MLforRecSys] [MLforRecSys] (9강) 인과성과 기계학습 I\n\n다. 즉 뮤재료와 유원을 만드는 재료가 좀 많이 상이한 거죠. 이럴 때는 또 우리가 뭐 이런 티넥 구조가 비교적 더 좋을 수도 아주 약간이라도 좋을 수도 있다라고 기대를 할 수가 있는 상황입니다. 그쵸? 그런 상황인 거고요. 그리고 여기서는 한번 보시면 이러한 뮤제로랑 묘원을 좀 잘 추정하기가 쉽지는 않겠죠. 왜냐면은 이렇게 완전히 디스인트로 되어 있다 보니까 그렇죠 이런 상황입니다. 그런 각각의 상황에서 한번 보면은 대부분의 경우에는 에스넷이 좀 많이 자랍니다. 이 앤이라는 건 데이터셋 개수를 의미하는 것이고요. 샘플 개수 에스넷이 아무래도 좀 대부분 많이 자라는 것을 우리가 확인을 할 수가 있습니다. 그렇죠 하지만 여기 세팅 세 번째는 독립적으로 이루어지고 있는 그쵸 이런 상황에서는 나머지 상황에서는 티넷을 잘 못하다가 여기서는 좀 티넷이 그래도 좀 선방을 하는 모습을 보이고 있습니다. 에스넷을 제외하고 나머지 쉐어드 네트워크보다는 여기 나와 있는 티넷이 더 좋은 걸 볼 수 있죠 왜 세 번째 세팅은 애초에 뮤제로와 미원이 따로 만들어진 상황이니까 티넷에 좀 더 유리할 겁니다. 에스넷은 사실은 뭐 그러한 개별적인 독립적인 것도 모델링하고 쉐어들도 동시에 다 모델링 하다 보니까 가장 좋은 네트워크 구조라고 볼 수가 있을 것이고요. 그다음에 또 이러한 러너 중에서 어떤 러너가 좋은지 또 우리가 한번 고려를 해 볼 수가 있겠죠. 자 한번 보시면 대부분의 경우에는 또 더블린 러버스트 러너가 굉장히 좋습니다. 주황색 굉장히 좋아요. 더블 로버스트 러너가 하지만 이런 좀 세 번째 스팅에서는 더블 로버스트 러너가 뭐 완전 못하지는 않지만 그래도 좀 상대적으로 많이 못하는 걸 볼 수가 있습니다. 왜 이 세 번째 같은 경우는 좀 어려운 세팅이었어요. 뮤제로랑 묘원이 이렇게 완전히 따로 놀다 보니까 즉 하나의 x에서 뮤제로가 나오고 미원이 나오는 게 아니라 다른 엑스에서 나오다 보니까 이 뮤제로와 뮤제로랑 미원을 좀 정확하게 추정하기가 쉽지 않습니다. 동시에 둘 다 정확하게 추정하기는 쉽지 않은 상황인 거고 그다음에 여기서 또 파이에 대한 것도 우리가 또 알기가 쉽지 않은 상황이에요. 그렇죠 그 까닭에 이러한 상황에서는 그 더블릿 러버 스트로너가 좀 잘 하지 못하는 상황입니다. 잘하기는 하지만 상대적으로 좀 잘 못하는 현상이 있는 거죠. 그래서 프로펜스 스코어나 아웃컴 리그레이션 즉 뮤제로나 뮤원 두 개 중에서 하나만 잘 작동해도 더블 로버스트러너는 잘하긴 하는데 좀 둘 다 맞추기 어려운 상황에서는 어려울 수도 있다라는 겁니다. 즉 지금 보면은 데이터가 어떻게 생성되느냐에 따라서 최고의 모델이 달라질 수도 있는 거예요. 그렇죠 어떤 방법을 쓰는 게 즉 그 말은 데이터가 이렇게 생성됐는지 아니면 또 다른 그래프로 생성됐는지 그러한 그래프에 대한 정보가 우리는 필요하다라는 겁니다. 저희가 이번 시간에는 인과성과 기계 학습에 대해서 살펴봤습니다. 즉 인과성이라는 게 무엇인지 우리가 살펴봤고요. 그래서 그런 인과성을 우리가 추정하기 위해서 앞서서 백도어 어저스먼트 즉 컨디션을 줘 가지고 백도어 페스트를 막는 역할을 봤었고 그다음에 랜덤 마이스 컨트롤 트라이어를 하면 된다라는 것도 봤었고 하지만 그게 현실적이지 않으니까 프로페스트 스코어를 추정해서 우리가 문제를 푸는 방법도 봤었고 그다음에 그러한 것들이 뉴럴 네트워크가 연결돼서 어떻게 같이 결합될 수 있는지 그래서 어떻게 하면 케이트를 추정할 수 있는지 왜 케이트라는 거는 스마다 또는 그룹마다의 아웃컴을 우리가 예측해야 되다 보니까 엑스라는 정보를 인풋으로 받아야 됩니다. 그렇죠 그러면은 그러한 x는 이미지 텍스트 테이블 데이터 다 될 수 있는 거고 우리가 그런 하이디맨셔널 피처를 잘 고려할 수 있는 뉴럴 네트워크 기반의 방법 그 뒤에 러너 단에서는 또 우리가 여러 가지 로버스트한 러너들을 살펴봤습니다. 그리고 결론적으로 최고의 러너 항상 모든 환경에서 다 잘 작동하는 모델이나 러너가 있진 않",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "[MLforRecSys] (9강) 인과성과 기계학습 I.json",
        "lecture_name": "[MLforRecSys] (9강) 인과성과 기계학습 I",
        "course": "MLforRecSys",
        "lecture_num": "9강",
        "lecture_title": "인과성과 기계학습 I",
        "chunk_idx": 15,
        "total_chunks": 17,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:a5abe758db6c94e58a6adffe5521d462055b94444e49d3d70f1542f8a75fffb4"
      },
      "token_estimate": 1088,
      "char_count": 1992
    },
    {
      "id": "transcript_mlforrecsys_mlforrecsys_9강_인과성과_기계학습_i_c016_ece15c",
      "content": "[MLforRecSys] [MLforRecSys] (9강) 인과성과 기계학습 I\n\n다. 그렇죠 그러면은 그러한 x는 이미지 텍스트 테이블 데이터 다 될 수 있는 거고 우리가 그런 하이디맨셔널 피처를 잘 고려할 수 있는 뉴럴 네트워크 기반의 방법 그 뒤에 러너 단에서는 또 우리가 여러 가지 로버스트한 러너들을 살펴봤습니다. 그리고 결론적으로 최고의 러너 항상 모든 환경에서 다 잘 작동하는 모델이나 러너가 있진 않다. 데이터가 어떻게 생성되느냐에 따라서 그 최고의 런은 달라지게 되고 그래서 데이터가 어떠한 그래프로 생성됐는지에 대한 이해가 필요하다까지 왔습니다. 네 여러분 고생 많았습니다.",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "[MLforRecSys] (9강) 인과성과 기계학습 I.json",
        "lecture_name": "[MLforRecSys] (9강) 인과성과 기계학습 I",
        "course": "MLforRecSys",
        "lecture_num": "9강",
        "lecture_title": "인과성과 기계학습 I",
        "chunk_idx": 16,
        "total_chunks": 17,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:a5abe758db6c94e58a6adffe5521d462055b94444e49d3d70f1542f8a75fffb4"
      },
      "token_estimate": 172,
      "char_count": 331
    }
  ]
}