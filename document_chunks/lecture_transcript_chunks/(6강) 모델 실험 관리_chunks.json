{
  "source_file": "(6강) 모델 실험 관리.json",
  "lecture_name": "(6강) 모델 실험 관리",
  "course": "기타",
  "total_chunks": 7,
  "chunks": [
    {
      "id": "transcript_기타_6강_모델_실험_관리_c000_ee1a97",
      "content": "[강의 녹취록] 과목: 기타 | 강의: 6강 | 제목: 모델 실험 관리\n\n안녕하세요. 도메인 공통 프로젝트 6강 모델 실험 관리 시작하도록 하겠습니다. 이번 강의에서는 머신 러닝 실험 관리의 필요성, 실험 관리 툴 중에 하나인 웨일 앤 바이어스 원디비를 이용한 실험 기록 및 분석, 그다음 원디비를 활용한 실험 고도화에 대해서 이야기해 보겠습니다. 먼저 머신 러닝 실험 관리의 필요성입니다. 머신 러닝 실험 관리란 머신러닝 모델 개발 과정에서 수행하는 모든 실험의 과정과 결과를 체계적으로 관리하는 활동입니다. 단순히 학습 성공, 학습 실패 여부만 기록하는 것이 아니라 실험을 구성하는 아래와 같은 핵심 메타 데이터를 추적하고 관리하여 모델 개발의 효율성과 재연성을 높이는 것을 목표로 합니다. 코드에서는 어떤 코드로 실험했는가에 대한 정보가 들어갑니다. 여기에는 사용한 코드의 메타 정보, 예를 들어 코드의 파일명 혹은 코드의 버전 혹은 기색, 커밋, 샤 같은 해시 값을 넣기도 합니다. 다음은 하이퍼 파라미터입니다. 이 모델을 학습하는 데 사용한 하이퍼 파라미터의 조합들을 기록합니다. 신경망 모델이라면 사용한 레이어의 종류, 레이어에 들어가는 각 파라미터들 혹은 정규화 혹은 뭐 로스, 어떤 옵티마이저 이런 것들까지 모두 다 기록할 수 있습니다. 데이터셋에서는 어떤 데이터로 모델을 학습하고 검증했는지, 그 데이터셋에 대한 버전 혹은 데이터셋을 쿼리할 수 있는 데이터셋을 가져올 수 있는 어떤 정보 등을 기록합니다. 인바이어먼트에서는 어떤 환경에서 모델을 학습했는지 코드를 실행했는지 기록합니다. 여기에는 파이썬 라이브러리 의존성들을 정의할 수도 있고요. 혹은 내가 어떤 GPU 혹은 어떤 CPU 얼마만큼의 메모리를 사용했는지 이런 것들을 확인할 수 있습니다. 어떤 특정 테스크에서는 내가 사용한 GPU의 종류가 매우 중요할 수 있습니다. 그렇기 때문에 GPU의 모델까지 기록하게 됩니다. 다음은 매트릭과 모델인데요. 그 결과 어떤 성능, 어떤 평가 매트릭 혹은 어느 정도의 로스를 보였고 어떤 모델이 만들어졌는지 그 모델의 버전 등을 기록합니다. 머신 러닝 시험 관리가 중요한 이유입니다. 모델 성능 향상 및 최적화에 용이합니다. 수많은 실험을 진행했지만 어떤 요인이 성능 향상에 기여했는지 파악하기 어려웠습니다. 동일한 모델에 대해 팀원들이 서로 다른 하이퍼 파라미터 설정으로 실험을 진행하여 최적의 설정을 찾는 데 혼선이 있었습니다. 이런 예시와 같이 실험 관리를 통해 각 실험의 메타 데이터를 비교 분석하여 모델 성능에 영향을 미치는 주요 요인을 식별할 수 있습니다. 오른쪽에 있는 그림은 우리가 이번 강의에서 확인해 볼 웨이렌 바이어스의 페이지입니다. 각각의 실험에 대해 어떤 결과들이 있었는지 확인할 수 있고, 하이퍼 파라미터 옵티마이제이션에서 어떤 파라미터를 어떻게 선택했을 때 밸리데이션 에큐러시나 로스가 어떤 식으로 분포가 되는지를 한눈에 시각화해서 볼 수가 있습니다. 다음은 실험 재현성 확보입니다. 저번에 성능이 가장 좋았던 실험 설정이 기억나지 않아 다시 찾아보려고 했지만 정확한 설정을 확인할 수 없었습니다. 티원이 휴가로 인해 부재중일 때 해당 팀원의 실험을 이어서 진행해야 했으나 실험 설정을 파악하는 데 어려움을 겪었습니다. 이런 문제들은 실험 관리를 통해 과거 실험의 모든 설정을 추적할 수 있어 언제든지 최적의 모델을 재현할 수 있습니다. 또한 여러분들이 경진대회를 하면서 실험을 재현해야 되는 경우가 있을 텐데요. 예를 들어서 여러분들이 수상권에 들어가는 경우 그 대회의 호스트들은 여러분들에게 코드와 그리고 실험 조건들을 요구하게 됩니다. 이때 여러분들이 실험 관리를 하지 않고 실험 재연성을 확보하지 않았다면 불이익을 받을 수가 있겠죠. 다음으로는 협업 및 커뮤니케이션을 촉진하기 위한 이유도 있습니다. 팀원들이 나의 실험을 정확하게 이해하지 못해 프로젝트 진행에 어려움을 겪었습니다. 실험 결과 공유 회의에서 팀원들에게 실험 내용을 설명하는 데 많은 시간이 소요되었습니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(6강) 모델 실험 관리.json",
        "lecture_name": "(6강) 모델 실험 관리",
        "course": "기타",
        "lecture_num": "6강",
        "lecture_title": "모델 실험 관리",
        "chunk_idx": 0,
        "total_chunks": 7,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:f93ca0a31fa81432b59ff73565dc100dadc54753cbde31ecda230eb0820d3a9d"
      },
      "token_estimate": 1083,
      "char_count": 1967
    },
    {
      "id": "transcript_기타_6강_모델_실험_관리_c001_7362c6",
      "content": "[기타] (6강) 모델 실험 관리\n\n다. 이때 여러분들이 실험 관리를 하지 않고 실험 재연성을 확보하지 않았다면 불이익을 받을 수가 있겠죠. 다음으로는 협업 및 커뮤니케이션을 촉진하기 위한 이유도 있습니다. 팀원들이 나의 실험을 정확하게 이해하지 못해 프로젝트 진행에 어려움을 겪었습니다. 실험 결과 공유 회의에서 팀원들에게 실험 내용을 설명하는 데 많은 시간이 소요되었습니다. 이러한 내용들은 실험 관리를 통해 실험 내용을 체계적으로 기록하고 공유함으로써 팀원 간 이해도를 높이고 효과적인 커뮤니케이션이 가능하도록 합니다. 오른쪽에 있는 예시는 웨이렌 바이어스에서 여러분들이 실험한 실험 기록들을 기반으로 작성할 수 있는 레포트의 예시입니다. 다음과 같은 레포트를 작성하고 팀원들에게 공유함으로써 쉽게 팀원과 협업하고 커뮤니케이션을 할 수 있도록 도와줍니다. 실험 관리를 통한 성능 비교를 통해 최적의 모델을 선정하거나 개선할 수 있습니다. 실험 관리는 다음 큰 세 가지의 흐름을 따르는데요. 실험 메타 데이터 기록, 실험 간 성능 비교 분석, 최적 모델 선정 및 개선 실험 메타 데이터 기록에서는 이전에 언급했었던 각 실험의 설정, 하이퍼 파라미터 데이터 셋 등을 기록합니다. 또한 실험 결과 정확도나 손실과 같은 이런 매트릭들도 같이 저장합니다. 실험 간 성능 비교 분석에서는 기록된 메타 데이터를 바탕으로 실험 간 성능을 비교할 수 있도록 합니다. 주요 성능 지표 정확도나 정밀도, 재현율 1 스코어 등 이런 스코어들을 활용을 하게 되고요. 시각화 도구인 그래프나 차트 등을 통해서 직관적으로 비교할 수 있게 됩니다. 최적 모델 선정 및 개선에서는 비교 분석 결과를 바탕으로 최적 성능의 모델을 선정하게 되는데요. 선정된 모델의 하이퍼 파라미터 데이터셋 등을 분석하여 개선점을 도출합니다. 개선된 설정으로 추가 실험 수행 및 반복적인 개선이 가능해집니다. 다음은 웨일렌 바이어스를 활용한 실험 기록 및 분석에 대해서 알아보겠습니다. 이런 실험 관리 툴에는 다양한 도구들이 있습니다. 대표적으로는 ML 플로우 혹은 간단하게 우리가 사용할 수 있는 텐서 보드 같은 것부터 시작을 해서 다양한 툴들이 있는데요. 대부분 유사한 핵심 기능들을 제공합니다. 실험 추적 및 관리 트래킹 기능입니다. 예측 결과 시각화 비주얼라이제이션 기능입니다. 하이퍼 파라미터 튜닝 옵티마이제이션 기능입니다. 데이터 및 모델 버전 관리 버저닝 기능입니다. 하지만 우리 강의에서는 웨이 앤 바이어스라고 하는 툴을 중심으로 소개를 시켜 드리겠습니다. 그러면 왜 웨이앤 바이러스이냐 단 다섯 줄의 코드로 시작하는 간편함 그리고 파이토치, 텐서플로우, 케라스 등 모든 프레임워크와의 간편한 통합이 가능합니다. 또한 CPU, GPU 사용량 등 여러분들이 학습에 사용하는 리소스의 실시간 모니터링도 가능합니다. 추가로 웹 브라우저를 통한 직관적인 결과 확인 및 팀원과의 손쉬운 공유 이게 가능한데요. 이게 왜 장점이냐라고 하면 우리가 일반적으로 쉽게 사용할 수 있는 텐서보드나 엠엘 플로우 같은 경우는 산에 숨겨져 있는 인프라에 설정이 되기 때문에 인프라 바깥에서 접속하는 게 제한되어 있는 경우가 있습니다. 하지만 웨이드 앤 바이러스 같은 경우는 단순히 휴대폰 혹은 웹 브라우저 로그인을 통해서 그 결과를 확인할 수 있기 때문에 다른 툴들에 비해 조금 더 자유롭게 조금 더 쉽게 공유를 하거나 확인을 할 수 있게 됩니다. 터미널에 다음과 같이 명령어를 입력해서 라이브러리를 설치하고 로그인을 합니다. API 키는 익스포트 명령어로 환경 변수에 직접 설정하거나 여러분들이 완디비 로그인이라는 명령어를 실행을 하게 되면 웹 페이지를 연동해서 인증할 수가 있습니다. 그렇기 때문에 여러분들이 터미널을 사용하는 것에 두려움이 있으시다면 원디비 로그인이라고 하는 명령을 사용하는 걸 추천을 드립니다. 그런데 당연히 웨이드 앤 바이어스를 사용하시려면 먼저 회원 가입을 하시는 것을 추천을 드리고요. 회원 가입을 먼저 하지 않았다 하더라도 완디비 로그인이라고 하는 명령어를 수행을 하실 때 회원 가입을 자연스럽게 하시게 될 겁니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(6강) 모델 실험 관리.json",
        "lecture_name": "(6강) 모델 실험 관리",
        "course": "기타",
        "lecture_num": "6강",
        "lecture_title": "모델 실험 관리",
        "chunk_idx": 1,
        "total_chunks": 7,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:f93ca0a31fa81432b59ff73565dc100dadc54753cbde31ecda230eb0820d3a9d"
      },
      "token_estimate": 1108,
      "char_count": 2007
    },
    {
      "id": "transcript_기타_6강_모델_실험_관리_c002_8638fc",
      "content": "[기타] (6강) 모델 실험 관리\n\n다. API 키는 익스포트 명령어로 환경 변수에 직접 설정하거나 여러분들이 완디비 로그인이라는 명령어를 실행을 하게 되면 웹 페이지를 연동해서 인증할 수가 있습니다. 그렇기 때문에 여러분들이 터미널을 사용하는 것에 두려움이 있으시다면 원디비 로그인이라고 하는 명령을 사용하는 걸 추천을 드립니다. 그런데 당연히 웨이드 앤 바이어스를 사용하시려면 먼저 회원 가입을 하시는 것을 추천을 드리고요. 회원 가입을 먼저 하지 않았다 하더라도 완디비 로그인이라고 하는 명령어를 수행을 하실 때 회원 가입을 자연스럽게 하시게 될 겁니다. 다음으로는 원디비 대시보드 둘러보기입니다. 대시보드는 프로젝트와 실행 런이라고 하는 것으로 구성됩니다. 프로젝트는 모든 관련 실험들을 담는 최상위 폴더라고 생각하시면 됩니다. 일반적으로는 어떤 모델의 이름 정도로 이해를 하시면 되고요. 런즈는 그 프로젝트 안에서 하나하나의 실험들을 기록하는 단위입니다. 한 번의 실험에 대한 모든 기록 로그와 결과 이런 것들이 저장되는 단위라고 생각하시면 됩니다. 이미지에서 보여지듯이 상단을 보시면 프로젝트 파인 튠 벌트 텍스트 클래시피케이션이라고 되어 있고요. 아래쪽에 런즈라고 하는 리스트를 보시면 이전에 실험했었던 실험 기록들을 확인을 하실 수가 있습니다. 다음은 워크스페이스입니다. 워크 스페이스는 다양한 차트와 테이블을 조합하여 여러 실험을 한눈에 비교하고 분석하는 메인 분석 화면입니다. 사용자가 자유롭게 패널을 추가하고 레이아웃을 변경할 수 있는데요. 워크스페이스에 들어가는 방법은 왼쪽 탭에 있는 워크스페이스 버튼을 통해서 워크스페이스로 진입할 수 있습니다. 워크스페이스의 주요 패널 몇 가지에 대해 살펴보겠습니다. 첫 번째는 차트입니다. 모델이 학습하면서 기록했었던 로스 에큐라시 등 완디비 닷 로그 메소드로 기록된 지표들이 시각화되는 기본 단위입니다. 라인 차트나 막대 차트 등 여러 가지 차트로 그릴 수 있습니다. 다음은 테이블입니다. 예측 결과, 이미지, 텍스트 등 복잡한 데이터를 표 형태로 기록하고 정렬하거나 쿼리하며 상세히 분석하는 강력한 기능입니다. 다음은 시스템입니다. 실험이 실행되는 동안에 CPU, GPU 사용량, 메모리, 네트워크 상태 등을 실시간으로 보여주는 패널입니다. 우리가 이 패널을 통해 우리 모델 학습의 병목이 발생하는 지점을 분석해서 모델 학습 속도 혹은 메모리 사용량 등을 파악해 볼 수 있습니다. 예를 들어 CPU나 GPU 사용량이 매우 낮다고 가정을 해 보겠습니다. 그런데 네트워크 사용량이 매우 높다고 한번 해볼게요. 그리고 우리의 모델 학습 파이프라인이 데이터를 매번 원격에서 가져온다고 해 보겠습니다. 이런 경우일 때는 네트워크의 속도가 지피유랑 씨피유가 연산하는 속도를 따라가지 못해서 네트워크에서 병목이 발생한다라고 이해하시면 되겠습니다. 이런 경우에는 매 에폭 혹은 미니 배치마다 데이터를 원격에서 가져오는 것이 아니라 모델 학습을 시작할 때 데이터를 먼저 로컬에 다운을 받은 뒤에 디스크에서 직접 읽는 것을 추천드립니다. 물론 이 경우에서도 우리 디스크의 속도가 느린 경우라면 동일하게 디스크 병목이 발생할 수 있겠죠. 다음은 실제로 파이썬 코드에 연동하는 방법에 대해서 확인해 보겠습니다. 단 몇 줄의 코드로 기존 파이썬 스크립트에 완디비를 손쉽게 연동할 수 있습니다. 여러분들이 기억해야 하는 함수는 세 가지입니다. 이닛, 컨피그 로그, 원디비 닷 이닛 실험 추적을 시작하고 실험을 초기화합니다. 완디비 닷 컨피그 하이퍼 파라미터처럼 실험 시작 전에 고정되는 설정 값들을 저장합니다. 완디비 로그 학습 과정에서 변화하는 로스, 에큐러시 같은 값들을 기록합니다. 완디비 이닛 예시를 살펴보도록 하겠습니다. 실험을 추적하기 위해 새로운 실행을 생성을 해야 되는데요. 이때 완디비 이닛을 호출합니다. 완디비 이닛에 전달하는 인자로는 이 실행이 저장될 프로젝트의 이름을 전달합니다. 예시에서는 베이직 인트로라고 하는 프로젝트의 런이 기록이 될 거고요. 이 런의 이름은 익스페리먼트 언더스코어 1이라고 하는 런을 생성을 하게 됩니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(6강) 모델 실험 관리.json",
        "lecture_name": "(6강) 모델 실험 관리",
        "course": "기타",
        "lecture_num": "6강",
        "lecture_title": "모델 실험 관리",
        "chunk_idx": 2,
        "total_chunks": 7,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:f93ca0a31fa81432b59ff73565dc100dadc54753cbde31ecda230eb0820d3a9d"
      },
      "token_estimate": 1112,
      "char_count": 2008
    },
    {
      "id": "transcript_기타_6강_모델_실험_관리_c003_eae931",
      "content": "[기타] (6강) 모델 실험 관리\n\n다. 완디비 닷 컨피그 하이퍼 파라미터처럼 실험 시작 전에 고정되는 설정 값들을 저장합니다. 완디비 로그 학습 과정에서 변화하는 로스, 에큐러시 같은 값들을 기록합니다. 완디비 이닛 예시를 살펴보도록 하겠습니다. 실험을 추적하기 위해 새로운 실행을 생성을 해야 되는데요. 이때 완디비 이닛을 호출합니다. 완디비 이닛에 전달하는 인자로는 이 실행이 저장될 프로젝트의 이름을 전달합니다. 예시에서는 베이직 인트로라고 하는 프로젝트의 런이 기록이 될 거고요. 이 런의 이름은 익스페리먼트 언더스코어 1이라고 하는 런을 생성을 하게 됩니다. 이 완디비 이닛이 호출되는 순간 대시보드에는 새로운 실험 런이 생성이 되어 실시간 추적이 시작됩니다. 다음으로는 컨피그 실험 조건을 기록할 수 있는 기능인데요. 다음과 같이 러닝 웨이트 아키텍처, 데이터셋, 에폭스 같은 값들을 컨피그 필드에다가 추가를 해서 기록해 줍니다. 이런 식으로 전달된 컨피그 값들은 완디비 대시보드에서 표 형태로 관리되어 실험 간의 조건을 비교하고 분석하는 데 사용됩니다. 오른쪽 예시에서 보시면 컨피그로 전달한 필드들이 컬럼 형태로 추가된 것을 확인하실 수 있습니다. 다음은 실험 결과 혹은 지표를 기록할 수 있는 로그입니다. 여러분들이 훈련 루프 혹은 검증 루프 혹은 테스트 루프에서 기록하고 싶은 곳에서 원디비 닷 로그 그리고 딕셔너리로 여러분들이 기록할 정보들을 전달을 해 주시면 해당 정보들이 완디비에 저장이 됩니다. 완디비닷 로그 명령어를 사용하게 되면 각 실험 런의 학습 과정을 실시간으로 1디비 대시보드에서 모니터링 할 수 있습니다. 오른쪽 그림과 같이 각 에폭 혹은 각 스텝별로 기록된 로스와 에큐러시 등을 볼 수 있습니다. 다음 예시는 여러 러닝 레이트에 대해서 실험을 수행하는 것을 보여주는 코드입니다. 다음과 같이 여러 개의 실험, 여러 개의 런을 수행하는 경우 오른쪽에 있는 그림과 같이 여러 개의 런이 생성이 됩니다. 이 생성된 런들은 하나의 차트에서 결과를 확인하실 수 있습니다. 이것으로 우리가 다양한 실험을 한눈에 볼 수 있게 됩니다. 다음은 완디비를 활용한 실험 고도화입니다. 먼저 아티팩트에 대해서 이야기해 보겠습니다. 아티팩트는 웨이레인 바이러스 원에 사용된 입력 그리고 출력을 추적하고 버전을 관리하는 기능입니다. 이를 통해서 실험의 재연성을 완벽하게 보장할 수 있습니다. 다음으로는 원과 아티팩트에 대해서 비교해 보겠습니다. 런에서는 실험의 설정과 스칼라 결과 값들을 기록을 하고요. 아티팩트에서는 실험에 사용된 파일 그 자체를 기록합니다. 주요 예시로는 런에서는 하이퍼 파라미터, 러닝 레이트, 메타데이터 모델 이름, 성능 지표, 에큘러시, 로스 등을 기록하고요. 아티팩트에서는 데이터 셋 혹은 모델 가중치 혹은 결과 파일, 결과 파일에서는 평가 그래프나 예측 결과표 같은 것들을 이야기합니다. 런은 실험 과정과 결과를 모니터링하는 데 집중이 되어 있고, 아티팩츠는 데이터와 모델의 버전 관리 및 계보를 추적하는 데 있습니다. 사실 아티팩트는 웨이 앤 바이어스에서만 사용하는 용어는 아닙니다. 우리가 AI 모델을 학습하면서 발생하는 여러 가지 파일 형태의 정보들을 모두 아티팩트라고 이야기를 합니다. 아티팩트를 통해 실험 파이프라인을 어떻게 관리하는지 예시로 보여드리겠습니다. 첫 번째로는 데이터셋을 생성하는 부분입니다. 학습 검증 평가 데이터셋을 로그 아티팩트를 통해 기록합니다. 여기에서 데이터 셋은 버전 0으로 기록이 됩니다. 다음 트레인 모델 쪽에서 유스 아티팩트라고 하는 메소드를 사용해 학습 검증 데이터셋을 다운로드 후 모델 학습에서 사용합니다. 여기서 사용하는 모델의 버전은 이전 단계에서 저장한 데이터 셋 브제로입니다. 로그 아티팩트를 통해 학습이 완료된 모델 체크 포인트를 기록할 수 있고요. 여기서 기록된 모델 아티팩트 이름은 모델 브제로가 됩니다. 다음 이밸류에이션 평가 단계에서는 유즈 아티팩트로 이전 단계에서 학습된 모델 체크 포인트와 평가 데이터셋을 불러와서 성능을 평가합니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(6강) 모델 실험 관리.json",
        "lecture_name": "(6강) 모델 실험 관리",
        "course": "기타",
        "lecture_num": "6강",
        "lecture_title": "모델 실험 관리",
        "chunk_idx": 3,
        "total_chunks": 7,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:f93ca0a31fa81432b59ff73565dc100dadc54753cbde31ecda230eb0820d3a9d"
      },
      "token_estimate": 1094,
      "char_count": 1979
    },
    {
      "id": "transcript_기타_6강_모델_실험_관리_c004_4d8443",
      "content": "[기타] (6강) 모델 실험 관리\n\n다. 여기에서 데이터 셋은 버전 0으로 기록이 됩니다. 다음 트레인 모델 쪽에서 유스 아티팩트라고 하는 메소드를 사용해 학습 검증 데이터셋을 다운로드 후 모델 학습에서 사용합니다. 여기서 사용하는 모델의 버전은 이전 단계에서 저장한 데이터 셋 브제로입니다. 로그 아티팩트를 통해 학습이 완료된 모델 체크 포인트를 기록할 수 있고요. 여기서 기록된 모델 아티팩트 이름은 모델 브제로가 됩니다. 다음 이밸류에이션 평가 단계에서는 유즈 아티팩트로 이전 단계에서 학습된 모델 체크 포인트와 평가 데이터셋을 불러와서 성능을 평가합니다. 여기서 불러오는 모델과 데이터 셋의 버전은 모델 브이제로 데이터 셋 브제로가 됩니다. 아티펙트를 활용하는 예시를 보여드리겠습니다. 먼저 데이터 전처리 및 버전 관리입니다. 이전에 배웠던 것과 동일하게 이닛이라고 하는 함수를 사용을 해서 런을 초기화합니다. 해당 런은 프리 프로세스 파이프라인이라고 하는 이름의 프로젝트에 기록이 됩니다. 먼저 리뷰스 프로세스라고 하는 이름으로 데이터 셋 타입의 아티팩트를 생성합니다. 이 아티팩트에 기록할 데이터를 다 에드 파일이라고 하는 메소드를 호출을 해서 파일에 경로를 전달합니다. 여기에서 런 닷 록 아티팩트 그런 다음 방금 생성한 아티팩트를 전달해서 해당 아티팩트를 웨일렌 바이어스 서버에 기록하도록 합니다. 여기서 기록된 정보 무비 리뷰스 닷 시스브 파일은 리뷰스 슬래시 프로세스 버전 지로라고 하는 이름과 버전으로 웨일렌 바이어스 서버에 저장됩니다. 이 버전은 전 처리가 적용되지 않은 초기 상태로 정의했습니다. 여기서 주의할 점은 여러분들이 이 예시에서 나오는 방식만을 꼭 따라야 한다는 것은 아닙니다. 우리 예시에서는 버전 제로는 전처리가 되지 않은 초기 상태다라고 정의했고 그렇게 저장한 것뿐입니다. 마지막으로 런 피니시라고 하는 함수를 호출해서 종료합니다. 이전 단계에 저장한 전처리되지 않은 데이터셋을 불러와서 가공 후 전처리한 뒤에 다시 저장하는 예시를 보겠습니다. 다시 한 번 더 웨이 인 바이러스 이닛 프리 프로세스 파이프라인이라고 하는 프로젝트의 런을 생성을 하고요. 이전 단계에서 저장한 리뷰스 슬래시 프리 프로세스 v0를 유즈 아티팩트라고 하는 메소드를 사용을 해서 불러옵니다. 아티팩트를 가져온 뒤에 실제로 사용하기 위해 다운로드 함수를 호출을 해서 실제 로컬 경로에 아티팩트를 다운을 받고요. 여기서 반환 받은 아티팩트 디아알이라고 하는 변수에는 이 아티팩트가 저장된 경로가 지정되어 있습니다. 판다스 리드 시스브 를 사용을 해서 CSV 파일을 읽어보겠습니다. 여기서 읽은 판다스 데이터 프레임에 텍스트라고 하는 컬럼에 대해서 구두점 제거 및 소문자 변환하는 전처리를 적용을 하고 다시 한 번 더 리뷰스 프리 프로세스 CSV라고 하는 파일로 저장합니다. 그다음에 전처리가 완료된 이 파일을 새로운 아티팩트 버전으로 기록을 하기 위해 동일한 이름으로 새 아티팩트를 생성합니다. 생성한 아티팩트 객체에 에드 파일이라고 하는 함수를 호출해서 파일을 기록합니다. 그다음 로그 아티팩트라고 하는 함수를 뉴 아티팩트와 함께 호출해서 실제 웨일 앤 바이어 서버에 저장되도록 합니다. 이때 저장된 리뷰 프로세스라고 하는 아티팩트의 버전은 0에서 1로 하나 추가됩니다. 이때 버전은 자동으로 올라가니까 별도로 신경 쓰지 않으셔도 괜찮습니다. 이제 모델 학습 등 혹은 다음 단계에서는 us 아티팩트 함수를 호출할 때 리뷰스 프리 프로세스트 v1이라고 하는 아티팩트 이름과 버전을 사용해야 합니다. 예시에서도 보시면 유즈 아티팩트 리뷰 프로세스트 v1 이라고 하는 아티펙트를 불러와서 다운로드를 한 뒤에 그 경로에 있는 데이터를 모델 학습에 사용하도록 합니다. 이를 통해 어떤 데이터로 실험했는지 명확히 추적하고 재연성을 보장할 수 있습니다. 여기서 추가로 주의할 점이 있는데요. 만약에 여러분들이 사용하는 데이터셋의 크기가 너무나 크다면 모든 데이터셋을 웨일 앤 바이어스 서버에 저장하는 것이 비효율적일 수 있습니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(6강) 모델 실험 관리.json",
        "lecture_name": "(6강) 모델 실험 관리",
        "course": "기타",
        "lecture_num": "6강",
        "lecture_title": "모델 실험 관리",
        "chunk_idx": 4,
        "total_chunks": 7,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:f93ca0a31fa81432b59ff73565dc100dadc54753cbde31ecda230eb0820d3a9d"
      },
      "token_estimate": 1093,
      "char_count": 1974
    },
    {
      "id": "transcript_기타_6강_모델_실험_관리_c005_e392f4",
      "content": "[기타] (6강) 모델 실험 관리\n\n다. 예시에서도 보시면 유즈 아티팩트 리뷰 프로세스트 v1 이라고 하는 아티펙트를 불러와서 다운로드를 한 뒤에 그 경로에 있는 데이터를 모델 학습에 사용하도록 합니다. 이를 통해 어떤 데이터로 실험했는지 명확히 추적하고 재연성을 보장할 수 있습니다. 여기서 추가로 주의할 점이 있는데요. 만약에 여러분들이 사용하는 데이터셋의 크기가 너무나 크다면 모든 데이터셋을 웨일 앤 바이어스 서버에 저장하는 것이 비효율적일 수 있습니다. 실제로 여러 클라우드 벤더사들은 클라우드 인프라 내에서 외부로 큰 데이터가 빠져나가는 부분에 대해서 비용을 청구하기도 하는데요. 웨일렌 바이어스는 일반적으로 각 클라우드사의 외부에 인프라가 존재하기 때문에 이 부분에서 비용이 발생할 수도 있습니다. 따라서 무조건 아티팩트로 데이터 셋을 저장해야 된다 이거는 잘못된 판단일 수 있습니다. 그렇기 때문에 여러분들이 사용하시는 인프라 개발 환경에 따라서 이 데이터셋 자체를 저장할지 혹은 이 데이터셋을 재현할 수 있는 어떤 메타 정보만을 기록할지는 잘 판단하셔야 됩니다. 다음은 방금 전에 저장된 이 아티팩트들의 정보들을 대시보드에서 확인을 해 보겠습니다. 왼쪽에 있는 그림과 같이 우리가 저장한 리뷰 프로세스라고 하는 데이터셋의 버전이 브이제로 브1으로 설정된 것을 보실 수가 있습니다. 코드를 우리가 두 번 실행했기 때문에 원본 브제로와 전처리 브1 2개의 버전이 자동으로 기록된 것을 볼 수 있습니다. 가장 최신 버전에는 엘레이티스트 태그가 자동으로 부여되고요. 여러분들이 유즈 아티팩트 이름을 전달하면서 버전을 전달했었는데 여기에 버전이 아니라 레이티스트를 전달하는 것으로 최신 버전은 쉽게 불러올 수 있습니다. 주요 프레임워크와의 통합 부분을 살펴보겠습니다. 웨일 앤 바이어스는 허깅페이스, 파이토치, 라이트닝 등 주요 라이브러리와 긴밀한 통합을 제공합니다. 이를 통해 아티팩트와 같은 고급 기능을 코드를 거의 작성하지 않고도 자동화할 수 있습니다. 다음은 허깅페이스 트레이너의 예시를 먼저 보겠습니다. 위에서 보시면 학습 인자의 레퍼트 2를 1db로 설정을 합니다. 그다음 트레이너의 콜백스라고 하는 인자에다가 완디비 콜백 클래스를 전달하는 것으로 체크 포인트마다 모델을 아티팩트로 저장하는 기능을 제공합니다. 트레이너 닷 트레인이라고 하는 메소드를 실행하는 것으로 모델이 각 체크 포인트마다 아티팩트로서 완디비 서버에 저장이 됩니다. 다음은 레포트 기능입니다. 레폴스는 실험 결과 차트 표와 같은 분석 내용을 마크다운 텍스트를 결합해서 하나의 인터랙티브 문서로 만들어 주는 기능입니다. 실험 결과를 단순히 나열하는 것이 아니라 왜 이 실험을 했는지, 결과는 어떠했는지, 다음 스텝은 무엇인지와 같은 스토리를 담아 팀원들과 손쉽게 공유하고 논의할 수 있습니다. 특정 테스크에 대한 모든 실험 과정과 결론을 하나의 문서로 정리하여 팀의 지식 재산으로 축적합니다. 레포트 링크 하나로 모든 논의를 진행하여 별도의 발표자를 만들 필요가 없습니다. 다음과 같이 레포츠 기능을 통해 작성한 ML 실험 레포트를 팀원과 공유하고 협력하는 데 사용할 수 있습니다. 그 외의 강력한 기능들도 언급하고 넘어가겠습니다. 웨이렌 바이오스는 실험 추적을 넘어 엠메로스 파이프라인 전반을 지원하는 더 많은 고급 기능들을 제공합니다. 첫 번째로 스윕입니다. 스윗은 여러 하이퍼 파라미터 조합을 자동으로 탐색하여 최적의 조합을 찾아주는 기능입니다. 다음은 모델 레지스트리입니다. 훈련된 모델의 버전을 관리하고 스테이징 프로덕션 등 배포 단계를 체계화하는 중앙 저장소입니다. 다음은 오토메이션즈입니다. 정확도 95% 달성 시 슬랙 알림 보내기 등 특정 조건에 따라 후속 작업을 자동화하는 기능입니다. 이번 강의를 요약해 보겠습니다. 머신 러닝 실험 관리의 필요성에서는 머신러닝 모델 개발 과정에서 수행하는 모든 실험의 과정과 결과를 체계적으로 관리하는 활동이라고 했습니다. 이는 모델 성능 향상 및 최적화, 실험 재연성 확보, 팀 협업 및 커뮤니케이션 촉진에서 중요성을 가지고 있습니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(6강) 모델 실험 관리.json",
        "lecture_name": "(6강) 모델 실험 관리",
        "course": "기타",
        "lecture_num": "6강",
        "lecture_title": "모델 실험 관리",
        "chunk_idx": 5,
        "total_chunks": 7,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:f93ca0a31fa81432b59ff73565dc100dadc54753cbde31ecda230eb0820d3a9d"
      },
      "token_estimate": 1110,
      "char_count": 1999
    },
    {
      "id": "transcript_기타_6강_모델_실험_관리_c006_879505",
      "content": "[기타] (6강) 모델 실험 관리\n\n다. 훈련된 모델의 버전을 관리하고 스테이징 프로덕션 등 배포 단계를 체계화하는 중앙 저장소입니다. 다음은 오토메이션즈입니다. 정확도 95% 달성 시 슬랙 알림 보내기 등 특정 조건에 따라 후속 작업을 자동화하는 기능입니다. 이번 강의를 요약해 보겠습니다. 머신 러닝 실험 관리의 필요성에서는 머신러닝 모델 개발 과정에서 수행하는 모든 실험의 과정과 결과를 체계적으로 관리하는 활동이라고 했습니다. 이는 모델 성능 향상 및 최적화, 실험 재연성 확보, 팀 협업 및 커뮤니케이션 촉진에서 중요성을 가지고 있습니다. 웨이 레인 바이러스를 활용한 실험 기록 및 분석에서는 핵심 기능인 1db 이닛, 디비 컨피크, 디비 로그 세 가지 함수를 통한 실험 조건 및 결과의 손쉬운 기록과 시각화를 살펴보았습니다. 웨이 레인 바이러스를 활용한 실험 고도화에서는 고급 기능인 아티팩스를 통한 재연성 확보, 레포츠를 통한 지식 공유 그리고 허깅페이스 통합, 스위스 모델 레지스트리 등을 통한 워크플로우 자동화 및 고도화에 대해 배웠습니다. 이번 강의는 여기까지입니다. 고생 많으셨습니다.",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(6강) 모델 실험 관리.json",
        "lecture_name": "(6강) 모델 실험 관리",
        "course": "기타",
        "lecture_num": "6강",
        "lecture_title": "모델 실험 관리",
        "chunk_idx": 6,
        "total_chunks": 7,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:f93ca0a31fa81432b59ff73565dc100dadc54753cbde31ecda230eb0820d3a9d"
      },
      "token_estimate": 305,
      "char_count": 562
    }
  ]
}