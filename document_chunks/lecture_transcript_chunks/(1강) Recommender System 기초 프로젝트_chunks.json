{
  "source_file": "(1강) Recommender System 기초 프로젝트.json",
  "lecture_name": "(1강) Recommender System 기초 프로젝트",
  "course": "RecSys",
  "total_chunks": 14,
  "chunks": [
    {
      "id": "transcript_recsys_1강_recommender_system_기초_프로젝트_c000_82d6a8",
      "content": "[강의 녹취록] 과목: RecSys | 강의: 1강 | 제목: Recommender System 기초 프로젝트\n\n안녕하세요. 추천 시스템 기초 프로젝트 강의를 맡게 된 이준원이라고 합니다. 저는 학교에서 머신 러닝을 전공한 뒤에 기업에서 에듀테크와 추천 시스템 관련 업무를 주로 진행했습니다. 추천 시스템에 필요한 데이터 작업, 모델링, 사후 분석 등을 주로 진행해 왔고 이런 업무를 진행하면서 추천 시스템에 필요한 기초 이론들을 정리해 왔는데요. 저는 이러한 내용들을 강의로 묶어서 여러분들에게 전달해 드리게 되었습니다. 이번 강좌는 추천 시스템의 기둥이 되는 내용을 다루게 됩니다. 추천 시스템이라는 연구 분야가 처음 다져지는 시기에 등장했던 전통적인 추천 방법론부터 최근에 등장한 딥러닝 기반 모델 발전까지의 내용을 여러분들이 강의를 통해 이해하시고 직접 구현하시게 됩니다. 또한 강의와 함께 진행되는 대회를 통해서 추천 시스템에 필요한 이디에나 피처 엔지니어링 모델링 등을 경험하고 최종 지표를 통해서 대회를 통해 스스로 여러분들이 발전할 수 있게 됩니다. 네 이번 강좌에서 주로 다루게 되는 내용 추천 시스템 이론인데요. 첫 번째로는 추천 시스템의 기본 원리와 방법론을 학습하게 됩니다. 두 번째로는 다양한 추천 시스템 모델과 알고리즘을 이해하고 문제 상황에 맞는 데이터를 설명할 수 있습니다. 세 번째로는 추천 시스템에 사용되는 주요 알고리즘과 모델의 원리를 논문을 통해서 배우고 설명 가능할 수 있게 됩니다. 마지막으로 딥러닝 기반 추천 시스템 이론을 배우고 구현을 파이썬과 파이토치 실습으로 배우게 됩니다. 우측에 보이는 이 표는 여러분들이 앞으로 다루게 될 추천 모델을 분류에 따라 정리한 내용입니다. 지금 봐서는 이해하기 어렵겠지만 전체 모든 강의를 소화한 후에 이 분류표를 다시 보시면 한눈에 우리가 다뤘던 추천 시스템 모델 종류들이 들어오게 될 것입니다. 강좌와 함께 진행되는 대회를 통해서는 아래 목표들을 배우게 됩니다. 먼저 추천 시스템 경진대회 자체의 프로세스를 이해하고 실제 데이터를 통해서 다양한 이론과 모델로 접근해 보면서 추천 시스템 애플리케이션을 수행해 보게 됩니다. 그리고 추천 시스템의 주요 사용되는 라이브러리들을 여러분이 직접 인포트 해 보고 코딩을 통해서 직접 모델링을 경험해 볼 수 있고요. 그리고 이제 가장 중요한 것이 데이터마다 특성이 있는데 그 특성을 여러분들이 고민하셔서 발굴한 eda를 통해서 데이터의 인사이트를 찾고 이를 통해 모델에 적용하여서 최종적으로는 추천 시스템 대회와 친해지는 것이 여러분들의 목표입니다. 대회에서는 이 우측에 보이는 책 평점 북 레이팅을 예측하는 대회를 참여하게 될 것인데요. 이 대회에 대해서는 가장 마지막에 자세하게 다루도록 하겠습니다. 네 그래서 이번 첫 번째 시간은 추천 시스템에 사용되는 다양한 모델을 살펴보기에 앞서서 먼저 추천 시스템이란 무엇인지, 어떤 데이터를 다루고 풀어야 되는 문제는 무엇인지 등에 대한 가장 베이직한 내용을 살펴보겠습니다. 비교적 쉽고 굉장히 기본적인 내용으로 이루어져 있지만 그만큼 추천 시스템의 내용을 이해하기 전에 가장 다루고 가야 할 중요한 부분입니다. 네 이번 강의에서 다루는 내용은 크게 세 가지인데요. 먼저 추천 시스템에 대한 개요를 다루고 그다음에 추천 시스템을 평가하는 지표 평가 지표를 배운 이후에 가장 기본적으로 쉬운 방법인 인기도 기반 추천 방식을 학습하게 됩니다. 네 먼저 추천 시스템에 대한 개요 부분입니다. 추천 시스템이 왜 필요한지 앞으로 우리가 어떤 문제를 풀 것이고 어떤 데이터를 사용할 것인지에 대한 가장 기초적인 내용을 학습합니다. 근데 지금 보시는 다양한 서비스들은 이미 여러분들이 잘 알고 있는 것이고 이런 서비스 안에서는 다양한 콘텐츠를 소비하거나 또는 물건을 구입하는 등의 다양한 유저들의 행위가 이루어집니다. 보시면 넷플릭스나 유튜브와 같이 영상 콘텐츠를 소비할 수도 있고 네이버 웹툰 안에서 웹툰을 볼 수도 있고요. 또는 쿠팡이나 알리 익스프레스에서 여러분들이 온라인으로 다양한 상품을 구매할 수도 있습니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(1강) Recommender System 기초 프로젝트.json",
        "lecture_name": "(1강) Recommender System 기초 프로젝트",
        "course": "RecSys",
        "lecture_num": "1강",
        "lecture_title": "Recommender System 기초 프로젝트",
        "chunk_idx": 0,
        "total_chunks": 14,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:e6fc1d273d498669899a80c7e20b85dc05964f93f465a2c4a11c518f0be25258"
      },
      "token_estimate": 1100,
      "char_count": 1998
    },
    {
      "id": "transcript_recsys_1강_recommender_system_기초_프로젝트_c001_09f90f",
      "content": "[RecSys] (1강) Recommender System 기초 프로젝트\n\n다. 추천 시스템이 왜 필요한지 앞으로 우리가 어떤 문제를 풀 것이고 어떤 데이터를 사용할 것인지에 대한 가장 기초적인 내용을 학습합니다. 근데 지금 보시는 다양한 서비스들은 이미 여러분들이 잘 알고 있는 것이고 이런 서비스 안에서는 다양한 콘텐츠를 소비하거나 또는 물건을 구입하는 등의 다양한 유저들의 행위가 이루어집니다. 보시면 넷플릭스나 유튜브와 같이 영상 콘텐츠를 소비할 수도 있고 네이버 웹툰 안에서 웹툰을 볼 수도 있고요. 또는 쿠팡이나 알리 익스프레스에서 여러분들이 온라인으로 다양한 상품을 구매할 수도 있습니다. 여기서의 공통점은 각각의 서비스는 그 안에 아주 많은 수백만 개, 수천만 개 수억 개의 아이템으로 이루어져 있다는 점입니다. 그렇다면 이런 서비스를 사용하는 유저들의 입장에서는 원하는 아이템을 내가 어떻게 소비하게 될까요? 첫 번째 방법은 여러분들이 많이 사용하시는 검색이라는 방법이 있습니다. 이 검색 같은 경우에는 내가 이 서비스에 방문했을 때 이미 어떠한 의도를 가지고 상품이나 콘텐츠를 찾는 행위입니다. 따라서 검색에는 사용자의 의도가 담긴 키워드가 보통 사용이 됩니다. 고양이 관련된 영상을 보고 싶으면은 유튜브에 고양이라는 키워드로 검색을 할 수도 있고요. 노트북을 구매하고 싶으면 쿠팡에 들어가서 노트북이라고 검색할 수도 있겠죠. 이렇게 검색을 통해서 아이템을 소비하는 방식을 풀 방식이라고 합니다. 사용자가 어떤 의도를 가지고 아이템을 당겨오기 때문에 풀이라고 표현되는 것이죠. 그래서 유저가 비교적 정확한 의도를 가지고 적절한 키워드를 선택해서 상품을 검색하면 그에 맞는 상품들이 유저에게 노출되고 그 상품 리스트 중에 유저가 원하는 상품을 선택해서 소비하게 되는 방식입니다. 그러나 반대로 추천은 푸시 방식입니다. 추천의 경우에는 사용자가 어떤 의도를 가지거나 어떤 키워드를 명목적으로 제공하지 않더라도 상품을 유저에게 노출해 줘야 합니다. 사용자의 의도나 흥미를 전혀 고려하지 않고도 노출하기도 하고요. 어떨 때는 사용자가 본인이 모르는 어떤 취향이나 페르소나에 맞게 아이템을 추천하기도 합니다. 그렇다면 추천 시스템이 왜 중요하고 왜 필요할까요? 사실 과거에는 우리가 유저들이 접할 수 있고 소비할 수 있는 콘텐츠가 굉장히 제한적이었습니다. TV 채널, 영화관, 신문 등이 전부인 시절에는 사실 유저가 세상에 존재하는 모든 아이템을 소비할 수 있을 정도로 개수가 굉장히 적었습니다. 그러나 웹 모바일 환경이 발달하고 지금은 다양한 상품 서비스 콘텐츠들이 등장하게 되면서 과거에는 정보가 부족했지만 지금은 오히려 너무나 많아지는 풍요의 상태가 되었죠. 그래서 몇 개의 아이템이 아주 많이 소비되는 것이 아니라 아주 다양한 아이템이 롱테일의 형태로 분포하면서 소비되고 있습니다. 이걸 롱테일 피드맨넘이라고 부르는데요. 인기 있는 소수의 아이템이 많이 소비되고 그 외에 아주 많은 다수의 아이템들이 적게 소비되는 형태입니다. 그래서 아이템의 개수가 많아지면 많아질수록 이 꼬리가 점점 길어지게 됩니다. 이렇게 아이템의 개수가 기하급수적으로 많아지면서 유저가 원하는 정보를 찾는 행위도 오래 걸리고 비효율적으로 점점 되고 있습니다. 그래서 사실 검색이라는 기술도 유저가 내가 원하는 정보를 효율적으로 찾기 위해서 등장하게 되었습니다. 애초에 상품이 100개밖에 안 되면 검색할 필요도 없겠죠. 그러나 어떤 경우에는 검색이 아니라 유저가 의도가 없어도 서비스를 이용하고 싶고 콘텐츠를 보고 상품을 소비하고 싶을 수 있는데요. 이럴 경우에 추천이 가장 정확한 적용 사례가 됩니다. 유저가 자신이 원하는 거를 어떤 키워드로 찾아야 될지 모를 수도 있고 이럴 때 좋은 추천 엔진이라고 하는 것은 유저가 원하는 것을 유저 그 자신보다 더 잘 알고 적합한 아이템을 추천해 주는 것이죠. 요즘 많은 사람들에게 알려져 있는 유튜브 알고리즘이라는 것과 비슷한 원리입니다. 그래서 이제 이러한 추천은 소수의 아이템을 추천해 주는 데서 시작해서 점점 개인화의 영역으로 발전하고 있습니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(1강) Recommender System 기초 프로젝트.json",
        "lecture_name": "(1강) Recommender System 기초 프로젝트",
        "course": "RecSys",
        "lecture_num": "1강",
        "lecture_title": "Recommender System 기초 프로젝트",
        "chunk_idx": 1,
        "total_chunks": 14,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:e6fc1d273d498669899a80c7e20b85dc05964f93f465a2c4a11c518f0be25258"
      },
      "token_estimate": 1107,
      "char_count": 2004
    },
    {
      "id": "transcript_recsys_1강_recommender_system_기초_프로젝트_c002_890be0",
      "content": "[RecSys] (1강) Recommender System 기초 프로젝트\n\n다. 유저가 자신이 원하는 거를 어떤 키워드로 찾아야 될지 모를 수도 있고 이럴 때 좋은 추천 엔진이라고 하는 것은 유저가 원하는 것을 유저 그 자신보다 더 잘 알고 적합한 아이템을 추천해 주는 것이죠. 요즘 많은 사람들에게 알려져 있는 유튜브 알고리즘이라는 것과 비슷한 원리입니다. 그래서 이제 이러한 추천은 소수의 아이템을 추천해 주는 데서 시작해서 점점 개인화의 영역으로 발전하고 있습니다. 이렇게 될 경우에 소수의 많은 적은 아이템을 많은 사람들이 보는 것이 아니라 점점 우측의 롱테일 영역이 점점 커지게 되는 것이죠. 그래서 추천 시스템이 풀고자 하는 문제의 본질은 이 롱테일 영역을 점점 더 두껍게 만들어서 많은 사람들이 자신이 원하는 개인화된 콘텐츠나 개인화된 상품을 소비할 수 있도록 도와주는 것입니다. 네 그렇다면 추천이 사용되는 사례를 간단하게 살펴봅니다. 롱테일 추천 개인화 추천 위주로 사례를 살펴볼 텐데요. 사실 이러한 추천 사례는 이제 머신 러닝이나 AI를 모르는 사람들도 아이템이 뭐 알고리즘을 통해 추천된다고 알려질 정도로 모두가 아는 기술이 되었습니다. 특히 유튜브 동영상 추천이 더더욱 그런데요 어떤 조회 수가 높고 아주 높은 인기 있는 영상이 등장할 경우에 이 영상을 소비하고 나면 해당 영상과 관련이 있거나 혹은 그 해당 영상이 업로드되어 있는 채널의 영상을 추천하기도 합니다. 이때 추천되는 영상은 좌측 영역에 있는 인기도가 아주 많고 마치 인기 급상승 영상처럼 그런 것들이 추천될 수 있지만 사실 그렇지 않고 조회수가 높지 않은 몇 천 개 혹은 몇백 개의 오른쪽에 있는 롱테일 영역의 동영상들이 추천되는 경우도 꽤 많이 경험하셨을 것입니다. 그래서 지금 사용자가 보고 있는 현재 영상이라든지 혹은 과거에 좋아했던 영상들을 참고해서 과거의 패턴들을 참고해서 조회 수가 적지만 사용자가 좋아할 것 같은 영상을 개인화 추천해 주는 것이죠. 그래서 이런 롱테일 추천이 잘 이루어질수록 사용자는 더 큰 만족도를 느끼게 됩니다. SNS 친구 추천도 롱테일 추천이라고 볼 수 있습니다. SNS에는 수천만 혹은 수십억 명의 유저가 있고 이 중에서 인기가 많은 유저는 우리가 보통 알고 있는 연예인이나 인플루언서들이 많겠죠. 그렇지만 나한테 추천되는 것은 연예인이나 내가 알 만한 사람들도 있지만 말고 내 친구 혹은 내 친구와 친구 혹은 나와 가깝게 연결된 사람들도 추천이 많이 됩니다. 따라서 개개인별로 추천되는 친구들이 모두 다르기 때문에 어떻게 보면 이것도 롱테일 추천이라고도 볼 수 있습니다. 네 다음은 추천 시스템에서 사용되는 데이터에 대해 살펴보겠습니다. 모델링을 할 때 가장 중요한 것이 데이터가 되겠죠. 데이터는 크게 세 가지 분류로 나눌 수 있습니다. 서비스를 사용하는 유저에 대한 정보 그리고 추천을 통해 제공되는 아이템에 대한 정보 그리고 유저가 과거에 아이템을 소비했던 유저 아이템 상호 작용 정보 이렇게 세 가지입니다. 아래 그림과 같이 유저 원 유저 2 유저 3가 있고 우측의 아이템 1 아이템 2 아이템 3들이 있겠죠. 그리고 각각의 유저들은 자신이 가지고 있는 유저 정보 남자 혹은 여자 나이와 같은 어떤 메타데이터 정보들이 있고요. 아이템도 마찬가지로 그 아이템이 가지고 있는 어떤 카테고리나 아이템이 출시되어 있는 연도들이 등장하겠죠. 그럼 이 유저가 어떤 아이템을 소비했는지에 대한 이 가운데에 있는 데이터가 바로 유저 아이템 상호작용 정보입니다. 네 그럼 이 세 가지 데이터 중에서 먼저 유저 관련 정보를 살펴보겠습니다. 일단 유저에 대한 정보를 생성하는 작업 자체를 보통 유저 프로파일링이라고 하는데요. 우리가 추천을 수행할 유저들에 대한 정보를 다양한 방법으로 구축하는 행위 그 자체를 의미합니다. 그래서 유저 프로파일링을 통해 생성된 유저 정보는 꼭 추천 시스템뿐만 아니라 서비스의 다른 영역의 다른 피처로 사용될 수도 있습니다. 먼저 가장 중요한 가장 기본적인 데이터는 유저 아이디가 됩니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(1강) Recommender System 기초 프로젝트.json",
        "lecture_name": "(1강) Recommender System 기초 프로젝트",
        "course": "RecSys",
        "lecture_num": "1강",
        "lecture_title": "Recommender System 기초 프로젝트",
        "chunk_idx": 2,
        "total_chunks": 14,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:e6fc1d273d498669899a80c7e20b85dc05964f93f465a2c4a11c518f0be25258"
      },
      "token_estimate": 1077,
      "char_count": 1976
    },
    {
      "id": "transcript_recsys_1강_recommender_system_기초_프로젝트_c003_7a52e0",
      "content": "[RecSys] (1강) Recommender System 기초 프로젝트\n\n다. 네 그럼 이 세 가지 데이터 중에서 먼저 유저 관련 정보를 살펴보겠습니다. 일단 유저에 대한 정보를 생성하는 작업 자체를 보통 유저 프로파일링이라고 하는데요. 우리가 추천을 수행할 유저들에 대한 정보를 다양한 방법으로 구축하는 행위 그 자체를 의미합니다. 그래서 유저 프로파일링을 통해 생성된 유저 정보는 꼭 추천 시스템뿐만 아니라 서비스의 다른 영역의 다른 피처로 사용될 수도 있습니다. 먼저 가장 중요한 가장 기본적인 데이터는 유저 아이디가 됩니다. 서비스에서 발급하는 유저 아이디가 제일 일반적이고요. 뭐 광고 추천 같은 경우에서는 유저 아이디가 아니라 모바일 디바이스 여러분들이 들고 있는 아이폰이나 갤럭시가 가지고 있는 고유한 디바이스 아이디가 고유한 유저 아이디로 사용되기도 합니다. 그리고 서비스에 로그인하지 않은 경우에는 브라우저에 있는 쿠키를 유저 아이디 대용으로도 사용하기도 합니다. 네 그리고 전통적인 추천 시스템에서 가장 많이 사용되는 정보 중의 하나가 바로 데모 그래픽 정보입니다. 사용자의 성별, 연령, 지역 관심사 등을 이야기하는데요. 이러한 정보들은 유저들이 직접 가입할 때 입력하도록 하는 것이 가장 정확합니다. 그러나 요즘에는 개인정보 수집이 점점 까다로워지고 유저들도 가입하면서 이런 정보들을 적는 것이 점점 안 하기 때문에 이러한 정보를 직접 받는 것이 어려워졌습니다. 그래서 어떤 경우에는 사용자의 성별이나 연령이나 관심사를 추정 혹은 모델링을 통해서 클러스터링을 통해서 만든 다음에 이 추정된 정보를 사용하기도 합니다. 그리고 마지막으로 유저의 행동 정보입니다. 유저가 최근에 어떤 아이템을 소비했는지 어떤 페이지를 방문했는지 이런 것에 대한 정보입니다. 과거에는 이제 이러한 정보들을 많이 사용하고 싶었지만 모델링 자체가 굉장히 단순하고 피처를 많이 넣을 수 없기 때문에 이런 데이터를 사용하지 못했는데요. 요즘에는 다양한 딥러닝 모델들이 등장하면서 최근에 유저가 어떤 행동을 했는지에 대한 데이터를 사용해서 더 정교한 추천을 하게 되었습니다. 그래서 사실 요즘에는 이 유저 행동 정보를 피처화해서 이 데이터를 가지고 추천을 제공해 주는 것이 가장 중요한 피처가 되었습니다. 다음은 아이템 관련 정보입니다. 아이템에서 가장 중요한 정보는 아이템 아이디입니다. 이는 추천을 수행하는 서비스에서 발급되는 고유한 아이디고 이 아이템 아이디 없이는 추천을 수행할 수 없습니다. 그리고 이 아이템 안에 있는 정보 같은 경우에는 사실 추천 시스템에서 제공하는 상품이나 혹은 추천 시스템의 도메인에 따라서 크게 달라질 수 있는데요. 보통 이런 것들을 메타 데이터라고 합니다. 영화의 경우에는 뭐 영화 장르 출연, 배우 개봉, 연도 이런 것들이 아이템 메타데이터라고 볼 수 있고요. 커머스 서비스 같은 경우에는 뭐 상품 카테고리, 브랜드 가격 이런 것들이 되고요. 음악 같은 경우에는 음악이 가지고 있는 고유한 정보 아티스트나 작곡자, 작곡가 장르 그리고 혹은 음악 신호 그 자체가 아이템이 가지고 있는 고유한 정보가 됩니다. 그래서 아이템 관련 정보는 이 아이템 아이디를 제외한 나머지 영역에 대해서는 추천 아이템별로 추천 도메인별로 크게 다르기 때문에 보통은 이 추천 케이스마다 사용하는 방법론이 크게 달라지게 됩니다. 그리고 우리가 배우는 지금 이 이론 강의에서는 거의 다루지 않지만 콘텐트 베이스 레코멘데이션이라는 추천 모델에 대해서는 유저 아이템 정보보다는 아이템이 가지고 있는 그 고유한 정보만을 가지고 추천을 활용하는 방법론도 있습니다. 이런 경우에는 아이템이 가지고 있는 데이터들이 추천 시스템에서 굉장히 중요한 데이터가 되겠죠. 마지막으로는 유저가 아이템을 소비한 정보인 유저 아이템 상호작용 정보 상호작용 데이터가 있습니다. 유저가 오프라인에서 하던 온라인에서 하든 어쨌든 아이템과 어떤 상호작용을 할 때 그 데이터는 보통 로그 시스템의 로그로 남게 되고 이 로그가 추천 시스템에서 사용되는 모델의 피드백 데이터가 됩니다. 그래서 이 피드백은 보통 두 가지 분류로 나눌 수가 있는데요. 익스플리싯과 인플리시 피드백이 있습니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(1강) Recommender System 기초 프로젝트.json",
        "lecture_name": "(1강) Recommender System 기초 프로젝트",
        "course": "RecSys",
        "lecture_num": "1강",
        "lecture_title": "Recommender System 기초 프로젝트",
        "chunk_idx": 3,
        "total_chunks": 14,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:e6fc1d273d498669899a80c7e20b85dc05964f93f465a2c4a11c518f0be25258"
      },
      "token_estimate": 1128,
      "char_count": 2042
    },
    {
      "id": "transcript_recsys_1강_recommender_system_기초_프로젝트_c004_e3d6f6",
      "content": "[RecSys] (1강) Recommender System 기초 프로젝트\n\n다. 이런 경우에는 아이템이 가지고 있는 데이터들이 추천 시스템에서 굉장히 중요한 데이터가 되겠죠. 마지막으로는 유저가 아이템을 소비한 정보인 유저 아이템 상호작용 정보 상호작용 데이터가 있습니다. 유저가 오프라인에서 하던 온라인에서 하든 어쨌든 아이템과 어떤 상호작용을 할 때 그 데이터는 보통 로그 시스템의 로그로 남게 되고 이 로그가 추천 시스템에서 사용되는 모델의 피드백 데이터가 됩니다. 그래서 이 피드백은 보통 두 가지 분류로 나눌 수가 있는데요. 익스플리싯과 인플리시 피드백이 있습니다. 먼저 e스플래시 피드백 같은 경우에는 유저에게 아이템에 대한 만족도를 직접 물어봐서 그 만족도를 어떤 평점으로 나타내는 경우를 보통 의미합니다. 그래서 보통 영화나 맛집에 대한 우리가 평가를 할 때 1점부터 5점 척도 1점부터 10점 척도를 유저한테 요구하게 되고 그 유저는 거기에 대한 평가를 내리게 되겠죠. 근데 반대로 인플리시 피드백 같은 경우에는 어떤 익스플리시 어떤 명시적인 게 아닌 암묵적인 피드백인데요. 유저가 아이템에 대해서 직접 평가를 한 데이터가 아닙니다. 유저가 아이템을 클릭했다든지 어떤 상품을 구매했다든지 혹은 유튜브에서 10분짜리 동영상에 대해서 5분 동안 봤다. 이러한 데이터들이 모두 인플리시 피드백입니다. 그렇다 보니 이 익스플리시 피드백보다 인플리시 피드백의 데이터 양이 훨씬 많고 그래서 실제로 추천 모델을 학습할 때 서비스 내에서도 익스플리시 피드백이 제일 좋긴 하지만 요즘에 우리가 대부분 사용하는 어떤 플랫폼에서는 이 익스플리시 피드백 데이터는 보통 없고 대부분이 인플리시 피드백 데이터로 구성되어 있습니다. 그래서 추천 모델링을 할 때도 이 인플리시피 피드백을 많이 사용합니다. 그래서 만약에 쿠팡에서 유저가 어떤 상품을 구매했다라고 하면은 구매하면 1 구매하지 않음 0 이런 식으로 바이너리 값으로 10의 인플리시 피드백을 데이터로 저장하고 이것을 모델에 학습하게 됩니다. 네 자 그렇다면은 이제 추천 시스템에서 풀어야 되는 문제를 심플하게 정리해 보겠습니다. 추천 시스템이 하는 것은 특정 유저에게 적합한 아이템을 추천하거나 혹은 반대로 말하면은 특정 아이템에게 적합한 유저를 추천하는 것입니다. 그렇게 하기 위해서는 이 유저 아이템의 상호 작용을 평가할 수 있는 어떤 스코어 값이 필요하고 그 스코어 값을 기반으로 이 유저에게 높은 스코어를 가진 아이템들을 추천하게 되는 것입니다. 그래서 결국 이 추천을 위한 스코어를 구하는 게 가장 중요하고요. 그렇다면 이 스코어는 어떻게 구해지고 어떻게 사용되는지가 추천 시스템 모델링과 추천 시스템 서빙에서 가장 중요한 영역입니다. 네 그래서 이제 추천 시스템에서 다루는 문제를 살펴볼 텐데요. 추천 시스템 문제는 보통 크게 두 가지로 나눌 수 있습니다. 랭킹 문제 또는 예측 문제입니다. 먼저 랭킹 문제는 보통 탑 앤 레코멘데이션이라고도 불리는데요. 유저에게 적합한 어떤 유한한 아이템 톱 케이개를 유저에게 추천하는 문제입니다. 그리고 이 케이 계의 아이템을 선정하기 위한 기준 어떤 스코어가 필요하게 되겠죠 이 스코어를 구하게 되면 이 스코어를 이용해서 케이계의 아이템에 대해서 정렬을 하고 가장 높은 스코어를 가진 아이템 케이계를 추천하게 되는 것입니다. 그리고 이 케이디 아이템이 추천됐을 때 그 케이기 중에 사용자가 몇 개를 좋아했는지 그것들을 계산해서 평가하는 방식으로 진행이 됩니다. 먼저 이때 랭킹을 하기 위해서는 여기서 얘기하는 이 스코어가 어떤 유저가 아이템에 대한 정확한 선호도일 필요는 없습니다. 예를 들면 평점 1점부터 5점 중에서 예를 들면 뭐 어떤 영화는 4점 5점 어떤 영화는 3점 이런 식으로 유저한테 추천되는 것이 아니라 이 스코어는 1점부터 5점이 아닌 다른 스케일이어도 전혀 상관이 없습니다. 스코어를 정의하고 스코어를 계산할 수 있으면은 이 스코어를 구해서 아이템에 대해서 내림차순 정렬만 하게 되면은 그 내림차순 정렬 중에 가장 높은 아이템 k개가 사용자에게 추천되는 것입니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(1강) Recommender System 기초 프로젝트.json",
        "lecture_name": "(1강) Recommender System 기초 프로젝트",
        "course": "RecSys",
        "lecture_num": "1강",
        "lecture_title": "Recommender System 기초 프로젝트",
        "chunk_idx": 4,
        "total_chunks": 14,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:e6fc1d273d498669899a80c7e20b85dc05964f93f465a2c4a11c518f0be25258"
      },
      "token_estimate": 1098,
      "char_count": 2002
    },
    {
      "id": "transcript_recsys_1강_recommender_system_기초_프로젝트_c005_9351fb",
      "content": "[RecSys] (1강) Recommender System 기초 프로젝트\n\n다. 먼저 이때 랭킹을 하기 위해서는 여기서 얘기하는 이 스코어가 어떤 유저가 아이템에 대한 정확한 선호도일 필요는 없습니다. 예를 들면 평점 1점부터 5점 중에서 예를 들면 뭐 어떤 영화는 4점 5점 어떤 영화는 3점 이런 식으로 유저한테 추천되는 것이 아니라 이 스코어는 1점부터 5점이 아닌 다른 스케일이어도 전혀 상관이 없습니다. 스코어를 정의하고 스코어를 계산할 수 있으면은 이 스코어를 구해서 아이템에 대해서 내림차순 정렬만 하게 되면은 그 내림차순 정렬 중에 가장 높은 아이템 k개가 사용자에게 추천되는 것입니다. 그래서 이 케이 개가 선택된 이후에 평가하기 위한 지표들이 아래와 같이 프리시전 k WIC k 등등이 있고 이게 여기에 케이가 붙은 이유가 케이기를 추천했을 때 사용자가 얼마나 좋아했느냐를 정량적인 지표로 평가하기 위해서 이런 지표들을 사용하고 있습니다. 예측 문제 같은 경우에는 유저가 아이템을 가질 선호도 자체를 정확하게 예측하는 것입니다. 즉 평점을 정확하게 예측하는 혹은 이 유저가 이 상품을 클릭하거나 뭐 웹툰이나 어떠한 콘텐츠를 구매할 확률 그 확률 자체를 정확하게 예측하는 문제를 의미합니다. 그래서 익스플리 피드백 같은 경우에는 뭐 철수가 아이언맨이라는 영화에 대해서 내릴 평점 값을 정확하게 예측하는 문제가 될 수도 있고요. 인플리시 피드백 같은 경우에는 영희가 아이폰 10이라는 상품을 조회하거나 혹은 구매할 그 값 자체를 정확하게 예측하는 0과 1 사이의 확률 값을 예측하는 문제를 말합니다. 그래서 이 강의 이후에도 언급하겠지만 유저 아이템 행렬을 만든다고 했을 때 여기에 행렬에 있는 값들을 하나하나 채우는 문제라고도 볼 수 있습니다. 이제 이러한 예측 문제의 평가 지표는 앞에서 얘기했던 랭킹 문제의 평가 지표와는 완전히 다릅니다. 케이 개의 아이템을 얼마나 잘 추천했느냐가 아니라 어떤 에라는 유저가 어떤 1번 아이템에 갖는 정확한 선호도 정확한 평점 정확한 확률을 정확하게 예측했냐 예측하지 못했냐에 대한 값을 정량적으로 평가해야 합니다. 그래서 주로 사용되는 지표는 여러분들이 알고 있는 머신러닝 회귀 문제 분류 문제에서 사용되는 MA RMSE AUC 같은 지표를 가지고 평가하게 됩니다. 그래서 이러한 지표들에 대한 자세한 내용은 뒤쪽에서 다루도록 하겠습니다. 네 그래서 추천 시스템이 적용되는 사례는 뭐 굳이 설명하지 않더라도 너무나 많습니다. 넷플릭스 같은 경우에는 하나하나의 탭을 따서 서로 다른 추천 알고리즘을 적용해서 유저들이 좋아할 만한 추천 리스트가 뭔지 모르기 때문에 그 리스트를 여러 개를 준비해 놓는 경우도 있고요. 그래서 뭐 올 타임 인기 최근 인기 개인화된 추천 이런 식의 탭을 가져가기도 합니다. 쿠팡 같은 경우에는 첫 페이지에 들어갔을 때 tok 추천이 나오는데 이런 경우에는 이제 여러분들이 최근에 쿠팡에서 구매했던 상품들을 기반으로 어떤 케이크의 아이템 서로 다른 아이템을 추천할 수도 있고요. 그 밑에 있는 경우는 여러분들이 노트북을 구매했을 때 노트북과 관련된 연관된 노트북 상품들을 추천하기도 합니다. 그래서 어떤 케이스마다 UI마다 추천되는 아이템의 형태나 영역이 굉장히 달라질 수 있습니다. 네 그리고 여러분들은 잘 모르실 수 있지만 광고 영역도 굉장히 큰 추천의 도메인 중에 하나입니다. 왜냐하면 광고는 이걸 돈이 되기 때문입니다. 물론 콘텐츠도 많이 보면 돈이 되지만 광고는 광고를 송출하는 즉시 광고를 클릭하는 즉시 광고주가 플랫폼을 통해서 돈을 지불하고 플랫폼이나 여기에 있는 미디어들은 돈을 버는 구조이기 때문에 생각보다 추천 시스템 영역에서 광고가 굉장히 큰 영역을 차지하고 있습니다. 그래서 이 광고가 보여지는 영역이 왼쪽 이 부분도 있고요. 이 부분도 있고 이 부분도 있고 이 부분도 있고 한 페이지만 해도 광고가 이 부분도 있네요. 한 대여섯 개가 영역이 정해지고 이 영역에 대해서 어떤 광고를 내보낼지 그 광고의 소재를 정하는 것도 추천 문제라고 볼 수 있습니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(1강) Recommender System 기초 프로젝트.json",
        "lecture_name": "(1강) Recommender System 기초 프로젝트",
        "course": "RecSys",
        "lecture_num": "1강",
        "lecture_title": "Recommender System 기초 프로젝트",
        "chunk_idx": 5,
        "total_chunks": 14,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:e6fc1d273d498669899a80c7e20b85dc05964f93f465a2c4a11c518f0be25258"
      },
      "token_estimate": 1080,
      "char_count": 1987
    },
    {
      "id": "transcript_recsys_1강_recommender_system_기초_프로젝트_c006_cd9758",
      "content": "[RecSys] (1강) Recommender System 기초 프로젝트\n\n다. 그래서 이 광고가 보여지는 영역이 왼쪽 이 부분도 있고요. 이 부분도 있고 이 부분도 있고 이 부분도 있고 한 페이지만 해도 광고가 이 부분도 있네요. 한 대여섯 개가 영역이 정해지고 이 영역에 대해서 어떤 광고를 내보낼지 그 광고의 소재를 정하는 것도 추천 문제라고 볼 수 있습니다. 그 사용자가 좋아할 만한 광고를 내보내야 그 광고를 클릭하고 이 광고를 클릭을 통해서 상품을 구매하거나 앱을 설치하게 되면은 자연스럽게 광고주와 이 미디어 그리고 플랫폼이 모두 다 돈을 벌게 되는 그래서 이 추천 알고리즘이 광고 시스템 영역에서 굉장히 중요한 부분 중에 하나입니다. 그럼 지금까지 추천 시스템에 대한 전반적인 개요를 살펴보았습니다. 이제 추천 시스템 혹은 모델이 잘 작동하고 있는지 성능을 평가하는 평가 지표에 대해서 살펴보도록 하겠습니다. 네 새로운 추천 시스템이나 추천 모델을 적용했을 때 혹은 기존에 있는 모델을 새로운 모델로 교체했을 때 어떻게 평가해야 할까요? 일반적으로 추천 시스템을 적용한 뒤에 평가하는 관점은 다음과 같습니다. 먼저 비즈니스나 서비스 관점으로 추천 시스템을 새로 교체했을 때 혹은 새로 적용했을 때 매출이 증가했느냐 혹은 피브 페이지뷰 방문자 수 혹은 방문 순 방문 수가 증가했느냐 혹은 서비스적으로 이 추천 아이템을 통해서 유저의 CTR 즉 클릭할 확률이 상승했느냐 이런 것들이 어떻게 보면 비즈니스나 서비스 관점에서 가장 중요한 부분이고요. 그 밑에 있는 추천 품질 관점에서 봤을 때는 이제 추천된 아이템이 유저한테 얼마나 관련이 있는지 그리고 추천된 케이의 아이템이 다 비슷비슷한 게 아니라 얼마나 다양한지 그래서 유저들이 이걸 보고 다 비슷한 것만 있는 게 아니라 여러 가지 내가 좋아할 만한 것들이 많이 있는지 이런 것들이 다양성 부분이고 그리고 새로움 같은 경우에는 이제 여러분들이 새로 고침할 때마다 계속 똑같은 추천 아이템이 나오는 게 아니라 밖에 나갔다 다시 들어왔을 때는 이번에는 또 새로운 아이템들이 나와서 아 내가 아까 보지 않았던 아이템들이 추천이 되고 있는지, 그리고 이 밑에 있는 세련된 피티 같은 경우에는 위에 있는 연관성과 충돌될 수도 있는데 내가 어떤 노트북을 샀다고 해서 죄다 노트북 관련된 상품을 추천하기보다는 완전 새로운 재미인 노트북과 전혀 관련되지 않은 강아지 같은 상품을 추천해서 강아지 펫 용품 같은 상품이 전혀 관련은 없지만 어떤 유저가 기대할 수 있는 재미 혹은 생뚱맞은 아이템을 추천하는지 같은 평가 지표도 사용되기도 합니다. 그러나 우리는 추천 시스템 엔지니어로서 이러한 서비스적인 관점, 품질 관점보다는 먼저 정량적이고 공학적인 접근이 필요합니다. 그래서 추천 시스템을 위한 모델을 만든다고 했을 때 새로운 모델을 검증하기 위해 가장 먼저 수행되는 것은 이 오프라인 테스트입니다. 직접 유저로부터 수집된 실제 데이터를 사용해서 학습 데이터를 트레인 밸리드 테스트로 나누고 이 모델의 성능을 이 데이터를 사용하여서 객관적으로 평가하는 것입니다. 그래서 이 오프라인 테스트라는 것은 어떤 특별한 새로운 것이 아니라 보통 여러분들이 머신 러닝 모델을 만든다고 했을 때 그때 테스트 데이터 혹은 밸리데이션 데이터에 대해서 성능을 평가하는 그 평가를 말합니다. 그래서 보통 이러한 오프라인 테스트에서 좋은 성능을 보이면 온라인에서도 그러한 결과가 나오길 보통 기대하는데요. 물론 그렇지 않고 다양한 양상을 보이기도 합니다. 그중에 하나가 바로 서빙 바이어스인데요. 간단하게 서빙 바이어스가 뭔지 설명을 하자면 이제 우리가 사용했던 오프라인 테스트 데이터는 사실 과거의 추천 모델이 과거의 당시에 만든 추천 아이템을 소비한 로그입니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(1강) Recommender System 기초 프로젝트.json",
        "lecture_name": "(1강) Recommender System 기초 프로젝트",
        "course": "RecSys",
        "lecture_num": "1강",
        "lecture_title": "Recommender System 기초 프로젝트",
        "chunk_idx": 6,
        "total_chunks": 14,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:e6fc1d273d498669899a80c7e20b85dc05964f93f465a2c4a11c518f0be25258"
      },
      "token_estimate": 1010,
      "char_count": 1840
    },
    {
      "id": "transcript_recsys_1강_recommender_system_기초_프로젝트_c007_984d5d",
      "content": "[RecSys] (1강) Recommender System 기초 프로젝트\n\n다. 그래서 보통 이러한 오프라인 테스트에서 좋은 성능을 보이면 온라인에서도 그러한 결과가 나오길 보통 기대하는데요. 물론 그렇지 않고 다양한 양상을 보이기도 합니다. 그중에 하나가 바로 서빙 바이어스인데요. 간단하게 서빙 바이어스가 뭔지 설명을 하자면 이제 우리가 사용했던 오프라인 테스트 데이터는 사실 과거의 추천 모델이 과거의 당시에 만든 추천 아이템을 소비한 로그입니다. 그래서 새로운 추천 모델로 교체될 경우에 새로운 추천 모델이 생산하는 아이템이 소비가 될 것이고 그 아이템은 다시 학습 데이터에 사용되게 되겠죠. 그렇게 되면은 그 학습 데이터 안에 있는 아이템들은 계속 추천이 되지만 새로 추가된 아이템 같은 경우에는 기존 모델을 확인하지 못했기 때문에 계속해서 서빙되는 아이템만 계속 바이러싱이 일어나는 이런 서빙 바이러스 문제도 실제로 오프라인 테스트에서는 없지만 온라인 상황에서는 발생할 수도 있습니다. 그래서 꼭 이런 서빙 바이러스가 아니어도 실제 온라인 상황에서는 다양한 이유로 오프라인 테스트와 다른 양상을 보이기도 합니다. 그럼에도 오프라인 테스트가 선행되어야 하는 이유는 오프라인 테스트가 좋았는데 온라인 테스트가 안 좋을 수는 있지만 오프라인 테스트가 별로 안 좋았는데 온라인 테스트가 좋은 역 케이스는 거의 없기 때문에 오프라인 테스트는 반드시 먼저 진행되고 이후에 어떻게 해야 온라인 테스트를 잘 할 수 있을지를 설계해야 합니다. 네 다시 돌아와서 추천 모델의 성능을 평가하기 위한 오프라인 테스트의 지표를 보시면은 먼저 이 랭킹 문제와 예측 문제로 나눌 수 있다고 앞에 말씀드렸죠. 랭킹 문제에서는 이런 프리sion AK recl k 뒤에 k가 붙은 영역 이런 지표들이 있는데 이번 강의에서는 이 랭킹 문제에 대한 매트릭을 위주로 설명하겠습니다. 사실 예측 문제 같은 경우에는 여러분들이 리그레션이나 클래시피케이션에서 이미 많이 알고 있는 지표이기 때문에 굳이 다룰 필요가 없다고 생각했습니다. 네 그래서 프리시전 리콜 같은 경우에는 원래 에케가 붙지 않는 경우에는 여러분들이 바이너리 클래시피케이션 혹은 뭐 멀티클래스 클래시피케이션 문제에서 많이 사용되는 매트릭인데요. 이를 추천에 활용하게 되면은 랭킹을 통해서 케이 계의 아이템을 추천한 뒤에 그 케이계에 대한 프리시전과 리콜을 구할 수 있게 됩니다. 그래서 우리가 추천한 k개의 아이템 가운데 실제로 유저가 관심 있어 하는 아이템의 비율 이 프리시전이고 k개 중에 몇 개를 관심 있어 했는지 그리고 리콜 같은 경우에는 유저가 관심 있어 했던 전체 아이템 중에서 우리가 추천한 아이템이 포함돼 있는 비율이 되게 됩니다. 그래서 아래 예시를 보시면은 우리가 5개의 아이템을 추천했고 그중에서 추천한 아이템 5개 중에서 2개를 관심 있어야 했고 그리고 사실 유저는 자기가 관심 있어 하는 아이템 전체 개수가 3개라고 했을 때 프리션 n5는 5분의 2 분모가 k가 되겠죠. 그리고 리콜 에5는 분모가 케가 아니라 유저가 관심 있어 하는 아이템 개수 전체 3이 돼서 3분의 2가 됩니다. 그리고 map 같은 경우에는 방금 전에 프리션 lk에서 한 단계 더 발전한 매트릭인데요. 여기서 가장 큰 차이점은 추천된 k개의 아이템의 순서가 지표에 반영된다는 점입니다. 그래서 관련 아이템을 더 높은 순위에 추천했을 때 똑같이 5개를 추천한다고 했을지라도 a b c d e를 추천할 수도 있고 반대로 a d c be를 추천할 수 있겠죠. prestion AK 같은 경우에는 이 두 개의 값이 같은데요. 이제 map로 넘어오게 되면 순서에 따라서 이 값이 달라지게 됩니다. 그래서 이 AP 같은 경우에는 유저 1명에 대한 값을 의미하는 것이고요. 이 유저 1명에 대한 AP 값을 유저 n 명의로 평균을 냈을 때 그 값을 map라고 합니다. 그래서 이 맥시멈 에버리지 프리시션 map 같은 경우에는 유저 한 명당 하나의 AP 값이 나오고 그 유저를 전체로 확장했을 때 전체의 map 값이 나오게 됩니다. 네 다음은 추천 시스템에서 가장 많이 사용되는 NDCG라는 지표입니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(1강) Recommender System 기초 프로젝트.json",
        "lecture_name": "(1강) Recommender System 기초 프로젝트",
        "course": "RecSys",
        "lecture_num": "1강",
        "lecture_title": "Recommender System 기초 프로젝트",
        "chunk_idx": 7,
        "total_chunks": 14,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:e6fc1d273d498669899a80c7e20b85dc05964f93f465a2c4a11c518f0be25258"
      },
      "token_estimate": 1079,
      "char_count": 2023
    },
    {
      "id": "transcript_recsys_1강_recommender_system_기초_프로젝트_c008_2c1d1f",
      "content": "[RecSys] (1강) Recommender System 기초 프로젝트\n\n다. 그래서 이 AP 같은 경우에는 유저 1명에 대한 값을 의미하는 것이고요. 이 유저 1명에 대한 AP 값을 유저 n 명의로 평균을 냈을 때 그 값을 map라고 합니다. 그래서 이 맥시멈 에버리지 프리시션 map 같은 경우에는 유저 한 명당 하나의 AP 값이 나오고 그 유저를 전체로 확장했을 때 전체의 map 값이 나오게 됩니다. 네 다음은 추천 시스템에서 가장 많이 사용되는 NDCG라는 지표입니다. 원래는 이 지표는 검색에서 등장하던 지표인데 마찬가지로 여러분들이 t k개의 리스트 t k개의 리스트를 만들고 이 k를 추천했을 때 유저가 선호하는 아이템을 비교하여서 값을 구하는 것입니다. map와 마찬가지로 얘도 추천의 순서에 가중치를 두어서 이제 이 가중치가 점점 높아진다는 뜻은 이제 추천된 아이템을 가장 앞쪽에 추천했을 때겠죠. 근데 이제 map와 같이와 다르게 어떤 그 연관성 값을 바이너리 값이 아니라 어떤 수치값으로 사용할 수 있기 때문에 유저에게 얼마나 더 걸려 있는 아이템을 상위로 노출시키고 있는지 자체까지 알 수 있습니다. 그래서 말로 설명하기엔 좀 어려우니까 다음 페이지에 있는 예시를 통해 차이점을 살펴보겠습니다. 그래서 먼저 엔디시지를 구하기 위해서는 총 4가지의 개념 수식을 거쳐가야 하는데요. 네 먼저 큐뮬리티브 게인은 추천된 상위 케이개의 아이템에 대한 관련도 랠러번스 값을 모두 더한 값입니다. 그래서 k 이기 때문에 RLVC i부터 k까지 더하게 되고요. 이제 여기에 대해서 디스카운트 개념이 나오게 됩니다. 여기는 지금 순서가 없죠. 그런데 밑에 보시면 여기는 로그 2의 아이 플러스 1 요 아이가 순서가 되는 거죠. 그래서 첫 번째로 추천된 아이템은 아가 1, 두 번째로 추천된 아이템은 아이가 2 이렇게 들어가게 되는 것이고요. 그리고 이 디시지와 별개로 아이디얼 디시지 즉 만약에 여러분들이 신이라고 해서 유저가 이미 알고 있는 아이템 유저가 이미 선호했던 아이템을 다 알고 있다고 했을 때 그 선호도의 순서에 맞춰서 내가 추천했을 때 이상적으로 구해진 디시지 값 아이디얼 디슈지입니다. 그리고 최종적으로 여러분들이 구하고자 하는 앤디시지는 그 아이디얼 디슈지가 가장 값이 클 것이고 그리고 그 디시지는 실제로 여러분들이 추천 시스템을 통해서 케이를 추천했을 때 얻어지는 디슈지 값이 되겠죠. 그래서 이 값은 아무리 커도 1 이하가 됩니다. 네 그래서 총 5개의 아이템을 추천한다고 가정해 봅시다. 오프라인 테스트 상황이기 때문에 여러분들은 어떤 유저가 내가 가장 선호하는 아이템의 리스트를 이미 다 알고 있어요. 이 유저는 지금 CA be d 5개의 아이템을 좋아하는데 그 아이템을 좋아하는 정도가 3 3 2 2 1입니다. 그래서 가장 좋아하는 아이템 2개가 앞에 붙어 있고 그다음에 이거 그다음에 이거겠죠. 그러면 이 순서대로 cabed를 추천했을 때가 가장 이상적인 추천 시스템이고요. 만약에 저희가 만든 모델이 5개를 추천했을 때 그때 추천 시스템이 eac DB 순서대로 추천했다고 가정해 봅시다. 그럼 아이디얼 DCG 값은 여기에 1, 2, 3, 4 5 순서가 들어가게 되고요. 값이 스코어 값이 3 3 2 2 1이 들어가서 최종 7.14 가장 높은 값이 되겠죠. 그러나 실제 추천 시스템은 이 이상적으로 추천하는 것이 아니라 이에 c d b로 했기 때문에 이에 해당하는 2 a에 해당하는 3 그리고 c에 해당하는 3 그리고 d에 해당하는 1 그리고 마지막으로 b에 해당하는 2 이렇게 구해지게 되겠죠. 그래서 실제 앤디 SG 값은 이 값을 나눈 0.93이 됩니다. 그래서 이번 같은 경우에는 이 모든 아이템이 다 포함되어 있지만 만약에 포함되어 있지 않은 경우에는 이 값이 날아가기 때문에 더 엔디시 값이 낮아질 수 있게 됩니다. 네 그래서 오프라인 테스트를 통해서 여러분들이 어떤 가설을 검증하고 어떤 추천 모델을 만들고 나서는 이제 온라인 환경에 디플로이 해야 합니다. 그래서 실제 추천 결과를 내가 만든 모델을 통해서 서빙해서 성능을 평가하는 단계가 온라인 에이비 테스트입니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(1강) Recommender System 기초 프로젝트.json",
        "lecture_name": "(1강) Recommender System 기초 프로젝트",
        "course": "RecSys",
        "lecture_num": "1강",
        "lecture_title": "Recommender System 기초 프로젝트",
        "chunk_idx": 8,
        "total_chunks": 14,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:e6fc1d273d498669899a80c7e20b85dc05964f93f465a2c4a11c518f0be25258"
      },
      "token_estimate": 1060,
      "char_count": 2023
    },
    {
      "id": "transcript_recsys_1강_recommender_system_기초_프로젝트_c009_6d38f0",
      "content": "[RecSys] (1강) Recommender System 기초 프로젝트\n\n다. 그래서 이번 같은 경우에는 이 모든 아이템이 다 포함되어 있지만 만약에 포함되어 있지 않은 경우에는 이 값이 날아가기 때문에 더 엔디시 값이 낮아질 수 있게 됩니다. 네 그래서 오프라인 테스트를 통해서 여러분들이 어떤 가설을 검증하고 어떤 추천 모델을 만들고 나서는 이제 온라인 환경에 디플로이 해야 합니다. 그래서 실제 추천 결과를 내가 만든 모델을 통해서 서빙해서 성능을 평가하는 단계가 온라인 에이비 테스트입니다. 이때 주의해야 할 점은 추천 시스템 변경 전후의 성능을 비교하는 것이 아니라 동시에 대조군과 실험군의 성능을 평가해야 된다는 것입니다. 그래서 이 대조군과 실험군의 환경은 최대한 동일해야 하고 보통 유저를 랜덤하게 반으로 나누거나 혹은 트래픽을 랜덤하게 반으로 나누는 경우를 많이 합니다. 만약에 지난주와 이번 주를 비교하게 되면 지난주와 이번 주에 우리가 컨트롤 할 수 없는 다양한 요인들이 있기 때문에 그래서 반드시 동시에 이루어져야 합니다. 그래서 가장 이상적인 것은 트래픽을 반반 나눠 가지고 이 a와 b에 대한 추천 시스템 평가 지표 즉 이번에는 오프라인 테스트가 아니라 온라인 테스트 아까 전에 우리가 처음 다뤘던 어떤 서비스적 관점 CTR이 얼마나 높은지 혹은 PV나 매출이 얼마나 높은지를 가지고 온라인 ab 테스트를 비교하게 됩니다. 그래서 보시면은 결국 현업에서 의사결정에 사용되는 지표는 어떤 모델 성능이 아니라 매출 CTR 같은 비즈니스 서비스 지표를 통해서 결국 ab 테스트가 이루어지게 됩니다. 자 그래서 지금까지는 추천 시스템의 개요 그리고 성능 평가에 대해서 배워봤는데요. 그럼 이제 가장 쉽고 간단한 추천인 인기도 기반 추천에 대해서 살펴보도록 하겠습니다. 인기도 기반 추천 같은 경우에는 보통 머신 러닝이나 이 아니라 통계적으로 모든 사용자에게 좋은 피드백을 받은 아이템을 추천해 주는 방식입니다. 그래서 보통 서비스가 처음 론칭했을 때 데이터가 부족하거나 추천 모델을 구축하는 데 시간이 소요되는데 이 처음에 소요되는 시간을 준비하기 위해서 서비스 론칭 초반에 많이 사용하는 추첨 방식입니다. 그래서 우리가 알고 있는 대부분의 고도화된 서비스도 개인화 추천 모델과 함께 이런 인기도 기반 추천을 같이 쓰고 있습니다. 그래서 여러분들이 유튜브 같은 거나 넷플릭스를 봐도 가장 인기 있는 탑 1 혹은 실시간 급상승 동영상 같은 것도 어떻게 보면은 이 인기도 기반 추천을 활용하고 있다고 볼 수 있습니다. 그렇다면 인기 있다라는 것에 대한 정의가 중요한데요. 이 인기도에 대한 척도는 사실 서비스마다 다르게 됩니다. 조회 수일 수도 있고 맛집 같은 경우에는 평균 편점일 수도 있고요. 리뷰 개수나 좋아요 싫어요 개수 같은 것들이 인기도의 척도로 사용됩니다. 그래서 네이버 쇼핑 같은 경우에는 아예 내가 어떻게 랭킹을 하고 있는지 네이버에서 이렇게 설명을 하고 있어요. 그래서 보시면은 적합도 인기도 신뢰도 같은 네이버가 나름대로 어떤 지표를 정해서 이게 인기도 있으면서 이 상품을 신뢰할 수 있는지 이 구매자를 신뢰할 수 있는지 같은 것들을 어떤 스코어로 만들어서 결국에는 웨이티드 썸으로 산출하고 있고요. 다음 뉴스 추천 같은 경우에 보면 추천 댓글이라고 하는 부분이 있어요. 여기에 보면 댓글은 결국 좋아요와 싫어요의 개수와 어떤 비율 같은 것들을 활용해서 좋아요가 충분히 많고 실어요가 적으면서 그 비율이 좋을 때 가장 상단으로 올라오게 됩니다. 그리고 여러분 레딧 같은 경우에는 이제 미국의 DC 인사이드 같은 경우인데요. 가장 많은 사람에게 좋아요를 받은 추천을 올려주되 대신에 이 글이 너무 옛날이 아니라 최신이면 최신일수록 추천이 되고 있습니다. 이제 그렇다면 어떠한 인기도라는 것은 결국에는 어떤 하나의 스칼라 값인 스코어로 만들어야 되는데요. 이 스코어는 크게 두 가지로 분류할 수 있습니다. 첫 번째는 조회 수가 가장 많은 아이템 모스트 파퓰러 아이템인 거고요. 보통 뉴스 추천 같은 곳에서 많이 쓰입니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(1강) Recommender System 기초 프로젝트.json",
        "lecture_name": "(1강) Recommender System 기초 프로젝트",
        "course": "RecSys",
        "lecture_num": "1강",
        "lecture_title": "Recommender System 기초 프로젝트",
        "chunk_idx": 9,
        "total_chunks": 14,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:e6fc1d273d498669899a80c7e20b85dc05964f93f465a2c4a11c518f0be25258"
      },
      "token_estimate": 1083,
      "char_count": 1987
    },
    {
      "id": "transcript_recsys_1강_recommender_system_기초_프로젝트_c010_8af690",
      "content": "[RecSys] (1강) Recommender System 기초 프로젝트\n\n다. 그리고 여러분 레딧 같은 경우에는 이제 미국의 DC 인사이드 같은 경우인데요. 가장 많은 사람에게 좋아요를 받은 추천을 올려주되 대신에 이 글이 너무 옛날이 아니라 최신이면 최신일수록 추천이 되고 있습니다. 이제 그렇다면 어떠한 인기도라는 것은 결국에는 어떤 하나의 스칼라 값인 스코어로 만들어야 되는데요. 이 스코어는 크게 두 가지로 분류할 수 있습니다. 첫 번째는 조회 수가 가장 많은 아이템 모스트 파퓰러 아이템인 거고요. 보통 뉴스 추천 같은 곳에서 많이 쓰입니다. 혹은 아까 레딧에서 사용되는 어떤 블로그 글 추천 그래서 내가 좋아하는 아이템이 아마 다른 많은 유저들도 좋아할 것 같고 관심이 많은 아이템을 추천해 주는 것이죠. 그리고 두 번째 같은 경우에는 하이웨이트드 어떤 평점이 높은 것들을 추천해 주는 건데요. 이제 맛집 추천이나 영화 추천 같은 경우에 평점이 존재한다고 했을 때 평점이 높은 것들을 상위로 올려줘서 그것들을 볼 수 있도록 추천을 해 주는 것입니다. 먼저 모스터 파퓰러 방식부터 살펴봅시다. 그래서 뉴스를 본다고 했을 때 가장 많이 조회된 뉴스 혹은 좋아요가 가장 많이 눌려져 있는 뉴스 게시글 뉴스 기사를 추천해 주는 것이 좋은데요. 그런데 문제는 최신성도 중요하다는 것이죠. 밑에 있는 데이터를 보면은 가장 많은 조회 수는 지금으로부터 10년 전에 있던 세월호 참사 데이터인데 지금 이 뉴스 데이터를 추천해 줄 수 없는 것이죠. 따라서 인기도 즉 조회수도 중요하지만 최신성도 같이 스코어를 계산하는 데 고려가 되어야 합니다. 그래서 단순하게 수식으로 나타내면은 뭐 페이지 뷰 혹은 좋아요 빼기 싫어요 개수에서 얼마나 시간이 지났는지를 빼면은 어떻게 보면 값이 되겠죠. 왜냐하면 얘는 플러스 요인 얘는 마이너스 요인이니까요. 그래서 보시면은 10개의 페이지 뷰인데 6시간이 지났다 그리고 25개의 페이지 뷰인데 24시간이 지났다라고 했을 때 값을 가장 단순하고 어떻게 보면 무식하게 구할 수 있게 되겠죠. 근데 문제는 이렇게 단순하게 수식을 구하게 되면은 이 페이지 뷰가 굉장히 높을 때 뭐 10만 100만 갔을 때 아무리 시간이 지나도 그 스코어 값이 계속해서 1등이 될 수 있겠죠. 그래서 이렇게 단순한 수식이 아니라 조금 더 정교한 수식이 필요합니다. 그래서 이 모스트 파퓰러 스코어의 첫 번째 예시는 해커 뉴스 포뮬러입니다. 해커 뉴스 같은 경우에는 뉴스를 추천해 주는 서비스인데요. 핵심은 앞에서 언급했던 대로 많은 사람이 봤던 뉴스를 추천해 주되 시간이 오래될 경우에 점수를 빠르게 깎는 것입니다. 그래서 이 위에 있는 게 페이지 뷰인데요. 여기서 이 AG라는 값이 시간이 지날수록 점점 증가하게 되는데 단순히 빼기가 아니라 나누기이기 때문에 특정 시간이 지나게 되면은 페이지 뷰가 아무리 높아져도 이 스코어 값은 거의 0에 수렴하게 됩니다. 그래서 이 얼마나 빨리 수렴하게 되는지에 대한 그 정도를 이 그래비티 값으로 조정할 수 있게 됩니다. 그래서 이 그래비티 값이 높아지면은 그만큼 최신성을 더 빨리 반영하겠다는 것입니다. 두 번째 경우는 이제 앞에서 다뤘던 레딧이라는 커뮤니티에서 쓰고 있는 모스트 파퓰러 스코어 레딧 포뮬라입니다. 이제 이 수식은 해커스 뉴스와는 좀 다른데 가장 큰 차이점은 이제 시간이 지날수록 스코어를 감점시키는 방식이 아니라 최신 포스팅된 글에다가 더 높은 스코어를 절대 시간으로 부여한다는 것입니다. 그래서 첫 번째 텀 같은 경우에는 파퓰러리티 그래서 업보트가 가장 많으면 많을수록 점수를 높게 주고요. 이 두 번째 경우에는 이 세컨즈라는 게 절대 시간입니다. 그래서 과거 것보다 최신 뉴스가 더 세컨즈가 높게 되겠죠. 그리고 이제 보시면은 단순히 업보트를 그대로 쓰는 것이 아니라 여기다 로그 스케일을 취했는데요. 이 말은 첫 보트 첫 업보트에 대해서는 가치를 높게 부여하되 이 업보트가 1에서 10 10 천만으로 올라갈 경우에 그걸 리니어하게 적용시키는 것이 아니라 로그 스케일로 해서 그 보트가 늘어날수록 스코어의 증가 폭을 좀 작게 만들기 위함입니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(1강) Recommender System 기초 프로젝트.json",
        "lecture_name": "(1강) Recommender System 기초 프로젝트",
        "course": "RecSys",
        "lecture_num": "1강",
        "lecture_title": "Recommender System 기초 프로젝트",
        "chunk_idx": 10,
        "total_chunks": 14,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:e6fc1d273d498669899a80c7e20b85dc05964f93f465a2c4a11c518f0be25258"
      },
      "token_estimate": 1095,
      "char_count": 2022
    },
    {
      "id": "transcript_recsys_1강_recommender_system_기초_프로젝트_c011_9b6dce",
      "content": "[RecSys] (1강) Recommender System 기초 프로젝트\n\n다. 그래서 과거 것보다 최신 뉴스가 더 세컨즈가 높게 되겠죠. 그리고 이제 보시면은 단순히 업보트를 그대로 쓰는 것이 아니라 여기다 로그 스케일을 취했는데요. 이 말은 첫 보트 첫 업보트에 대해서는 가치를 높게 부여하되 이 업보트가 1에서 10 10 천만으로 올라갈 경우에 그걸 리니어하게 적용시키는 것이 아니라 로그 스케일로 해서 그 보트가 늘어날수록 스코어의 증가 폭을 좀 작게 만들기 위함입니다. 그래서 오래된 포스팅일수록 이 세컨스 값이 이제 오래됐다는 것은 상대적으로 좀 낮겠죠. 오래된 포스팅일수록 상대적으로 아주 많은 보트가 있어야 높은 스코어를 가지게 되고요. 그리고 이 오래된 포스팅이 정말 오래된 경우에는 보트가 아무리 많아도 이 포뮬러의 스코어 값이 낮아지기 때문에 더 이상 추천이 되지 않습니다. 네 다음 두 번째 방식은 하이리레이트드입니다. 말 그대로 통계적으로 높은 평점을 받은 아이템을 추천해 주는 방식입니다. 그래서 높은 평점을 받은 영화나 맛집을 추천해 주는 곳에서 많이 사용될 수 있고요. 근데 이제 문제는 이 평점이 신뢰할 수 있는가에 대한 것인데요. 여러분들 밑에 있는 것을 보시면 평점이 가장 높은 값은 영화는 2번 영화죠. 그런데 이 영화는 평가 횟수가 고작 5개밖에 없고요. 나머지 a b 같은 경우에는 4점이 넘는데 평가 횟수가 22천이라고 했을 때 여러분들이 직관적으로 어떤 영화가 가장 안전하고 좋은 영화라고 평가할 수 있겠습니까? 저라면 아마 a를 안전하게 고를 것 같습니다. 그 말은 평가 자체가 개수가 충분한지도 굉장히 중요하다는 것입니다. 그래서 스코어를 구할 때 단순 평균을 내는 것보다도 이 평점 데이터가 얼마나 몇 개나 모였느냐도 이 포뮬러에 반영이 돼야 되는 것입니다. 그래서 이 하이 웨이티드 스코어링 방식으로 추천을 하는 곳이 스팀에 있는 인기도 기반 추천입니다. 스팀 같은 경우에는 이제 게임에 대한 평점을 매길 수가 있는데요. 이제 아래와 같은 수식을 사용하는데요. 이 위에 있는 에버리지 웨이팅 같은 경우에는 말 그대로 전체 리뷰 개수 중에서 positive 리뷰가 몇 개인지에 대한 단순 평균입니다. 근데 실제 사용되는 스코어는 이 밑에 있는 값을 사용하고 있어요. 그래서 보시면은 이게 평균 평점인데 평균 평점에서 어떤 평점 개수로 보정을 하게 됩니다. 그래서 만약에 내가 0.8이라는 평균 평점을 어떤 아이템에 대해서 구했는데 평균 평점 개수가 많이 부족하게 되면은 이 값이 디스카운트가 많이 됩니다. 그래서 실제 0.8보다 훨씬 낮아지는 뭐 0.6 정도로 값을 구해주게 됩니다. 반대로 만약에 0.8이 아니라 되게 낮은 평점인 0.2가 들어간다고 했을 때 이제 0.2가 평점 개수가 별로 없으면은 반대로 0.2보다 높게 보장이 되는 것입니다. 그래서 평균값을 기본적으로 사용은 하되 리뷰의 개수가 너무 적을 경우에 평균이 0.5죠. 왜냐하면은 좋았을 때는 1 나빴을 때 0이라고 했을 때 그 중간이 0.5니까요. 그 개수가 너무 적을 때는 그 값에서 조금 더 0.5 방향으로 좀 더 보정을 해주는 것이죠. 그런데 만약에 리뷰의 개수가 아주 많다 그러면 얘가 아주 많아지게 되면 이 값이 0에 수렴하기 때문에 얘가 다 날아가게 되겠죠. 그래서 결국에는 평균 평점과 매우 유사해지게 됩니다. 그래서 개수가 적을 때는 중간값으로 수렴하게 만들고 개수가 많아지면 평균 평점을 사용하도록 하는 것이 이 스팀 레이팅 포뮬러입니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(1강) Recommender System 기초 프로젝트.json",
        "lecture_name": "(1강) Recommender System 기초 프로젝트",
        "course": "RecSys",
        "lecture_num": "1강",
        "lecture_title": "Recommender System 기초 프로젝트",
        "chunk_idx": 11,
        "total_chunks": 14,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:e6fc1d273d498669899a80c7e20b85dc05964f93f465a2c4a11c518f0be25258"
      },
      "token_estimate": 914,
      "char_count": 1718
    },
    {
      "id": "transcript_recsys_1강_recommender_system_기초_프로젝트_c012_459126",
      "content": "[RecSys] (1강) Recommender System 기초 프로젝트\n\n다. 그래서 개수가 적을 때는 중간값으로 수렴하게 만들고 개수가 많아지면 평균 평점을 사용하도록 하는 것이 이 스팀 레이팅 포뮬러입니다. 자 그렇다면 이 스팀 레이팅을 응용해서 무비 레이팅으로 바꿔본다고 했을 때 분모는 평점의 개수고 분자는 그 각각의 평점에 sum이 되겠죠. 그래서 평균 평점을 구할 수 있고요. 영화 평점은 01이 아니라 뭐 1부터 5라고 했을 때 그 1부터 5의 중앙값이 3점이 되겠죠. 그래서 이제 내가 어떤 영화에 대한 평점이 예를 들면은 4.3인데 그러면 4.3에 대해서 평점의 개수가 5개밖에 없다라고 하면은 4.3에서 조금 더 보정돼서 3.0 쪽으로 가겠죠 뭐 그러면 예를 들면 뭐 3.7 뭐 이런 식으로 값이 구해지게 되겠죠. 마찬가지로 리뷰 개수가 엄청 많다 예를 들면 이게 뭐 만 개다라고 하면은 이 전체 값은 0으로 수렴하게 돼서 실제로 그 평균 평점 값 그대로인 4.3이 최종 스코어가 됩니다. 네 그래서 여기까지가 이제 첫 번째 강의의 이론 내용이었습니다. 자 마지막으로 여러분들이 왜 강의와 함께 참여하게 될 대회에 대해서 간단하게 소개하겠습니다. 네 추천 시스템 문제는 아까 설명드렸던 것처럼 랭킹 문제와 프리딕션 문제로 나눌 수가 있는데요. 본 대회는 먼저 레이팅 프리딕션 즉 예측 문제를 먼저 풀게 됩니다. 그래서 말 그대로 유저가 기존에 매겨놓은 평점 값을 과거의 학습 데이터와 추천 모델을 통해서 예측하는 문제입니다. 그래서 이번 대회에서는 처음 웜업하는 느낌으로 최대한 다양한 모델과 다양한 방법론을 사용해 보시길 권장드립니다. 그리고 이번 대회에서는 트레인 데이터만 제공해 드리는 것이 아니라 테스트 데이터 물론 정답이 없는 테스트 데이터를 제공해 드리는데요. 사실 일반적인 대회에서는 테스트 데이터를 아예 공개하지 않고 그냥 모델이 돌아가는 코드만 보통 올리게 돼 있어요. 그러면 그 모델이 돌아가는 코드가 테스트를 해서 결과값인 딱 하나 값 뭐 예를 들면 몇 점 이렇게 나오게 되는데요. 이번 대회에서는 여러분들의 실력 증진이 목표이기 때문에 테스트 데이터에 대해서도 정답을 제외하고 모두 제공해 드리게 됩니다. 그래서 테스트 데이터에 대한 분석을 해서 역으로 어떤 추천 모델을 만들어야 되는지 그래서 테스트 데이터를 어떻게 평가했을 때 어떻게 점수가 나오는지까지 분석을 하실 수도 있습니다. 그래서 대회와 친해지기 위해서는 처음에 대회가 시작했을 때 여러분들이 다양한 베이스 라인을 먼저 제공해 드립니다. 이제 이 코드는 막연하게 처음 대회를 하는 게 어려울 수도 있어서 주어지는 것이기 때문에 이를 그대로 사용하거나 단순히 튜닝하기 위한 목적은 아닙니다. 여러분들이 스스로 고민한 끝에 발굴한 본인만의 뭐 eda 혹은 그를 통해서 발견한 인사이트를 모델링에 직접 적용해 보는 것을 권장드립니다. 그래서 이런 대회를 처음 해보는 분은 이거 자체가 어렵기 때문에 이 베이스 라인을 활용하는 것 자체도 어려울 수 있겠지만 결국에는 이러한 과정이 직접 모델을 만들어 보는 데 큰 도움이 될 것으로 생각합니다. 네 그래서 북 레이팅 프리딕션은 굉장히 단순한 대회인데요. 사용자의 책 평점 데이터를 바탕으로 사용자가 어떤 책을 선호하는지 예측하는 테스크이고 그 선호도라는 것은 결국 평점을 예측하는 것입니다. 그래서 이번 대회는 이제 책 구매 과정에서 소비자에게 도움을 줄 수 있는 어떤 개인화된 추천 시스템을 개발하는 것인데요. 그 거기서 활용되는 것이 결국에는 특정 책에 얼마나 높은 평점을 부여할지 그 값을 예측해서 결국엔 그 예측 값을 가지고 추천 시스템에 활용하게 되는 것입니다. 그래서 저희가 만들 것은 탑 케를 추천하는 것이 아니라 그 사용자가 그 책에 대해서 평점을 얼마 내렸는지 그 정확한 값을 예측하는 것이 본 대회의 목표입니다. 네 대회를 진행하면서 여러분들이 가장 시간을 많이 쏟는 부분은 사실 모델을 학습하는 부분이 아니라 모델을 학습시키는 재료인 데이터를 탐색하는 시간입니다. 좋은 데이터를 넣어야 사실 좋은 모델이 나옵니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(1강) Recommender System 기초 프로젝트.json",
        "lecture_name": "(1강) Recommender System 기초 프로젝트",
        "course": "RecSys",
        "lecture_num": "1강",
        "lecture_title": "Recommender System 기초 프로젝트",
        "chunk_idx": 12,
        "total_chunks": 14,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:e6fc1d273d498669899a80c7e20b85dc05964f93f465a2c4a11c518f0be25258"
      },
      "token_estimate": 1084,
      "char_count": 2001
    },
    {
      "id": "transcript_recsys_1강_recommender_system_기초_프로젝트_c013_28a69a",
      "content": "[RecSys] (1강) Recommender System 기초 프로젝트\n\n다. 그래서 저희가 만들 것은 탑 케를 추천하는 것이 아니라 그 사용자가 그 책에 대해서 평점을 얼마 내렸는지 그 정확한 값을 예측하는 것이 본 대회의 목표입니다. 네 대회를 진행하면서 여러분들이 가장 시간을 많이 쏟는 부분은 사실 모델을 학습하는 부분이 아니라 모델을 학습시키는 재료인 데이터를 탐색하는 시간입니다. 좋은 데이터를 넣어야 사실 좋은 모델이 나옵니다. 아무리 모델이 좋더라도 여러분들 가비지 인 가비지 아웃이라는 말이 있는데 아무리 좋은 모델을 넣어도 모델이 있더라도 그 안에 잘못된 데이터를 넣으면 잘못된 결과가 나온다는 말입니다. 그래서 기본적으로 수행해야 되는 어떻게 보면 정석적인 것이지만 이 기본적인 eda 팁을 간단히 공유하는 것으로 대회 소개를 마칠까 합니다. 그래서 먼저 여러분들이 데이터셋을 받으면 그 데이터셋의 하나하나의 피처의 의미와 데이터 타입을 파악해야 하고요. 그리고 사실 데이터 같은 경우에는 결치 값이 많기 때문에 특정 컬럼 3번에 대해서는 결치 값이 많기 때문에 이 결치값을 어떻게 딜링 해야 되는 다뤄야 되는지에 대해서도 여러분들이 고민해 보셔야 합니다. 그리고 이제 각각의 피처와 데이터 타입을 파악한 이후에는 이 데이터 분포를 시각화해서 뭐 평점은 어떤 분포를 가지고 있는지 사용자나 체의 빈도는 어느 정도인지 그리고 각각의 피처는 어떤 분포를 가지고 있고 피처와 피처 사이의 상관관계 그리고 피처와 예측값과의 상관관계 같은 것도 여러분들이 플라팅을 해서 직접 보시고 어떤 피처와 어떤 피처는 상관관계가 전혀 없고 너무 상관관계가 높은 피쳐는 하나를 제외해야 될 수도 있고 이런 것들을 결국에는 eda를 통해서 여러분들이 살펴보셔야 합니다. 네 그리고 이제 범주형 데이터를 처리하는 것도 되게 중요한 부분인데요. 이제 일반적인 그냥 머신 러닝 가장 쉬운 문제에서는 모든 데이터가 수치형으로 돼 있지만 사실 추천 시스템 같은 경우에는 아이템 아이디, 사용자 아이디 이런 것들이 다 범주형 데이터입니다. 그리고 뭐 메타 데이터 카테고리 성별 연령 이런 것들도 대부분 다 카테고리 데이터이기 때문에 이 카테고리 데이터의 적절한 인코딩을 사용해서 어떤 인코딩을 사용해야 되는 경우도 있고 반대로 연속형 데이터를 범주형으로 바꿔서 사용해야 되는 경우도 있습니다. 그리고 이제 마지막으로 데이터 정제 부분인데요. 어떤 피처를 사용할 수도 있고 어떤 피처를 사용하지 않을 수도 있겠죠. 그리고 아까 말했던 결칙 값을 지워야 될 수도 있고요. 그리고 어떤 아웃라이어가 등장했으면 그 아웃라이어는 아예 학습 데이터에서 제외해야 될 수도 있습니다. 그래서 이러한 데이터 정제도 굉장히 중요한 부분 중에 하나입니다. 네 그래서 지금까지 추천 시스템 대회의 강좌 첫 번째 시간이었고요. 이제 다음 강의에도 첫 번째 이론 강의에 이어서 두 번째 추천 시스템의 기초와 도메인이 연구되던 초기에 등장했던 알고리즘과 모델을 간단히 다루어 보겠습니다. 네 긴 시간 들어주셔서 감사합니다. 다음 시간에 뵙겠습니다.",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(1강) Recommender System 기초 프로젝트.json",
        "lecture_name": "(1강) Recommender System 기초 프로젝트",
        "course": "RecSys",
        "lecture_num": "1강",
        "lecture_title": "Recommender System 기초 프로젝트",
        "chunk_idx": 13,
        "total_chunks": 14,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:e6fc1d273d498669899a80c7e20b85dc05964f93f465a2c4a11c518f0be25258"
      },
      "token_estimate": 830,
      "char_count": 1516
    }
  ]
}