{
  "source_file": "(11강) RecSys Competitions.json",
  "lecture_name": "(11강) RecSys Competitions",
  "course": "RecSys",
  "total_chunks": 13,
  "chunks": [
    {
      "id": "transcript_recsys_11강_recsys_competitions_c000_1c431c",
      "content": "[강의 녹취록] 과목: RecSys | 강의: 11강 | 제목: RecSys Competitions\n\n안녕하세요. 이번 시간은 렉시스 컴피티션 실제로 개최되었던 추천 시스템 경진대회와 솔루션을 살펴보는 시간입니다. 지금 듣고 있는 강의에서 이미 여러분은 이론을 배운 뒤에 이를 바탕으로 대회를 진행하고 있을 텐데요. 그렇기 때문에 추천 시스템 대회 자체가 처음인 분들이 매우 많을 것으로 생각합니다. 그래서 대회를 참여하기 전에 또 대회를 하면서 도움이 될 만한 자료로 과거에 개최된 대회를 살펴보고 이를 레퍼런스 삼아서 여러분이 대회 테스크를 진행하는 데 도움이 많이 될 것으로 생각하고 이 강의를 준비했습니다. 네 그래서 이번 시간에는 추천 시스템 경진대회와 또 렉시스 컴피티션에 나왔던 쉐어챗 온라인 광고 추천 대회를 다뤄볼 예정입니다. 그래서 각 대회를 살펴보기 전에 추천 시스템에서 대회가 갖는 의미에 대해서 간단히 언급하고 넘어가겠습니다. 추천 시스템의 경우 비전이나 엔엘피보다 훨씬 더 이 도메인에 대한 의존성이 높습니다. 어떤 아이템이냐에 대한 추천 시스템 또 다루는 피처의 종류에 따라서 굉장히 풀어야 되는 문제가 크게 달라지게 됩니다. 그래서 이 도메인 자체의 백그라운드 놀리지에서 비롯되는 인사이트가 굉장히 많고 이를 활용해서 문제를 풀어야 되는 경우가 많습니다. 예를 들면 음악 추천 시스템과 광고 추천 시스템은 사용하는 모델 자체는 비슷할 수 있습니다. 근데 그 모델을 제외한 데이터 피처, 추천 파이프라인 등이 굉장히 크게 다릅니다. 따라서 하나의 플랫폼에서 하나의 아이템에 대한 추천 시스템을 경험하는 것보다는 여러 개의 도메인, 여러 개의 데이터를 경험해 보는 것이 중요합니다. 그러나 역설적이게도 여러 데이터를 경험해 봐야 하는 사실에 비해서 데이터가 굉장히 폐쇄적입니다. 추천 시스템의 데이터의 경우에는 대부분 실제 서비스에서 실제 유저가 행동한 데이터가 필요하기 때문에 대부분 어떤 민간 기업의 내부 데이터인 경우가 많습니다. 따라서 데이터셋 공개도 어렵고 또 이 유저 프라이버시 문제도 생길 수 있습니다. 그래서 어떻게 보면 이 컴퓨터 비전이나 NLP 같은 연구 분야에 비해서 이 어떤 개발에 대한 제약이 있습니다. 그리고 다소 산발적인 측면도 없지 않아 있습니다. 따라서 추천 대회가 열렸다는 것은 실제 데이터와 실제 문제가 공식적으로 오픈된 것입니다. 그래서 보통 민간 기업이나 비영리 연구기관이 협력하여서 이 민간 기업의 실제 유저 행동 데이터를 법적인 문제가 없도록 마스킹 처리한 다음에 이를 공개하게 됩니다. 그래서 이러한 데이터를 살펴보고 현실 세계의 과제를 민간 기업에 근무하면서 실제로 맞닥뜨릴 수 있는 문제를 지금 풀 수 있는 기회가 바로 추천 대회입니다. 또한 대회를 통해서 최신 기술을 실제 문제에 적용해 봄으로써 최신 모델이 실제로 성능이 좋은지 아닌지 등에 대한 인사이트를 얻을 수 있습니다. 실제 필드에서 수집된 데이터를 가지고 실험을 해보면은 뭐 최근에 발표된 소타 모델이나 더 크고 무거운 모델이 성능이 좋지 않은 경우도 종종 존재하는데요. 이제 이러한 사실을 직접 경험해 보고 실제 데이터를 다뤄봐야지만 알 수가 있습니다. 그럼 이러한 추천 시스템 대회를 경험해 볼 수 있는 학회와 대회 플랫폼을 소개하겠는데요. 플랫폼은 이미 잘 알려진 대로 캐글이나 데이콘 같은 플랫폼이 있습니다. 이제 이런 플랫폼도 좋지만 렉시스 챌린지 와 같은 공식적인 추천 시스템 학회에서도 매년 대회를 개최하는데요. 이제 이번에 공개된 데이터 여기서 공개된 데이터 혹은 문제들은 퍼블리시 된 솔루션이 존재하고 그래서 스터디 하는 입장에서는 대회에도 존재되어 있고 대회에 대한 솔루션도 페이퍼로 공개되어 있기 때문에 굉장히 좋은 레퍼런스가 됩니다. 그래서 이번 강의에서 다루게 될 문제도 2023년 최근 가장 최신 렉션스 챌린지 대회에서 공개된 문제를 본 강의에서 다루게 될 것입니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(11강) RecSys Competitions.json",
        "lecture_name": "(11강) RecSys Competitions",
        "course": "RecSys",
        "lecture_num": "11강",
        "lecture_title": "RecSys Competitions",
        "chunk_idx": 0,
        "total_chunks": 13,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:2d7078f21cd46c6e5d61ebe1eb9876fbdff5ae1f121be48c2a8f3fa7054b0fca"
      },
      "token_estimate": 1049,
      "char_count": 1916
    },
    {
      "id": "transcript_recsys_11강_recsys_competitions_c001_99fd3d",
      "content": "[RecSys] (11강) RecSys Competitions\n\n다. 이제 이런 플랫폼도 좋지만 렉시스 챌린지 와 같은 공식적인 추천 시스템 학회에서도 매년 대회를 개최하는데요. 이제 이번에 공개된 데이터 여기서 공개된 데이터 혹은 문제들은 퍼블리시 된 솔루션이 존재하고 그래서 스터디 하는 입장에서는 대회에도 존재되어 있고 대회에 대한 솔루션도 페이퍼로 공개되어 있기 때문에 굉장히 좋은 레퍼런스가 됩니다. 그래서 이번 강의에서 다루게 될 문제도 2023년 최근 가장 최신 렉션스 챌린지 대회에서 공개된 문제를 본 강의에서 다루게 될 것입니다. 그래서 이 학회에서 공개된 문제는 상위권 참가자들의 솔루션이 퍼블리시 된 어떤 페이퍼의 형태로 공개되기 때문에 이것을 직접 공부하고 요즘에는 이제 이러한 참가자들이 기업 코드도 공개하기 때문에 여러분들이 그 데이터로 직접 추천 시스템을 재현할 수도 있습니다. 그래서 이번 강의에서는 국제학회 렉시스에서 공개된 2023 렉시스 챌린지 에서 다뤄진 쉐어챗 온라인 에드벌 타이즈 레코멘데이션이라는 문제를 다뤄보겠습니다. 그래서 이 문제를 알아보고 여기서 퍼블리시 된 솔루션 가운데 일부를 자세히 살펴보면서 대회에서 어떤 접근법들이 사용되고 있는지 공부해 보도록 하겠습니다. 네 먼저 렉시스 챌린지가 어떤 대회인지 살펴보겠습니다. 렉시스 챌린지란 에이씨엠 렉시스 학회에서 주관하고 있는 대회입니다. 렉시스라는 이름 그대로 추천 시스템이 메인 주제가 되는 추천 시스템에서 가장 권위 있는 학회입니다. 그리고 매년 이 학회와 함께 공식적으로 챌린지를 열리고 있고요. 이 챌린지 대회는 학회가 개최되기 몇 달 전에 문제와 데이터가 공개되고 누구나 이 대회에 참여해서 리더보드를 제출하고 그 리더보드와 함께 페이퍼도 같이 제출해야 합니다. 그래서 리더보드에서 상위권을 차지하거나 혹은 리더보드 점수가 다소 부족하더라도 페이퍼에 명시된 아이디어가 훌륭한 팀에 대해서는 학회에서 공식적으로 발표할 수 있는 기회를 얻게 됩니다. 그리고 이 렉시 챌린지가 가장 권위 있는 대회이기 때문에 이 대회에서 공개되는 데이터 또한 가장 활발하게 서비스되고 있는 민간 기업이나 연구기관에서 수집된 실제 데이터를 사용하게 됩니다. 그래서 이 추천 시스템 분야에서 분야는 말씀드린 대로 데이터가 폐쇄적이기 때문에 어떤 뭐 캐글이나 데이콘 같은 경우에서도 사실 데이터가 많지 않은데요. 이 렉시 챌린지 같은 경우에는 매년 대회가 꾸준히 열리고 그 대회를 통해 제공되는 데이터도 굉장히 양질의 데이터입니다. 그래서 이게 아마 챌린지가 이렇게 메인 토픽이 되는 학회는 별로 없는데 이 렉시스 학회가 이러한 특징을 가지고 있습니다. 네 그래서 이번 강의에서 다룰 렉시스 챌린지 2023에 대해 살펴보겠습니다. 이번 챌린지는 쉐어 챗이라는 서비스에서 제공한 온라인 광고 데이터를 바탕으로 진행됩니다. 온라인 광고에서 사용자가 광고를 보고 그 광고를 클릭하고 그리고 그 광고를 클릭한 이후에 그 광고가 보통 앱인데요. 그 광고를 인스톨 했는지에 대한 데이터가 제공되면서 이제 이 광고를 인지한 다음에 클릭하고 최종 설치까지 단계인 이 퍼널을 최적화하고 또 광고가 추천될 때 이 유저 프라이빗시 가 최대한 사용되지 않도록 이것들을 모두 만족시킬 수 있는 형태의 대회가 열렸습니다. 그래서 이 셰어챗 같은 경우에는 우리는 당연히 모르지만 인도 최대의 소셜미디어 회사로 전 세계적으로 4억 명 이상의 사용자를 보유하고 있습니다. 그래서 뭐 우리는 잘 모르는 서비스일 수 있지만 굉장히 권위 있는 회사고 거기에서 제공되는 데이터도 굉장히 양질의 데이터다라고 볼 수 있습니다. 네 그러면은 이 챌린지에서 제공된 데이터셋을 한번 살펴보겠습니다. 이제 이 3개월 이상 쉐어챗과 모즈 앱을 방문한 천만 명에 대한 유저의 광고 클릭과 인스톨 정보에 대한 데이터 셋입니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(11강) RecSys Competitions.json",
        "lecture_name": "(11강) RecSys Competitions",
        "course": "RecSys",
        "lecture_num": "11강",
        "lecture_title": "RecSys Competitions",
        "chunk_idx": 1,
        "total_chunks": 13,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:2d7078f21cd46c6e5d61ebe1eb9876fbdff5ae1f121be48c2a8f3fa7054b0fca"
      },
      "token_estimate": 1032,
      "char_count": 1876
    },
    {
      "id": "transcript_recsys_11강_recsys_competitions_c002_a7f856",
      "content": "[RecSys] (11강) RecSys Competitions\n\n다. 그래서 이 셰어챗 같은 경우에는 우리는 당연히 모르지만 인도 최대의 소셜미디어 회사로 전 세계적으로 4억 명 이상의 사용자를 보유하고 있습니다. 그래서 뭐 우리는 잘 모르는 서비스일 수 있지만 굉장히 권위 있는 회사고 거기에서 제공되는 데이터도 굉장히 양질의 데이터다라고 볼 수 있습니다. 네 그러면은 이 챌린지에서 제공된 데이터셋을 한번 살펴보겠습니다. 이제 이 3개월 이상 쉐어챗과 모즈 앱을 방문한 천만 명에 대한 유저의 광고 클릭과 인스톨 정보에 대한 데이터 셋입니다. 그래서 각각 유저 광고 데이터 그리고 인터랙션 데이터를 살펴보면은 일단 유저에 대한 데모 그래픽 피처 그리고 유저가 광고 외에 어떤 콘텐츠에 대한 선호도 값을 인베딩으로 나타낸 값 그리고 과거에 광고가 사용자가 이 앱을 설치했는지에 대한 그 로우한 데이터 말고 그 데이터를 인베딩한 값을 제공합니다. 광고 같은 경우에도 광고 아이디 외에 광고의 크기나 카테고리 그리고 실제 그 광고가 가지고 있는 이미지나 비디오 콘텐츠를 인베딩한 값을 제공합니다. 이렇게 인베딩한 값을 제공하는 이유는 이 데이터를 그대로 제공해 줄 경우에는 프라이버시 문제가 있기 때문에 최대한 이 데이터에 대한 익명화를 보장하기 위해서 사용자가 과거에 사용했던 다양한 데이터들을 최대한 인베딩 값으로 표현한 것입니다. 네 그리고 마지막으로 가장 중요한 데이터인 유저가 광고를 어떻게 소비했냐에 대한 인터랙션 데이터는 이제 유저가 다양한 기간 동안에 어떤 광고 혹은 광고주 혹은 그 광고가 속해 있는 카테고리와 상호 작용한 횟수도 데이터로 제공되고 있습니다. 네 그래서 해결해야 되는 문제는 무엇이냐 풀어야 되는 문제는 굉장히 심플합니다. 특정 기간 동안에 서브 샘플링된 유저 광고 데이터를 바탕으로 가장 마지막 날 15일째 되는 날에 그 앱을 설치할 확률을 0과 1 사이의 확률로 예측해야 합니다. 그래서 테스트 데이터 같은 경우에는 학습 데이터와 동일한 컬럼을 가지고 있되 학습 데이터에는 클릭했냐 설치했냐라는 두 가지 레이블이 0 1로 있는 반면에 테스트 데이터에서는 그 두 개의 레이블이 없습니다. 이 두 개 중에서 결국 최종적으로 예측해야 되는 데이터는 이즈 인스톨드 설치했냐에 대한 데이터인데 이 이지 클릭트는 사실 제출해야 되는 값은 아니지만 앞서 문제에서 의도했던 퍼널 최적화를 위해서 이 두 가지를 예측하고 이 두 가지를 동시에 사용하는 것이 성능에 도움이 될 수 있기 때문에 아마 주최 측에서 이러한 문제를 설계한 것 같습니다. 자 그래서 예측해야 되는 두 개 값 외에 나머지 피처들을 살펴보면 아까 그 프라이버시 문제 그 이슈로 인해서 거의 모든 피처가 이렇게 프원부터 79까지 익명화가 되어 있습니다. 근데 이제 그냥 단순히 익명화가 돼 있다고 그냥 다 때려 놓는 거는 문제가 있겠죠. 그래서 하나씩 살펴보면은 이제 프1 같은 경우에는 이 액션이 일어난 날짜 가 되고요. 그리고 f2부터 f9까지는 카테고리 변수 그리고 f41까지는 이제 그 카테고리 변수 중에서 이진형이 있고 단순 카테고리 변수가 있고요. f42부터 79까지는 어떤 수치형 뉴메리컬한 피처임을 알 수 있습니다. 그래서 이렇게 익명화된 정보가 주어지기 때문에 사실은 여러분들이 실제 민간 기업에 취업해서 하는 풀어야 되는 문제보다 어떻게 보면 더 챌린징한도 볼 수 있는데 그럼에도 이렇게 피처가 익명화되어 있기 때문에 피쳐에 대한 이디에와 엔지니어링이 여전히 중요합니다. 그래서 어떻게 피처에 대해서 이디에를 하고 거기서 얻은 인사이트를 어떻게 모델링을 했는지에 대해서는 각각의 솔루션별로 자세하게 살펴볼 예정입니다. 네 그래서 이번 강의에서는 총 학회에 선정된 9개의 논문 중에서 4개의 솔루션을 다뤄볼 것입니다. 첫 번째 두 개는 피처 엔지니어링에 대해 초점을 맞춘 연구이고 그 뒤에 있는 두 개는 모델링에 대해서 초점을 맞춘 연구입니다. 그래서 먼저 피처 엔지니어링에 초점을 맞춘 연구 2개를 살펴보면서 이 데이터 익명화된 데이터를 어떻게 파서 어떤 인사이트를 얻고 어떻게 모델에 적용했는지에 대해서 살펴보겠습니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(11강) RecSys Competitions.json",
        "lecture_name": "(11강) RecSys Competitions",
        "course": "RecSys",
        "lecture_num": "11강",
        "lecture_title": "RecSys Competitions",
        "chunk_idx": 2,
        "total_chunks": 13,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:2d7078f21cd46c6e5d61ebe1eb9876fbdff5ae1f121be48c2a8f3fa7054b0fca"
      },
      "token_estimate": 1104,
      "char_count": 2026
    },
    {
      "id": "transcript_recsys_11강_recsys_competitions_c003_aea2ee",
      "content": "[RecSys] (11강) RecSys Competitions\n\n다. 네 그래서 이번 강의에서는 총 학회에 선정된 9개의 논문 중에서 4개의 솔루션을 다뤄볼 것입니다. 첫 번째 두 개는 피처 엔지니어링에 대해 초점을 맞춘 연구이고 그 뒤에 있는 두 개는 모델링에 대해서 초점을 맞춘 연구입니다. 그래서 먼저 피처 엔지니어링에 초점을 맞춘 연구 2개를 살펴보면서 이 데이터 익명화된 데이터를 어떻게 파서 어떤 인사이트를 얻고 어떻게 모델에 적용했는지에 대해서 살펴보겠습니다. 첫 번째 논문은 간단하면서도 꽤 리즈너블한 아이디어로 데이터 전처리와 피처 엔지니어링을 적용한 다음에 가장 단순한 라잇 지비엠 모델을 사용해서 높은 예측 성능을 보인 논문입니다. 크게 보면은 데이터 전처리 부분 그리고 피처 엔지니어링 부분 모델링 단계로 나눠져 있지만 가장 중요한 부분은 여기 에드버서리얼 밸리데이션과 딜링 위드 노이즈 컨티뉴 피처스 이 두 부분이 가장 중요한 부분입니다. 이 두 가지 부분을 중심으로 살펴보겠습니다. 네 먼저 이 advert리얼 밸리데이션은 약간 어려울 수 있는데 천천히 설명을 해보면 이제 아무런 전처리를 하지 않고 그냥 주어진 학습 데이터를 가지고 라잇 GBM 모델을 사용해서 이제 밸리데이션 셋을 설정하고 이 밸리데이션 셋에 대해서 리더보드에 스코어를 제출한 결과 그 크로스 밸리데이션의 스코어와 리더보드의 간극이 꽤 크다는 점을 이 팀이 발견을 했습니다. 그 말은 우리가 가지고 있는 그 학습 데이터와 실제 리더보드에 제출해야 하는 밸리데이션 테스트 데이터셋의 분포가 다르다는 것이죠. 그래서 이것들을 처리하고 이것들을 해결하기 위해서 이 애드버서리얼 밸리데이션이라는 기법을 사용하였습니다. 그래서 방법은 굉장히 간단한데요. 학습 데이터에 대해서는 레이블을 0이라고 테스트 데이터에 대해서는 레이블을 1이라고 어떻게 보면 새로운 문제를 정의한 거죠. 그래서 각각 0 1 레이블을 적용하고 그리고 아까 주어져 있던 수십 개의 피처를 하나의 피처만 사용해서 이 피처를 입력 값으로 두고 학습 데이터와 테스트 데이터를 0 1로 둬서 무엇이 학습 데이터고 무엇이 테스트 데이터인지 예측하는 어떻게 보면 바이너리 클래시 파이어를 만들어서 그 피처 수십 개에 대해서 각각 만들어서 그 피처의 성능이 그 모델의 성능이 어떠한지를 확인한 방법입니다. 예를 들면은 이제 어떤 피처 x의 6이라는 것을 가지고 y를 예측하는 건데 이 y 같은 경우에는 학습 데이터가 0이고 테스트 데이터가 1이겠죠. 이제 이러한 클래시파이어를 피처 개수만큼 만들 수 있겠죠. F1부터 뭐 f 71까지 만들 수 있겠죠. 그러면은 이 바이너리 클래시피케이션 문제 같은 경우에는 사실 학습 데이터와 테스트 데이터는 서로 다른 특징을 가지고 있지 않으면 이 분류기의 성능은 0.5를 가지는 것이 가장 이상적입니다. 그 말은 이 f6이라는 피처만으로는 어떤 게 학습 데이터고 어떤 게 테스트 데이터인지 예측할 수 없다는 것이죠. 근데 반대로 이렇게 만든 클래시 파이어의 성능이 굉장히 뛰어나다라는 것은 이 피쳐가 학습 데이터와 테스트 데이터의 분포가 다르다는 것이죠. 그래서 예를 들면 0.75보다 높다는 것은 학습 데이터에서의 어떤 변수 특정 변수와 테스트 데이터의 어떤 특정 변수가 분포가 다르기 때문에 이 피처는 그대로 사용했을 때 어떻게 보면 예측 정확한 우리가 예측해야 되는 인스토리를 예측하는 것이 아니라 학습 데이터와 테스트 데이터의 분포 그 자체를 배우게 되는 것이죠. 그래서 이렇게 될 경우에는 이제 크로스 밸리데이션 우리가 사용한 검증 데이터에서의 성능과 실제 제출해야 되는 리더보드의 성능의 괴리를 만들어서 이 피처를 사용하는 게 결국에는 성능에 안 좋은 영향을 미치게 됩니다. 그래서 이런 피처는 아예 변수에서 제거하는 방식을 사용했습니다. 그래서 보시면 여기에 굉장히 많은 피처 중에서 바이너리 클래시 파이어를 학습했을 때 0.75가 넘는 몇몇 피처들이 존재하게 됩니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(11강) RecSys Competitions.json",
        "lecture_name": "(11강) RecSys Competitions",
        "course": "RecSys",
        "lecture_num": "11강",
        "lecture_title": "RecSys Competitions",
        "chunk_idx": 3,
        "total_chunks": 13,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:2d7078f21cd46c6e5d61ebe1eb9876fbdff5ae1f121be48c2a8f3fa7054b0fca"
      },
      "token_estimate": 1052,
      "char_count": 1937
    },
    {
      "id": "transcript_recsys_11강_recsys_competitions_c004_5a0422",
      "content": "[RecSys] (11강) RecSys Competitions\n\n다. 그래서 이런 피처는 아예 변수에서 제거하는 방식을 사용했습니다. 그래서 보시면 여기에 굉장히 많은 피처 중에서 바이너리 클래시 파이어를 학습했을 때 0.75가 넘는 몇몇 피처들이 존재하게 됩니다. 그래서 이런 피처는 대회에서 우리에게 주어졌음에도 불구하고 과감하게 안 쓰는 것이 오히려 전체 모델 성능 즉 우리가 만족해야 되는 리더 보드의 성능에 더 좋기 때문에 이 데이터는 아예 안 쓰겠다라고 하는 것이 이 팀에서 선택한 방법입니다. 그래서 가장 중요한 부분이 이 애드버서리얼 밸리데이션이라는 비법이었고요. 그래서 결국엔 이걸 통해서 피처 엔지니어링을 하고 내가 사용할 피처와 사용하지 않을 피처를 선택하는 방법인 거죠. 두 번째로 적용한 피처 엔지니어링 같은 경우에는 이제 일부 연속형 변수를 정수형으로 변환한 것입니다. 이제 이것도 어떤 계기로 발견하게 되었냐면은 아까 전에 피처에 대해서 이디에이를 할 때 피처와 피처에 대한 코릴레이션 상관 분석도 할 수도 있다고 말씀드렸잖아요. 이 왼쪽이 피처들이 쭉 영역이고 여기도 피처들의 영역인데 이 피처에 대한 페어와이즈 코릴레이션을 구했을 때 어떤 특정 변수 간의 상관관계가 굉장히 비정상적으로 높으면서 동시에 해당 피처가 어떤 등차수열 어떤 이제 이상한 규칙을 가지고 있는 것을 발견했습니다. 그래서 이제 이런 데이터를 다 뽑아봤더니 연속형 변수임에도 불구하고 어떤 연속형 변수 같은 경우에는 어떤 분포를 가져야 하는데 0.1 0.2 0.3 0.4 이렇게 등차수열의 형태를 가지고 있다는 것을 발견했습니다. 그래서 이런 데이터는 수치형으로 쓰는 것이 아니라 이 데이터는 각각을 1 1 2 3 4 같은 어떤 카테고리컬 변수로 바꿔야겠다라고 해서 이것을 정수형 인티저로 변환해서 이 변수가 더 명확하게 값을 갖도록 변환을 해서 그래서 연속형 변수로 사용하지 않고 정수형 변수로 변환해서 모델에 넣었습니다. 그래서 더 이 피처는 단순히 수치형보다 정수형으로 가질 때 더 명확한 정보를 갖게 되고 그 명확한 정보를 처리하도록 만든 것입니다. 그리고 세 번째 같은 경우에는 이제 일반적으로 사실 많이 사용하는 방법인데 이제 카테고리 변수 같은 경우에 이제 카디널리티라고 해서 카테고리가 하나의 피처에 너무나 많은 디멘전을 가지게 된 경우에는 이것을 그대로 썼을 때 사실 문제가 생길 수 있습니다. 그래서 보통 많이 사용하는 방식이 프리퀀스 인코딩이나 캣 부스트 인코딩 같은 경우인데요. 하나의 피처가 카테고리 개수가 막 만 개가 넘어가는 경우에는 그거를 그대로 카테고리컬 변수로 사용하는 것보다는 이렇게 동일한 피처 밸류가 등장한 횟수나 혹은 그 동일한 피처 밸류가 가지고 있는 데이터의 어떤 타겟 평균 같은 값으로 치환을 가지고 그 카테고리 콜 데이터를 그대로 쓰는 것이 아니라 다른 인코딩 방식을 사용해서 결국 모델의 피처로 넣게 되는 것입니다. 그래서 일반적으로 이렇게 카디널리티가 굉장히 큰 카테고리컬 변수 같은 경우에는 이 프리퀀시 인코딩이나 캐퍼스트 인코딩을 쉽게 사용할 수 있기 때문에 보통 많이 적용하는 방법입니다. 그래서 이제 이러한 데이터 전처리와 피처 엔지니어링을 적용한 뒤에서 뒤에 본 논문에서는 가장 로버스트한 성능을 가진 라잇 GBM 가지고 이제 사용을 하였고요. 아무것도 전처리하지 않은 라잇 GBM에 대해서 하나씩 피처 엔지니어링을 추가했을 때 최종적으로 가장 좋은 성능을 보였고 거기다가 이제 추가적으로 하이퍼 파라미터 튜닝을 해가지고 이제 가장 높은 성능인 6.05의 리더 보드 스코어를 기록하였습니다. 그래서 이 팀 같은 경우에는 어떤 모델링 같은 건 전혀 하지 않고 피처에 대한 eda를 통해서 뭐 수치형 변수를 정수형 변수로 변환하기도 하고 그리고 특정 피처를 제거하기도 하고 그리고 특정 카테고리 변수 같은 경우에는 너무 카디널리티가 크기 때문에 이 디멘전을 줄여주기 위해서 어떤 인코딩 방식을 활용한 그래서 모델은 굉장히 단순한 모델로 정해 놓고 피처들만 되게 많이 가공을 해서 결과적으로는 좋은 성능을 냈",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(11강) RecSys Competitions.json",
        "lecture_name": "(11강) RecSys Competitions",
        "course": "RecSys",
        "lecture_num": "11강",
        "lecture_title": "RecSys Competitions",
        "chunk_idx": 4,
        "total_chunks": 13,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:2d7078f21cd46c6e5d61ebe1eb9876fbdff5ae1f121be48c2a8f3fa7054b0fca"
      },
      "token_estimate": 1087,
      "char_count": 1994
    },
    {
      "id": "transcript_recsys_11강_recsys_competitions_c005_29a9b9",
      "content": "[RecSys] (11강) RecSys Competitions\n\n다. 그래서 이 팀 같은 경우에는 어떤 모델링 같은 건 전혀 하지 않고 피처에 대한 eda를 통해서 뭐 수치형 변수를 정수형 변수로 변환하기도 하고 그리고 특정 피처를 제거하기도 하고 그리고 특정 카테고리 변수 같은 경우에는 너무 카디널리티가 크기 때문에 이 디멘전을 줄여주기 위해서 어떤 인코딩 방식을 활용한 그래서 모델은 굉장히 단순한 모델로 정해 놓고 피처들만 되게 많이 가공을 해서 결과적으로는 좋은 성능을 냈다. 그래서 추천 시스템 같은 경우에는 모델도 중요하지만 데이터를 가공하는 것이 굉장히 중요하다라고 말씀드릴 수 있습니다. 네 두 번째 페이퍼 같은 경우에도 다양한 피처 엔지니어링을 통해서 클러스터 피처, 크로스 피처 그리고 히스토리컬 모델링 피처 등 이러한 다양한 피처 추가를 해서 결과적으로 사용하는 모델은 또 간단한 xg 무스트 모델을 사용해서 최종적으로 3위를 차지한 연구입니다. 마찬가지로 모델은 굉장히 단순하지만 eda를 통해서 피처의 특성을 분석하고 또 피처를 새로 생성하기도 하고 그리고 온라인 광고의 특성을 반영한 특히 이 히스토리컬 모델링을 사용하여서 피처를 생성해서 결국에는 좋은 성능을 낸 것이 본 솔루션의 특징이라고 볼 수 있습니다. 네 주어진 데이터는 사실 모두 익명화가 되어 있기 때문에 각 피처가 어떤 의미를 가지고 있는지 아까 그 날짜 데이터를 빼고는 사실은 알 수가 없는데 그럼에도 불구하고 결국 이 데이터에 대한 설명을 보면 유저나 또는 광고에 대한 어떤 상호작용을 인베딩으로 만들었기 때문에 특정 피처키리는 유의미한 패턴을 가지고 있을 것이다라고 이 팀은 생각을 했습니다. 그래서 일단 먼저 할 수 있는 게 전체 데이터 중에서 아까 수치형 데이터가 있었죠. 그 수치형 변수에 대해서 PCA로 차원 축소를 한 다음에 TSN이 클러스터링 결과를 했을 때 어떠한 재미있는 특징을 발견했습니다. 예를 들면 밑에 있는 것을 보면 f 56부터 f 70 까지의 데이터를 가지고 클러스터링을 해서 시각화를 했고 반대로 프64부터 프72까지의 데이터 가지고도 똑같이 클러스터링을 했는데 이 두 개의 결과가 굉장히 유사하다는 것을 볼 수 있습니다. 그래서 아 어떤 스페셜한 프레젠테이션이 있다. 그래서 이 클러스터링 결과를 추가적으로 모델의 피처로 사용하자. 그래서 원래 가지고 있는 피처 외에 이 클러스터링 피처도 xg 부스트 최종 모델의 피처로 사용을 하였습니다. 이 두 번째로 적용한 방법은 피처 인포턴스가 높은 피처들에 대해서 강제로 크로스 피처를 추가한 방식인데 이제 이러한 방식은 사실 CTR CVR 예측 우리가 지금 풀고 있는 게 씨브알 컨버전 웨이트 즉 인스톨을 얼마나 할 건지에 대한 예측 문제인데 이제 이러한 예측 문제에서 많이 사용되는 방법입니다. 그래서 이 피처의 교호 작용이라고 하는 이 크로스 인터랙션 크로스 피처 같은 경우에는 사실 모델한테 맡길 수도 있어요. 왜냐하면 모델이 모델에게 데이터를 쭉 넣어주면 저희가 전 강의에서 배웠던 뭐 와이드앤디이라든지 혹은 뭐 딥시티r 계열의 논문은 사실 모델 아키텍처에서 이미 서로의 크로스 인터랙션을 모델 안에서 계산하기 때문에 필요 없을 수도 있지만 그럼에도 불구하고 명시적으로 크로스 피처를 추가하는 경우 피처들 사이의 교호 작용을 극대화할 수 있습니다. 그래서 본 솔루션에서는 피처 인포턴스를 각각에 대해서 구하고 저희가 지금 2부터 아까 프 70 몇 까지 쭉 있었죠 이 데이터들에 대해서 타겟을 가지고 피처 인포턴스를 구한 다음에 그 상위 피처 인포턴스가 높은 피처들에 대해서는 강제로 그 두 피처의 교 작용을 극대화할 수 있는 크로스 피처를 새로 생성했습니다. 그래서 그냥 피처만 사용한 것이 아니라 크로스 피처도 모델에 추가해서 새로운 피처로 만들어서 결국 최종적으로 xg 부스트 모델에 넣은 것이 또 이 솔루션 팀이 채택한 방법 중에 하나입니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(11강) RecSys Competitions.json",
        "lecture_name": "(11강) RecSys Competitions",
        "course": "RecSys",
        "lecture_num": "11강",
        "lecture_title": "RecSys Competitions",
        "chunk_idx": 5,
        "total_chunks": 13,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:2d7078f21cd46c6e5d61ebe1eb9876fbdff5ae1f121be48c2a8f3fa7054b0fca"
      },
      "token_estimate": 1037,
      "char_count": 1915
    },
    {
      "id": "transcript_recsys_11강_recsys_competitions_c006_459ee3",
      "content": "[RecSys] (11강) RecSys Competitions\n\n다. 그래서 본 솔루션에서는 피처 인포턴스를 각각에 대해서 구하고 저희가 지금 2부터 아까 프 70 몇 까지 쭉 있었죠 이 데이터들에 대해서 타겟을 가지고 피처 인포턴스를 구한 다음에 그 상위 피처 인포턴스가 높은 피처들에 대해서는 강제로 그 두 피처의 교 작용을 극대화할 수 있는 크로스 피처를 새로 생성했습니다. 그래서 그냥 피처만 사용한 것이 아니라 크로스 피처도 모델에 추가해서 새로운 피처로 만들어서 결국 최종적으로 xg 부스트 모델에 넣은 것이 또 이 솔루션 팀이 채택한 방법 중에 하나입니다. 네 그리고 마지막이 사실 제일 중요한데 이 논문 자체에 이름에 들어가 있는 이 히스토리 모델링 이 부분이 가장 중요한 부분인데요. 사용자는 어떤 특정 세션이나 특정 시간대에 대해서 서로 다른 관심사나 서로 다른 액션의 형태를 가질 수 있습니다. 그리고 이제 온라인 광고와 같이 유저의 데이터가 많은 환경에서는 이제 유저의 이러한 성향이 데이터로 축적되어서 히스토리로 남게 되고 또 이러한 성향이 지난주에는 뭘 좋아했는데 이번 주에는 다른 걸 좋아할 수도 있겠죠. 그래서 이러한 성향을 히스토리컬 모델링으로 표현해서 어떤 명시적인 피처로 만드는 방법입니다. 그래서 여기 있는 피처를 그대로 직역하자면 지난 제1 동안 뭐 예를 들면 지난 일주일 동안 어떤 ki라는 피처에서 엠디라고 하는 데이터가 등장한 횟수, 그래서 전체 데이터 중에서 얼마나 많이 인스톨 했냐 즉 어떤 특정 카테고리의 어떤 특정 피처에서 인스톨을 얼마나 많이 했냐 적게 했냐라는 것을 명시적인 피처로 만들어서 이제 이 피처를 모델에 추가적으로 더하는 것입니다. 예를 들면은 요 케아라는 피처가 아까 얘기했던 광고 카테고리 피처라고 생각을 해봅시다. 지난 일주일 동안 광고 카테고리 피처에 대해서 게임 카테고리를 인스톨한 비율 그리고 화장품 카테고리를 인스톨한 비유를 구한다면은 최근 7일 동안 어떤 광고 카테고리를 선호했는지를 이 피처를 통해서 표현할 수 있습니다. 그래서 이 피처를 모델을 사용하면은 최근 일주일 동안의 사용자의 광고 카테고리 선호도를 어떤 간접적인 형태로 사용하여서 이 모델의 정확도를 더더욱 올릴 수 있는 것이죠. 그래서 그렇게 사용한 선호도를 어떤 점수로 만들어서 이 점수가 히스토리 티컬한 유저의 행태를 반영해서 결국에 모델의 추가 피처로 사용되게 된다면은 단순히 그냥 모든 피처를 그냥 때려 넣은 모델보다 더 명확한 어떤 정보를 갖게 되고 이 정보는 결국에는 그 앱 인스톨할 확률의 정확도를 높여주게 됩니다. 그래서 이러한 히스토리컬 모델링 방법은 방금 전에 소개했던 솔루션에서 소개했던 캡부스트 인코딩과 사실 유사한데 이제 이 솔루션에서는 단순히 캐포스트 인코딩만 사용한 게 아니라 좀 더 디테일하게 최근 애닐 동안 어떤 특정 피처에서 특정 데이터가 등장했던 것들을 어떤 값으로 만들어서 그 값에 대해서 하나하나로 피처로 넣어줬던 것이 좀 더 발전된 방법이라고 볼 수 있습니다. 그래서 최종 결과는 다음과 같습니다. 이제 본 논문에서는 이제 데이터를 보시면 하루씩 늘려가면서 사용을 했는데요. 보시면 가장 모든 데이터를 사용한 게 아니라 19일 치만 까지의 데이터를 사용하기가 가장 좋았다고 해서 전체 21일 중에서 최근 19일 데이터만 사용을 했고요. 보시면은 이 소타가 이제 이 모델 이 팀이 가장 제출한 좋은 모델이고 보시면 거기서 하나씩 피처를 뺐는데 이 히스토리컬 피쳐를 뺐을 때 가장 모델의 성능이 하락했습니다. 그 말은 결국에는 이 히스토리컬 피처가 이 모델의 성능을 높이는 데 가장 주요했다라고 볼 수 있겠죠. 그래서 이 솔루션 팀은 히스토리컬 모델링이라는 것을 페이퍼의 제목으로 사용해서 이것을 어떤 명시적인 피처로 만드는 것이 좋다라는 것을 주장하고 있습니다. 네 앞으로 다룰 2개의 연구는 이제 피처 엔지니어링보다는 모델링을 고도화하는 접근법인데요. 이제 먼저 소개할 연구는 컨트레스티브 러닝을 사용해서 자기 주도 학습 즉 셀프 슈퍼바이즈 러닝을 통해서 모델의 파라미터를 학습하고 성능을 끌어올려서 최종적으로 1위를 차지한 연구입니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(11강) RecSys Competitions.json",
        "lecture_name": "(11강) RecSys Competitions",
        "course": "RecSys",
        "lecture_num": "11강",
        "lecture_title": "RecSys Competitions",
        "chunk_idx": 6,
        "total_chunks": 13,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:2d7078f21cd46c6e5d61ebe1eb9876fbdff5ae1f121be48c2a8f3fa7054b0fca"
      },
      "token_estimate": 1107,
      "char_count": 2024
    },
    {
      "id": "transcript_recsys_11강_recsys_competitions_c007_a1d587",
      "content": "[RecSys] (11강) RecSys Competitions\n\n다. 그 말은 결국에는 이 히스토리컬 피처가 이 모델의 성능을 높이는 데 가장 주요했다라고 볼 수 있겠죠. 그래서 이 솔루션 팀은 히스토리컬 모델링이라는 것을 페이퍼의 제목으로 사용해서 이것을 어떤 명시적인 피처로 만드는 것이 좋다라는 것을 주장하고 있습니다. 네 앞으로 다룰 2개의 연구는 이제 피처 엔지니어링보다는 모델링을 고도화하는 접근법인데요. 이제 먼저 소개할 연구는 컨트레스티브 러닝을 사용해서 자기 주도 학습 즉 셀프 슈퍼바이즈 러닝을 통해서 모델의 파라미터를 학습하고 성능을 끌어올려서 최종적으로 1위를 차지한 연구입니다. 그래서 본 모델의 구조를 보면은 이제 먼저 주어진 피처들을 인베딩 레이어를 통해서 인베딩 디멘전을 같은 인베딩 디멘전 딜을 갖게 한 다음에 그리고 이제 트랜스포머 레이어 를 통과하도록 하고 최종적으로 MLP 레이어를 통과해서 최종적으로 이제 인스톨해야 되는 확률을 구하는 그런 식의 모델 구조를 가지고 있습니다. 네 그래서 먼저 모델의 구조를 살펴보면은 이제 본 논문은 트랜스포머 모델을 사용했는데요. 이제 모든 피처들을 각각의 피처 타입에 맞게 어떤 동일한 차원인 디 차원으로 인베딩을 했습니다. 그래서 보시면은 저희가 피처 종류가 실수형 그리고 바이너리 그리고 카테고리 콜이 있었는데 이제 실수형 피처 같은 경우에는 그대로 인베딩하지 않고 어떤 빈을 만들어서 카테고리 피처를 만들어서 인베딩을 했고 이제 그 외에 바이너리 피처나 카테고리 피쳐는 모두 원아인 코딩 방식으로 같은 인베딩 차원인 딜을 갖도록 임베딩을 했습니다. 그래서 이렇게 인베딩 레이어를 통과한 이후에 이제 여기다가 추가적으로 씨엘스 토큰이라는 걸 하나 더 붙여가지고 총 인베딩 개수가 엠개라고 하면은 엠에다가 플러스 1 즉 씨엘스라는 토큰이 디 차원의 인베딩을 갖도록 해서 결국에는 이 디 차원의 인베딩이 최종 예측은 이 씨에스 토큰에 대해서만 예측을 수행하도록 했습니다. 네 다음으로는 본 연구에서 가장 중요한 부분이 이제 컨트레스티브 러닝인데요. 이 컨트레스티브 러닝을 먼저 간단하게 설명하면 두 데이터에 대해서 같은 클래스면은 가깝게 다른 클래스면 멀어지도록 학습하는 방법입니다. 그리고 그 같은 클래스는 가깝고 다른 클래스는 멀어지도록 하는 것을 로스 펑션으로 만들어 가지고 그 로스 펑션이 줄어들도록 모델이 학습되도록 하는 방식입니다. 이제 여기서 가깝고 멀다 여기서 말하는 샘플의 유사도 같은 경우에는 보통 뭐 코사인 시밀러리티 같은 유사도 펑션을 사용하는데요. 여기 보시는 예시 그림을 보시면은 강아지 그림이 있고 의자 그림이 있습니다. 그래서 이 강아지 그림에 대해서 데이터 어그멘테이션을 통해 강아지의 일부 부분인 얼굴이나 다리를 샘플링하고 마찬가지로 의자 데이터에 대해서도 의자 전체와 혹은 의자 일부 부분을 어그멘테이션 한 다음에 각각 모델을 동일한 모델을 통과시키게 됩니다. 그다음에 같은 클래스 즉 강아지에서 나오는 데이터끼리는 가까워지도록 그리고 서로 다른 클래스인 강아지와 의자끼리의 유사도는 멀어지도록 학습하는 것입니다. 이제 이렇게 학습을 하는 것은 보통 이제 모델은 단순히 얘가 강아지다 얘가 의자다라는 것을 예측하는 게 보통 슈퍼바이즈 러닝인데 이제 이렇게 유사도를 로스로 만들어서 학습을 하게 되면은 단순히 클래스만 예측하는 것이 아니라 이 데이터가 가지고 있는 어떤 특성 혹은 어떤 분포를 이 모델이 잘 배우도록 학습하는 것입니다. 그래서 가지고 있는 데이터를 단순히 슈퍼바이즈 러닝만 하는 것이 아니라 컨트레스티브 로스를 사용한 이 러닝을 통해서 이 모델이 더욱더 데이터의 패턴을 풍부하게 배우도록 학습하는 방식입니다. 네 본 연구에서는 이 컨트레스티브 러닝을 사용해서 셀프 슈퍼바이즈 러닝을 사용했는데요. 이제 이 경우에는 아까 전에 강아지나 의자와 같은 클래스 개념이 사용되지 않습니다. 대신에 같은 데이터에서 만들어진 샘플의 유사도는 최대화하고 다른 데이터에서 만들어진 샘플의 유사도는 최소화하도록 모델을 학습하고 이제 이 학습된 모델을 최종 인스톨을 예측하는 다운스트림 테스크에 사용하는 것입니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(11강) RecSys Competitions.json",
        "lecture_name": "(11강) RecSys Competitions",
        "course": "RecSys",
        "lecture_num": "11강",
        "lecture_title": "RecSys Competitions",
        "chunk_idx": 7,
        "total_chunks": 13,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:2d7078f21cd46c6e5d61ebe1eb9876fbdff5ae1f121be48c2a8f3fa7054b0fca"
      },
      "token_estimate": 1122,
      "char_count": 2023
    },
    {
      "id": "transcript_recsys_11강_recsys_competitions_c008_1c7d55",
      "content": "[RecSys] (11강) RecSys Competitions\n\n다. 네 본 연구에서는 이 컨트레스티브 러닝을 사용해서 셀프 슈퍼바이즈 러닝을 사용했는데요. 이제 이 경우에는 아까 전에 강아지나 의자와 같은 클래스 개념이 사용되지 않습니다. 대신에 같은 데이터에서 만들어진 샘플의 유사도는 최대화하고 다른 데이터에서 만들어진 샘플의 유사도는 최소화하도록 모델을 학습하고 이제 이 학습된 모델을 최종 인스톨을 예측하는 다운스트림 테스크에 사용하는 것입니다. 좀 더 자세히 살펴보면은 이 컨트레스티브 러닝을 하기 위해서는 학습 과정에서 어떤 엘게의 데이터 샘플이 등장을 하게 됩니다. 그럼 이 엘게의 데이터 샘플은 각각 2개로 어그멘테이션에서 서로 다른 데이터 셋 엘게가 2개가 생성되게 됩니다. 그럼 이 LG 데이터 샘플은 같은 데이터에서 생성된 애들끼리는 positive 페어라고 하고 서로 다른 데이터에서 생성된 애들은 negative 페어가 되겠죠. 그래서 이 positive 페어끼리는 이 유사도가 점점 더 높아지도록 그리고 negative 페어끼리는 유사도가 낮아지도록 로스 펑션을 설계해서 학습을 합니다. 그래서 이 과정에서 사용되는 그 유사도 로스 펑션이 바로 이 인포 NC라는 로스고 이 로스에서는 특별히 negative 페어보다는 positive 페어끼리의 유사도가 점점 더 높아질 수 있도록 로스 펑션을 설계해서 이 컨트레스티브 로스가 낮아지도록 모델이 학습되게 됩니다. 그래서 이 과정에서 또 중요한 부분이 이 어그멘테이션 방법인데 이 어그멘테이션은 다음 장표에서 설명하도록 하겠습니다. 그래서 이렇게 데이터를 셀프 슈퍼바이저 러닝을 사용해서 어떤 클래스를 배우는 게 아니라 데이터끼리의 유사도가 서로 가까워지고 멀어지도록 학습하게 되면은 단순히 이 어떤 인스토럴 확률을 구하는 것 자체가 중요한 게 아니라 이 데이터가 가지고 있는 어떤 피처별 특성과 어떤 데이터의 분포를 이 모델이 배우게 됩니다. 그래서 이것이 셀프 슈퍼바이즈 러닝의 장점인데 이제 이 대회에서는 모든 피처가 익명화되어 있지 않기 때문에 특정 피처별로 적절한 피처 엔지니어링을 하기가 어렵다고 이 솔루션 팀은 생각한 것 같습니다. 그래서 이렇게 컨트레스티브 러닝을 가지고 데이터가 가지고 있는 피처들의 특성을 난 잘 모르겠지만 알아서 모델이 잘 학습할 수 있도록 그렇게 설계해서 모델 학습 방법을 적용한 것 같습니다. 네 그래서 말씀드린 대로 이 컨트레스티브 러닝을 하기 위해서는 하나의 데이터셋에 대해서 두 개로 각각 어그멘테이션을 해야 되는데 저희가 가지고 있는 데이터셋 자체가 익명화되어 있기 때문에 각각의 피처가 어떤 것을 가지고 있는지 몰라서 그 익명화된 데이터에 가장 적합한 어그멘테이션 방법을 사용했습니다. 그래서 첫 번째로는 피처 콜옵션인데요. 데이터가 주어진 것이 원본 데이터가 있으면 그 원본 데이터의 일부 값을 다른 값으로 그냥 강제로 치환하는 방식입니다. 그래서 데이터가 MD가 있으면 그중에서 뭐 m개 중에서 5개 혹은 10개를 강제로 치환해서 다른 데이터로 만들어 버리는 거죠. 두 번째 같은 경우에는 인베딩 퍼티베이션인데 이 데이터를 각각을 이제 인베딩을 한 다음에 그 인베딩한 값의 일부를 강제로 마스킹합니다. 마치 저희가 드롭 아웃과 같은 효과를 내서 인베딩 값을 그대로 쓰는 것이 아니라 인베딩의 일부 값을 이렇게 0으로 만들어 버리는 거죠. 그리고 마지막으로 적용하는 것은 모델 PT베이션인데 각각의 데이터를 학습할 때마다 매번 드로바웃 레이어에 대한 시드를 다르게 적용해서 같은 데이터가 들어가도 매번 드롭아웃 시드가 달라지게 돼서 서로 다른 최종 결과가 달라질 수 있도록 강제로 이렇게 시드를 변경하는 방법입니다. 그렇게 해서 매번 데이터가 어그멘테이션 될 때 서로 다른 데이터가 어그멘테이션 되도록 사용하였습니다. 그래서 이러한 여러 개의 어그멘테이션을 동시에 적용해서 contressive lan을 하게 되면은 이제 이 모델은 갖고 있는 학습 데이터의 유저나 광고의 패턴을 복합적으로 학습하게 돼서 인스톨 예측을 하기 전에 이미 이 모델은 어떠한 유저나 광고의 패턴을 잘 알고 있는 모델이 되게 됩니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(11강) RecSys Competitions.json",
        "lecture_name": "(11강) RecSys Competitions",
        "course": "RecSys",
        "lecture_num": "11강",
        "lecture_title": "RecSys Competitions",
        "chunk_idx": 8,
        "total_chunks": 13,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:2d7078f21cd46c6e5d61ebe1eb9876fbdff5ae1f121be48c2a8f3fa7054b0fca"
      },
      "token_estimate": 1096,
      "char_count": 2031
    },
    {
      "id": "transcript_recsys_11강_recsys_competitions_c009_3ef388",
      "content": "[RecSys] (11강) RecSys Competitions\n\n다. 그렇게 해서 매번 데이터가 어그멘테이션 될 때 서로 다른 데이터가 어그멘테이션 되도록 사용하였습니다. 그래서 이러한 여러 개의 어그멘테이션을 동시에 적용해서 contressive lan을 하게 되면은 이제 이 모델은 갖고 있는 학습 데이터의 유저나 광고의 패턴을 복합적으로 학습하게 돼서 인스톨 예측을 하기 전에 이미 이 모델은 어떠한 유저나 광고의 패턴을 잘 알고 있는 모델이 되게 됩니다. 그래서 최종적으로는 이 컨트레티브 로스 를 우리가 구하는 것은 아니고 원래 우리가 해야 되는 것은 이 슈퍼바이즈 러닝 로스 즉 이 모델이 이 데이터에 대해서 인스톨을 했냐 안 했냐 결국 그 값을 구하는 것인데 이제 처음에 프리트레이닝 과정에서는 각각의 로스를 어떤 웨이hd SM을 해서 슈퍼바이저 러닝 로스와 컨트레esv 로스를 동시에 배우도록 학습이 됩니다. 그렇게 해서 학습을 진행하다가 일정 기간이 지나게 되고 프리 트레이닝이 끝나게 되면은 그때는 이제 이 로스를 사용하지 않고 원래 우리가 하려고 했던 인스톨하는 그 확률 인스톨하는 그 로스를 구하기 위해서 알파를 1로 지정해서 슈퍼바이저 로스만 계산하게 됩니다. 그래서 그래프를 보시게 되면은 이제 이 컨트레시블 로스를 사용하지 않고 단순히 슈퍼바이저 러닝 그냥 원래 일반적으로 우리가 사용하는 인스토라는 확률을 구하기 위해서는 이렇게 로스가 쭉 떨어지다가 이렇게 올라가서 오버피팅이 되게 되는데 이제 이 중간에 컨트레스블 로스를 같이 사용해서 학습을 하게 되면은 로스가 오버피팅 되지 않고 더 데이터에 많은 패턴을 배워서 더 낮은 값을 기록함을 볼 수 있습니다. 그래서 이것이 바로 컨트레스티브 러닝을 동시에 활용한 효과라고 볼 수 있습니다. 네 마지막으로 네 번째 페이퍼는 멀티태스크 러닝을 사용한 기법입니다. 이 멀티테스크 모델 중에 대표적인 모델인 MMO 멀티게이트 믹스처 오브 익스퍼트라고 하는 모델을 사용해서 우리가 원래 제출해야 되는 값은 인스톨이긴 하지만 인스톨뿐만 아니라 클릭까지 같이 예측해서 최종적으로는 인스톨에 확률도 더 정확하게 예측하기 위한 그런 모델을 설계하였습니다. 네 그래서 가장 중요한 부분인 MMO 부분을 설명하겠습니다. 멀티태스크 러닝이라는 말은 말 그대로 하나의 테스크가 아니라 두 가지 이상의 테스크를 동시에 예측할 수 있는 모델을 학습하는 방법입니다. 그래서 우측의 그림을 보면은 익스퍼트가 NK 개가 있죠 이 각각의 익스퍼트는 우리가 명시적으로 지정하진 않지만 어떤 서로 다른 특징을 추출해서 그것을 잘 배우도록 학습할 것을 기대하고 케겔을 선정하였습니다. 그다음에 이제 이 개별 엑스퍼트의 출력 값을 각각의 테스크 클릭 테스크와 인스톨 테스크에 맞도록 웨이티드 서브를 하게 되는데 이 부분이 바로 게이트입니다. 그래서 저희는 클릭 예측과 인스톨 예측 두 가지가 있기 때문에 이 두 가지 게이트가 존재하게 되고 이 게이트는 어떤 정해진 상수가 아니라 이 게이트 또한 파라미터로 구성되게 됩니다. 그래서 이 모델 전체가 학습되면서 이 게이트가 어떤 웨이트로 웨이티드 썸을 해야 잘 학습이 될지도 이 모델이 알아서 학습을 하게 됩니다. 그리고 마지막으로 이 타워 부분은 게이트를 통과한 어떤 인베딩 값이 최종적으로 클릭에 대한 로스와 인스톨에 대한 로스를 계산할 수 있는 레이어입니다. 그래서 본 논문에서는 각각의 익스퍼트나 요 게이트 그리고 타워 부분을 어떤 복잡한 모델 구조가 아니라 전부 다 멀티 레이어 퍼스톤 제일 기본적인 엠엘피 레이어를 사용했다고 주장하고 있습니다. 사실 복잡한 모델은 아니지만 이 MMO 자체의 모델 설계 구조를 가져간 것이 핵심이라고 볼 수 있습니다. 네 그래서 본 논문에서는 이제 앙상부를 하기 위해서 모델 여러 개를 만들었는데 이제 특이한 점은 각각의 그 앙상블 모델 하나하나에 대해서 서로 다른 인베딩 차원을 사용했다는 것입니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(11강) RecSys Competitions.json",
        "lecture_name": "(11강) RecSys Competitions",
        "course": "RecSys",
        "lecture_num": "11강",
        "lecture_title": "RecSys Competitions",
        "chunk_idx": 9,
        "total_chunks": 13,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:2d7078f21cd46c6e5d61ebe1eb9876fbdff5ae1f121be48c2a8f3fa7054b0fca"
      },
      "token_estimate": 1044,
      "char_count": 1916
    },
    {
      "id": "transcript_recsys_11강_recsys_competitions_c010_cd1b9d",
      "content": "[RecSys] (11강) RecSys Competitions\n\n다. 그래서 본 논문에서는 각각의 익스퍼트나 요 게이트 그리고 타워 부분을 어떤 복잡한 모델 구조가 아니라 전부 다 멀티 레이어 퍼스톤 제일 기본적인 엠엘피 레이어를 사용했다고 주장하고 있습니다. 사실 복잡한 모델은 아니지만 이 MMO 자체의 모델 설계 구조를 가져간 것이 핵심이라고 볼 수 있습니다. 네 그래서 본 논문에서는 이제 앙상부를 하기 위해서 모델 여러 개를 만들었는데 이제 특이한 점은 각각의 그 앙상블 모델 하나하나에 대해서 서로 다른 인베딩 차원을 사용했다는 것입니다. 사실 보통 앙상블 같은 경우에는 특히 CTR 예측 같은 문제나 지금 우리가 풀고 있는 CVR 예측 같은 문제에서는 서로 다른 모델 구조를 앙상블을 하는 게 일반적인데요. 예를 들면은 딥러닝 계열의 모델과 라잇 GBM 같은 GVDTM 같은 서로 다른 모델 구조의 값을 앙상블 하는 게 보통 일반적입니다. 그러나 이제 본 모델은 이미 MMO를 사용했다는 것 자체가 각각의 익스퍼트가 서로 다른 모델이라고 가정을 했기 때문에 어떤 이 MMO 자체를 앙상블을 할 때는 좀 더 직접적으로 다양성을 고려하기 위해서 아예 인베딩을 어떤 모델은 인베딩 차원을 굉장히 크게 만들고 어떤 모델은 인베딩 차원을 작게 만들어서 각각의 모델이 서로 다른 데이터의 패턴을 배우도록 학습을 하고 그 모델을 앙상블 하도록 하였습니다. 네 그리고 멀티태스크 러닝에서 또 가장 중요한 것이 바로 로스 펑션인데요. 왜냐하면 동시에 두 가지 이상의 테스크 저희 같은 경우에는 클릭과 인스톨을 동시에 수행해야 되지만 결국에 학습을 통해서 우리가 최적화해야 되는 로스는 하나이기 때문이죠. 그래서 인스톨 예측과 클릭 예측의 중요한 정도를 가중치 알파와 베타로 사용해서 이를 웨이티드 썸 한 다음에 최종적으로는 이 하나의 로스를 최적화하는 방식으로 모델이 학습되게 됩니다. 그래서 씨브알 예측이 현재는 씨티알보다 더 중요한 거고 결국에는 우리는 씨브알 즉 인스톨 컨버전 웨이트에 대한 예측을 해야 되기 때문에 알파보다 베타를 더 크게 해서 학습을 했다고 말하고 있습니다. 그리고 또 하나 시도한 방법이 이제 시비알 예측에서는 일반적인 바이너리 크로스 앤트오피를 사용한 로스 펑션을 그대로 사용하되 클릭 같은 경우에는 다이렉트한 바이너리 크로스 앤트오피가 아니라 억실러리 로스라고 하는 어떤 보조 로스 펑션을 사용한 방법입니다. 그래서 이 모델이 다이렉트하게 클릭과 컨버전을 동시에 예측하도록 하게 되면은 이제 어떤 경우에는 우리가 정답으로 제출해야 되는 인스톨보다는 클릭을 더 정확하게 예측하도록 학습될 수도 있기 때문에 아예 클릭을 정확하게 예측하는 게 아니라 클릭 샘플의 어떤 유사도의 거리를 줄이도록 로스 펑션을 설계해서 그 로스 펑션과 실제 인스톨을 예측해야 되는 바이너리 크로스 엔트로피 이 두 개를 웨이티드 썸에서 이 최종 로스를 이걸로 정의해서 모델이 학습되도록 하는 그런 모델도 사용했습니다. 그래서 이제 이 asler 로스에 대한 내용은 논문이나 기업 코드를 볼 수 있는데요. 결국 이것만 사용한 것이 아니라 결과적으로 다음 장을 보면은 이제 MMO를 쓰되 데이터셋도 좀 다르게 구성하고 그리고 방금 얘기했던 억실러리 로스를 사용한 모델과 사용하지 않은 모델도 나누고 그리고 인베딩 디맨션도 아예 1로 엄청 낮게 만들거나 아니면 좀 크게 만든 조합 그리고 이 로스를 구성할 때도 알파 베타를 1 대 1로 하거나 혹은 베타를 크게 해서 컨버전을 더 강조한 모델 이제 이렇게 모델을 6개를 만든 다음에 결국에는 이 6개의 모델을 최종 앙상블해서 최종 스코어 인 더 낮은 스코어인 6.15라는 스코어로 다음과 같은 성능을 내었습니다. 그래서 보시면은 각각의 방법을 뭐 다 조합했을 때 가장 좋은 모델이 나오는 것이 아니라 대회이기 때문에 여러 가지 시도를 한 다음에 그 시도를 앙상블 했을 때 결국 최종적으로 가장 높은 성능이 나옴을 확인할 수 있습니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(11강) RecSys Competitions.json",
        "lecture_name": "(11강) RecSys Competitions",
        "course": "RecSys",
        "lecture_num": "11강",
        "lecture_title": "RecSys Competitions",
        "chunk_idx": 10,
        "total_chunks": 13,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:2d7078f21cd46c6e5d61ebe1eb9876fbdff5ae1f121be48c2a8f3fa7054b0fca"
      },
      "token_estimate": 1051,
      "char_count": 1943
    },
    {
      "id": "transcript_recsys_11강_recsys_competitions_c011_51baee",
      "content": "[RecSys] (11강) RecSys Competitions\n\n다. 그래서 보시면은 각각의 방법을 뭐 다 조합했을 때 가장 좋은 모델이 나오는 것이 아니라 대회이기 때문에 여러 가지 시도를 한 다음에 그 시도를 앙상블 했을 때 결국 최종적으로 가장 높은 성능이 나옴을 확인할 수 있습니다. 네 그래서 총 4개의 솔루션을 살펴봤는데요. 각각의 솔루션이 접근법이 모두 다르지만 공통점이 있는데 먼저 첫 번째로는 이 밸리데이션 데이터셋을 학습 데이터의 가장 마지막 날짜로 사용했다는 것입니다. 이제 본 대회는 총 이제 원래 21일의 데이터를 주고 마지막 20일 치의 데이터를 예측하는 것이기 때문에 사실 시계열 정보가 꽤 중요한데 만약에 우리가 받은 21일 치의 데이터에 대해서 랜덤 샘플링을 해 가지고 밸리데이션 셋을 구성하게 되면은 미래의 데이터를 가지고 과거의 데이터를 예측하는 꼴이 되게 됩니다. 그래서 이런 특히 CTR 예측 문제나 시비 예측 문제 그리고 추천 문제에 대해서는 보통 검증 데이터 셋을 가장 마지막 날짜로 정하고 혹은 뭐 가장 마지막 하루 혹은 이틀로 정하고 보통 문제를 구성해서 밸리데이션 셋을 구성하게 됩니다. 두 번째 같은 경우에는 이제 피처 eda를 먼저 수행한 다음에 그다음에 피처 엔지니어링을 했다는 것인데요. 사실 피처 eda에 대한 내용이 자세하게 나와 있지 않고 모든 페이퍼에 대해서는 사실 피처 엔지니어링만 딱 나와 있는데 이게 이 피처 엔지니어링 어떤 피처 엔지니어링을 해야 하기 위해서는 결국에는 이디에를 통해서 아 이 피처는 이런 엔지니어링을 해야 되고 저 피처는 저런 엔지니어링을 해야 되는구나 라는 결론을 얻어내게 됩니다. 그렇기 때문에 모든 팀들은 다 피처 eda를 엄청나게 많이 수행했을 거라고 추측할 수 있습니다. 특히 가장 많은 내용이 뭐 수치형 데이터를 어떻게 쓸 것인가 카테고리컬 데이터를 어떻게 인베딩할 것인가 이제 이런 것들이 많은데 이런 것들은 다 피처 이디에이를 통해서 각각의 피처가 가지고 있는 특징을 찾아낸 다음에 그것들을 적절하게 변환해서 모델에 최종적으로 넣게 되는 것입니다. 그리고 마지막으로 되게 뻔한 얘기지만 이제 대회에서 앙상블은 기본인데요. 뭐 마지막 팀뿐만 아니라 대부분의 팀들이 여러 가지 시도를 한 것들을 다 논문에 적어놓긴 하지만 결국에는 하나의 모델이 아니라 이 시도 저 시도 또 다양한 조합들의 그 모델들을 결국 앙상블에서 최종적으로는 5개 혹은 10개의 모델의 앙상블 값이 최종 대회 성능이 되게 됩니다. 그래서 각각의 모델이 잘하는 게 있고 못하는 게 있는데 이것들을 앙상블 하게 되면은 사실 성능은 무조건 좋아지기 때문에 앙상블은 대회에서 필수라고 볼 수 있습니다. 네 마지막으로 이제 이러한 대회를 통해서 얻은 솔루션의 한계와 또 대회를 진행하면서 여러분들이 알고 있으면 좋을 팁을 간단하게 말씀드리겠습니다. 대외 솔루션은 말 그대로 그냥 솔루션일 뿐입니다. 사실 오프라인 모델은 실험실 환경에서 사용할 수도 있고 근데 이제 이러한 모델 같은 경우에는 앙상블을 통해서 모델의 n개를 조합하기도 하지만 큰 모델 혹은 모델 여러 개를 조합해서 실제 서빙하는 것은 사실 실제 온라인 환경에서는 거의 적용하기 어렵습니다. 그래서 강의에서 다룬 1등 솔루션 같은 경우에는 6개의 레이어의 트랜스폼을 사용했고 실제 학습할 때는 a1 GPU 8대를 사용했다고 하는데요. 사실 모든 회사가 이렇게 a1 GPU를 가지고 학습을 할 수 없기 때문에 실제 추천 시스템에서는 이제 이러한 모델을 매일매일 학습하고 매일매일 서빙하기에는 다소 무리가 있습니다. 이제 또한 오프라인 모델의 성능이 온라인 모델의 성능으로 이어지지 않는데 이것은 사실 첫 번째 강의에서도 말씀을 드렸고 어떨 때는 이제 큰 모델을 사용하는 것보다 작은 모델을 매일매일 학습해서 유저나 아이템의 증가 혹은 유저의 취향 변화 등을 그때그때 대응하는 작은 모델이 실제 온라인 환경에서는 더 좋을 수도 있습니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(11강) RecSys Competitions.json",
        "lecture_name": "(11강) RecSys Competitions",
        "course": "RecSys",
        "lecture_num": "11강",
        "lecture_title": "RecSys Competitions",
        "chunk_idx": 11,
        "total_chunks": 13,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:2d7078f21cd46c6e5d61ebe1eb9876fbdff5ae1f121be48c2a8f3fa7054b0fca"
      },
      "token_estimate": 1047,
      "char_count": 1932
    },
    {
      "id": "transcript_recsys_11강_recsys_competitions_c012_2f2e5c",
      "content": "[RecSys] (11강) RecSys Competitions\n\n다. 이제 또한 오프라인 모델의 성능이 온라인 모델의 성능으로 이어지지 않는데 이것은 사실 첫 번째 강의에서도 말씀을 드렸고 어떨 때는 이제 큰 모델을 사용하는 것보다 작은 모델을 매일매일 학습해서 유저나 아이템의 증가 혹은 유저의 취향 변화 등을 그때그때 대응하는 작은 모델이 실제 온라인 환경에서는 더 좋을 수도 있습니다. 그렇기 때문에 여러분들이 지금 하고 있는 대회는 순수하게 피처 엔지니어링과 모델을 다양하게 다뤄보면서 아 내가 데이터를 다루고 모델의 성능을 높이는 것이 중요하고 이러한 경험을 해야 되는구나 거기에 초점을 맞추셔서 대회를 참여하시면 좋을 것 같습니다. 내 도메인과 무관하게 이 대회를 진행하면서 도움이 되는 팁을 두 가지 말씀드리겠습니다. 이제 첫 번째는 가장 많은 데이터를 샘플링해서 사용하는 것입니다. 대부분의 대회에서는 내가 만든 모델과 내가 만든 피처를 검증하는 데 많은 시간을 사용하게 되는데요. 이제 여기서 우리가 검증 데이터를 어떻게 딱 샘플링을 해서 사용하게 될 것이잖아요. 그런데 이 검증 데이터를 샘플링해서 사용한 이 크로스 밸리데이션 값과 실제 리더보드 값의 상관관계를 우리가 확인을 해야지만 내가 열심히 검증 데이터를 의 성능을 높였는데 결국엔 그게 리더보드와는 괴리가 있게 되면은 사실 내가 했던 모든 것들이 다 헛으로 돌아가게 됩니다. 그렇기 때문에 너무 작은 양의 검증 데이터나 너무 작은 양의 학습 데이터를 샘플링하는 것보다는 충분한 양의 학습 데이터를 샘플링해서 이제 이 그 모델을 최적화하게 되면은 내가 가지고 있는 크로스 밸리데이션 스코어와 리더보드의 스코어의 상관관계를 높일 수 있는 쪽으로 계속해서 진행할 수 있게 됩니다. 또 두 번째로는 이제 다양한 아이디어를 리스팅 해 놓고 고민하기보다는 초기에 생각나는 한 두 개의 아이디어를 먼저 빠르게 실행해서 테스트를 해보고 실제 리더보드에 제출해서 스코어를 확인하는 것입니다. 보통 페이퍼를 보면은 가장 기초적인 데이터 프리 프로세싱하고 그것들을 가지고 가장 간단한 모델을 먼저 넣어서 기본적인 베이스 라인 스코어를 확보를 한 다음에 거기서부터 한 단계 한 단계 올라가게 됩니다. 그래서 처음부터 어떤 큰 모델을 사용하기보다는 최소한의 피처 프리 프로세싱과 엔지니어링을 가지고 먼저 베이스라인 스코어를 한 점 하나 한 번 뽑은 다음에 거기서 내가 다양한 실험들을 통해서 그 스코어를 조금씩 조금씩 올리는 방법이 일반적으로 좋은 방법입니다. 그래서 모델이나 데이터를 만지느라 시간을 많이 쓰기보다는 빠르게 로컬 검증을 몇 번 하고 그 로컬 검증을 많이 하면 할수록 점점 더 스코어가 올라가기 때문에 어떤 좋은 모델을 한 번 빵 만들어서 터뜨리는 것보다는 짧게 짧게 사이클을 가져가면서 대회를 진행하는 것이 여러분들의 높은 스코어 확보에 도움이 될 것 같습니다. 네 여기까지가 11강 대회 내용이었고요. 그동안 이제 추천 시스템 이론 대회 강의 듣느라 정말 수고 많으셨습니다. 대회에서도 좋은 결과가 있기를 바랍니다. 감사합니다.",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(11강) RecSys Competitions.json",
        "lecture_name": "(11강) RecSys Competitions",
        "course": "RecSys",
        "lecture_num": "11강",
        "lecture_title": "RecSys Competitions",
        "chunk_idx": 12,
        "total_chunks": 13,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:2d7078f21cd46c6e5d61ebe1eb9876fbdff5ae1f121be48c2a8f3fa7054b0fca"
      },
      "token_estimate": 830,
      "char_count": 1512
    }
  ]
}