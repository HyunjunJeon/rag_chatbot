{
  "source_file": "(7강) 기초 신경망 이론 -4 - Training Neural Networks.json",
  "lecture_name": "(7강) 기초 신경망 이론 -4 - Training Neural Networks",
  "course": "Deep Learning Basic",
  "total_chunks": 8,
  "chunks": [
    {
      "id": "transcript_deep_learning_basic_7강_기초_신경망_이론_4_training_neural_c000_9a94ec",
      "content": "[강의 녹취록] 과목: Deep Learning Basic | 강의: 7강 | 제목: 기초 신경망 이론 -4 - Training Neural Networks\n\n네 안녕하세요 어 이화여자대학교 인공지능 융합 전공 김수경이고 저희 앞에 강의부터 쭉 저희 머신 러닝 라이프 사이클에 대해서 배우고 있습니다. 그래서 지난 몇 개의 강의에서는 저희 뉴럴레 트레이닝 하는 방법에 대해서 배우고 있습니다. 그래서 백 프로퍼게이션에서부터 시작을 해가지고 저희가 그 뉴럴레 트레이닝 할 때 중요하게 생각되는 뭐 액티베이션 펑션이라든지 웨 이니셜라이제이션이라든지 러닝 레잇을 갖다가 스케줄링하는 어떤 테크니컬한 방법에 대해서도 저희가 저번 시간에 배웠고요. 어 오늘은 사실은 이 트레이닝 뉴럴 네트워크에 약간 컴퓨터 비전에 국한된 내용을 이렇게 가볍게 배우는 시간을 가지도록 하겠습니다. 그래서 사실은 이게 데이터 프리 프로세싱 데이터 어그멘테이션에 대해서 간략하게 설명을 드릴 텐데요. 이게 사실 소위 말하면 데이터 노가다입니다. 그래서 여러분들 이제 데이터 가지고 뉴럴넷 트레이닝 하실 텐데 그 데이터들이 많이 없을 때 아니면 데이터들이 이렇게 깨끗하게 정리가 되어 있지 않을 때 어떻게 해야 되는지 이런 데이터 프리 프로세싱이랑 또 데이터가 적을 때 어떻게 그 데이터를 최대한 없는 살림에 가장 많이 이렇게 늘려 가지고 트레이닝을 할 수 있는지 이런 것들을 살펴보도록 하겠습니다. 그래서 어 이제까지 저희가 배운 내용들은 사실 어떻게 보면은 되게 수학적인 내용들이 많았잖아요 백프로파게이션이나 뭐 액티베이션 펑션 이런 거는 저희가 뭐 익스포넨셜 펑션을 그리기도 하고 미분도 하고 그래서 사실 수학적인 내용들이 많았는데요. 오늘 배우실 내용은요 인트로덕션이라고 생각을 하고 편한 마음으로 들으시면 좋겠습니다. 자 먼저 데이터 프리 프로세싱 데이터 전처리라고 하죠. 이 데이터 전처리의 어떤 중요성과 다양한 기법에 대해서 오늘 설명드리도록 하겠습니다. 자 그래서 우리가 어 예를 들어서 이제 슈퍼바이즈 러닝을 중심으로 저희가 쭉 강의를 하고 있는데요. 이 데이터 트레이닝 데이터를 모아 가지고 뉴럴넷을 이용해서 학습을 시킬 때 이 데이터의 디스트리뷰션이 굉장히 스큐 되어 있고 어 잘 정리가 되어 있지 않는 그런 경우가 많이 있습니다. 그럴 때 어 모델 문제가 아니고 이 데이터 디스트리뷰션이 이렇게 스큐 되어 있고 잘 정리가 되어 있지 않으면은 저희가 이 모델을 트레이닝하는 데 무리가 있을 수가 있어요. 그래서 이런 전처리 과정이 되게 중요합니다. 그래서 제 경험에 의하면은요 실제로 어떤 예측 모델을 만들 때 데이터 전처리를 제대로 하지 않았더니 결과가 되게 안 나오고 모델이 굉장히 노이지하게 트레이닝이 됐는데 전 처리를 한 다음에 트레이닝 하니까 되게 예쁘게 트레이닝이 된 경우가 엄청 많았어요. 그래서 이런 어떻게 보면은 좀 인페리컬한 메서드가 여러분 현업에서는 굉장히 중요할 수 있다는 거를 이렇게 말씀드립니다. 자 먼저 제로 센터링 노멀라이제이션 이 두 가지에 대해서 말씀드리도록 하겠습니다. 어 우리의 트레이닝 데이터셋이 모든 입력 값이 양수일 때 문제가 생긴다고 저번 시간에 배웠습니다. 특히 뭐 시그모이드나 탄젠트 h 같은 펑션 저희 봤을 때 뭐 픽셀 밸류 같은 거 양수의 인풋을 갖다가 쓰면은 그 업스트림에서 다운스트림으로 갈 때 그 부호가 항상 같은 어떤 문제가 발생이 된다고 그랬어요. 그래서 그 데이터의 센터를 이렇게 디스트리뷰션을 봤을 때 0이 되지 않으면 문제가 생기는 경우가 많습니다. 그래 가지고 우리가 웬만하면 그 데이터의 디스트리뷰션이 0을 중심으로 분포하게 하는 게 좋아요. 그래서 여기 제가 써놨죠. 인풋의 모든 입력 값이 양수일 때 어 이 데이터 디스트리뷰션이 0이 아니면은 시그모이드 펑션과 비슷하게 그레디언트들이 다 같은 부호를 갖는 그런 안 좋은 상황이 존재를 해요. 그 그레디언트 다 부호가 같으면은 저희 저번 시간에 배웠지만 굉장히 비효율적으로 그레디언트가 업데이트될 수밖에 없습니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(7강) 기초 신경망 이론 -4 - Training Neural Networks.json",
        "lecture_name": "(7강) 기초 신경망 이론 -4 - Training Neural Networks",
        "course": "Deep Learning Basic",
        "lecture_num": "7강",
        "lecture_title": "기초 신경망 이론 -4 - Training Neural Networks",
        "chunk_idx": 0,
        "total_chunks": 8,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:60b55395652e8ca06d4965352265c97010bb66dd44559486c908463ece7b6854"
      },
      "token_estimate": 1074,
      "char_count": 1969
    },
    {
      "id": "transcript_deep_learning_basic_7강_기초_신경망_이론_4_training_neural_c001_99d280",
      "content": "[Deep Learning Basic] (7강) 기초 신경망 이론 -4 - Training Neural Networks\n\n다. 그래 가지고 우리가 웬만하면 그 데이터의 디스트리뷰션이 0을 중심으로 분포하게 하는 게 좋아요. 그래서 여기 제가 써놨죠. 인풋의 모든 입력 값이 양수일 때 어 이 데이터 디스트리뷰션이 0이 아니면은 시그모이드 펑션과 비슷하게 그레디언트들이 다 같은 부호를 갖는 그런 안 좋은 상황이 존재를 해요. 그 그레디언트 다 부호가 같으면은 저희 저번 시간에 배웠지만 굉장히 비효율적으로 그레디언트가 업데이트될 수밖에 없습니다. 옵티멀 패스를 따라가지 않고 왜냐하면은 그레디언트의 모든 부호가 같으니까 같은 방향으로 밖에 그레디언트가 업데이트 되지 않기 때문이죠. 그래서 여기에서는 전처리 과정의 일부로 데이터에서 평균을 빼 가지고 데이터의 디스트리뷰션을 데이터의 확률 분포를 임의적으로 0의 중심이 되게 만드는 것이 또 하나의 중요한 제로 센터링이라는 전처리 과정입니다. 그래서 여기 이렇게 그림에 보시는 바와 같이 빨간색 점들에서 보이는 것처럼 오리지널 데이터가 원본 데이터가 이렇게 0이 중심이 아닌 경우에 이렇게 분포를 한다고 생각을 해봐요. 그러면은 이 빨간색 데이터의 분포를 갖다가 0이 중심이 되게 우리가 억지로 만들기 위해서 어떻게 하냐면요. 되게 쉬워요. 데이터에다가 데이터 전체의 평균으로 빼주면 돼요. 그렇죠 데이터의 이 빨간색 데이터에서 이 빨간색 전체 데이터의 평균을 구해가지고 각각의 데이터 포인트에 그 빨간색 데이터의 평균으로 빼줘요. 그러면은 당연히 이 분포가 제로 센터가 되겠죠. 0 중심으로 되겠죠 그렇죠 한 가지 더 이 데이터를 갖다가 노멀라이즈 하기 위해서 이 데이터 포인트의 표준 편차로 이렇게 나누어 줍니다. 이거를 갖다가 제로 센터링 노멀라이제이션 프로세스라고 그래요. 그래서 궁극적으로 이렇게 평균으로 빼면은 데이터 분포가 0 중심으로 이렇게 시프트돼서 가게 되고 이 데이터 포인트를 그다음에 이 스탠다드 디비에이션 표준 편차로 나누어 주면은 이렇게 그 그 베리언스가 이렇게 유닛하게 스쿼시가 돼 가지고 노멀 디스트리뷰션으로 분포하게 되는 거죠. 이렇게 데이터를 노멀라이즈 하지 않으면요. 여러분 그 결과가 되게 잘 안 나와요. 기본적으로 뉴럴넷이라는 것이 데이터의 분포 자체를 정규 분포로 가정하기 때문에 여러분 어떤 데이터를 처리하시든 간에 꼭 이 데이터 노멀라이제이션을 해줘야 됩니다. 이거는 컴퓨터 비전 데이터도 예외가 아니에요. 예를 들어서 어 우리가 그림 데이터를 갖다가 이미지 데이터를 갖다가 처리할 때 그냥 전처리되지 않은 그 사진이라든지 이미지 데이터를 보면은요. 그 이미지 데이터가 3차원인데 x 콤마 y 그리고 RGB 채널로 되어 있는데 각각의 밸류가 0부터 228인가까지의 그 유닛 a라는 형태로 다 그렇게 인티저 밸류로 되어 있어요. 그래서 이거를 갖다가 노멀라이즈 해줘야 돼요. 0과 1 사이에 분포하고 제로 센터도 되게 이렇게 평균으로 빼줘서 분산으로 나누는 작업을 꼭 거치시기를 바랍니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(7강) 기초 신경망 이론 -4 - Training Neural Networks.json",
        "lecture_name": "(7강) 기초 신경망 이론 -4 - Training Neural Networks",
        "course": "Deep Learning Basic",
        "lecture_num": "7강",
        "lecture_title": "기초 신경망 이론 -4 - Training Neural Networks",
        "chunk_idx": 1,
        "total_chunks": 8,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:60b55395652e8ca06d4965352265c97010bb66dd44559486c908463ece7b6854"
      },
      "token_estimate": 809,
      "char_count": 1497
    },
    {
      "id": "transcript_deep_learning_basic_7강_기초_신경망_이론_4_training_neural_c002_415aba",
      "content": "[Deep Learning Basic] (7강) 기초 신경망 이론 -4 - Training Neural Networks\n\n다. 이거는 컴퓨터 비전 데이터도 예외가 아니에요. 예를 들어서 어 우리가 그림 데이터를 갖다가 이미지 데이터를 갖다가 처리할 때 그냥 전처리되지 않은 그 사진이라든지 이미지 데이터를 보면은요. 그 이미지 데이터가 3차원인데 x 콤마 y 그리고 RGB 채널로 되어 있는데 각각의 밸류가 0부터 228인가까지의 그 유닛 a라는 형태로 다 그렇게 인티저 밸류로 되어 있어요. 그래서 이거를 갖다가 노멀라이즈 해줘야 돼요. 0과 1 사이에 분포하고 제로 센터도 되게 이렇게 평균으로 빼줘서 분산으로 나누는 작업을 꼭 거치시기를 바랍니다. 이게 데이터 전처리의 가장 기본이에요. 근데 왜 이렇게 0을 중심으로 데이터가 분포하는 게 중요하냐면요. 여기서 쓰여 있던 것처럼 그 WI의 작은 변화에 모델이 덜 민감해져요. 예를 들어서 이 왼쪽 거는요. 사실 이 데이터 빨간 데이터랑 파랑 데이터가 그 중심 제로라는 중심에 분포하지 않는 경우죠. 여기 보시면은 데이터들이 이 오른쪽 아래에 분포돼 있고 오른쪽은 이 데이터들을 갖다가 제로 센터 되게 우리가 평균으로 빼가지고 분선으로 나눠준 경우라고 생각하시면 돼요. 자 그러면은 WI의 작은 변화에 덜 민감해진다는 건 무슨 말이냐 우리가 앞에 강의에서 리니어 모델에 대해서 배웠잖아요. 리니어 모델에서 웨잇은 무슨 의미를 가지고 있죠? 그렇죠 이 디시전 바운더리의 기울기 값이에요. 그래서 이 제로 센터 안 된 경우에 이렇게 리니어 모델의 웨이을 바꾸면 어 이 파란색 디시전 바운더리가 이 노란색 점선 디시전 바운더리로 바뀔 거예요. 그러면은 이렇게 디시전 바운더리가 로테이트 하면서 이 데이터들이 굉장히 많은 데이터들이 틀리게 돼요. 요 빨간색이 빨간색으로 분류가 안 되고 2개나 이렇게 어긋나게 되죠. 근데 만약에 이거를 제로 센터로 바꾸면 이렇게 디시션 바운더리가 조금 로테이트 해도 0 포인트 중심으로 로테이트 하기 때문에 많은 데이터가 틀리지 않게 됩니다. 직관적으로 이해가 되셨으면 좋겠어요. 이 그림을 통해서 이렇게 제로 센터링을 함으로써 웨잇의 작은 변화에도 덜 민감해지고 따라서 어 웨잇의 작은 변화에 덜 민감해지기 때문에 자연스럽게 최적화도 옵티마이즈도 쉽게 됩니다. 네 그다음에 이제 피씨에랑 화이트닝 프리 프로세싱 테크닉에 대해서 간단하게 설명드리도록 하겠습니다. 사실 이 PCA 프랜스포 컴포넌트 어널리시스는요. 뉴럴넷이라는 게 생기기 전에 굉장히 널리널리 사용되었던 어떤 데이터 컴프레션 메소드였어요. 그래서 기본적으로 데이터가 굉장히 많은 디멘전을 가질 때 제일 중요한 그 디맨전들에 대한 값만 남기고 나머지는 다 날리는 어떻게 보면 데이터 셋이 굉장히 그니까 데이터의 벡터가 클 때 그 벡터를 압축하는 기술로써 널리 사용된 그런 방법이었어요. 그래서 기본적으로 이 PCA가 하는 일이 뭐냐면요. 이렇게 데이터 분포가 있을 때 이 데이터 분포에서 가장 분산이 넓은 축을 중심으로 로테잇을 합니다. 그러니까는 우선 그러니까 직관적으로 설명을 드릴게요. 이거를 수학적으로 들어가면 너무 복잡해지니까 예를 들어서 원본 데이터가 이렇게 빨간색 점이 있다고 생각해요. 그러면은 여기에서 가장 분산이 긴 축은 이 축이죠. 데이터가 이렇게 길게 분포를 했으니까 이 축을 중심으로 가장 데이터가 분산이 크게 분포를 할 거예요. 그러면은 이 축을 갖다가 중심으로 로테이트를 해 가지고 이런 식으로 돌려주는 거예요. 그래서 이렇게 함으로써 우리가 데이터가 0을 중심으로 분포하게 제로 센터가 되게 우선 만듭니다. 그래서 이렇게 분산이 큰 방향으로 로테이트 함으로써 먼저 이렇게 스텝 1 프리 프로세싱이 끝나고 그다음에 이 데이터 분포를 갖다가 베리언스로 나누어져 가지고 이렇게 정규 분포를 따르도록 만듭니다. 그래서 기본적으로 굉장히 분산이 큰 데이터의 경우에 그 분산 파라미터를 없애주면서 데이터의 키가 되는 어떤 본질적인 성질만 우리가 표현할 수 있도록 압축시켜 주는 기술이 이 피시에 화이트닝 방법입니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(7강) 기초 신경망 이론 -4 - Training Neural Networks.json",
        "lecture_name": "(7강) 기초 신경망 이론 -4 - Training Neural Networks",
        "course": "Deep Learning Basic",
        "lecture_num": "7강",
        "lecture_title": "기초 신경망 이론 -4 - Training Neural Networks",
        "chunk_idx": 2,
        "total_chunks": 8,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:60b55395652e8ca06d4965352265c97010bb66dd44559486c908463ece7b6854"
      },
      "token_estimate": 1082,
      "char_count": 2000
    },
    {
      "id": "transcript_deep_learning_basic_7강_기초_신경망_이론_4_training_neural_c003_b07028",
      "content": "[Deep Learning Basic] (7강) 기초 신경망 이론 -4 - Training Neural Networks\n\n다. 그래서 이렇게 분산이 큰 방향으로 로테이트 함으로써 먼저 이렇게 스텝 1 프리 프로세싱이 끝나고 그다음에 이 데이터 분포를 갖다가 베리언스로 나누어져 가지고 이렇게 정규 분포를 따르도록 만듭니다. 그래서 기본적으로 굉장히 분산이 큰 데이터의 경우에 그 분산 파라미터를 없애주면서 데이터의 키가 되는 어떤 본질적인 성질만 우리가 표현할 수 있도록 압축시켜 주는 기술이 이 피시에 화이트닝 방법입니다. 그래서 실제로 이런 방법들을 이용해 가지고 이제 굉장히 중구난방이고 프리 프로세싱이 안 된 데이터를 갖다가 예쁘게 정리하는 기술입니다. 자 두 번째는 데이터 오그멘테이션인데요. 데이터 오그멘테이션 데이터 증강이라는 거죠. 그래서 이거는 기본적으로 뭐냐하면요 데이터가 많지 않을 때 이거를 갖다가 억지로 늘려주는 테크닉입니다. 어떻게 늘려줄까 한번 보도록 하겠습니다. 자 실제 우리가 사용할 수 있는 데이터 셋의 양은 굉장히 적어요. 실제 존재하는 데이터 셋은 레이블링을 해야 되기 때문에 레이블링된 데이터셋이 굉장히 적어요. 그래서 우리가 원하는 거는요 데이터의 의미에 영향을 주지 않고 각각의 데이터들을 수정하는 방법을 이용해서 데이터를 늘릴 수 있는 만큼 늘리고 싶어요. 자 그리고 데이터를 늘린 다음에 클래스 파이어는 불변해야 돼요. 그러니까 그 클래시 파이어가 하는 그 어떤 테스크를 갖다가 변형시키지 않고 그대로 그 테스크는 하게 함으로써 클래식 파이어는 변형시키지 않지만 데이터 자체는 변형시켜서 우리가 데이터셋을 늘려가지고 트레이닝 하고 싶은 거예요. 예를 들어서 이런 원본 데이터가 있어요. 이 여자 얼굴이 여자 이 여자가 예를 들어 메리라고 하면은 이 여자 얼굴이랑 메리라는 레이블이 있겠죠 근데 이 메리의 얼굴이 하나밖에 없기 때문에 트레이닝 하는 데 부족해요. 그럼 어떻게 하냐면요 이런 방법들을 쓸 수가 있겠죠 이 이미지를 갖다가 오른쪽으로 시프트 해 가지고 좀 오른쪽으로 밀어요. 그러면은 여전히 메리죠 그래서 이렇게 해가지고 데이터를 하나에서 2개로 늘릴 수 있고 그다음에 이 메리에서 눈과 입을 가려가지고 메리라고 또 레이블을 달고 또 메리의 그림의 색조를 갖다가 틴트를 줘 가지고 이렇게 파란 명조를 줌으로써 얘도 또 메리라고 레이블 합니다. 그래서 이런 식으로 여러 가지 테크닉을 이용해서 벌써 하나의 이미지가 지금 4개가 됐잖아요 이런 식으로 데이터를 증강할 수가 있어요. 사실 여러분들 생각하기에 약간 어 이거 좀 노가다스러운데라고 생각할 수 있는데요. 실제로 되게 많이 씁니다. 특히 이미지 프로세싱 같은 경우에 원본 데이터가 적은 경우가 많거든요 그래서 이런 식으로 여러 가지 어 데이터의 변화를 줘 가지고 그 데이터를 같은 레이블로 매핑시킴으로써 이렇게 데이터를 증강시키는 방법이 있어요. 네 그런 다음에 또 이제 그 NLP 테스크에서도 데이터 어그멘테이션이 쓰여요. 예를 들어서 뭐 디시즈 베리 c이라는 문장이 있다고 생각을 해 봐요. 그러면은 이거에 같은 의미를 갖는 여러 가지 문장을 갖다가 만들어내요. 예를 들어서 디시스 프리코 디시즈 릴리쿨 디시즈 수퍼 쿨 다 같은 말이잖아요 결국 디시스 베리쿨을 다른 방법으로 이렇게 표현한 거죠. 그래서 이런 식으로 패러프라이즈 해 가지고 어 이런 식으로 데이터를 증강하기도 합니다. 실제로 요새 nip 테스크에서는 어떤 거를 쓰냐면요. 여러분들 챗gpt 많이 쓰시잖아요 그래서 데이터가 있으면은 챗gpt로 걔를 패러프라이즈 하게 시켜요. 그러니까 다시 쓰게 하는 거죠. 그래서 의미는 같되 다른 문장으로 표현을 하는 겁니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(7강) 기초 신경망 이론 -4 - Training Neural Networks.json",
        "lecture_name": "(7강) 기초 신경망 이론 -4 - Training Neural Networks",
        "course": "Deep Learning Basic",
        "lecture_num": "7강",
        "lecture_title": "기초 신경망 이론 -4 - Training Neural Networks",
        "chunk_idx": 3,
        "total_chunks": 8,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:60b55395652e8ca06d4965352265c97010bb66dd44559486c908463ece7b6854"
      },
      "token_estimate": 982,
      "char_count": 1810
    },
    {
      "id": "transcript_deep_learning_basic_7강_기초_신경망_이론_4_training_neural_c004_2a6283",
      "content": "[Deep Learning Basic] (7강) 기초 신경망 이론 -4 - Training Neural Networks\n\n다. 실제로 요새 nip 테스크에서는 어떤 거를 쓰냐면요. 여러분들 챗gpt 많이 쓰시잖아요 그래서 데이터가 있으면은 챗gpt로 걔를 패러프라이즈 하게 시켜요. 그러니까 다시 쓰게 하는 거죠. 그래서 의미는 같되 다른 문장으로 표현을 하는 겁니다. 그런 식으로 그 문장 데이터를 증강하는 데 쓸 수가 있어요. 네 자 여기서 큰 데이터셋을 가지는 거는 돈이 많이 들기 때문에 기존 데이터를 최대한 활용해서 사용을 해야 된대요. 그래서 어 제가 이걸 느낀 게요. 제가 그 미국에서 했던 연구 중에 하나가 허리케인을 갖다가 어 분류하는 뉴럴넷 알고리즘을 트레이닝하고 학습하는 그런 연구를 했어요. 허리케인 레코드를 보면요. 실제로 그 남아 있는 허리케인 기록이 그렇게 많지가 않아요. 뭐 2천 개가 안 되더라고요. 그 허리케인 레코드를 보면은 왜냐하면 실제로 우리가 존재하는 허리케인들이 그렇게 많지 않기 때문에 그래서 사실 그 몇 천 개의 허리케인으로 뉴럴넷을 트레이닝 하는 건 너무 힘들잖아요. 그래서 제가 학습을 잘 하기 위해서 가지고 있는 허리케인의 오그멘테이션 이런 트랜슬레이션이나 뭐 틴트 이런 것들을 가지고 어 데이터를 증강해 가지고 실제로 허리케인 트레킹을 하는 그런 알고리즘을 만든 적이 있습니다. 네 그리고 그다음에 이제 데이터 오그멘테이션 테크닉 중에 노이즈를 더하는 증강 기법들에 대해서 설명하도록 하겠습니다. 이거는 컴퓨터 비전에 국한된 거지만 뭐 제가 했던 무슨 대기 데이터라든지 비전과 가까운 뭐 비슷한 데이터들에도 다 쓰이는데요. 어 이것도 고양이고 이것도 고양이죠 사람이 볼 때는 둘 다 고양이입니다. 근데 우리가 원하는 거는 클래식 파이어도 동일한 방식으로 우리가 사람이 이해하는 것처럼 인식을 하기를 원해요. 그래서 어떻게 하냐 되게 간단해요. 이 두 개의 사진 모두 고양이라고 가르치면 되겠죠. 그래서 이런 식으로 여러 방향으로 고양이 사진을 뒤집어 가지고 똑같이 고양이라고 레이블을 하는 방법이 있겠죠. 그래서 이런 식으로 왼쪽 오른쪽 이렇게 시프트 해 가지고 고양이 사진을 반전시켜서 고양이라고 레이블을 할 수도 있고 이 그 나무 바다와 나무 사진을 이렇게 뒤집어 가지고 바다 사진이라고 레이블을 할 수도 있어요. 그래서 그 이미지의 시멘틱에 따라서 여러 방법으로 플립을 해서 호리젠탈 플립이든 버티컬 플립이든 플립을 해가지고 이렇게 데이터를 어그먼트 할 수 있습니다. 네 그리고 이거는 좀 어떻게 보면은 진짜 노가다스러운 방법인데요. 랜덤 크롭이라고 써있죠 이렇게 고양이라는 큰 사진이 있어요. 그러면은 이 고양이 얼굴도 고양이고 고양이 발도 고양이고 고양이 몸통도 다 고양이잖아요. 그래서 우리가 원하는 거는요. 우리가 트레이닝 하는 이 클래식 파이어가 고양이의 부분만 봐도 고양이라고 인식하면 너무 좋겠어요. 그래서 이렇게 랜덤하게 크롭하는 겁니다. 이 고양이 사진에 얼굴 부분 몸통 부분 다리 부분 이런 거를 이렇게 계속 랜덤하게 무작위로 크롭을 해가지고 트레이닝 셋을 널 이렇게 늘리는 방법도 있어요. 그래서 여기에서 이제 새로운 개념이 나오는데 트랜지레이션 인베리언스 이게 뭐냐면은 우리가 이미지를 트랜슬레이트 해도 바뀌지가 않는다는 거예요. 예를 들어서 이 고양이의 이미지를 갖다가 몇 개의 픽셀만 이용해 가지고 크롭을 해도 걔가 고양이라는 건 바뀌지 않잖아요. 그래서 우리가 이미지 데이터라고 하면은 이 트랜슬레이션 인베리언스가 있습니다. 몇 개의 픽셀만 이동하더라도 두 개의 이미지가 같은 속성을 갖다고 인식하는 게 트랜슬레이션 인베리언스 그래서 우리는 우리가 원하는 거는 우리가 뉴럴넷으로 클래스 파이어를 트레이닝을 했을 때 그 클래스 파이어가 트랜슬레이션 인베리언스 하기를 원합니다. 그래서 그거를 갖다가 획득하기 위해서 이런 식으로 랜덤하게 시프트하고 크롭한 이미지를 갖다가 트레이닝을 합니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(7강) 기초 신경망 이론 -4 - Training Neural Networks.json",
        "lecture_name": "(7강) 기초 신경망 이론 -4 - Training Neural Networks",
        "course": "Deep Learning Basic",
        "lecture_num": "7강",
        "lecture_title": "기초 신경망 이론 -4 - Training Neural Networks",
        "chunk_idx": 4,
        "total_chunks": 8,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:60b55395652e8ca06d4965352265c97010bb66dd44559486c908463ece7b6854"
      },
      "token_estimate": 1057,
      "char_count": 1941
    },
    {
      "id": "transcript_deep_learning_basic_7강_기초_신경망_이론_4_training_neural_c005_a94fc4",
      "content": "[Deep Learning Basic] (7강) 기초 신경망 이론 -4 - Training Neural Networks\n\n다. 몇 개의 픽셀만 이동하더라도 두 개의 이미지가 같은 속성을 갖다고 인식하는 게 트랜슬레이션 인베리언스 그래서 우리는 우리가 원하는 거는 우리가 뉴럴넷으로 클래스 파이어를 트레이닝을 했을 때 그 클래스 파이어가 트랜슬레이션 인베리언스 하기를 원합니다. 그래서 그거를 갖다가 획득하기 위해서 이런 식으로 랜덤하게 시프트하고 크롭한 이미지를 갖다가 트레이닝을 합니다. 그리고 이거는 사실 다른 유형의 데이터에서도 비슷하게 적용이 돼요. 어디오나 비디오나 텍스트나 시퀀스 모드 예를 들어서 뭐 오디오 같은 경우는 음악이 쭉 나온다고 생각을 해봐요. 여러분들 뭐 아이유의 음악이 나와요 그러면은 그 음악을 처음부터 끝까지 다 가지고 와서 아이유의 무슨 음악이라고 레이블링을 하고 그다음에 그 음악을 시작하는 부분을 조금 뒤로 시프트 해 가지고 중간부터 녹화를 해서 그게 아이유의 음악이라고 또 레이블을 할 수도 있겠죠. 비디오도 마찬가지예요. 유튜브 비디오를 처음부터 끝까지 쭉 인풋으로 넣고 어떤 비디오라고 레이블을 할 수도 있고 중간에서 어떤 특정 부분까지 끊고 그거를 어떤 비디오라고 레이을 할 수도 있겠죠. 그리고 텍스트랑 시퀀스도 마찬가지입니다. 자 랜덤 크롭을 해가지고 하면은 데이터를 굉장히 많이 늘릴 수가 있습니다. 자 이거는 자명하죠 스케일링입니다. 다양한 이미지의 크기에 관계없이 물체가 인식이 돼야 되죠. 예를 들어서 고양이를 갖다가 이렇게 얼굴을 갖다가 쭉 크게 늘어뜨렸어요. 고양이를 원본 이미지라고 그러면은 점점 점점 확대된 겁니다. 그런데 확대된 돼 가는 이미지에서 똑같은 크기의 바운딩 박스로 이렇게 데이터를 땄어요. 그러면은 이 빨간색 박스 안에서의 고양이의 얼굴이 점점 커지죠. 이렇게 스케일링을 해가면서 데이터를 샘플링해서 다양한 크기의 이미지에서 무작위로 이렇게 크롭해서 샘플링한 이미지를 같은 클라스를 레이블 해서 훈련 이미지에 사용을 할 수가 있겠죠. 그래서 이거는 사실 어떻게 보면은 또 커먼 프랙티스입니다. 현업에서 어떻게 하냐면요 예를 들어서 어 우리가 이미지 크기가 256바이 480 이렇게 있으면은 여기에서 가로 세로 길이 중에 짧은 길이를 선택을 해요. 256이랑 480 중에서 256이 더 작잖아요 그러면은 256보다 조금 작은 조정된 이미지 크기에 대해 패치에 대해서 정사각형으로 무작위로 이미지를 샘플링 해요. 여러 개를 크롭을 해 가지고 데이터를 쫙 올리는 거죠. 그래서 트레이닝을 하고 테스트할 때는 우리 모델이 224바이 224의 사이즈의 이미지만 받으니까 이 이미지를 스케일링을 해 가지고 점점 확대시켜서 오리지널 이미지에서 점점 점점 확대시킨 다음에 각각의 그 이미지에 대해서 224바이 224 사이즈에서 랜덤한 개수의 이미지를 갖다가 크롭하고 샘플링해서 테스팅 하게 됩니다. 자 이렇게 크롭하고 스케일링 하면은 사실 엄청나게 많이 데이터 숫자를 갖다가 늘릴 수가 있습니다. 이게 어떻게 보면 좀 이미지 프로세싱에 대해서 팁이라고 여러분들한테 전해 드릴 수 있는 어떤 노하우입니다. 자 그리고 이거는 칼라 지터라고 그러는데요. 사실 어 우리가 뭐 여러분들 요새 그 스마트폰에 다 그 이미지 보정 앱들을 하나씩 가지고 있을 거예요. 그래서 사실 원본 이미지를 그렇게 보정을 하거나 아니면 빛을 넣거나 여러 다른 요인을 갖다가 추가시켜서 포토샵을 한다고 생각을 하면 돼요. 그래서 빛이나 다른 요인들에 의해서 그 이미지의 원본 색깔이 다르게 보일 수가 있잖아요. 그래서 그런 것들 영향을 줘 가지고 예를 들어 이 고양이를 갖다가 좀 더 회색 톤으로 바꿔 가지고 또 똑같이 고양이라고 레이블을 합니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(7강) 기초 신경망 이론 -4 - Training Neural Networks.json",
        "lecture_name": "(7강) 기초 신경망 이론 -4 - Training Neural Networks",
        "course": "Deep Learning Basic",
        "lecture_num": "7강",
        "lecture_title": "기초 신경망 이론 -4 - Training Neural Networks",
        "chunk_idx": 5,
        "total_chunks": 8,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:60b55395652e8ca06d4965352265c97010bb66dd44559486c908463ece7b6854"
      },
      "token_estimate": 991,
      "char_count": 1833
    },
    {
      "id": "transcript_deep_learning_basic_7강_기초_신경망_이론_4_training_neural_c006_3bdacc",
      "content": "[Deep Learning Basic] (7강) 기초 신경망 이론 -4 - Training Neural Networks\n\n다. 자 그리고 이거는 칼라 지터라고 그러는데요. 사실 어 우리가 뭐 여러분들 요새 그 스마트폰에 다 그 이미지 보정 앱들을 하나씩 가지고 있을 거예요. 그래서 사실 원본 이미지를 그렇게 보정을 하거나 아니면 빛을 넣거나 여러 다른 요인을 갖다가 추가시켜서 포토샵을 한다고 생각을 하면 돼요. 그래서 빛이나 다른 요인들에 의해서 그 이미지의 원본 색깔이 다르게 보일 수가 있잖아요. 그래서 그런 것들 영향을 줘 가지고 예를 들어 이 고양이를 갖다가 좀 더 회색 톤으로 바꿔 가지고 또 똑같이 고양이라고 레이블을 합니다. 그렇게 되면은 이제 이렇게 다양한 형태의 변형된 이미지를 보고 고양이라고 클래스 파이 하기 때문에 요 이렇게 다양한 컬러 지터의 어그멘티드 된 데이터를 이용해 가지고 트레이닝한 클래스 파이어는요 이런 빛이나 다른 요인에도 영향을 받지 않고 굉장히 안정적으로 이 고양이를 분리할 수 있는 로보스트한 트레이닝 알고리즘으로 트레이닝이 되겠죠. 그래서 사실 이거는 그림판의 어떤 펑션이에요. 그래서 그림판에 보시면은 제가 옛날에 옛날에 옛날에 썼던 이런 툴인데요. 요새는 더 좋은 툴이 많아요. 여기 책 편집에 보면은 이 나 세츄레이션이나 라이트니스나 여러 가지 색상 채도 명도의 파라미터들이 있어요. 이거를 효율적으로 이용해서 이미지를 원하는 톤으로 바꿀 수가 있고 그렇게 해서 오그멘티드 된 데이터셋을 트레이닝 셋에 넣을 수가 있습니다. 그리고 이거는 그 색상 명도 채도 이거를 수학적으로 사실은 어떻게 바꾸는지를 설명하는 거예요. 그래서 우리가 알지비 채널이 있고 그 알지비 채널들은 사실은 까보면은 각 픽셀 밸류이 밸류들이 0부터 255까지의 그 그 인티저 밸류로 되어 있어요. 그렇게 인티저 밸류로 되어 있을 때 이 휴 세트레이션 라이트니스를 바꾸기 위해서 이런 수학적인 테크닉들이 이용된다. 그래서 참고로 한번 보시면 됩니다. 그리고 마지막으로 또 할 수 있는 게 문제와 데이터의 영역에 따라 이런 여러 가지 변형들 그러니까 기하학적인 변형들을 볼 수가 있어요. 그러니까 기하학적이라고 하면 어렵게 들릴 수도 있지만 별거 아니에요. 그냥 이미지를 갖다가 선택을 해 가지고 쭉 늘려 가지고 납작하게 만든다든지 아니면 로테입 된다든지 아니면 이렇게 대각선을 늘린다든지 여러 가지 어 그 이미지 어그멘테이션 테크닉들이 있습니다. 그래서 더 많은 테크닉들을 보고 싶으시면 이 링크를 가시면은 사람들이 적용했던 수많은 그 이미지 데이터 어그멘테이션 방법들이 있습니다. 그리고 뭐 예를 들어서 여러분들 뭐 NLP를 하신다든지 오디오 프로세싱을 하신다고 그러면은 또 각각의 영역에서 데이터를 갖다가 증강시키는 굉장히 많은 테크닉들이 인터넷에 있습니다. 그래서 사실 어떻게 보면은 여러분들 어 이거는 좀 되게 데이터 노가다적이고 되게 팬시하지 않아라고 생각할 수도 있겠지만 이렇게 다양한 테크닉을 이용해서 데이터를 증강시켜 가지고 트레이닝 데이터에다가 넣으면요. 실제로 굉장히 좋아요. 그 모델이 훨씬 더 로버스트해집니다. 즉 이렇게 이미지에다가 노이즈를 어 에드함으로써 사실 이미지를 막 구기고 변형시키고 우리가 이미지를 손상시키는 거죠. 그렇게 해도 클래시피케이션이나 우리가 원하는 테스크가 잘 되기 때문에 실제로 이렇게 오그멘테이션 해 가지고 트레이닝 셋에다가 합쳐 놓으면은 모델이 훨씬 더 잘 모델의 정확도가 더 높아져요. 그래서 꼭 어그멘티드 된 그런 데이터 셋을 한번 사용해 보시고 그렇지 않은 경우랑 비교해 보는 것도 재밌는 실험이 될 것 같아요. 그래서 오늘은 사실 데이터 어그멘테이션 어떻게 보면은 굉장히 수학적이지 않은 내용입니다. 그래서 좀 편하게 재미있게 들을 수 있는 데이터 노가다 기법에 대해서 어떻게 보면은 좀 티리어스하다고 생각할 수 있는 그런 기법들에 대해서 배워봤고요. 다음 시간에는 본격적으로 좀 더 어려운 내용에 들어갑니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(7강) 기초 신경망 이론 -4 - Training Neural Networks.json",
        "lecture_name": "(7강) 기초 신경망 이론 -4 - Training Neural Networks",
        "course": "Deep Learning Basic",
        "lecture_num": "7강",
        "lecture_title": "기초 신경망 이론 -4 - Training Neural Networks",
        "chunk_idx": 6,
        "total_chunks": 8,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:60b55395652e8ca06d4965352265c97010bb66dd44559486c908463ece7b6854"
      },
      "token_estimate": 1065,
      "char_count": 1952
    },
    {
      "id": "transcript_deep_learning_basic_7강_기초_신경망_이론_4_training_neural_c007_45b395",
      "content": "[Deep Learning Basic] (7강) 기초 신경망 이론 -4 - Training Neural Networks\n\n다. 그래서 좀 편하게 재미있게 들을 수 있는 데이터 노가다 기법에 대해서 어떻게 보면은 좀 티리어스하다고 생각할 수 있는 그런 기법들에 대해서 배워봤고요. 다음 시간에는 본격적으로 좀 더 어려운 내용에 들어갑니다. 여러분들 챗gpt 많이 쓰시고 계시죠? 그래서 다음 시간부터 이어지는 그 세계의 일련의 강의에서는 트랜스포머라고 그러죠. 그래서 챗gpt의 어떤 백 본 스트럭처가 되는 트랜스포머 기술에 대해서 앞에 이제 다음에 세 개의 강의에 대해 강의 동안 계속 배울 거예요. 근데 어떻게 보면 조금 테크니컬 할 수도 있고 어려울 수도 있으니까는 여러분들 집중 잘 하셔가지고 다음 시간부터 3개의 강의에 트랜스포머를 정확하게 이해해 가지고 완벽하게 챗gpt가 어떻게 동작하는지 이해할 수 있도록 하면 좋겠습니다. 네. 이번 시간도 집중해 주셔서 감사합니다. 다음 시간에 뵙겠습니다.",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(7강) 기초 신경망 이론 -4 - Training Neural Networks.json",
        "lecture_name": "(7강) 기초 신경망 이론 -4 - Training Neural Networks",
        "course": "Deep Learning Basic",
        "lecture_num": "7강",
        "lecture_title": "기초 신경망 이론 -4 - Training Neural Networks",
        "chunk_idx": 7,
        "total_chunks": 8,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:60b55395652e8ca06d4965352265c97010bb66dd44559486c908463ece7b6854"
      },
      "token_estimate": 259,
      "char_count": 506
    }
  ]
}