{
  "source_file": "(7강) Multimodal 2_Vision Language Models.json",
  "lecture_name": "(7강) Multimodal 2_Vision Language Models",
  "course": "NLP",
  "total_chunks": 2,
  "chunks": [
    {
      "id": "transcript_nlp_7강_multimodal_2_vision_languag_c000_38fff9",
      "content": "[강의 녹취록] 과목: NLP | 강의: 7강 | 제목: Multimodal 2_Vision Language Models\n\n또는 일시와 같은 이런 장점들을 보게 되면 생각들을 접촉을 한다든지 또는 행복한 데에서 유통주의 같은 이용법을 통해서 이런 투어 완료 모델을 만들기 위한 TV 모델에 대해서 한번 보고 시작하도록 하겠습니다. 첫 번째로 필요한 연구는 cr 어드 카드입니다. 그래서 그 다음 주에 보면은 이제 신랑인데라는 연구가 있는데 이 신랑인데는 이런 식으로 예술의 신사 이지선 측에서 그런 이미지와 그다음 이미지에 대한 편견 모든 이미지와 이미지와 편견 이런 무력적 타협을 예측했는데 일반적으로 인식의 사이즈가 굉장히 다채로운 사이즈를 가지고 있었고 34 17 기능자는 대체로 체험을 지는 그런 태의 미션 키메라를 볼 수 있습니다. 그래서 45 모듈을 조금 더 섬세하게 살펴본다면 먼저 메너드 카드 세트가 있습니다. 그래서 물이 차트를 선택하기 전에 정성된 배수만큼 카드를 선택하고요. 그다음 택하면서 이 카드 그렇기 때문에 자연의 모델이 추가 특히 근로자를 적으면 사용할 수 있는 그런 형태를 해서 있어야 된다고 하면 이런 형태의 안정적인 부분은 있을 수 없는 것이 아닙니다. 효과적인지 확인해 보여지는 그런 모델이 나 있습니다. 나가는 작년처럼 끝나는 것처럼 이미지 을 때 그 이미지에 대한 디스커션과 대화를 할 수 있는 그런 모델입니다. 이 모델의 디자인은 굉장히 긴장합니다. 먼저 시트에 있는 마스크의 렌디스 모델을 가지고 하도록 하는데요. 이렇게 이제 먼지 모델의 사전 지시를 기대를 하도록 하고요. 제설 기리에는 이 캐스트 레이어를 선택하기 위해서 데이터가 필요할 겁니다. 이제 데이터를 기존 인스펙션 데이터라고 해서 디피스트 모델을 캐니티 모델을 가리고 이런 리스컬팅 데이터를 선택합니다. 그래서 기분이 있었던 에너지 포트 이미지와 색상과 밴드 파크 데이터들을 활용하면서 전공은 이런 이미지 패턴이 아니라 어떤 패턴을 통해서 질문을 생성한다든지 이런 식으로 움척하게 만들어 주게 됩니다. 이 단계에서 인스퍼터 데이터를 활용을 할 때 먼지 레벨이 미스 데이터와 그다음에 먼지 스포터를 시 이용할 수 있는 그런 상태를 실시 되고 습니다. 미 의 유사한 이 차트 그리라는 형태를 바꾸었습니다. 이쪽 그림은 센스가 천지 식으로 사용될 수 있는 그런 모델인데 마찬가지로 이미지에 대해서는 그 이미지에 대한 지가 이 안을 수 있는 그런 모델입니다. 그 다음에는 이제 실제마라는 모듈이 등장을 하는데 이 7제마라는 모델은 이인증 모델들을 핸드폰으로 해서 염증성 모델을 이해할 수 있는 포트먼트를 개발해 주는 습니다. 소 염증을 앓을 수 있는 초기 창출 레이어를 찾아 서 이번에는 분자를 이제 어러러이 이 수 있는 이 세트를 전환을 해서 연결을 해줍니다. 어떤 얼라이먼트를 수행하는 지도 조금 위험한 생각입니다. 여기서 올라온 텍스트 필터는 이미지에 대한 정보가 어느 정도 모델 사에 제공하고 있고 그다음에 선착 1을 매니 할 때는 이때 그거를 티션 마킹을 통해서 인체트 또는 영업을 통해서 각각 정보가 어느 정도 섞일지 어떤 정보가 섞일지를 이제 결정을 하시게 됩니다. 그래서 여기서 매너 배터리는 테이퍼 텐션과 함께 다음 디테이스터의 전개가 어느 정도 묻어 있는 상태가 되게 되는데요. 그래서 이제 메너배터리 부분은 조금 더 디테이프 담당 바람을 이어 고 그래서 세트 속에서 피터가 올라오고 비로 프퍼텐션이 없어서 이미 피터를 선택할 수 있는 방법은 없지만 센터에서의 이런 텐션 마스크는 허리에 있는 데이터가 테스트로 넘어올 수 있도록 준비를 함으로써 이 쪽 바향에서부터 이제를 이제 멀크하게 체제를 한 그런 단백이 넘어오도록 준비를 합니다. 그렇게 하면서 최초 제너레이션 에서는 어 추가적으로 에버랜드라든지 기존 엔터를 추가적인 책임을 마치고 제 성능을 발휘하는지 저희가 한번 보여드리는데요. 이번 시의 아이디어는 30인터의 미디어 즉 이미지의 것이 될 때 이미지를 어떤 키를 공유해서 재활동을 해야 되는지 그에 대한 각자의 절차를 계획을 하고 그 절차에 대한 대로 한꺼번에 발표를 드리고 이 4개의 전차 에서는 이렇게 됩니다. 먼저 렌디즈 모델을 사용했는데 3를 시작합니",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(7강) Multimodal 2_Vision Language Models.json",
        "lecture_name": "(7강) Multimodal 2_Vision Language Models",
        "course": "NLP",
        "lecture_num": "7강",
        "lecture_title": "Multimodal 2_Vision Language Models",
        "chunk_idx": 0,
        "total_chunks": 2,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:63d5b2ce40a2296513b6d21a25f928cba8567c3715e2e6a47ed62aae9e1494a9"
      },
      "token_estimate": 1119,
      "char_count": 2063
    },
    {
      "id": "transcript_nlp_7강_multimodal_2_vision_languag_c001_7dcc8b",
      "content": "[NLP] (7강) Multimodal 2_Vision Language Models\n\n다. 그렇게 하면서 최초 제너레이션 에서는 어 추가적으로 에버랜드라든지 기존 엔터를 추가적인 책임을 마치고 제 성능을 발휘하는지 저희가 한번 보여드리는데요. 이번 시의 아이디어는 30인터의 미디어 즉 이미지의 것이 될 때 이미지를 어떤 키를 공유해서 재활동을 해야 되는지 그에 대한 각자의 절차를 계획을 하고 그 절차에 대한 대로 한꺼번에 발표를 드리고 이 4개의 전차 에서는 이렇게 됩니다. 먼저 렌디즈 모델을 사용했는데 3를 시작합니다. 그리고 먼저 인터되는 를 해서 인턴 테스트 레니를 위해서 이중 선천 원인은 구 수에서부터 많이 사용되기 시작하고 된다는데요. 신선 원인을 위해서 미리 몇 가지 이 선을 통해서 이 수치가 어떻게 수행되는지를 가르쳐주고 그다음에 다른 문제를 해서 예술을 탐지해서 발을 내리도록 만들어주는 그런 시장이 된 것입니다. 그래서 모델을 직접 골든 파테이트 하지 않고 앞에서 예술을 금으로써 의거력으로 부족해지는 거죠. 이런 방식으로 인적성과 소관 채널에 입력으로 잔뜩 넣어야 돼서 이 상이 많이 입니다. 저희가 소변을 예술로 보면은 이용 인적성이 이렇게 재열될 거고 그때 소변은 페이스 디펙트를 사용을 하고 그때는 이런 식으로 폭력성을 하고 그다음에 이를 잡아라 이런 식의 프로그램을 이렇게 미리 예스를 맞아 주고 이런 프로그램 시트를 위에다가 이렇게 만들 겁니다. 그래서 미리 관리 돼 있던 메컬라이제이션이나 사이트나 이베레이션 콘텐츠를 활용을 해서 이것이 기능이 주어졌을 때 그때 그러다 프로그램을 만들게 되고 이 프로그램에다가 입력 이미지를 넣어주면서.",
      "metadata": {
        "doc_type": "lecture_transcript",
        "source_file": "(7강) Multimodal 2_Vision Language Models.json",
        "lecture_name": "(7강) Multimodal 2_Vision Language Models",
        "course": "NLP",
        "lecture_num": "7강",
        "lecture_title": "Multimodal 2_Vision Language Models",
        "chunk_idx": 1,
        "total_chunks": 2,
        "schema_version": "2.0.0",
        "pipeline_version": "2.0.0",
        "corpus_version": "2025.11.27",
        "processed_at": "2025-12-04T15:35:42Z",
        "source_hash": "sha256:63d5b2ce40a2296513b6d21a25f928cba8567c3715e2e6a47ed62aae9e1494a9"
      },
      "token_estimate": 443,
      "char_count": 825
    }
  ]
}