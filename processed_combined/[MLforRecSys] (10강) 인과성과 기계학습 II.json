{
  "lecture_name": "[MLforRecSys] (10강) 인과성과 기계학습 II",
  "source_file": "[MLforRecSys] (10강) 인과성과 기계학습 II_93.mp4_2025-12-04-104340892.json",
  "text": "네 안녕하세요 여러분 이번에는 저희 인과성과 기계 학습 두 번째 시간입니다. 이번에는 저희가 인과관계 그래프 가 무엇이고 그런 인과관계 그래프를 저희가 어떻게 찾을 수가 있는지 그다음에 그거를 또 뉴럴 네트워크 기반으로는 어떻게 할 수 있는지 한번 살펴보도록 하겠습니다. 먼저 첫 번째로 인과관계 그래프가 무엇이고 그게 왜 중요한지 한번 볼게요. 저희가 그 인과관계 그래프라는 거는 일단 어떤 거냐면 다음과 같이 데이터가 주어져 있습니다. 즉 테이블 데이터로 보통 많이 주어져 있겠죠 테이블 데이터로 이 환자는 연령이 어떻고 그다음에 환자의 몸 상태는 어떻고 성별은 어떻고 뭐 그런 것들이 나와 있고 그 환자가 과거에 또 어떠한 트리트먼트를 받았고 어떤 약을 받았고 그다음에 결과가 어땠고 그러한 정보들이 쫙 나와 있을 겁니다. 그렇죠 그랬을 때 물론 여기에는 이미지도 같이 있을 수가 있겠죠. 또는 텍스트도 같이 있을 수가 있고 그 환자가 당시 내원했을 당시에 찍었던 엑스레이 사진도 데이터로 같이 있고 그때 의사의 소견도 텍스트로 같이 있을 수가 있습니다. 자 그런 데이터들이 있을 때 우리가 커즐 그래프를 어떻게 추론할 수 있을까라는 얘기예요. 즉 이 변수들 사이에 관계성이 어떻게 되냐가 저희는 알고 싶은 겁니다. 여기서 한번 보면은 우리가 만약에 매번 실험을 랜덤 하이스 컨트롤 트라이어를 매번 합니다. 무슨 말이에요 에라는 변수가 비라는 변수를 인과하는지 아닌지 우리가 알 수 없는데 실제로 실험을 해보자는 거예요. 자 에라는 변수를 우리가 값을 막 랜덤하게 바꿔봐요. 즉 환자를 우리가 데려와서 뭐 약을 막 특정하게 주는 겁니다. 그랬을 때 뭐 몸 상태가 바뀌는지 안 바뀌는지 그거를 우리가 계속 하면은 정말 인과관계가 있는지 없는지 알 수 있겠죠 하지만 굉장히 비윤리적이고 굉장히 비효율적입니다. 또 다른 방법으로는 이런 관계를 우리가 알 수 있는 또 다른 방법으로는 우리가 이론적인 그 문헌 조사를 통해서 관계성을 찾는 것입니다. 하지만 그러한 관계성은 알려져 있지 않을 때도 사실 많고 또 우리가 그런 뭐 문헌 조사를 해서 이러한 관계를 추론한다고 하더라도 그게 틀릴 가능성이 있습니다. 그러면 전문가한테 찾아가면 되지 않냐라고 할 수 있지만 전문가분들도 전문가마다 이러한 변수들 간의 관계성에 대해서 의견이 다를 수가 있는 것입니다. 즉 그렇다면 우리는 또 여기서 새로운 질병 또는 새로운 종류의 데이터라고 한다면 그때는 전문가분들도 잘 모를 수가 있어요. 그러면 그럴 때 우리는 주어진 데이터만을 기반으로 해서 커절 그래프를 우리는 잘 추론하는 것이 필요합니다. 그거를 어떻게 할 수 있을까 인 거고 그게 바로 커s 디스커버리입니다. 또는 커절 그래프 디스커버리라고 부르기도 합니다. 그거를 어떻게 할 수 있을지 한번 볼게요. 일단 그전에 우리가 이 얘가 왜 중요한지 이미 지난 시간에 한번 살펴본 바가 있습니다. CSL 그래프에 따라서 최고의 모델이 달라질 수 있다라는 말을 우리가 했어요. 그렇죠 데이터가 어떻게 생성되느냐에 따라서 더블릿 러버스트 러너가 좋을 수도 있고 아레이 러너가 좋을 수도 있고 아니면 플러그인 러너 에스 러너 티러너가 좋을 수도 있다라는 것을 우리가 봤었습니다. 그러면은 이 데이터가 어떻게 생성되는지를 우리가 알아야지 그에 맞는 머신 러닝 방법을 쓸 수가 있고 그래야지만 좋은 성능이 나온다라는 얘기를 지금 하는 겁니다. 즉 데이터가 어떻게 생성됐는지 이렇게 생성된 건지 a가 b를 인과해서 b가 또 c를 인과해서 생성된 건지 그게 우리는 알고 싶다. 좀 더 리얼월드에서 얘가 왜 굉장히 중요했는지 살펴보도록 하겠습니다. 이 예시는 존스노라는 이제 감염 역학자가 실제로 발견한 예시인데요. 과거에 콜레라 사건이 발생을 했었습니다. 그런 콜레라가 실제로 발생을 했는데 그 콜레라가 왜 발생했는지 그다음에 그 콜레라의 원인이 뭔지 그거를 사람들이 알지를 못했어요. 왜 원인을 알아야지 우리가 이 콜레라의 원인을 해결해서 콜레라의 발병률을 우리가 낮출 수가 있을 텐데 대체 이 콜레라가 왜 발생하는 건지 모르겠다라는 거였습니다. 그거를 사람들이 계속 모르고 있다가 그 당시에 뭐 공기가 좋지 않아서 그랬던 건지 뭐 때문인지 사람들이 전혀 알지 못했는데 이 존 스노가 이제 콜레라가 집단적으로 많이 발생한 지역들을 그림으로 찍어본 거예요. 도시 이미지에다가 도시의 지도에다가 찍어 봤는데 신기하게 콜레라가 좀 많이 발병한 지역은 그 실제로 그 물이 지나가는 수도관이 지나가는 경로랑 굉장히 일치했다라는 겁니다. 그래서 존스노가 결국에는 아 콜레라를 우리가 야기시키는 원인은 수질 오염으로 인해서 그로 인해서 뭐 여러 물이나 아니면 그로 인한 음식의 오염이나 그러한 먹는 것과 관련된 오염이 발생해서 콜레라가 발생한 것이다라는 원인을 밝혀낸 겁니다. 그러한 원인이 밝혀지면 이제 우리는 뭐가 돼요? 해결할 수가 있게 되는 겁니다. 즉 우리의 지식을 한층 더 발전시키고 우리가 문제를 해결함에 있어서도 이러한 커즐 그래프 즉 성능을 올리는 것뿐만 아니라 이런 인류의 지식을 진보시키는 역량도 굉장히 큽니다. 추천 시스템도 마찬가지입니다. 결국에 우리가 앞서서 이런 예시를 한번 보도록 하겠습니다. 즉 예를 들어서 우리가 특정한 유저들의 클릭 수를 굉장히 많이 받을 수 있는 영상을 만들고 싶다고 하겠습니다. 즉 우리는 굉장히 예산이 재현되어 있어서 영상을 한 편밖에 만들 제작할 수밖에 없는 상황입니다. 그러면 그때 조회 수를 굉장히 올릴 수 있는 클릭을 만들고 싶은데 그때 어떤 영상을 만드는 게 좋을까라는 거예요. 그러면 뭘 해야 될까요? 우리가 영화의 장르 그다음에 그 유저 타입 그다음에 영상에 만드는 데 들어가는 비용 그다음에 영상을 업로드하는 시간 또는 그 영상이 업로드된 날짜에 날씨 또는 우리가 영상을 촬영하는 위치 등 영상을 어디에 공개할 건지 모바일 디바이스 쪽에서 많이 보는 플랫폼에서 공개할 건지 아니면 PC 디바이스에서 많이 보는 플랫폼에서 공개할 건지 그렇죠 그러한 모든 것들을 우리가 정의해야 됩니다. 그때 굉장히 그러면 정의해야 될 요소가 많겠죠 그러면 실제로 이 클릭에 인과적으로 영향을 미치는 요소가 뭔지 우리가 만약에 알 수 있다면 거기에 우리가 좀 더 집중적으로 고민을 해서 의사 결정을 할 수가 있다는 겁니다. 추천 시스템에서도 굉장히 많이 활용될 수 있는 요소가 됩니다. 즉 지금 우리가 하고 싶은 건 뭐냐면 커절 그래프 디스커버리 또는 커즐 디스커버리를 하고 싶은 겁니다. 변수들 사이에 인과 관계를 알고 싶다입니다. 자 그걸 하는 굉장히 많은 방법들이 있는데요. 저희는 그중에서 컨스트레인 기반의 방법론을 먼저 한번 살펴보고 넘어가도록 하겠습니다. 그다음에 저희가 뉴런의 기반의 컨티넌스 옵티마이제이션을 한번 보도록 하겠습니다. 저희가 컨스트링 기반의 방법론을 짚고 넘어가기 전에 그와 관련된 좀 기본적인 내용들을 한번 보고 넘어가도록 하겠습니다. 자 여기서 우리가 여러 가지 구조가 있었습니다. 자 여기서 3개의 변수가 있다고 할 때 이 3개의 변수들 사이에 관계성을 나타내는 방법이 이렇게 스에서 와 와에서 지로 가는 방법이 하나 있고 지에서 와 와에서 스로 가는 방법이 하나 있고 그다음에 와에서 스 와에서 지로 동시에 쏘는 방법이 하나 있습니다. 자 우리가 이런 거를 체인 스트럭처 라고 하기로 했었고 그다음에 이런 거를 우리가 포크 스트럭처 또는 커먼 커즈 스트럭처로 부르기로 했었습니다. 이런 거는 우리가 공이 이렇게 막 굴러갈 수 있다고 했어요. 막혀 있지 않으면 공이 이렇게 굴러갈 수 있다고 했습니다. 즉 독립이 아니라고 했습니다. 근데 y가 기본으로 주어지면 그때는 이 모든 거는 독립이 x에서 z로 가는 그거는 이제 우리가 독립이 된다고 말씀드렸습니다. y가 주어지면 그래서 얘를 우리가 비유하자면 과거 현재 미래 현재가 주어지면 과거는 미래에 영향을 미치지 않죠 현재만 중요하니까 현재 잘만 하면 미래가 되는 겁니다. 자 그다음에 여기서는 이 아래에서는 우리가 이 와라는 것을 뭐 클래스 스라는 걸 이미지 지라는 걸 또 다른 이미지 라이브 베이지 클래시 파이어라고 생각하기로 했었습니다. y라는 거는 클래스 강아지라고 하겠습니다. 그럼 강아지라는 클래스에서 강아지 이미지가 2개가 나오는 건데 y가 주어지면 애초에 강아지라는 걸 우리가 알게 되고 그러면 x랑 g는 우리가 독립이 되겠죠. 와가 주어지면 왜 와가 강한 시로만 주어지면 지가 스가 뭐가 됐든 상관없이 지는 무조건 강한 시민이신 겁니다. 그렇죠 그래서 이렇게 우리가 말을 하는데요. 여기서 마크 오버 이큐밸런스 클래스 에이시라는 게 뭐냐 라고 하면은 지금 이 3개는 이거를 다 공통적으로 만족하고 있습니다. 그렇죠 공통적으로 즉 이렇게 독립성 또는 조건부 독립을 우리가 셰어하는 집합을 마코브 이큐밸런스 클래스라고 부르겠습니다. 그런데 이모럴리티 또는 브이 스트럭처 또는 인버티드 포크 스트럭처 또는 콜라이드 스트럭처라고 부르는 거는 반대였습니다. 왼쪽은 y가 주어지면 독립인데 오른쪽은 y가 안 주어져야지 독립이었습니다. 그리고 y가 주어지면 독립이 아니게 됐어요. 이건 우리가 어떻게 비유하기로 했습니까? 얘는 y를 아기나 강아지나 반려견이나 아니면 같이 하는 취미 등으로 생각하시면 되고 x랑 z는 남녀 관계라고 생각합시다. 그러면 우리가 만약에 아기가 있거나 아니면 반려견이 있거나 아니면 반려 뭐가 있거나 아니면 같이 하는 취미가 있다고 하면 두 남녀는 더 이상 독립이라고 볼 수 없어요. 같이 책임져야 되는 게 하나 있는 거니까 그렇죠 독립이 아닌 겁니다. 근데 y가 없다 그러면 x랑 z는 우리가 독립적인 관계라고 볼 수가 있습니다. 그래서 반대로 이루어지는 관계 그래서 얘는 마코 이크밸런스 클래스입니다. 그러면 이제 우리가 뒤에서 뭘 볼 거냐면 데이터들 간의 독립성을 볼 거예요. 그래서 만약에 y가 주어졌는데 스랑 지가 독립이다 그럼 뭐예요? 얘가 아니라는 거예요 얘라는 겁니다. 얘 체인 스트록처거나 아니면 다음과 같은 커먼 커제스트록처거나 근데 y가 주어졌는데 x랑 g가 독립이 아니래요 그건 뭡니까? 이러한 브이스트록처 또는 콜라이드 스트럭처 또는 인모럴리티 스트럭처가 우리는 된다라고 커절 그래프를 추론할 수 있는 겁니다. 아시겠죠? 그래서 우리가 조건부 동의 독립성이나 조건부 독립성을 이용해서 커절 그래프를 추론해 나갈 겁니다. 자 물론 이러한 조건부 독립성을 기반으로 한 커절 그래프 디스커버리는 항상 우리가 할 수 있는 건 아니에요. 몇 가지 가정은 우리가 진행해야 됩니다. 자 무슨 말을 여기서 하고 있는 거냐면 다음과 같은 상황입니다. 우리가 가정을 두 가지 할 건데요. 첫 번째는 페인트 folins asion입니다. 즉 여기서는 우리가 쉽게 말해서 이러한 a b CD 이러한 우리가 인과성 그래프가 어떻게 이렇게 만들어지는지 어떻게 만들어지는지를 추론하기 위해서 결국 뭘 한다고 했습니까? 조건부 독립 테스트를 할 거예요. 조건부 독립 테스트 그렇죠 그때 그러한 조건부 독립 테스트가 유의미해야 된다라는 말을 하고 있는 겁니다. 무슨 말이냐면 언제 이게 유의미하지 않을 수가 있냐면 예를 들어서 이런 거 자 실제로 비가 a에서 나왔다고 할게요. 그럼 알파 a입니다. 좋아요 씨는 감마 a입니다. 좋습니다. 그러면은 씨를 만들 때 a에서 온 거니까 a가 c를 인가한다고 볼 수가 있는 거예요. 자 그리고 d는 d를 만들 때는 베타b 더하기 감마 c라고 한다고 할게요. 그러면 여기서 한번 보면은 b가 d를 인과하고 또 c가 d를 인과하는 건 맞아요 맞는데 지금 d를 보면은 d를 이제 a로 우리가 표현을 하게 되면 이렇게 표현이 됩니다. 알파 베타 더하기 감마 델타는 곱하기 a가 됩니다. 자 그러면은 실제로 한번 우리가 생각을 한번 해보면 얘가 만약에 0이라고 할게요. 얘가 만약 0이라고 하겠습니다. 그러면 a가 d에 미치는 영향이 없는 거예요. 즉 a랑 d가 독립이라고 판단할 수도 있는 거예요. 실제로 이 그래프 상에서 뭐예요? 비가 관측이 되면 공이 못 굴러가서 a랑 d는 우리가 비가 주어졌을 때 독립이라고 볼 수가 있지만 지금 단계에서는 a에서 d로 공이 막 굴러갈 수가 있는 상황이라고 하지 않았습니까? 그럼 a랑 d는 독립이 아니라고 우린 봤어요. 그렇죠 a랑 d는 독립이 아닙니다. 여기서는 근데 어쩌다가 이렇게 우연의 일치로 이러한 커즐 관계가 상쇄가 돼버리면 a랑 디가 마치 독립인 것처럼 판단이 되게 되는 거예요. 그러면 실제 커서 그래프는 이렇게 생겼는데 우리가 잘못해서 뒤에서 b로 추론을 d에서 b로 가는 이런 관계로 추론을 할 수도 있다는 겁니다. 그 까닭에 이렇게 상쇄가 되는 케이스를 우리가 좀 방지하기 위해서 우리가 이러한 가정을 하는 겁니다. 즉 우리가 실제 관측된 데이터로 독립성 테스트를 하는 것과 이렇게 베이지볼 알고리즘으로 공이 굴러가고 안 굴러가고로 독립성을 테스트하는 거는 우리가 동일한 결과를 내는 데이터에 한해서 이러한 인디펜던스 테스트를 통해서 우리가 커서 그래프를 찾을 수가 있다라는 가정입니다. 즉 다시 한번 말씀드리면 얘가 0이 되는 상황에서는 그래프상으로는 a가 d를 인과하는 게 맞아요. a에서 공이 굴러가니까 근데 얘가 0이 된다라는 말은 우리가 실제로 디랑 a를 우리가 실제 값들을 가지고 a 값과 d값을 가지고 정말 독립성 테스트를 정말 하게 되면은 확률적으로 우리가 독립 테스트를 하게 되면은 그때는 독립인 것처럼 나오게 되겠죠. 얘가 0이니까 그렇죠 그렇게 두 개가 상이한 케이스가 없다라는 가정을 하겠다는 겁니다. 네 그다음에 두 번째 가정은 커셜 서피션시입니다. 그리고 어사이클리스트도 있는데요. 어사이클리스트는 애초에 사이클이 없다 a에서 b b에서 c 그다음에 c에서 a로 다시 가는 그거는 없다라는 뜻이고요. 자 그다음에 여기서 서피션시 가정은 우리가 관측하지 못한 변수는 존재하지 않는다라는 뜻입니다. 즉 실제로 우리가 a b c 3개 가지고 놀고 있는데 갑자기 우리가 관측하지 못했던 뉴라는 변수가 있어 가지고 얘가 이렇게 여러 개로 소개되는 이런 언 업저브드 또는 레이턴트 컴파운더가 없다 우리가 관측한 게 전부다라는 가정을 하고 있는 겁니다. 만약에 우리가 예를 들어서 뭐 여기가 트리트먼트 이펙트고 여기가 환자의 몸 상태고 여기가 그 아웃컴이라고 하겠습니다. 그러면 그때 그 환자의 몸 상태가 트리트먼트 임펙트 쏘고 환자의 몸 상태가 아웃컴을 쏘고 그다음에 트리트먼트가 아웃컴을 쏘고 이런 커절 그래프 관계를 탐색할 수가 있는데 근데 우리가 미처 알지 못했던 갑자기 날씨 또는 습도가 실제로 이 환자의 아웃컴에 영향을 미치더라라는 우리가 관찰하지 못한 그런 관계성에 대해서는 그게 변수가 새로운 우리가 관찰하지 못한 변수가 존재한다면 그러한 관계성은 우리가 잘 고려하지 못한다. 그래서 그런 게 없다라는 가정을 우리가 하고 가자인 겁니다. 그게 커져 서피션시입니다. 자 이러한 가정을 우리가 하고 나면은 이제는 우리가 인과관계 그래프를 탐색할 수가 있게 돼요. 자 어떻게 할 건지 한번 보도록 하겠습니다. 우리가 실제로 커절 그래프는 이렇게 생겼다고 하겠습니다. 근데 우리는 이거를 알지 못하겠죠. 실제로는 a가 b를 인과하는지 비가 씨를 인과하는지 알지 못하니까 그냥 풀로 다 연결된 그래프만 하나 우리가 갖고 있는 겁니다. 이게 전부예요. 여기에서 결국 선을 지워 나가고 a랑 b는 관련이 없다 지워 나가고 에가 씨를 인과한다 이렇게 화살표를 만들어 나가는 과정이 필요한 겁니다. 이거를 우리가 어떻게 할 거냐 독립성 테스트를 통해서 진행할 겁니다. 자 실제로는 이 우리가 어떻게 할 거냐면 이 그래프는 모르지만 이 그래프를 통해서 뭔가 만들어진 관측 데이터는 우리가 알고 있는 거예요. 그 데이터를 통해서 역으로 이 그래프를 추론하는 게 우리의 목적입니다. 그러면 그 관측 데이터는 애초에 이러한 실제 그래프에서 나온 애니까 그 관측 데이터는 이 실제 그래프의 독립성을 잘 보존하고 있을 겁니다. 자 그러면 실제로 우리가 이제 독립성 테스트를 한번 해보도록 하겠습니다. 자 여기서 우리가 a랑 b가 독립인지 아닌지 우리한테 주어진 여기에는 없지만 주어진 가상의 테이블 데이터가 있다고 하겠습니다. 그럼 그때 a라는 컬럼이 있고 b라는 칼럼이 있을 거예요. a라는 컬럼과 b라는 컬럼이 독립인지 아닌지 우리가 한번 테스트를 해보자는 겁니다. 그렇죠 자 그랬을 때 a랑 b가 만약에 실제로 독립이 나왔다 실제로 독립이 나오겠죠. 왜냐하면 a랑 b는 여러분 독립으로 우리가 생각을 해야 되니까요. 그럼 a랑 b는 독립이라고 딱 나왔습니다. 그렇죠 그래서 우리가 얘를 끊을 수가 있다는 거예요. 얘를 끊고 그다음에 우리가 또 조건부 독립으로 생각하면은 우리가 a랑 이 씨가 주어졌을 때 a랑 이를 한번 보겠습니다. 그러면 실제로는 씨가 주어지면은 a랑 이는 어떻게 되나요? 그때는 우리가 이렇게 체인 스트럭처에서 얘가 한 번 생각하시면 씨가 색칠되어 있으니까 공이 못 굴러갑니다. 그럼 a랑 이는 독립이에요 이렇게 됩니다. 그 말은 a랑 a가 독립이니까 c가 주어지면 이런 선은 없는 거구나라고 생각을 할 수가 있겠죠. 이 과정을 다른 거에 대해서도 동일하게 다 하면 이렇게 남게 될 겁니다. 이런 구조 물론 이제 여기서는 우리가 이러한 컨디셔널 인디펜던스 테스트를 항상 정확하게 할 수 있을 거라는 보장은 없습니다. 애초에 우리한테 지금 주어진 샘플 관측 데이터가 굉장히 노이지 할 수도 있는 것이고요. 데이터가 굉장히 적을 수도 있는 것이고요. 그 까닭에 실제로는 우리가 이러한 컨디션 인디펜던스 테스트를 정확하게 하지 못한다라는 게 현실적이지만 여기서는 우리가 이러한 테스트를 할 수 있다라고 가정하고 문제를 풀어 나가겠습니다. 그러고 여기에서 우리가 이제 더 나아가야 될 텐데 이제 여기서는 어떠한 과정으로 우리가 진행할 것인지 한번 보면은 우리는 브이 스트럭처는 기가 막히게 또 찾아낼 수가 있습니다. 왜 한번 생각해 보시면 여기 나와 있는 브이 스트럭처 또는 이모럴리티는 다른 곳과는 달라요. 그렇죠 독립성 테스트를 했을 때 다른 것과는 다르다고 했습니다. 브이스트럭처는 그렇죠 왜 이 브이 스트럭처 같은 경우는 x랑 y가 독립입니다. 근데 지가 주어지면 독립이 아니라고 했어요. 나머지와는 반대인 거죠. 그렇죠 만약에 독립성 테스트를 했는데 어 스랑 y가 독립이다 어 지가 주어졌는데 스랑 와가 갑자기 연결이 된다 그러면은 그거는 바로 다른 구조들이 아니라 이러한 이모럴리티 구조라는 것을 알 수 있게 됩니다. 자 그래서 여기서 한 번 더 저희가 테스트를 진행해 나가면 a랑 b가 독립인지 아닌지 저희가 한번 판단해 보겠습니다. 실제로 a랑 b가 그 독립인지 아닌지 데이터가 있을 거니까요. 그러면은 a랑 b가 독립이라고 나올 겁니다. 왜 신체 커서 클립에서 a랑 b가 독립이니까 그렇죠 그다음에 여기서 c가 주어졌을 때 c를 기본으로 하고 a랑 b의 독립성 테스트를 진행합니다. 그러면 어떻게 될까요? c가 주어졌을 때 a랑 b의 독립성 테스트를 우리가 진행하면 그때는 독립이 아니라고 나와요. 디펜던트 하다고 나올 겁니다. 왜 실제 커셜 그래프가 그렇게 생겼으니까 그렇죠 그 말은 어 두 개가 독립인데 시가 주어지면 독립이 아니네 그러면 무슨 구조다 체인도 아니고 그다음에 그러한 커먼 커즈의 구조도 아니고 이러한 브이 스트럭처라는 거를 우리는 알게 되니까 이렇게 화살표가 됩니다. 즉 우리는 이렇게 하면은 모든 이모럴리티 구조를 다 탐색할 수가 있게 되는 거예요. 왜 얘를 했을 때 우리가 독립성 테스트를 하면 이제 브이 스트럭처인지 아닌지는 알 수 있는 거예요. 브이 스트럭처는 유니크해요. 좀 뭔가 특별하니까 다만 체인 스트럭처인 건지 아니면은 이러한 커먼 커즈 스트럭처인 건지는 우리가 알 수가 없습니다. 그건 몰라요. 하지만 브이스럭처는 알 수 있다. 즉 다르게 말하면 여기서 c에서 d로 가게 되면 뭐예요? BCD가 우리는 그때는 체인 스트럭처라고 볼 수 있을 겁니다. 그렇죠 그러면 그러한 체인 스트럭처인지 아니면 어떠한 구조인지 우리는 사실 알 수 없지만 v 구조는 우리가 찾을 수 있다라는 거예요. v 구조는 아시겠죠? 그러면 우리가 여기서 모든 브이스트록션을 다 찾을 수가 있다고 했잖아요. 자 여기서 더 나아갈 수 있을까요? 그러면 한번 고민 한번 해보시겠어요. 만약에 모든 브이스트록션을 다 찾았어요. 다 찾은 결과가 이거라고 하겠습니다. 그러면은 이거 말고는 더 이상의 브이 스트럭처는 없다라는 뜻입니다. 그때 우리가 이 그래프를 더 나아갈 수 있을까요? 가능합니다. 여기서는 운 좋게도 가능해요. 왜 애초에 브이 스트럭처가 이것만 있다라고 말씀드렸잖아요. 그러면 만약에 뒤에서 c로 쏘는 화살표이거나 시에서 d로 쏘는 화살표이거나 두 개 중에 하나만 고르면 됩니다. 그럼 만약에 뒤에서 c로 쏘는 화살표라고 할게요. 그럼 뭐가 됩니까? 브이 스트럭처가 되는 거예요. 그렇죠 그러면 문제가 발생하는 거죠. 왜 우리가 방금 브이 스트럭처를 다 찾은 겁니다. 근데 우리가 못 찾은 브이 스트럭처가 있으면 안 돼요. 근데 뒤에서 c로 가는 거였다고 한다면 또 새로운 브이 스트럭처가 나온 거니까 이건 저희가 원하는 게 아닙니다. 즉 c에서 디로 가는 거 마찬가지로 c에서 이로 가는 구조가 나오게 되는 겁니다. 여기서는 저희가 우연하게도 모든 커s 릴레이션십을 다 찾은 커s 그래프가 완성된 걸 찾을 수 있었습니다. 하지만 이게 항상 가능한 건 아니라고 말씀을 드리겠습니다. 앞서 말씀드린 것처럼 우리가 이러한 그 브이스트럭처는 우리가 찾을 수가 있지만 애초에 체인 스트럭처인지 아니면 커먼 커진인지는 우리가 알 수가 없다라고 여러분 생각하시면 되겠죠 그렇죠 아시겠죠 자 그러면은 여기서 만약에 당장 뭐 여기 이것만 없었다고 하더라도 이 비만 없었다고 하더라도 우리가 좀 알기가 어려운 상황들도 사실 많습니다. 자 그다음에는 우리가 뉴럴넷 기반으로 인과관계 그래프를 탐색할 수 있는 방법론에 대해서 살펴보도록 하겠습니다. 자 여기서는 또 다른 접근법인데요. 우리가 컨티넌스 옵티마이제이션 즉 뭔가 계속 최적화를 통해서 인과관계 그래프를 찾는다입니다. 자 여기서 말하는 아이디어는 굉장히 참신하면서 이제 간단합니다. 하지만 그 이론적으로 보장이 잘 되지는 않지만 리얼월드에서 굉장히 실험적으로 잘 작동하는 알고리즘입니다. 자 한번 보면은 우리가 여기서는 두 개의 변수만 있다고 하겠습니다. 그래서 a에서 b를 인과하는지 아니면 b에서 a를 인과하는지 우리가 알고 싶은 문제 상황이라고 할게요. 자 그러면 우리가 만약에 에 콤마 b라는 거는 이렇게 두 개로 적을 수가 있어요. 즉 a라는 걸 모델링하고 그다음에 a에서 b로 가는 거 비를 모델링하고 b에서 a로 가는 거 이렇게 두 가지 방향으로 모델링을 할 수가 있습니다. 그때 우리가 하고 싶은 거는 만약에 실제로는 a에서 b로 가는 게 정답이었다고 할게요. 실제로는 근데 우리한테는 주어진 건 뭐다 우리는 그냥 a 콤마 b만 주어지는 거예요. 계속 a가 b를 인과하는지 b가 a를 인과하는지 모르지만 a 콤마 b만 딱 주어진 겁니다. 근데 그런 데이터는 실제로는 a에서 b로 가는 그러한 그래프에서 나온 데이터라고 할게요. 에이 콤마 b라는 데이터는 그리고 얘가 실제 컨설 그래프라는 겁니다. 근데 우리한테 주어진 건 뭐냐면 이러한 샘플들 에이 콤마 비에서 나온 이런 샘플들이 주어져 있는 것이고 그다음에 여기서 한 개가 더 주어진다고 할게요. 에라는 데이터에 대해서 우리가 인터벤션을 한 겁니다. 그때 비가 어떻게 되는지 변화가 된 결과가 있다라고 하겠습니다. 즉 실제 에이 콤마 비가 있고 우리가 a라는 것에다가 트리트먼트를 하는 거예요. 그때 b가 어떻게 바뀌는지 그거에 대한 데이터도 갖고 있다라고 가정을 하겠습니다. 이러한 데이터를 우리는 인터벤션 데이터라고 부릅니다. 즉 이렇게 우리가 뭔가 방해를 가한 거죠. 그 방해를 가해서 뭔가 작업을 가해서 그렇죠 뭔가 우리가 값을 변화시켰을 때 얘가 어떻게 바뀌는지 그런 데이터를 우리가 갖고 있다라고 가정하겠습니다. 얘를 우리가 옵티베이셔널 데이터 얘를 우리가 인터베셔널 데이터라고 하겠습니다. 자 그러면 이러한 문제의 상황에서 저희가 어떠한 방법을 취할 수 있냐면요. 모델을 우리가 2개 학습합니다. 즉 우리가 첫 번째 방식으로 학습한 모델 그다음에 두 번째 방식으로 학습한 모델입니다. 즉 여기서 첫 번째 방식이라 함은 a를 인풋으로 주고 비를 예측하는 모델인 겁니다. 두 번째 방식은 비를 주고 a를 예측하도록 하는 방법입니다. 자 그때 두 모델 중에서 우리가 이러한 관측 데이터로 두 모델을 학습할 거예요. 그랬을 때 이러한 인터벤셔널 데이터에 대해서 우리가 파인 튜닝 시킬 겁니다. 좀 더 추가 학습을 시킨다라는 말입니다. 그때 더 빨리 어댑테이션 하는 모델이 뭐냐 더 빨리 좋은 성능을 내는 모델이 뭐냐 즉 모델 파라미터가 비교적 적게 바뀌면서 더 빨리 좋은 지점으로 가는 모델이 뭔지를 우리가 찾고 싶은 겁니다. 즉 다시 우리가 보면은 이러한 샘플 데이터 즉 인터미션 데이터가 아닙니다. 그냥 관측된 데이터를 기반으로 두 모델을 학습해요. 즉 두 모델이라 함은 a를 인풋으로 받아서 b를 예측하는 거 b를 인풋으로 받아서 a를 예측하는 거 이렇게 모델이 뉴럴 네트워크가 2개 있다라고 생각하시면 됩니다. 인풋 아웃풋 페어만 다른 거예요. 모델이 그리고 2개가 있는 거고 그러고 나서 이러한 인터벤셔널 데이터에 대해서 우리가 학습하는 거예요. 얘는 어쨌든 a가 주어지고 b를 예측하는 거잖아요. 그쵸? 실제로 인터벤션이 이렇게 가해졌다라는 말은 그러면은 여기 데이터에 대해서 더 빨리 우리가 수렴하는 데이터가 무엇인지 찾는 게 목표입니다. 실제 커절 그래프는 결국 a에서 b로 가는 거예요. a가 주어졌을 때 b가 나오는 게 실제 커절 그래프입니다. 그렇죠 그러면 그러한 커절 그래프를 우리가 더 잘 묘사할 수 있는 모델이 뭔지 보는 겁니다. 즉 이러한 인터벤셔널 데이터를 우리가 가져와서 우리가 다시 한 번 학습시킨다고 했습니다. 즉 정리하면 옵티베이션 데이터를 가지고 모델 각각을 한 번 학습시킵니다. 그게 첫 번째 스텝, 두 번째 스텝은 두 개의 모델을 인터메이션 데이터로 다시 한 번 학습을 시켜요. 그때 로그라이 클로드가 빠르게 올라가는 것이 뭐냐 a에서 b로 가는 방향으로 학습했던 모델이라는 겁니다. 왜 그러냐면 이미 이 모델은 a에서 b로 가는 방향으로 학습했기 때문에 추가적으로 더 학습할 게 많이 없기도 한 거예요. 그 까닭에 우리가 더 빨리 좋은 점으로 수렴할 수 있는 수렴할 수가 있는 겁니다. 왜 이미 a에서 b로 가는 것으로 학습했기 때문에 이미 좋은 파라미터를 얻은 거예요. 그래서 추가적으로 학습할 게 사실 적다는 겁니다. 그렇죠 그래서 얘를 우리가 수식으로 나타내면 이렇게 식으로 나타낼 수가 있습니다. 즉 여기서 r이라고 하는 것은 우리가 새로운 인터벤셔널 데이터에 대해서 새로운 이러한 데이터에 대해서 로스트를 낮추고 싶다고 하겠습니다. 즉 negative 로그 라이트로드를 우리가 낮추고 싶다고 하겠습니다. 이를 낮추고 싶다고 할게요. 그때 우리가 a에서 b로 학습된 모델을 쓰는 게 좋은지 아니면 b에서 a로 학습된 모델을 쓰는 게 좋은지 이 여기 나와 있는 시그모이드 감마가 결정하는 겁니다. 만약에 애초에 이러한 인터미셔널 데이터가 실제로 커s 그래프가 a에서 b로 가는 그래프라고 한다면 a를 인풋으로 받고 비를 아웃풋으로 받은 모델이 얘를 많이 활용하는 게 좋겠죠. 그러면 시그모이드 감마가 1에 가깝게 될 겁니다. 그렇죠 그래서 이 시그모이드 감마의 값이나 아니면 이 시그모이드 감마에 따라서 이 알이 어떻게 변하는지 그 변화량을 보고 우리가 아 a에서 b로 가는 게 좋은지 b에서 a로 가는 게 좋은지 우리가 정할 수가 있다는 겁니다. 아시겠죠? 즉 얘를 낮추기 위해서 모델 2개를 동시에 쓸 건데 어떤 모델을 쓰는 게 좋을지 왜 얘를 우리가 낮추기 위해서는 우리가 얘를 마이너스가 있으니까 이 얘를 높여야 되는 거고 얘를 높이기 위해서 뭘 하면 된다 이미 우리가 잘하고 있는 애를 가지고 하면 된다. 그래서 얘가 1이 되고 얘는 0에 가깝게 되면 얘는 없어지게 된다. 그러면 우리가 잘하고 있는 거에 대해서 집중해서 예측을 하면 된다. 언제 실제 커스 그래프도 a에서 b로 가는 거일 때 만약에 실제 커절 그래프가 b에서 a로 가는 거다 그러면 그때는 얘가 0이 되고 얘가 1이 되는 형태가 되겠습니다. 자 방금은 우리가 커져 그래프가 2개 변수가 2개가 있는 상황을 봤습니다. 이제는 우리가 커즐 그래프가 좀 더 커진 변수가 여러 개인 상황에서 우리가 어떻게 할 건지 3개 또는 3개 이상에 대해서 있을 때 어떻게 할 건지 살펴보도록 하겠습니다. 자 그때 우리가 만약에 다음과 같이 x축에 대한 인커밍 치에 대해서 스축을 야기하는 게 어떤 것들인지 좀 보고 싶다라고 하겠습니다. 엑스투를 야기하는 게 스원인지 아닌지 스3인지 아닌지 우리가 알고 싶은 문제 상황이라고 하겠습니다. 그거를 우리가 확장하면은 엑스원 엑스3 각각에 대해서도 우리가 다 할 수가 있게 되는 것입니다. 자 그때 우리가 만약에 엑스원에 대해서 인터베이션이 된 즉 엑스원에 대해서 인터베이션이 됐다라는 말은 엑스원에다가 우리가 랜덤한 값을 다 주는 거예요. 랜덤 하이스 컨트롤 트라이어를 생각하시면 됩니다. 즉 여기서는 원래는 x1이 x2에 대해서 영향을 받아야 돼요. 그쵸? 만약에 이렇게 연결되어 있다 면 근데 엑스원을 우리가 랜덤 하이즈 컨트롤 트라이를 한다라는 말은 x1이 어제 영향을 받았던 나는 모르겠고 그냥 엑스원을 랜덤하게 값을 부여해 주겠다라는 뜻입니다. 그래서 엑스원에 이제 더 이상 부모가 없는 거예요. 스트에서 스원으로 가든 엑스트에서 엑스원으로 가든 그런 연결 관계가 다 없는 그래프만 남는 겁니다. 그래서 x1 x2 3 이렇게 우리가 x1에다가 인터베이션을 주면 뭐 이런 식의 그래프들을 예를 들어서 얻을 수가 있겠죠. 그렇죠 여기서 얻은 데이터들도 우리가 존재를 할 거고 그러면 그때 우리가 이런 그래프로 x2를 추정하는 게 잘 추정되는지 이런 그래프로 스투를 추정하는 게 잘 추정되는지 이런 그래프로 x2를 추정하는 게 잘 추정되는지 우리가 알고 싶다는 겁니다. 왜 그러면 이 스투를 가장 잘 추정하기 위해서 만약에 실제로 이런 다른 그래프보다 이런 그래프가 스투를 추정하는 데 도움이 되더라 라고 하면은 실제로 엑스를 인과하는 건 스원이고 스3는 인과하지 않는다라는 결론을 우리가 내릴 수 있기 때문입니다. 자 얘를 우리가 큰 컨셉을 살펴봤고 좀 더 구체적으로 한번 살펴보겠습니다. 즉 앞에 있던 이 방식과 굉장히 유사한 거를 여러 개의 노드로 확장한 것뿐입니다. 앞에서 어떤 거예요? 실제 커s 그래프가 a에서 b로 가는 거라고 한다면 에를 인풋으로 받고 비를 아웃풋으로 쏘는 모델을 기반으로 우리가 얘를 추정해야지 인터메이션 데이터를 추론해야지 우리가 잘 되더라라는 얘기를 하는 겁니다. 지금 그 얘기를 똑같이 하는 거예요. 우리가 실제로 인터벤셔널 데이터가 이렇게 여러 개로 주어졌을 때 만약에 가장 좋은 데이터가 가장 좋은 그래프가 이거다라고 하면은 그때는 실제 리얼 그래프가 이렇게 생겼을 가능성이 크다는 겁니다. 자 이거를 우리가 앞에 거랑 연결 지어서 한번 보면은 자 앞에는 a에서 b로 가는지 b에서 a로 가는지 2개 중에 하나만 고르면 돼요. 마스크가 하나였습니다. 마스크가 1 또는 0으로 만들어지는 게 하나였어요. 그렇죠 근데 얘가 이제 우리는 그래프가 3개 노드가 3개 아니면 노드가 4개 이 노드가 여러 개로 된 겁니다. 그래서 여기서 여기로 가는 거 여기서 여기로 가는 거 여기서 여기로 가는 거 여기서 여기로 가는 거 마스크를 씌워야 되는 게 이제 여러 개가 나오는 겁니다. 그렇죠 자 그 까닭에 마스크가 여러 개로 된 거다라고만 여러분들께서 이해를 해 주시면 되고 앞에랑 굉장히 유사합니다. 앞에서도 어떤 과정을 거쳤어요? 앞에서도 먼저 옵저베이션 데이터에 대해서 옵저베이션 데이터에 대해서 우리 모델을 피팅 시켰어요. 이렇게도 피팅 시키고 이렇게도 피팅 시키고 그렇죠 그다음에 관측된 데이터로 학습된 걸 가져와서 인터메셔널 데이터에 대해서 우리 모델이 가장 잘하기 위해서는 어떤 마스크가 좋냐 얘가 1인 게 좋냐 얘가 0인 게 좋냐 그 마스크를 학습했다라고 볼 수 있습니다. 이 컨셉을 우리가 그대로 가져온 거예요. 즉 옵티베이션 데이터에 대해서 인터메이션 데이터가 아니라 옵저베이션 데이터에 대해서 우리가 뉴럴 네트워크를 학습해서 이러한 관측치 데이터에 대해서 가장 잘 할 수 있는 모델을 만들어 놓습니다. 엑스원을 가장 잘 설명할 수 있는 모델 엑스 2를 가장 잘 아웃풋으로 예측할 수 있는 모델 x3를 가장 잘 아웃풋으로 예측할 수 있는 모델 이렇게 만들어 놔요. 자 그다음에는 우리가 어떻게 할 거냐면 마스크를 학습할 거예요. 그랬을 때 인터메이셔널 데이터에 대해서 어디에다가 우리가 마스크를 줘야지 가장 우리 모델이 성능이 좋을지를 예측합니다. 그때 마스크는 여기서 두 개의 곱으로 표현이 됩니다. 하나는 마스크가 이런 연결 관계가 있을지 없을지 결정하는 거 액션이 있다 없다만 결정하는 겁니다. 그다음에 얘는 어떤 거냐면 그래서 그거의 방향성이 뭐냐 그래서 이렇게 가는 거냐 이렇게 가는 거냐 두 개를 결정하는 겁니다. 그 두 개의 곱으로 시그모이드를 써가지고 두 개가 이제 곱을 하면은 그러면 이제 0에서 사이의 값이 나오게 되겠죠. 그렇게 진행이 되는 겁니다. 즉 정리하면은 마찬가지로 앞과 마찬가지로 두 가지 스텝이에요. 첫 번째 스텝은 우리가 옵저베이션 데이터로 현재 주어진 인풋으로 아웃풋을 잘 예측하는 것을 목표로 합니다. 자 그러고 나서 여기 나와 있는 그래프 피팅에서는 마스크가 학습됩니다. 여기가 마스크와 관련된 로텐션이죠. 마스크가 학습됩니다. 우리가 얘를 어떻게 끊어야지 아니면 어떻게 연결 관계를 줘야지 가장 아웃풋이 잘 예측이 될까를 우리가 추론하는 겁니다. 인터미셔널 데이터에 대해서 얘가 진행됩니다. 그리고 이 두 개가 이터렉티브하게 돌아가요. 즉 처음에는 우리가 예를 들어서 엑스원을 예측한다고 할 때 나머지 모든 데이터를 가지고 엑스원 예측합니다. 모든 데이터를 인풋으로 주고 스투를 예측할 때도 나머지 모든 데이터를 인풋으로 주고 엑스 2 예측해요. 이런 식으로 하고 그다음에 이제 모델이 나왔습니다. 자 그러고 나서 우리가 그러면은 실제로 인터메이션 데이터가 있는데 그 데이터를 잘 설명하기 위해서 우리가 실제 커션 그래프가 어떻게 되어야 하는지 마스크를 학습합니다. 그러면 그 마스크 학습됐으면 어디가 연결되고 어디가 연결되지 않아도 되는지 방향이 뭔지 나오겠죠. 그거를 여기 다시 가져옵니다. 그러면 그걸 기반으로 우리가 엑스원을 예측할 때 여기서 마스크가 이제 예측이 됐겠죠. 엑스원을 예측할 때 만약에 3만 중요하더라라고 하면은 이제는 엑스원을 예측할 때 스3만 가져옵니다. 그렇게 해서 모델을 다시 학습시켜요. 그러고 나서 다시 그래프 피팅합니다. 그러고 나서 다시 마스크를 어디에 주는 게 좋은지 비교하는 거예요. 이게 약간 어렵게 느껴질 수도 있는데요. 심하다 보니까 그게 앞에서 봤던 페어yc 커즐 디스커버리랑 연결 지어서 큰 컨셉을 여러분들께서 이해해 주시면 좋겠습니다. 자 한번 살펴보면 어떻게 하는 거냐면 여기 나와 있는 노란색 단계가 옵티베이션 데이터로 학습된 모델인 거죠. 그렇죠 옵트로베이션 데이터로 우리가 애초 a에서 b로 가는 것도 학습하고 b에서 a로 가는 것도 학습을 합니다. 마치 이게 방금 봤던 거는 엑스원에서 이렇게 스2로 가는 것도 학습하고 그다음에 x축에서 엑스원으로 가는 것도 학습한다는 거예요. 다 학습합니다. 그렇죠 그래서 이렇게 우리한테 주어진 것처럼 a를 인풋으로 받아서 b를 잘 예측하도록 모델 학습 b를 인풋으로 받아서 a를 잘 예측하도록 학습 여기서도 우리가 마찬가지입니다. x1을 인풋으로 받아서 x축을 잘 예측, 스투를 인풋으로 받아서 엑스원 차이 예측 근데 그게 개수가 그냥 많을 뿐이다. 엑스원을 예측하기 위해서 스2부터 스엔까지를 인풋으로 받아서 엑스원을 예측한다든지 개수만 더 많아진다는 것뿐입니다. 자 그러고 나서 옵저베이션 데이터에 대해서 얘를 학습하고 나면은 우리가 인터벤션 데이터에 대해서 우리가 어떻게 마스킹을 하는 게 좋을지 학습이 들어갑니다. 여기서 이 감마가 학습이 되는 것이고요. 여기서는 결국 여기 나와 있는 감마랑 세타가 학습이 됩니다. 왜 여기서는 우리가 방향성 엣지의 방향성과 지의 유물을 우리가 따로 모델링 하기로 했습니다. 사실 이거 같이 해도 돼요. 그러니까 여기서는 그걸 따로 그냥 했다라고만 생각하시면 되겠습니다. 사실 특별한 이유가 있지 않습니다. 자 여기서는 그래서 왼쪽과 비교하면 오른쪽 왼쪽 오른쪽 모두 다 옵지베이션 데이터로 현재 주어진 인풋에서 y 아웃풋을 가장 잘 예측하도록 모델을 학습시킨다. 옵지베이션 데이터로 그다음에 인터베이션 데이터로 어떠한 연결 관계가 좋은 것인지를 우리가 학습을 하게 된다라는 뜻입니다. 네 여기까지 하면은 우리가 커절 그래프 디스커버리를 전통적인 통계적인 방법으로 컨디셔널 인터페이스 테스트를 통해서 하는 방법, 그다음에 뉴럴넷 기반으로 계속해서 업데이트해 나가면서 하는 방법 이 두 가지 방법을 모두 다 살펴봤습니다. 네. 그러면 여러분 고생 많았습니다."
}