{
  "lecture_name": "9강_인공지능을_위한_확률론",
  "source_file": "9강_인공지능을_위한_확률론_73.mp4_2025-12-04-103902911.json",
  "text": "네 안녕하세요 메스메릭스포 아트패션 인텔리전스 9강 인공지능을 위한 확률론 수업을 맡게 된 고려대학교 통계학과 임성빈입니다. 네 먼저 확률론에 좀 중요한 기초적인 개념들을 좀 살펴보도록 하겠습니다. 먼저 배우게 될 개념은 이제 확률 분포라는 개념이 되겠습니다. 확률 분포는 우리가 이제 데이터의 초상화라고 부를 수 있게 되는데요. 보시다시피 어떤 데이터 공간이라고 우리가 설정하는 개념이 있습니다. 바로 뭐냐 하면 입력 변수에 해당하는 x와 그리고 우리가 어떤 그라운트로스 그리고 또는 우리가 목표로 하는 값을 y라고 했을 때 이 두 공간을 프로덕트 시킨 걸 우리는 데이터 공간이라고 정의를 하게 됩니다. 만약에 비지도 학습인 경우에는 이 와가 없이 오로지 스만 어 데이터 공간으로 설정할 수가 있게 되겠죠 그렇게 됐을 때 데이터 공간에 정의된 데이터 분포는 어 확률 분포로서요. 이 공간에 주어져 있는 어떤 확률 분포로서 이 데이터를 추출하는 데 사용되는 확률 분포라고 이해하시면 되겠습니다. 데이터를 추출하는 확률 분포란 무슨 뜻일까요? 네 그 의미는 우리가 어 실제 이 데이터 분포를 볼 수 있는 것은 아니지만 우리가 데이터를 수집하는 과정에서 그 데이터를 관찰할 때 어떤 확률로 이 데이터를 관찰하게 될지를 우리가 결정해 주는 분포가 데이터 분포인데 우리가 실제로는 알 수는 없지만 뭔가 이 어떤 자연 공간이나 또는 어떤 어 데이터를 수집하게 되는 뭐 인터넷 공간에서 그 데이터를 마주치게 될 어떤 확률의 개념으로 이해하시면 되겠습니다. 이거를 좀 더 이해해 보기 위해서 우리가 그림을 한번 그려보았습니다. 다음과 같이 엑스가 이렇게 어 어떤 공간에서 이렇게 쭉 펼쳐져 있을 때 와가 1이거나 또는 와가 2인 데이터들을 이렇게 나눠서 한번 수집을 해 보았는데요. 보시면 스가 주로 이제 작은 경우에는 와가 1인 패턴들이 많이 있고 그리고 스가 좀 큰 경우에는 와가 2인 패턴들을 좀 볼 수가 있습니다. 우리가 이 파란색 점으로 구성되어 있는 이 데이터들을 수집하는 과정에서 자연스럽게 이 데이터들이 어떻게 분포되어 있는지를 한번 살펴볼 수가 있는데요. 이 데이터들이 분포되어 있는 모양을 통해서 우리는 어 이 데이터의 어떤 확률 분포가 이렇게 생겼구나라는 거를 추측을 해볼 수가 있고 이것이 바로 데이터 분포의 모양이다라고 추론할 수가 있게 됩니다. 그리고 이 데이터 분포를 통해서 아 우리는 데이터가 어떤 식으로 분포되어 있구나라는 거를 짐작할 수가 있게 되는 것이죠. 그러므로 데이터 분포 즉 피 데이터라는 확률 분포는 우리가 데이터 공간에서 데이터가 어떻게 생겼는지를 가늠해 주는 초상화라고 이해해 볼 수가 있게 되는 것이죠. 아까도 말씀드렸지만 우리는 데이터 분포 피 데이터를 직접 알 수는 없습니다. 즉 수학적으로 이 확률 분포가 어떻게 생겼는지를 아는 것은 굉장히 어렵습니다만 다만 우리는 이 확률 분포에서 데이터를 추출할 수는 있습니다. 이렇게 보시는 파란색 점들이 그렇게 추출된 데이터라고 볼 수 있는데요. 그때 이 데이터 분포에서 추출된 데이터를 우리가 이렇게 스콤마 와를 물결 표시해서 피 데이터에서 추출된 데이터다 즉 샘플링 된 데이터다라고 표기를 하게 됩니다. 어떻게 말하자면 이 추출된 데이터는 데이터 공간에서 이 데이터 확률 분포를 통해 관측한 데이터라고 얘기할 수가 있겠죠 네 맞습니다. 이렇게 데이터 공간상에서 관측 가능한 데이터를 우리가 매번 추출할 수가 있는데 이 추출할 때 사용하게 되는 분포가 데이터 분포인 것이고요. 우리가 직접적으로 알 수는 없지만 어떤 메커니즘에 의해서 이 데이터 분포를 통해 우리가 데이터를 관찰할 수가 있게 되고 이 관찰된 데이터로 우리가 패턴을 추론하거나 또는 기계 학습 모델을 학습할 수가 있게 되는 것이죠. 네 그렇습니다. 그래서 우리가 확률 분포를 알았을 때 그리고 이 확률 분포에 대한 개념을 이해했을 때 우리가 실제로 어떤 데이터의 어떤 성질이나 이 데이터를 어떻게 가지고 기계 학습 모델을 우리가 학습시킬지를 결정할 수가 있게 되는데요. 그렇기 때문에 이 확률 분포가 어떤 식의 성질을 가지는지에 따라서 우리가 좀 구별을 해 줄 필요가 있습니다. 그 성질들을 구별할 때 종종 사용하게 되는 성질들 중 하나가 바로 이산 확률 변수랑 연속 확률 변수로 어 성질들을 좀 사용해 볼 수가 있는데요. 확률 분포에 따라 이제 확률 변수가 우리가 사용하게 되는데 이때 이 확률 변수가 이산형인지 즉 디스크레이트인지 아니면 연속형인지 즉 컨티뉴스인지에 따라서 우리가 구별을 할 수가 있게 됩니다. 이산형 확률 변수는 확률 변수가 가질 수 있는 경우의 수를 모두 고려하여 확률을 더해서 모델링 하게 되는데요. 어떤 a라는 케이스를 만족하게 되는 확률 변수들에 대한 확률값을 계산할 때는 이 에에 속하는 모든 경우의 수에 대해서 우리가 그 스가 될 확률 값을 계산할 수가 있고 그 확률 값을 모두 더해 줬을 때 확률 변수가 이 에에 해당하는 값을 가질 확률을 계산할 수가 있게 되겠죠. 즉 확률 변수 스가 스몰스 값을 가지는 확률들을 이 스몰스가 에에 속하는 모든 경우에 대해서 다 더해주게 되면은 우리는 어 이 a라는 경우에 해당하는 확률값을 계산할 수가 있게 됩니다. 이렇게 경우의 수에 따라서 확률값을 계산할 수가 있고 이 경우의 수가 어떻게 보면은 셀 수 있는 경우 즉 다시 말해 우리가 더해줘서 셀 수 있는 경우를 보통 우리가 이상형이라고 불러줄 수가 있게 되는데요. 가령 정수형 데이터라든지 아니면 우리가 순서쌍을 가지는 어떤 데이터라든지 또는 좀 유한한 케이스에 맞춰서 우리가 경우의 수를 셀 수 있으면 이상형 확률 변수다라고 얘기를 할 수가 있게 됩니다. 반면에 연속형 확률 변수는 데이터 공간에 정의된 확률 변수를 연속형으로 파악하기 때문에 우리가 어떤 경우의 수를 구해 보자라고 하는 게 너무나 많게 됩니다. 수학적으로 얘기하자면 그 경우의 수가 셀 수 없이 많을 정도로 많다라고 얘기할 수가 있는데요. 이상형이랑 달리 연속형인 경우에는 경우의 수에 대해서 모두 다 카운팅을 해서 더해주는 것이 아니라 어떤 밀도 함수라는 거를 설정을 하고 그 밀도 함수에서 적분을 통해 우리가 확률값을 계산을 하게 됩니다. 조금 어려운 개념인데요. 밀도 함수란 어떤 의미냐면요. 해당 확률 변수가 어떤 x 값을 가지게 될 근처에 확률 값이 우리가 이 분자로 사용하게 되고 그다음에 이 전체의 어떤 가능성을 우리가 치라는 구간에서 쪼갰을 때 이 구간의 길이를 분모로 나눠서 우리가 극한에 취해 주게 되면은 마치 앞에서 배운 미분의 개념이랑 좀 비슷하게 보실 수가 있게 되는데요. 사실은 그 미분의 개념은 맞습니다. 그랬을 때 이 극한의 계산에서 얻게 된 함수가 바로 밀도 함수입니다. 어떻게 말하자면 이 x 마이너스h랑 x h 근처에서 확률 변수가 관찰될 확률을 의미하게 되는 것이죠. 그때 그 확률을 h로 나눴을 때의 극한값을 우리가 밀도 함수로 해석하게 되고 그 밀도 함수를 가지고 우리가 실제 a라는 집합 위에서 적분을 했을 때 그 a라는 사건이 일어날 확률을 계산할 수가 있게 됩니다. 한 가지 주의하실 점은 우리가 밀도 함수를 사용할 때 분자에서 확률 개념을 쓰긴 했지만 분모에서 우리가 다시 숫자로 나눠져서 극한을 취했기 때문에 확률의 개념이 아니라 어떤 누적 확률 분포의 변화율을 뜻하는 것이기 때문에 우리가 밀도 함수는 절대로 확률로 해석하시면 안 됩니다. 확률이란 개념은 0에서 1 사이의 값을 가져야 되는데 밀도 함수를 여러분이 실제로 해보시면은 어 1 이상의 값을 가지는 경우가 많기 때문에 우리가 절대로 확률이라고 해석하시면 안 되고 밀도 함수는 누적 확률 분포의 변화율을 의미한다라고 기억하시면 되겠습니다. 반면 이상형 확률 변수의 경우에는요 여러분이 확률로 해석을 하셔도 괜찮습니다. 네 이렇게 어떤 확률 분포가 주어져 있을 때 이상형이냐 또는 연속형이냐에 따라서 우리가 확률 밀도 함수를 생각할 수도 있고 또는 어 확률 질량 함수를 생각할 수도 있긴 한데 어떤 경우든지 간에 우리가 결합 분포라는 거를 선정할 수가 있습니다. 비록 우리가 데이터의 확률 분포인 피 데이터를 실제로는 관찰할 수는 없지만 모델링 할 수는 있는데요. 이렇게 모델링하게 됐을 때 사용되는 결합 분포를 우리가 피스y라고 표시를 하겠습니다. 이론적으로 존재하는 확률 분포이기 때문에 알 수는 없지만 우리가 결합 분포를 사용하게 되면은 이런 식으로 스가 주어졌을 때 와이가 어떻게 분포되어 있는지를 대략적으로 모델링 할 수가 있고요. 이걸 통해서 우리가 어 확률 분포의 피 데이터를 모델링하고 그걸 통해 우리가 기계 학습이나 또는 통계적 분석에서 활용할 수가 있게 되는 것이죠. 이때 결합 분포를 가지고 우리가 어떤 식으로 분석할 수가 있냐면은 어떤 입력 엑스에 대해서 마지널 확률 분포 정보로도 얻을 수가 있습니다. 마지널 확률 분포란 어떤 개념이 있냐면요. 이 위에서 살펴본 결합 분포에서 우리가 이제 와가 1일 때의 패턴과 그리고 와가 2일 때의 패턴들을 우리가 볼 수가 있었는데 이거를 y에 대한 패턴들을 우리가 y가 1인 경우랑 y가 2인 경우랑 모두 다 합쳐서 다 더해주거나 혹은 다 모아서 적분을 해주거나 해주게 되면은 우리가 마지널 즉 주변 확률 분포를 계산할 수가 있게 됩니다. 만약에 이산형 확률 변수인 경우에는 y에 대해서 다 더해 주면 되는 것이고요. 만약에 연속형 확률 변수인 경우에는 y에 대해서 적분을 취해주게 되면 됩니다. 위에 예시 같은 경우에는 y가 가질 수 있는 경우의 수가 y는 1 y는 2 두 가지 경우이고 셀 수 있는 범위이기 때문에 이상형에 속합니다. 그러므로 와가 1인 경우에 해당하는 확률값과 y가 2인 경우에 해당하는 어 결합 확률 분포와 확률 값을 다 더해주게 되면은 우리가 해당 셀에서의 주변 확률 분포 값을 구할 수가 있게 되는 것이죠. 그 결과가 이 밑에 그림처럼 나오게 됩니다. 참고로 이 주변 확률 분포는 어 주어진 입력 액스에 대해서 에비덴스라고도 부릅니다. 참고로 딥러닝에서는 에비던스라는 말을 더 많이 쓰기 때문에 여러분들이 이 용어를 잘 기억해 두시면 좋겠습니다. 다시 한 번 말씀드리지만 에비던스는 결합 확률 분포에 대해서 우리가 마지널 확률 분포를 계산했을 때 얻게 되는 확률 분포를 얘기하는 것이고 각 스 값에 대해서 우리가 어 이런 식으로 이산형인 경우에는 확률 값을 계산할 수가 있고요. 그리고 연속적인 경우에는 이렇게 밀도 함수를 적분한 걸 통해서 얻게 되는 새로운 밀도 함수가 나오게 됩니다. 이렇게 마지널 확률 분포를 계산할 수도 있지만 거꾸로 조건부 확률 분포를 계산할 수도 있습니다. 조건부 확률 분포란 이렇게 와가 1인 경우랑 y가 2인 경우를 다 합쳐서 계산하는 마지널이랑 좀 다르게 y가 1인 경우만 우리가 조사를 하고 싶다라고 생각할 수도 있겠죠. 그런 경우에는 y가 2인 데이터를 무시하고 y가 1인 데이터만 들고 와서 우리가 확률 분포를 한번 볼 수가 있는데 이 경우에는 y가 1인 경우에 데이터 분포를 보는 것이기 때문에 스가 클 때의 패턴은 관찰할 수가 없게 되겠죠. 그렇죠 그래서 이거를 실제로 보시게 되면은 스가 작은 경우일 때 이 패턴들을 살펴보실 수가 있습니다. 즉 요 확률 분포는 y가 1일 때 스들이 어떻게 분포되어 있는지를 보여주는 확률 분포인 셈이지요. 이렇게 조건부 확률 분포는 데이터 공간에서 입력 스랑 출력 y 사이의 관계를 모델링하는 데 쓸 수가 있게 되는 것이고요. 특히 y가 조건부로 주어져 있는 경우에는 어떤 특정 클래스 즉 이 경우에는 와가 1인 클래스라고 볼 수가 있을 텐데 특정 클래스가 주어진 조건에서 데이터의 에비던스를 보여주는 것이다라고 이해하실 수가 있겠습니다. 이와 같이 결합 분포에서부터 출발해서 어떤 주변 확률 분포 즉 에비덴스나 또는 조건부 확률 분포를 우리가 이렇게 모델링하는 것이 가능하다라는 거를 이해하시면 좋겠습니다. 조건부 확률 개념을 한번 더 깊게 살펴볼 건데요. 사실 기계 학습에서 굉장히 많이 사용되는 개념 중 하나가 이제 베이지안 스타 즉 베이즈 통계학입니다. 어 근데 베이즈 통계학을 좀 이해하기 위해서는 사실 조건부 확률의 개념을 먼저 좀 이해하실 필요가 있습니다. 어 우리가 중고등학교 시간 때 아마 조건부 확률을 배워봤을 텐데요. 먼저 조건부 확률을 이해하기 위해서는 이와 같이 정의를 좀 살펴봐서 이해를 해야 됩니다. 조건부 확률이란 그 우리가 이제 어떤 비라는 사건이 있을 때 그 비라는 사건이 일어난 상황하에서 어떤 사건 a가 발생할 확률을 의미하게 되는 것인데요. 그렇다면 이 조건부 확률을 어떤 식으로 우리가 산출할 수가 있냐면은 a랑 b가 동시에 발생한 확률 값에서 b가 발생할 확률을 나눠주게 되면은 우리가 이 조건부 확률을 다시 계산할 수가 있게 되겠죠 그래서 조건부 확률에 대해서는 우리가 이와 같은 어 정의가 성립하게 되고 사실은 이거는 우리가 공식처럼 사용할 수 있는 조건부 확률의 공식이 되겠습니다. 기억하실 점은 조건부 확률에서 사용되는 이 조건부의 사건은 이 사건이 일어난 상황에서 즉 전제하에서 계산하고자 하는 사건이 발생할 확률을 의미한다라는 점을 이해하시면 되겠습니다. 그래서 이걸 이용하는 것이 이제 베이지 정리가 되는 것인데요. 조건부 확률을 통해서 정보를 업데이트하는 방법을 우리가 이제 알 수가 있게 됩니다. 네 앞서 살펴본 조건부 확률의 정의에 의해서 우리가 사실은 비가 조건부로 주어졌을 때 a가 발생할 확률을 계산할 수 있듯이 거꾸로 사건 a가 발생했을 때 b가 일어날 확률을 또 한 번 계산해 볼 수가 있습니다. 네 이거를 계산하는 거는 위에서 사용한 공식을 뒤집으면 되는데요. a랑 b가 동시에 일어날 확률을 이번에는 사건 a가 발생하는 게 조건부니까 a가 일어날 확률을 나눠주게 됩니다. 네 이렇게 계산해 주게 되면은 우리가 a가 조건부일 때 b가 발생할 확률을 계산할 수가 있게 되겠죠. 근데 우리가 앞서 살펴보신 것처럼 a랑 b가 동시에 발생한 이 교집합 확률을 이와 같이 비가 주어진 조건부로 주어졌을 때 에가 발생할 확률과 비가 발생할 확률의 두 곱으로 표현할 수 있다라는 거를 배웠는데요. 이 공식을 하단에 분자에다가 대신 넣어주게 되면은 우리가 이렇게 풀어서 얻을 수가 있게 됩니다. 그러면 여러분들께서 보실 수 있는 게 a라는 정보가 주어졌을 때 b라는 사건이 발생할 확률을 다시 b라는 확률로부터 우리가 계산할 수 있는 공식을 얻게 되는 건데요. 이런 베이지 정리가 어 굉장히 유용하게 쓰일 수가 있게 됩니다. 방금 전에는 a랑 b라는 사건의 이벤트로서 설명을 했었는데요. 사실은 이제 이런 경우를 우리가 어떤 페라미터와 그리고 데이터의 관계로 우리가 또한 살펴볼 수가 있게 됩니다. 그래서 데이터가 주어졌을 때 어떤 사건에 대한 이런 확률 분포에 대한 모델링을 우리가 하고자 하는데요. 요 값을 계산할 때 우리가 세 가지 어 확률 분포로 업데이트하면서 계산할 수가 있습니다. 이걸 이용하는 게 이제 베이지 종류인데요. 세 가지가 이제 어떤 정보이냐면은 먼저 해당하는 사건이 발생할 사전적인 확률을 우리가 설정할 수가 있습니다. 이 사전적인 확률이라는 거는 우리가 실제로 데이터를 관찰하기 전에 한 이 정도 될 거야라고 가설을 세우는 사전 확률 분포라고 우리가 이해할 수가 있고요. 그리고 분모에 들어가는 에비던스는 우리가 앞서 살펴봤던 x라는 입력 값의 주변 확률 분포를 계산할 때 그걸 에비던스라고 부른다고 했었죠 그렇죠 그 개념이 사실 여기에 들어가게 됩니다. 즉 어떤 데이터를 관찰하게 될 주변 확률 분포를 여기 이렇게 에비던스로 우리가 사용할 수 있게 되는 것이고 그리고 마지막으로 라이클리우드가 있습니다. 라이클리우드라는 거는 우리가 어떤 사건이 발생했다라는 거를 전제로 했을 때 그 사건을 추정하는 어떤 정보량에 대해서 이 데이터가 관찰될 확률이 얼마나 되는가 즉 현재 내가 이 사건이 발생할 확률은 얼마다라고 짐작가 추론을 했을 때 실제로 이 데이터가 관찰될 확률이 얼마인가를 얘기해 주는 게 가능도 즉 라이클리드가 됩니다. 다시 정리하자면 우리가 어떤 사건이 발생할 확률을 어떻게 모델링을 했을 때 그 모델링 한 게 실제 데이터랑 얼마큼 일치하는가 즉 얼마큼 컨시스턴트 한가를 얘기해 주는 게 라이 클리드의 개념이 되겠습니다. 이렇게 세 가지 정보를 통해서 우리는 궁극적으로 데이터가 주어졌을 때 해당 사건이 발생할 확률을 우리가 계산해 보고 싶은 것이죠. 네 이것이 바로 어 베이지 정리를 이용한 우리가 통계적 추론 방법이 되는 것인데요. 이 메커니즘이 실제로 어떻게 사용되는지를 한번 예제로 살펴보도록 하겠습니다. 코비드 나인티9의 발병률이 10%로 알려져 있는 상황인데 실제로 걸렸을 때 검진될 확률은 99%로 주어져 있다고 할게요. 그리고 실제로 걸리진 않았는데 5 검진될 확률이 1%라고 우리가 설정을 해 보겠습니다. 즉 발병률이 10%이고 실제로 걸렸을 때 검진될 확률은 99% 걸리지 않았는데 오 검진될 확률이 1%라고 했을 때 저희가 구하고자 하는 거는 어떤 사람이 질병에 걸렸다고 검진 결과가 나왔을 때 그 사람이 정말로 이 코비드 나인티나인에 감염되었을 확률을 한번 계산해 보고자 하는 것입니다. 자 이 문제는 사전 확률 그리고 민감도 오탐률을 가지고 정밀도를 계산하는 문제로 여러분이 사실 이해해 볼 수가 있는데요. 이게 무슨 뜻인지는 뒤에서 제가 다시 한번 설명을 좀 드려보겠습니다. 자 그럼 저희는 이 문제를 풀 때 어떤 식으로 문제를 풀 수 있는지를 한번 살펴보도록 하겠습니다. 먼저 발병률이 10%라는 것은 우리가 사전 확률로 이해해 볼 수가 있겠습니다. 즉 우리는 실제로 이 발병률이 10%로 알려져 있다라고 하는 부분을 우리가 실제 발병하게 될 확률이라고 해서 데이터로 주어져 있지는 않지만 그 어떤 발병률이 이 정도 될 거다라고 우리가 사전에 설정되는 확률로 설정할 수가 있는데 이와 같이 사전 확률이라는 개념은 어 이 발병률에 대한 정보로 우리가 설정할 수가 있겠죠. 그래서 이 발병률 p 세터를 우리가 10% 0.1로 설정하게 되겠습니다. 그랬을 때 실제로 발병했을 때 검진될 확률 그 확률을 우리가 99%로 설정된다고 했었죠 즉 99%로 주어진다고 했었죠. 그래서 실제로 걸렸을 때 검진될 확률이 0.99가 되는 것이고요. 걸리지는 않는데 5 검진될 확률은 우리가 세타의 부정형 즉 네게이션을 시킨 거를 조건부로 주고 이때 검진될 확률로 표시를 하겠습니다. 즉 실제로 걸리지는 않았을 텐데 어 이렇게 d 안에 들어가게 될 확률을 계산하는 건데 이거는 1% 0.01로 표시를 하겠습니다. 그랬을 때 이 두 확률은 우리가 가능도 라고 설정하게 이해할 수가 있게 되는 것이죠. 그래서 더 정리하자면 발병률은 사전 확률 그리고 가능도는 우리 아 그리고 이제 실제로 걸렸을 때 검진될 확률이랑 그리고 걸리지 않았을 때 오 검진될 확률은 우리가 가능도 정보로 우리가 넣을 수가 있게 됩니다. 자 이런 정보들이 주어졌을 때 그렇다면 우리가 실제로 그 어떤 사람이 질병에 걸렸다고 나왔을 때 그럼 이 사람이 실제로 관련된 확률은 바로 뭐가 되냐면 검진이 되었을 때 이 사람이 실제 발병되었을 때 즉 감염되었을 확률을 계산하는 것이니까 이 사후 확률을 계산하는 게 우리의 목적식이 되겠죠. 그렇다면 우리가 발병률을 사전 확률로 설정했고요. 그리고 p 세터가 주어졌을 때 딜 확률 즉 가능도라는 정보도 이와 같이 주어져 있기 때문에 사실 이 분자에 해당하는 값이랑 사전 확률에 해당하는 값은 알고 있습니다. 그렇다면 우리가 구해야 되는 나머지는 바로 이 에비던스가 되는 것인데요. 이 에비던스를 구하기 위해서 사용되는 포뮬라가 바로 이 포뮬라입니다. 즉 다시 말해 우리가 현재 가지고 있는 경우의 수는 발병되었거나 발병되지 않았거나 즉 세타이거나 아니면 세타의 네게이션이거나 둘 중 하나입니다. 그래서 실제로 발병이 될 확률을 이렇게 세터가 조건부로 주어졌을 때 검진될 확률이 이 조건부 확률에다 곱해주게 되면은 그러면 발병되었을 때 그리고 검진되었을 때 이 두 가지 사건이 동시에 발생할 이벤트로 우리가 모델링 할 수가 있고요. 그리고 실제로 발병되지 않을 확률과 발병되지 않았는데 오검진될 확률인 가능도를 곱해 주게 되면은 어 발병되지 않았지만 검진될 케이스가 동시에 발생하는 교집합 확률도 같이 계산할 수가 있게 되겠죠. 그러면은 우리가 현재 상정하는 경우의 수는 발병했거나 또는 발병하지 않았거나 두 가지 케이스이기 때문에 두 가지 케이스에 대한 확률 분포의 합으로 설정할 수가 있게 됩니다. 따라서 발병률인 10%와 그리고 발병되었을 때 검진될 확률이 0.99를 곱해주고요. 그리고 발병되지 않을 확률은 이 세타가 걸리지 않을 확률이니까 1에서 이 피세타를 뺀 나머지 0.9가 되겠죠. 그리고 이 0.9는 세터가 걸리지 않는 확률이고 얘를 이 라이클리드에 곱했을 때 조건부 확률의 정의에 따라서 걸리지 않았지만 검진 그니까 발병이 되지는 않았지만 오검진될 확률 값을 우리가 계산할 수가 있게 됩니다. 그래서 이 두 가지 확률 값을 우리가 더해주게 되면은 우리가 원하는 에비던스 확률 값을 이와 같이 계산할 수가 있게 되는 것이고요. 그러면 사전 확률과 가능도와 그리고 에비던스 값을 우리가 모두 다 계산을 했기 때문에 이 세 가지 값을 통해서 우리가 이 사후 확률 분포를 계산할 수가 있게 됩니다. 결론적으로 발병률에 해당하는 0.1을 그리고 가능도에 해당하는 정보인 0.99 그리고 우리가 계산한 에비던스 값인 0.108을 나눠서 계산해 주게 되면은 0.916이 나옵니다. 그 말은 질병에 걸렸다고 검진 결과가 나왔을 때 실제로 코비드 나인티9에 감염되었을 확률이 91.6%다라고 이해할 수가 있겠죠. 근데 만약에 어 오 검진될 확률 즉 1종 오류가 즉 요 확률 값을 말하는 건데요. 실제로 걸리지는 않았는데 검진될 확률이 현재는 1%로 설정이 되어 있습니다만 만약에 이 확률 값이 1%가 아니라 10%로 높아지게 되면은 우리가 계산하고자 하는 성공 확률은 어떻게 바뀌게 되는지 한번 살펴보겠습니다. 그러면은 어떤 부분이 바뀌게 되냐면요. 바로 이 0.01로 계산되는 이 가능도 함수부에서 계산되는 부분이 바뀌게 되는데요. 0.1로 바뀌었기 때문에 이 부분이 바뀌게 되고 그런 전체적인 값이 0.189로 높여지게 됩니다. 그러면은 다른 부분들의 값은 다 똑같은데 이 에비던스에 해당하는 값이 분모에 들어가서 바뀌어서 전체적인 사후 확률 분포가 0.524 즉 52.45%로 바뀌게 되는데 이 값은요 실제로 걸리지 않았는데 검진될 확률이 이렇게 조금만 높아지기만 하더라도 어 우리가 질병에 걸렸다고 검진 결과가 나왔을 때 실제 코비드일 확률이 굉장히 낮아지게 되는 거를 볼 수가 있겠죠. 아까 전에 0.01이었을 때는 90%에 가까운 값이었지만 이 오탐률이 오르게 되면요. 실제로 검진 결과가 나왔을 때 질병에 걸렸다고 판단할 확률이 52.4%로 낮아질 정도로 정확도가 낮아지게 됩니다. 즉 다시 말해 오탐률이 오르면 테스트의 정밀도가 떨어진다라는 결론을 이렇게 베이지 정리를 통해서 이해할 수가 있게 되는 것이죠. 그러면 앞서 배워본 베이지 정리를 통해서 이렇게 정보를 업데이트하는 과정을 한번 시각화해서 그려보도록 하겠습니다. 먼저 우리가 실제로 발병을 했을 때 검진될 확률 이 부분 같은 경우에는 우리가 민감도라고 이해할 수가 있게 됩니다. 실제 사건에 대해서 우리가 그 사건을 탐지할 확률이 되는 것이기 때문에 이 경우는 우리가 이제 민감도라고 설정할 수가 있게 되는 것이고요. 그리고 이 사전 확률이라는 부분을 우리가 이제 아까 전에 보셨던 것처럼 실제 그 사건이 벌어질 확률을 우리가 이렇게 사전 확률로서 설정해 주게 되고 그다음에 그 사건이 실제로 벌어나지 않을 부분도 사실은 사전 확률에 속하게 됩니다. 그래서 코비드 나인티나인에 걸릴 확률과 또는 걸리지 않을 확률 이 두 가지가 이제 사전 확률을 구성한다라는 거를 보시면 되겠고요. 그래서 이 부분이 바로 뭐냐 하면은 이 세타가 발생하게 될 확률에 대해서 우리가 보여주는 시각화 그림이 되겠습니다. 그래서 이 영역이 실제로 세타가 발생할 확률이 되는 것이고 이 영역이 세타가 발생하지 않을 확률이 되게 되는 것이죠. 그랬을 때 세타가 발생하게 되는 영역에서 우리가 실제로 검진을 했을 때 세타랑 검진됐을 때 이 두 가지 이벤트가 모두 다 동시에 발생한 이벤트를 보시면은 실제로 발병될 확률 곱하기 그리고 발병했을 때 검진될 확률 요 두 가지를 곱하게 되면은 이 조건부 확률의 그리고 사전 확률의 고비이기 때문에 2개가 동시에 일어날 즉 교집합의 이벤트가 됩니다. 이 이벤트는 사전 확률과 그리고 민감도의 고비고 이제 이 경우가 트루 퍼스티브에 해당하는 것이 되겠죠. 이 값은 보시다시피 민감도에 해당하는 0.99 값이랑 그리고 사전 확률에 해당하는 0.1의 값을 곱한 0.099가 되는 것이죠. 그리고 이 나머지 부분에 해당하는 것은 실제로 발병을 했지만 우리가 검진을 했을 때 발병되지 않았다고 결론을 낼 확률입니다. 즉 이 같은 경우에는 퍼스트 negative인 건데요. 즉 실제로는 파시티브인데 negative로 판단하게 되는 것이니까 f스 negative로 판단하게 되는 것이죠. 이 경우는 이종 오류라고 부릅니다. 즉 어떤 우리가 탐지를 해야 되는 이벤트에 대해서 탐지를 못한 경우에 해당하는 것이기 때문에 이 용어는 이종 오류에 해당하는 것이고요. 그럼 이제 사건이 발생하지 않았을 때 즉 어 코비드 나인티나인티나인은 실제로 발병하지 않았는데 검진을 됐냐 안 됐냐로 한번 나눠서 살펴볼 텐데요. 실제로는 발병되지는 않았지만 발병되지 않은 상태에서 검진 즉 발병됐다고 검진될 이 조건부 확률을 곱해줘서 계산해 주게 되면은 이 확률 값은 발병되지 않았지만 발병됐다고 검진될 확률에 속합니다. 이 경우는 해당 사건이 아니지만 그걸 탐지한 이벤트이기 때문에 퍼스트 positive입니다. 즉 발병했어요라고 우리 테스트는 얘기해 주지만 그 결과 값이 f스인 경우이죠. 이 경우는 우리가 1종 오류라고 부릅니다. 2종 오류랑 차이점은 2종 오류는 실제로 걸렸는데 탐지를 못하는 경우이고요. 1종 오류는 걸리지 않았는데 걸렸다고 탐지할 확률이니까 두 개가 좀 다른 경우가 되겠죠 자 실제로 이 확률 분포는요 어 발병하지 않았는데 발병되었다고 탐지될 확률 즉 펄스 알람이랑 같은 수치라고 보시면 되겠습니다. 그래서 이 펄스 알람 수치가 실제로 걸리지 않을 사전 확률이랑 곱해져서 1종 오류의 확률인 0.09가 계산이 되는 것이고요. 그리고 발병되지도 않았고 실제로 걸리지 않았다라고 어 테스트가 나올 확률 나오는 경우가 이제 트루 negative에 이제 해당하는 것이죠. 자 이 경우는 우리가 어떻게 바라볼 수가 있냐면 발병하지 않은 상태에서 발병하지 않았다고 검진될 확률을 얘기하는 것이니까 이 경우는 우리가 이제 0.9로 즉 펄스 알람의 반대인 수치로 나오게 되겠죠 이 경우는 우리가 특이도 스페시피시티라고 정의를 해주게 됩니다. 그래서 정밀도를 계산하려면 우리가 발병되었다고 탐지가 되었을 때 즉 테스트 결과가 나왔을 때 실제로 발병될 확률이 얼마인지 구하는 테스크입니다. 자 이 부분을 우리가 프리시전 정밀도라고 부른다고 했었죠. 그렇다면 이 확률 값은 트루 퍼시티브에 해당하는 확률값과 그리고 걸리지 않았는데 걸렸다라고 테스트 결과가 나올 퍼스트 퍼시티브가 분모로 들어가서 더해지고요. 그리고 분자에는 실제로 이 트루 퍼스트뷰에 해당하는 값이 들어가서 계산이 되게 됩니다. 그럼 아까 보셨다시피 펄스 알람 수치가 0.1에 해당하게 되면은 즉 펄스 알람 수치가 매우 높게 되면은 이 정밀도의 수치가 굉장히 낮게 나온다라는 거를 여러분이 보실 수가 있게 되는데요. 그 이유는 분자에 해당하는 트루 퍼스티브에서 이 퍼스트 퍼시티브가 해당하는 부분의 영역이 커지면은 이 두 영역이 합쳐진 게 분모고 이 트루 퍼시티브에 해당하는 게 분자에 들어가기 때문에 정밀도가 낮아지게 되는 것입니다. 즉 이 경우는 민감도가 높아도 퍼스 퍼스티브 확률이 높기 때문에 실제로 정밀도가 떨어지게 되는 케이스가 되는 것이죠. 만약에 퍼스 알람 수치를 우리가 0.1에서 0.01로 계산할 수 있게 되었다 하게 되면은 퍼스 퍼시티브 수치가 이렇게 낮아지기 때문에 분모에 들어가게 되는 트루 퍼시티브랑 퍼스트 퍼시티브의 합이 같이 낮아지게 돼서 정밀도의 값이 높아지게 되는 것이죠. 자 이 경우에는 그래서 프리시전 정밀도의 값이 0.9의 수치로 좋아지기 때문에 우리가 이 테스트의 결과를 믿고 쓸 수 있게 되는 것이죠. 그러므로 우리가 특정 수치 즉 리콜 수치가 높다고 해서 항상 정밀도 프리시션 수치가 높아지는 것은 아니다 라는 사실을 여러분들께서 기억하시면 좋을 것 같고요. 이런 어떤 통계적인 분석에 있어서 굉장히 중요한 부분들 중 하나가 바로 이런 퍼스트 퍼시티브 또는 1종 오류랑 그리고 퍼스트 negative 이중 오류에 해당하는 수치들이 실제로 예측된 확률에 즉 어떤 모델의 예측 결과에 대한 신뢰성을 평가하는 기준이 된다라는 거를 기억하시면 좋겠습니다. 자 이렇게 조건부 확률을 시각화해서 해석하는 방법을 한번 배워봤고요. 지금부터는 확률론에서 배우게 되는 이제 다른 개념인 기댓값이라는 개념을 한번 배워보도록 하겠습니다. 기댓값이란 확률 분포가 주어지면은 데이터를 이제 분석할 때 사용 가능한 여러 종류의 통계적 범함수라는 개념을 쓰는데 영어로는 스타트 스티컬 펑셔널이라고 얘기를 합니다. 조금 어려운 용어이지만 쉽게 생각하자면 이 데이터를 대표하는 값이 무엇이냐라고 묻게 됐을 때요. 그 대표 값으로 우리가 평균을 계산하거나 분산을 계산해 볼 수가 있겠죠 바로 이렇게 평균과 분산을 계산할 때 사용되는 이런 연산이 바로 기댓값을 통해서 계산을 하게 됩니다. 평균과 기댓값은 같은 것이 아닌가요라고 생각하실 수가 있는데요. 네 사실 산술 평균과 기댓값은 통계적으로 일치되는 부분이 있습니다만 우리가 분산을 계산할 때도 기수 값을 사용하기 때문에 어 기댓값의 의미는 조금 더 넓게 범함수 개념으로 우리가 보는 게 좀 더 이해하는 데 도움이 될 것입니다. 어떤 뜻인지 좀 살펴보도록 할게요. 일단 기댓값이라는 거는 데이터를 대표하는 통계량이면서도 동시에 확률 분포를 통해 다른 통계적 범함수를 계산하는 데 사용된다라는 거를 일단 이해하시면 되는데 무슨 말이냐면 다른 통계량을 계산할 때 이 기댓값을 통해서 많이 계산된다라고 이해하시면 되겠습니다. 그래서 기댓값을 계산할 때 우리가 종종 많이 쓰는 개념이 바로 이 밀도 함수랑 그다음에 그 질량 함수 즉 연속 확률 분포인 경우에는 이와 같이 밀도 함수를 통한 적분으로 계산하게 될 것이고요. 이산 확률 분포인 경우에는 확률 밀도 함수의 곱을 통해서 이렇게 급수 즉 덧셈을 통해서 기댓값을 계산하게 됩니다. 수식을 좀 더 살펴보시게 되면요. 우리가 어떤 그 확률 변수 x가 주어져 있을 때 이 x는 이 확률 분포 피에서부터 관찰되는 x이고요. 어떤 함수 f가 에프가 주어졌을 때 이 프스에 대한 기댓값을 계산하고 싶다고 우리가 생각해 보겠습니다. 그때 이 기댓값의 의미란 연속 확률 변수인 경우에는 프스에다가 밀도 함수를 곱해서 적분을 해 주게 되면은 우리는 이 에프엑스에 대한 기댓값을 계산하게 되는 것이고 이산 확률 분포인 경우에는 이 프스에다가 밀도 함수를 곱해줘서 다 모든 엑스의 경우의 수에 다 더해주게 되면은 우리가 기댓값을 계산할 수가 있게 되는 것입니다. 그러므로 기댓값이라는 거는 우리가 데이터를 대표하는 통계량이라고 일단 볼 수가 있는데요. 이 함수 프 자리에다가 어떤 함수 f를 넣느냐에 따라 우리가 또한 측정하고자 하는 어떤 대상에 어 이 통계적인 어떤 패턴을 파악하는 데도 쓸 수가 있기 때문에 통계적 범함수를 쓰는데 계산하는 데 사용할 수 있다라고 얘기하는 것입니다. 대표적인 예로 우리는 기댓값을 이용해서 분산 첨도 공분산 등의 여러 통계량을 계산할 수가 있습니다. 우리가 수식을 한번 잘 살펴보시면요. 분산이라는 거는 사실 어떤 확률 변수에서 기댓값을 뺀 후 제곱을 한 값에다가 다시 기댓값을 계산하는 게 바로 분산의 정의고요. 코베리언스는 두 확률변수 x1이랑 x2가 있을 때 각각의 x1의 x2에서 기댓값을 뺀 후에 그 두 개의 곱을 우리가 결합 분포에 대한 기댓값으로 계산하는 것이 공분산에 해당하는 겁니다. 보시다시피 이런 공분산의 개념이나 분산의 개념도 바로 기댓값을 통해서 계산된다는 거를 여러분이 확인하실 수가 있고 이렇게 첨도 같은 스튜네스를 계산할 때도 보시다시피 기댓값이 또한 여러 개 활용된다는 걸 보실 수가 있습니다. 네 바로 이렇게 x 마이너스 기댓값의 제곱이나 또는 두 확률 변수에 각각 기댓값을 뺀 후에 각각을 곱하는 함수들이나 그리고 요라게티 세제곱이 들어가야 되는 이런 함수들이나 우리가 전부 다 다 프로 사용할 수 있는 함수들이기 때문에 저 기댓값 수식에 프를 넣게 되면은 해당 통계량을 계산할 수 있다라는 뜻입니다. 그러므로 기댓값이라는 거는 단순하게 산수 평균만 계산하는 것이 아니라 우리가 관찰하고자 하는 여러 통계량을 계산할 때 사용되는 개념이다라고 여러분이 이해해 볼 수가 있겠습니다. 문제는 우리가 실제로 어떤 확률 분포의 밀도 함수나 또는 질량 함수를 우리가 명시적으로 아는 것은 아니기 때문에 어 그런 경우에는 우리가 기댓값을 계산할 때 어 실제 적분을 수행하거나 덧셈을 수행하는 게 한도가 있습니다. 그러므로 이런 경우에는 우리가 데이터를 관찰하면서 그 데이터에 관찰된 값을 이용해 가지고 기댓값을 계산하는 방법이 좀 필요한데요. 이때 사용되는 법칙이 바로 이론이 대수의 법칙입니다. 로우더 라즈 넘버라고 불리는 대수의 법칙은 통계학에서 굉장히 많이 사용되는 법칙인데요. 이게 어떤 법칙인지 좀 살펴보도록 하겠습니다. 대수의 법칙은 데이터를 우리가 어떤 확률 분포 우리의 경우는 데이터 분포겠죠 데이터 분포로부터 반복적으로 독립 추출할 때 해당 산수율 평균이 기댓값으로 수렴하는 정확히 말하자면 거의 확실이라는 표현을 쓰는데요. 이 말은 수렴하지 않을 확률이 0이라는 표현입니다. 그랬을 때 기댓값으로 수렴하는 이 법칙을 우리가 대수의 법칙이라고 부릅니다. 여기서 핵심적인 부분은 이 확률 변수들을 우리가 데이터를 어떤 데이터 분포에서 뽑아내서 관찰한 이 관측 값들을 독립적으로 추출해야 된다는 것이고요. 그리고 이 산술 평균이 즉 엔게이 데이터를 관찰하고 그 엔게이 데이터를 관찰하는 걸 다시 엔으로 나눈 이 산술 평균이 해당 기댓값으로 n이 무한대로 갈 때 수렴한다는 의미입니다. 즉 우리가 반복적으로 독립 추출했을 때 우리가 데이터를 많이 모으면 모을수록 이 산수 평균이 기댓값으로 간다는 표현인데요. 자 만약에 우리가 엑스1 스엔 대신에 함수 프를 설정하고 그 프에다가 이 스원과 스을 넣고 우리가 산수 평균을 취해주게 되면은 그 프스들의 산수 평균이 될 텐데요. 그 산수 평균들은 그렇다면 어디로 실험하게 될까요? 네 맞습니다. 프를 프스에 대한 기댓값으로 우리가 수렴하게 되는 것입니다. 실제로 이런 산술 평균의 어떤 추정값의 불확실성이 어느 정도 큰지를 한번 보실 수가 있는데요. 이 산술 평균 추정의 불확실성은 데이터 개수가 n일 때 n의 역수만큼의 상한을 가지기 때문에 데이터를 더 모으면 모을수록 이 산술 평균의 분산이 점점 낮아져서 우리가 실제로 추정값이 더 정확해진다라는 거를 보실 수가 있게 됩니다. 여러분이 기억하셔야 될 점은 대수의 법칙은 데이터가 따르는 확률 분포 비 데이터가 어떤 확률 분포이든지 상관없이 성립하는 법칙이라서 기댓값을 계산할 때 범용적으로 쓸 수 있다는 사실입니다. 이게 굉장히 중요한 사실인데요. 즉 어떤 확률분포 p 데이터가 여러분이 알고 있는 정규 분포나 아니면 그런 다른 분포에 상관없이 어떤 확률 분포이든지 간에 기댓값을 계산할 때 사용될 수가 있다라는 의미이기 때문에 독립 추출한다라는 가정만 성립하게 되면은 이 대수의 법칙을 우리가 언제든지 쓸 수 있어서 굉장히 유용한 정리가 되겠습니다. 한편 대수의 법칙이랑 중심극한 정리는 가끔 많이들 혼동하시는데요. 2개는 굉장히 다른 의미이므로 해석할 때 주의하시기 바랍니다. 대수의 법칙은 아까도 말씀드렸듯이 어떤 이런 x 그 자체에 대한 산수 평균과 기댓값을 계산하는 데 쓰이는 것이 아니라 조건부 기댓값이나 또는 기댓값으로 정의되는 다른 통계량 계산에도 적용할 수가 있습니다. 즉 기댓값으로 계산되는 모든 통계량은 우리가 대수의 법칙을 적용해서 우리가 근사를 할 수가 있기 때문에 굉장히 유용하게 쓸 수 있다는 점을 기억하시고요. 단 기댓값이 정의되지 않는 경우 즉 기댓값이 발산하거나 정의되지 않는 경우에는 쓸 수 없다는 사실을 여러분이 주의하시면 좋겠습니다. 그리고 이 대수의 법칙을 이용을 해서 그리고 데이터 샘플링을 이용을 해서 우리가 어떤 그 모르는 데이터 확률 분포에서 기댓값을 계산할 때 쓸 수 있는 기법이 바로 몬테 카를로 샘플링입니다. 기계 학습의 많은 문제들이 실제로 몬테칼러 샘플링을 통해서 해결이 많이 되는데요. 확률 분포를 명시적으로 모르지만 그 확률 분포에서 데이터를 샘플링 할 수 있을 때 우리는 몬테칼러 샘플링을 통해 기댓값을 계산할 수가 있습니다. 좀 더 구체적으로 살펴보면요 어떤 데이터를 우리가 확률 분포에서 독립적으로 추출이 가능하다고 우리가 가정하겠습니다. 즉 어떤 확률 분포인지 우리는 명시적으로 알 수는 없습니다만 우리가 데이터 수집을 하는 과정에서 그 데이터 확률 분포로부터 독립적으로 추출할 수 있다라고 가정하겠습니다. 예를 들어서 여러분이 어떤 데이터를 수집하는 과정에서 모은 데이터가 독립적으로 추출했다라고 가정하게 되면은 몬테칼로 샘플링을 적용할 수 있다는 뜻이고요. 그게 이상형이든 또는 연속형이든 상관없이 성립한다는 것입니다. 그때 그렇게 모은 데이터를 함수 f에다가 집어넣어서 함숫값을 계산하고 그리고 이 함수 f에 대한 산술 평균을 내가 모은 모든 데이터에 대해서 산수 평균을 계산해 주게 되면은 이 산수 평균값은 실제로 FX에 대한 기댓값으로 대수의 법칙에 의해 성립하게 됩니다. 바로 이 대수의 법칙에 근거해서 근사시키는 방법이 몬테칼로 샘플링 기법입니다. 몬테칼로 샘플링은 독립 추출만 보장된다면 대수의 법칙에 의해 수렴성이 보장된다라는 사실을 기억하시면 되고요. 그리고 대수의 법칙에서 분산의 크기가 내가 데이터의 개수의 역 수에 비례해서 분산의 크기가 줄어든다는 사실을 여러분이 기억하시면은 어 몬델 컬러 샘플링에 굉장히 유용하게 쓰일 수 있다라는 거를 알 수가 있겠죠. 그래서 굉장히 많은 기계 학습 기법에서 몬테칼로 샘플링을 통해 기댓값을 계산할 수가 있습니다. 네 그럼 이번에는 앞에서 배운 몬테칼로 샘플링을 이용해서 실제로 우리가 어떻게 쓸 수 있는지를 한번 살펴보도록 하겠습니다. 네 사실 몬테칼로 샘플링은 기댓값을 계산하는 데 쓸 수 있다라고 말씀드렸는데요. 실제로는 훨씬 더 다양한 예제에서 쓸 수가 있습니다. 이 예제는 어떤 함수 FX가 2 2 더 마이너스 x 제곱으로 마이너스 1과 1 사이에서 정의가 되어 있을 때 이 함수의 적분 값을 계산하는 문제입니다. 자 이 지수 함수 형태로 되어 있으니까 왠지 아마 여러분들께서는 실제로 손으로 접근할 수 있지 않을까 공식이 있지 않을까 생각하실 텐데요. 실제로는 이 함수를 계산할 수 있는 적분 공식은 없습니다. 그렇기 때문에 손으로 적분하는 것은 불가능합니다. 그렇다면 이 적분값을 우리가 실제로 계산하려면 우리가 어떻게 해야 될까요? 네 이때 사용하게 되는 것이 바로 몬테칼로 샘플링입니다. 먼저 구간이 마이너스 1서부터 1이라는 것은 일단 길이가 2인 적분 구간인데 이 전체 길이가 2인 적분 구간을 우리가 균등 분포로 생각해서 균등 확률 분포의 밀도 함수의 2분의 1을 설정해 주게 되면은 마이너스 1과 1 사이의 밀도 함수가 2분의 1인 우리가 확률 변수를 한 번 생각할 수가 있고 그 확률 변수로부터 확률 분포를 설정해 가지고 우리가 데이터를 추출할 수가 있게 됩니다. 정리하자면 마이너스 1과 1 사이의 균등 분포를 설정을 해서 거기서로부터 우리가 데이터를 추출할 수가 있고 우리가 균등 분포의 경우 밀도 함수의 값을 알고 있기 때문에 그 밀도 함수의 값이 마이너스 1에서 1 사이니까 이 구간에서 함수 값이 2분의 1인 밀도 함수를 생산해 볼 수가 있는데요. 그러면 어 이 밀도 함수에 대해서 우리가 실제로 기댓값을 계산하는 이런 포뮬러의 공식을 세워 볼 수가 있습니다. 다시 말해 마이너스 1에서 1 사이까지 이 투 더 마이너스 제곱이라는 프스를 2분의 1을 밀도 함수로 가지는 기댓값을 계산하는 공식으로 우리가 생산해 볼 수가 있는데 이 기댓값을 계산할 때는 실제로는 적분을 계산할 수는 없기 때문에 우리가 균등 분포에서 데이터를 뽑아서 독립적으로 데이터를 뽑아서 이 데이터를 뽑은 거를 함수에다 집어넣고 이 함수값의 산술 평균을 구하는 것으로 이 기댓값을 근사를 할 수가 있습니다. 즉 실제로 이 기댓값을 구할 수는 없지만 우리가 손으로 구할 수는 없지만 균등 분포에서 샘플링한 데이터를 무수히 많이 모아서 함수 프에다 집어넣는 건 가능하니까 함수 프에다 집어넣고 그 함수 프에 대한 산술 평균만 계산해 주면은 우리가 근사적으로 이 기댓값을 계산할 수가 있게 되는 것이고요. 그리고 이렇게 계산된 적분값에다가 이를 곱해 주게 되면은 우리가 원래 구하고자 했던 적분값을 구할 수가 있게 되는 것이겠죠. 이렇게 기댓값의 개념을 이용해서 실제로 어 적분을 계산하는 것이 가능하다라는 걸 볼 수가 있습니다. 이거를 코드로 한번 구현해 보도록 하겠습니다. 어 몬데칼로 적분을 한번 구현해 보기 위해서요. 우리가 다음과 같이 코드를 한번 짜봤는데요. 먼저 이 적분 구간에 해당하는 마이너스에서부터 12 사이까지를 설정하기 위해서 로우랑 하이라는 정보를 받습니다. 로우라는 거는 적분 구간에서 가장 작은 값을 의미하는 것이고 하이라는 것은 적분 구간에서 가장 높은 값을 의미하는 것이고요. 샘플 사이즈는 몬테 컬러 샘플링 할 때 우리가 추출하게 될 데이터의 숫자가 되겠습니다. 리핏은 우리가 실제로 몬테 컬러 샘플링이 얼마큼 정확한지 보기 위해서 어 얼마큼 반복해서 계산할지 설정하는 리핏 설정 값입니다. 그리고 함수 f를 추상적으로 인풋을 받게 되고요. 이때 설정된 적분 구간의 차이를 우리가 이제 랭스로 우리가 설정하게 됩니다. 그리고 이 설정된 구간을 가지고 우리가 이제 실제로 몬트 컬러 샘플링을 한번 수행해 보게 될 텐데 먼저 설정된 적분 구간 내에서 데이터를 유니폼 하게 샘플링 해 가지고 데이터를 모읍니다. 이 샘플 사이즈 개수만큼 셀을 모은 거다라고 보시면 되고요. 그리고 주어진 함수 f에 대해서 펑션에 대해서 x 값을 입력으로 넣은 정보들을 우리가 모아줍니다. 그리고 그렇게 모은 데이터들에 대해서 우리가 산수 평균을 구해주게 되면은 앞서 설명드렸던 이 몬테칼로 샘플링을 통해서 기댓값을 계산하는 파트가 되고요. 그리고 방금 전에 구했던 이 마이너스 1 사이에서의 구간의 길이 즉 2를 다시 곱해주게 되면은 우리가 원래 구하고자 했던 이 적분 값을 계산할 수가 있게 되겠죠. 그렇게 구하는 것이 바로 이 인트벨 즉 어 이 인테그레이션 값 즉 적분값을 계산하는 부분이 되겠습니다. 그래서 이거를 실제로 한번 수행해서 여러분이 한번 몬테칼로 인테그레이션 한번 수행해 보시게 되면은 이 1.493875 나온 이 결과값이 우리가 이 몬테칼로 샘플링의 기댓값에서 얻게 되는 그 기댓값의 어떤 평균에 해당하는 값이고요. 즉 이 적분 값에 이 평균에 해당하는 것이고 이 0.0039가 바로 뭐냐면은 대수의 법칙에 의해서 우리가 모은 실제 데이터에 의해 이 기댓값의 오차 범위라고 보시면 되겠습니다. 즉 1.49387 근처에 0.0039 범위 내에서 우리가 보고자 하는 이 적분값의 범위가 실제로 있다라는 얘기입니다. 실제로 이 마이너스 14부터 이 22 마이너스 x 제곱의 적분값을 수치적으로 한번 계산해 보시면 한 1.49364 정도 나오나 보시면 1.49387이랑 굉장히 유사한 범위라는 걸 보실 수가 있게 되는데요. 이 오차 범위 내에 접근 값이 존재하게 되겠죠 네 그래서 몬테 카울러 샘플링이 데이터를 많이 모으면 모을수록 실제로 굉장히 정확하구나라는 거를 여러분이 아실 수가 있게 됩니다. 이렇게 확률론 기반의 어떤 수치적 적분 또는 어 이 확률론 기반의 어떤 기댓값 계산하는 방식들은 기계 학습에서 굉장히 많이 사용되고 실제로 기계 학습뿐만이 아니라 다른 응용에서도 많이 쓰이기 때문에 여러분들께서 잘 기억해 두시면 좋겠습니다. 네 이렇게 구강 확률론을 한번 맞춰보았습니다. 다음 시간에는 이제 기계 학습에서 사용되는 통계학을 좀 더 광범위하게 살펴보도록 하겠습니다. 수고하셨습니다."
}