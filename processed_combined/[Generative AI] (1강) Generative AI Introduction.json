{
  "lecture_name": "[Generative AI] (1강) Generative AI Introduction",
  "source_file": "[Generative AI] (1강) Generative AI Introduction_86.mp4_2025-12-04-104155737.json",
  "text": "안녕하세요. 강필성 교수입니다. 오늘 저와 제너러티브 AI라는 주제로 여섯 번의 강의를 이제 같이 진행을 하도록 하겠습니다. 저와 함께 김재희, 이우준, 이우경, 허재혁 학생이 멘토로 참여를 하겠습니다. 첫 번째 주제로서 제너러티브 AI에 대한 개괄적인 소개 인트로덕션을 먼저 말씀을 드리겠습니다. 간단하게 제 소개를 다시 한번 드리자면 저는 이제 서울대학교 산업공학과에서 박사학위를 취득하고 현대카드라는 회사에서 고객 데이터 분석을 이제 주 업무로 하다가 서울과학기술대학교 글로벌 융합 산업공학과에 조교수로 4년 동안 재직을 하고 2015년부터 지금까지 고려대학교 산업경영공학부의 교수로서 연구와 교육을 진행을 하고 있습니다. 저희 연구실에서 주로 다루는 분야는 인더스트리얼 데이라 어노틱스 멀티모달 데이터라는 큰 주제이고요. 그 안에 자연어 처리에 대한 부분 비전에 대한 부분 시리얼 데이터에 대한 부분이 있습니다. 저희 홈페이지에 대한 주소는 아래와 같고 연구실 유튜브 채널을 운영을 하고 있습니다. 유튜브 채널은 유튜브 검색에서 dsba로 검색을 하시면 저희 연구실이 나올 것이고 저희 연구실 내부에서 수행하고 있는 여러 가지 세미나 활동들을 모두 공개하고 있으니 혹시나 특정한 논문에 대해서 궁금하실 경우에는 함께 찾아봐 주시고 많이 대응해 주시면 감사하겠습니다. 오늘 강의는 크게 첫 번째 강의는 크게 두 가지 파트로 구성이 됩니다. 첫 번째는 생성 AI GNR티브 AI에 대한 개괄적인 개요 그리고 큰 흐름에 대해서 말씀을 드릴 것이고요. 그중에서도 언어적인 지능을 이해하고 생성하고자 하는 자연어 처리 그리고 시각적인 지능을 이해하고 생성하고자 하는 비전 분야에 대해서 설명을 드리겠습니다. 그리고 난 뒤에 현재 생성 인공지능이 어떤 분야에 대해서 활용이 되고 있는지 챗gpt와 지피티4에 대한 사례를 중심으로 그리고 비전 쪽에서는 달리와 스테이블 디퓨전 기준으로 설명을 드리도록 하겠습니다. 첫 번째 파트입니다. 제너러티브 AI에 대한 개요와 흐름에 대한 부분을 설명을 드리도록 하겠습니다. 먼저 언어 지능에 대한 부분 설명드리고요. 이후에 시각 지능에 대한 부분 이어서 설명을 하도록 하겠습니다. 우선 제너티브 AI 생성형 AI라는 것은 첫 번째 키워드가 바로 생성입니다. 생성이라는 말은 무슨 말이냐면 무엇인가를 만들어 낼 수 있다라는 뜻이고요. 인공지능은 이 생성형 AI에 대한 발전을 통해서 한 번에 큰 퀀텀 점프를 이룩하게 됩니다. 지금까지는 과거에는 AI를 하고자 했던 거는 대부분이 이해하는 AI입니다. 벌써 한 10년 가까이 지났지만 과거에 이세돌 9단이 이제 졌던 알파고 같은 경우에는 바둑에 대한 수와 법칙을 이해해서 새로운 대국을 진행을 할 때 어떠한 수를 두었을 때 지지 않을 것인지를 만들어내는 학습하는 AI였고요. 이것은 과거 데이터를 학습하고 이해하는 데 목적을 둔 AI입니다. 지금 여러분들이 활용을 하고 계시는 챗gpt나 달리 그리고 며칠 전에 공개된 오픈 에아의 동영상 생성 모델인 소라 같은 경우는 생성을 한다는 뜻이죠. 생성을 한다라는 뜻은 이해를 한다라는 뜻과는 조금 더 넓은 개념입니다. 무엇인가에 대한 개념을 이해할지라도 그것을 생성할 수는 없지만 무엇인가를 생성할 수 있다면 그 무엇인가에 대해서 완벽하게 이해하고 있다는 뜻입니다. 그래서 자연어 처리에서 이러한 생성 인공지능이 가능해지게 된 계기는 대형 언어 모델 다시 말해서 LS 랭귀지 모델이라고 표현을 할 것이고요. 본 강의를 통해서 LLM이라고 제가 무의식적으로 얘기를 하게 되면 바로 이 대규모 언어 모델이라고 생각을 하시면 되겠습니다. 이 LS 랭귀지 모델은 텍스트를 입력으로 받아서 적절한 출력을 산출하는 언어 모델입니다. 이 라즈 랭귀지 모델은 보시는 바와 같이 대량의 텍스트 데이터로 먼저 사전 학습 이해를 하기 위한 학습을 한 뒤에 무엇인가에 대한 아웃풋을 이렇게 남겨주는 것을 의미를 합니다. 입력이 텍스트로 들어오고요. 중간 단계의 대형 언어 모델이 있고요. 그리고 이후에 텍스트에 대한 출력이 있는 겁니다. 이러한 이 모델은 여기서 우리가 이제 여러분들이 이전 강의들을 통해서 많이들 배우셨겠지만 머신 러닝에서의 파라미터라는 용어는 학습을 통해서 최적화를 해야 되는 대상입니다. 그런데 그 파라미터가 수십 개 수백 개 수천 개 수준이 아니라 빌리언 스케일이니까 수십억 개 수준의 학습이 필요한 파라미터가 존재한다라는 미지수가 존재한다라는 뜻입니다. 이러한 라지 랭귀지 모델은 발전이 인스트럭트 지피티와 챗 g피티 출연 이후에 활발히 연구되고 적용되고 있습니다. 학습을 어떻게 하면 잘 시킬 것인가에 대해서는 학습 대상이 되는 코퍼스를 정지하는 것 그리고 인스트럭션 자체를 어떻게 하면 잘 주었을 때 학습이 더 잘될 것인가에 대한 연구 그리고 활용 관점에서는 의료 분야에 대한 활용, 법률 도메인에 대한 적용 또는 서비스를 적용하는 데 있어서 사용이 되고 있고요. 그다음으로는 지금 이 빌리언 스케일이기 때문에 한 번 모델을 학습하고 활용하는 데 있어서 굉장히 많은 리소스를 사용을 합니다. 여기서 리소스라는 거는 하드웨어 그리고 더 나아가서는 전력이겠죠. 그래서 추론 속도와 메모리 사용량을 최적화하는 부분, 입력 문장의 길이를 확장하거나 줄이는 부분에 대한 연구도 활발히 진행이 되고 있습니다. 그러면 이 라즐 랭귀지 모델이 갑자기 하늘에서 뚝 떨어진 것이 아니기 때문에 자연어 처리의 모델이 어떻게 발전했는지 내추럴 랭귀지 프로세싱의 모델 발전을 간단하게 말씀을 드려보겠습니다. 가장 먼저 시도되었던 거는 통계적 언어 모델입니다. 스테티스티컬 랭귀지 모델이라고 표현이 되는데요. 이거는 통계와 어휘 빈도를 가지고 백업 워즈라는 말을 들어보셨을 겁니다. 오른쪽 그림에 보자면 이러한 하나의 문장을 또는 문서를 여러 단어들의 조합으로 잘라내고 각각의 단어들이 몇 번 등장했는가를 카운팅을 해서 숫자를 세서 어떤 문서를 1년에 100호로 연속형의 숫자 100호로 만드는 것입니다. 이러한 방식에는 텀 프리퀀시 인버스 다큐먼트 프리퀀시로 표현되는 tfidf라든지 bm25와 같은 방법론이 있습니다. 그러나 이러한 모델들은 검색 시스템과 관련해서 또는 매우 제한적으로 이제 특정한 테스크에 적용이 되어 왔고요. 특정한 시스템을 적용하기 위해서는 굉장히 많은 엔지니어링 비용이 소모가 되었습니다. 소위 말하는 전처리가 굉장히 많이 들어간다라는 얘기죠. 시스템 전용의 단어 사전을 구축을 해야 된다든지 또는 a라는 시스템에서 만들었던 모델을 b라는 시스템으로 옮겨갈 수 있는 전이가 불가능하다든지 또는 단순히 어떤 단어를 카운팅만 하는 것이기 때문에 의미가 가지고 있는 부분이 숫자에 반영이 되지 않는다. 이러한 굉장히 많은 단점들이 존재했습니다. 이후 뉴럴 네트워크를 이용한 랭귀지 모델이 나오면서 한 단계 발전을 합니다. 딥러닝 기술을 자연어 처리 분야에 적용한 것이고요. 단어의 의미를 단순히 그 단어를 몇 번 등장했는지를 카운팅을 하는 게 아니라 학습을 통해서 고정된 크기의 벡터의 표현을 하는 겁니다. 대표적으로 워 투 백 또는 글러브라는 부분들이 있겠죠. 오른쪽 아래 그림을 보시면 워먼이라는 단어와 맨이라는 단어가 이러한 3차원 좌표기에 표현이 되었을 때 워먼과 맨과의 벡터 공간 사이의 거리는 퀸과 퀸과의 벡터 공간 사이의 거리를 굉장히 비슷하게 표현하고 있습니다. 이 말은 무슨 얘기냐 결국 그 두 조합 간의 차이는 성별이 여성이냐 남성이냐의 차이만 있는 것이지 나머지 부분들은 굉장히 같습니다. 이렇게 차이가 나는 부분에 대해서 벡터 공간상에서의 숫자의 차이 디퍼런스로 표현이 될 수 있다는 얘기입니다. 그래서 통계적인 기반 학습에 비해서 언어 모델에 비해서 감성 분석을 포함한 좀 더 확장된 테스크에 적용이 가능해졌고요. 사전 학습이 된 언어 벡터 다시 말하면 인터넷에 있는 여러 가지 문서를 통해서 웜먼의 벡터가 무엇이고 맨의 벡터가 무엇인지를 활용을 해서 사전 학습된 벡터를 활용하기 때문에 특정한 시스템을 구축하는 데 있어서 처음부터 프롬 스크래치로 학습을 하는 게 아니라 여기에서부터 시작하는 초기 값으로 활용을 할 수 있다라는 얘기입니다. 또한 시스템별 별도 모델 구축과 학습이 필요하다라는 단점은 여전히 존재를 하고요. 그렇기 때문에 여전히 시스템 간의 전이가 불가합니다. 또한 단어가 가진 의미는 고정된 길이의 벡터의 연속형의 숫자로 표현이 되지만 단어 사이의 맥락을 반영하는 건 불가능하다라는 얘기입니다. 이 말은 무슨 얘기냐 특정 단어가 앞뒤에 어떤 단어들과 사용이 됐을 때 긍정적인 뉘앙스로 쓰일 수도 있고 부정적인 뉘앙스로 쓰일 수도 있는데 그러한 맥락을 반영할 수가 없다라는 얘기죠. 그다음 단계가 사전 학습된 랭귀지 모델입니다. 대량의 코퍼스로 사전 학습된 언어 모델을 사전 학습을 하고 이거를 특정한 테스크에 미세 조정을 하는 파인 튜닝을 하는 방식입니다. GPT가 나오기 전에 발표되었던 버트라든지 t5 이런 모델들이 모두 사전 학습된 모형이고요. 그림에서 보시는 것과 같이 프리 트레인용 코퍼스를 가지고 문서 대규모의 문서 집합을 가지고 버트와 지피티와 같은 언어 모델을 한 번 러프하게 학습을 한 다음에 어떤 특정한 테스크에 특화된 데이터 이게 감성 분석이 될 수도 있고요. 또는 neto 랭귀지 인퍼런스가 될 수도 있습니다. 이러한 테스크를 수행하기 위한 데이터의 데이터를 활용을 해서 한 번 더 파인튜닝을 하는 방식입니다. 이렇게 함으로써 다양한 테스크에 적용이 가능이 되고요. 사전 학습을 통해 습득된 언어를 정복할 수가 있습니다. 그리고 이걸 위해서는 태스크별로 파인 튜닝용 데이터를 구축하는 게 필요하다라는 문제점은 여전히 갖고 있었고 그렇기 때문에 시스템별로 파인 튜닝을 진행을 하고 유지 보수를 할 필요가 있습니다. 일부 시스템에는 여전히 적용이 불가되는데 챗봇이라든지 글쓰기 코드 생성 눈치 채셨겠지만 지금 이 시스템에 적용이 불가능한 내용들은 전부 무엇인가를 새로 만들어야 되는 다시 말하면 생성을 해야 되는 것들입니다. 챗봇, 창의적 글쓰기 코드 생성 등이 이에 해당합니다. NLP 모델 발전의 마지막 단계로서 대형 언어 모델 라즈 랭귀지 모델이 등장을 합니다. 요 라즈 랭귀지 모델은 대량의 코퍼스를 가지고 아까보다 훨씬 더 많은 파라미터를 모델을 사용을 해서 사전 학습을 수행을 합니다. 그리고 난 다음에 일련의 파인튜닝 과정을 통해서 최종적인 모델 학습을 종료를 하는데 이 라즐 랭귀지 모델이 기존의 언어 모델들과 다른 점은 무엇이냐면 매우 다양한 테스크에 적용이 가능하다라는 점입니다. 이걸 바꿔 말하면 사전에 학습되지 않은 테스크를 수행할 수 있는 능력을 보유한다는 것이고요. 그게 바로 이 그림에서 보이는 프롬포팅을 통해서 가능하게 된 것입니다. 인스트럭션과 프롬프트를 적당하게 주게 되면 사전 학습된 모형이 태스크에 대해서 b라는 테스크를 수행할 수도 있고 a라는 태스크를 수행할 수도 있고 다시 돌아와서 비라는 테스크를 수행할 수도 있다라는 뜻입니다. 이 말은 바꿔 말하면 각 태스크별로 파인 튜닝용 데이터를 구축할 필요가 없다라는 뜻이고요. 입력 문장 다시 말하면 프롬프트 내에서 묘사를 통해 특정한 테스크를 우리가 원하는 방식으로 수행하도록 유도하는 것이 가능해졌다라는 뜻입니다. 대부분의 시스템에 적용이 가능하다는 장점이 생기고 단일 모델을 이용해서 다양한 시스템을 적용하기 때문에 프롬포팅을 통해서 모델의 생성문과 테스크를 제어할 수 있는 역량을 갖추게 되었습니다. 이러한 라진 랭귀지 모델의 장점을 다시 한번 말씀을 드리자면 요약을 하자면 별도의 파인 튜닝 없이 다양한 테스크를 수행할 수가 있습니다. 그렇기 때문에 여러 가지 분야에 적용이 되어서 광범위한 활용 가능성을 보유하고 있고요. 사용자의 입력에 대해서 적절한 테스크를 수행할 수 있는 능력이 갖춰지게 되었고요. 이를 위해서 텍스트 입력을 통해 테스크와 출력문을 이제 제어를 하게 되는 것입니다. 그림에서 보시는 바와 같이 어떤 분류, 감성 분류라든지 또는 문서를 요약하는 것, 창의적인 글쓰기 또는 어떤 특정 언어에 대한 코드를 생성하는 것, 이러한 여러 가지의 테스크가 모두 하나의 언어 모델에 의해서 출력으로 생성될 수 있다라는 뜻입니다. 그런데 요 라즐 랭귀지 모델은 매우 높은 비용으로 인해서 특정한 상황에서만 지금 현재는 사용이 되고 있습니다. 높은 비용이라고 하는 거는 학습을 하는 데 있어서 굉장히 대규모의 하드웨어와 전력이 필요하다는 뜻이고요. 활용을 하는 데 있어서도 에피아 사용료가 상당히 높은 편에 속합니다. 그렇기 때문에 인간 행동 모사가 필요한 경우 챗봇이라든지 또는 테스크가 매우 어려운 경우라든지 또는 데이터가 매우 제한된 경우 마지막으로 사실 정보를 기반으로 생성해야 되는 경우 이러한 경우에 대해서만 현재는 특정한 상황에서 사용되고 있는 현실입니다. 지금까지는 생성형 AI의 자연어 처리 관련된 모형을 말씀을 드렸고요. 지금부터는 생성형 AI의 비전에 관련된 개요를 말씀을 드리겠습니다. 생성형 이미지 모델이라는 것은 이 피 모델이라고 표현되는 것이 바로 이미지를 만들어내는 모델이고요. 이것은 특정한 데이터의 분포를 기반으로 새로운 이미지를 생성하는 모델입니다. 그렇기 때문에 요 생성형 이미지에 학습하고자 하는 목표는 특정 데이터를 생성할 확률인 라이 클리우드를 최대화하는 것이라고 할 수 있겠습니다. 그래서 여기 수식에서 보시자면 sta라는 거는 우리가 학습을 해야 되는 파라미터를 의미하고요. 결국은 x가 데이터의 어떤 분포를 따를 때 세타라는 파라미터가 주어졌을 때 엑스라는 데이터가 만들어질 가능성이 매우 높은 세타를 찾아서 세타 스타라고 최적화를 하겠다라는 뜻입니다. 대표적인 생성형 이미지 모델은 여러 가지 하이어라키와 위계 구조를 가지고 있는데요. 큰 틀에서는 맥시멈 라이크 리드 생성 가능성 또는 생성 우도라고 하죠. 이것을 최대화하는 것을 목적으로 하는데 이것을 데이터의 확률 밀도 함수를 직접적으로 모델링을 하는 익스프레시 댄스티 모형이 있을 수가 있고 이거를 정의하지 않고 생성을 하는 인플리식 모델이 있을 수가 있습니다. 익스플리싯 모델 같은 경우에는 플로우 베이스 모델 그리고 베리어브 오토 인코더와 같은 부분들이 있고요. 또는 이 데이터 밀도 함수를 정의하지 않는 인플레시 댄스티 같은 경우에는 다이렉트로 제너럴티브 어드버스 네트워크 겐이라고 하는 모델이 존재를 합니다. 크게 보면 오늘 이 후반부에서는 생성형 이미지 관련해서 겐 브에 플로우 기반의 모델 디퓨전 모델을 말씀을 드릴 건데요. 큰 그림에서 보자면 겐 같은 경우에는 초록색 스가 실제 데이터입니다. 이걸 통해서 실제 데이터와 스프라임이라고 하는 생성된 데이터가 있을 때 이 데이터를 잘 구분할 수 없도록 원본 이미지와 생성된 이미지가 구분을 잘 안 되도록 굉장히 생성 이미지의 퀄리티를 높이는 게 목표고요. 그래서 둘 사이에 진짜 이미지인지 가짜 이미지인지를 구분하는 모형 디스크리미네이터 판별자가 있고요. 어떤 z라고 하는 어떤 레이턴트 벡터 또는 값으로부터 생성을 통해서 모델을 만들어 나가는 과정이 있습니다. 그래서 제너러티브 어드버서리 네트워크에서는 모델이 두 가지가 있습니다. 생성자와 판별자가 있다라고 보시면 되겠고요. 베리에이셔널 오토 인코더 같은 경우에는 어떤 데이터를 통해서 인코딩 과정을 통해서 정보를 압축해서 레이턴트 베리업을 만들고 벡터를 만들고 이렇게 정보가 압축된 레이턴트 벡터를 통해서 다시 이미지를 생성하게 되는 과정을 거치게 됩니다. 반면에 플로우 기반의 모델은 어떠한 스가 있을 때 이 엑스라는 이미지는 z라는 레이턴트 벡터를 만드는 플로우 함수가 존재할 것이다라는 가정 하에서 이 함수를 학습을 하게 되면 이번에는 z라는 레이턴트 벡터가 주어졌을 때는 역으로 이 함수의 역함수를 이용을 해서 모델을 생성하게 되는 겁니다. 최근에 이제 그 소라를 비롯해서 굉장히 많은 이미지 생성에서 이제 위치를 가지고 있는 디퓨전 모델 같은 경우에는 한 번에 만드는 것이 아니라 한 단계 여러 단계를 거치면서 점점 더 확산이 되는 이러한 방식으로 레이턴트 벡터를 만들었다가 다시 역방향으로 돌아오는 이러한 구조를 가지고 있습니다. 조널티브 애드버스럴 네트워크 겐 같은 경우에는 다시 한번 판별자와 생성자를 적대적으로 학습하는 모델 구조이고요. 여기서 적대적으로 학습한다라는 뜻은 판별자는 무엇인가를 최대화 또는 최소화를 해야 된다면 생성자는 반대로 그 판별자와는 반대되는 목적을 갖고 있기 때문에 적대적이라는 표현을 붙이는 겁니다. 판별자는 입력 이미지가 생성된 가짜 이미지인지 진짜 이미지인지를 판별하는 것을 학습하는 것이고요. 생성자는 잠재변수 z를 입력으로 받아서 학습 데이터의 분포에 가까운 이미지를 생성을 시켜서 판별자가 잘 판단을 못하게 헷갈리게 하는 것을 목적으로 하고 있는 것입니다. 제너러티브 어드버스 네트웍이 초반에 이미지 생성 모형에 있어서 굉장히 큰 이 메인 스트림을 차지했었고요. 그림에서 보시다시피 관련된 연구가 굉장히 많습니다. 아키텍처의 구조적인 측면에서는 네트워크 아키텍처를 바꾸거나 또는 레이턴트 스페이스를 어떻게 다르게 표현해 보거나 또는 애플리케이션을 이제 그 활용하는 관점이 있었고요. 학습 측면에서는 로스 타입을 다르게 바꿔가거나 또는 여러 가지 추가적인 제약을 두어서 레규럴라이제이션 정규화를 하는데 어 중점을 둔 연구들도 존재합니다. 두 번째로 오토 인코더의 계열은 인코더와 디코더로 구성이 되어 입력 이미지를 다시 복원하도록 학습하는 모델 구조입니다. 여기서의 핵심은 여기에 있는 원본 이미지보다 당연히 가운데에 있는 z라는 레이턴트 벡터의 차원이 훨씬 더 줄어들어 있다는 것이고요. 인코더는 입력 이미지를 저차원의 잠재 공간으로 매핑하여 잠재 변수로 변환하는 겁니다. 그래서 x가 주어지면 이거를 z라는 것으로 잘 만들어내는 q 파일을 학습하는 것이고요. 디코더는 잠재 변수를 입력으로 사용해서 원본 이미지를 복원하게 되는 z를 입력으로 받아서 x가 가장 잘 복원이 될 수 있는 p 세터라는 모델을 만드는 것을 의미를 합니다. 오토 인코더의 여러 가지의 변종으로는 잠재 변수의 분포를 정의하지 않는 오리지널 오토 인코더에서 시작을 해서 잠재 변수의 분포, z의 분포를 컨티뉴스하게 연속적으로 정의하는 베리에이션 오토 인코더 또는 잠재 변수의 분포를 이산화하여서 정의하는 벡터 퀀타이즈 베리에이션을 오토 인코더 이렇게 세 가지가 대표적입니다. 세 번째로 플로우 베이스드 모델에 대해서는 입력 이미지를 어떠한 특정한 함수를 통해서 잠재 공간으로 명시적으로 변환을 하고 이거를 반대로 역함수를 통해서 이미지를 복원하는 겁니다. 그림에서 보시는 바와 같이 인코더가 바로 플로우가 되겠고요. 인벌스가 바로 디코더의 역할을 하는 것입니다. 다만 함수는 연속적이어야 되고 미분 가능해야 되며 역변환이 가능한 함수라는 제약을 가지고 있습니다. 변수 변환을 기반으로 구성되어 있는 구조이기 때문에 x의 확률 분포와 z의 확률 분포가 이제 보시는 바와 같이 모두 인터레이션을 했을 때 1의 값을 갖게 될 것이고요. 인퍼런스를 할 때는 x를 통해서 f를 적용을 해서 z를 만들어내고 제너레이션을 할 때는 z를 통해서 이 f 인버스를 통해서 x를 만들어내는 겁니다. 그림에서 보시는 것처럼 이렇게 두 개의 말굽 모양 또는 좌석 유자형 자석 모양이 서로 이제 크로스 되어 있는 이러한 그림에서 레이턴트 스페이스로 변환을 먼저 프라는 함수로 하게 되면 이렇게 만들어진 이 레이턴트 벡터들의 값들을 역변환을 프 인벌스로 하게 되면 원래의 이미지와 비슷한 형태로 만들어진다라는 것을 의미합니다. 플로우 베이스트 모델은 변수 변환을 기반으로 구성되어 있는 구조이기 때문에 목적 함수는 x가 주어졌을 때 이 x의 생성될 확률을 최대화하는 것입니다. 그런데 여기서 보시는 것처럼 로그 p xx가 여기서 로그 p z의 zk로 변환이 되죠. 이거는 잠재 공간에서의 가우션 디스트리뷰션의 생성 확률을 최대화하면서 여기에 있는 볼륨 텀도 최대화하는 것입니다. 그래서 단계별로 이렇게 스에서부터 제1 제2 제케까지 여러 번 반복을 하게 되는 방향으로 진행이 될 수도 있습니다. 마지막으로 디퓨전 모델은 입력 이미지를 포워드 프로세스를 통해서 잠재 공간으로 변환을 하고 여기서 보시는 실선 화살표입니다. 그렇게 해서 변환된 잠재 공간에서의 벡터를 리버스 프로세스 역변환을 통해서 복원하는 구조입니다. 그래서 포드 프로세스는 결국은 뭐냐 점진적으로 가우시 노이즈를 추가해서 마지막에는 실제로 사실은 전혀 그 이미지에 대한 특성은 남아있지 않고 노이즈만이 낀 이 벡터로서 매핑을 하는 것이고요. 리버스 프로세스 같은 경우에는 폴드 프로세스에서 추가된 노이즈를 역으로 추정을 한 다음에 이거를 제거를 하면 원본 이미지를 복원할 수 있다라는 이러한 과정을 통해서 진행되는 모델입니다. 디퓨전 모델은 최근에 굉장히 이미지 생성 관련해서 이제 가장 높은 우수한 성능을 가지고 있기 때문에 다양한 관점에서 연구가 진행이 되어 있고요. 알고리즘 측면에서는 디퓨전 알고리즘 자체를 연구하는 것 또는 다른 생성 모형과의 어떤 연결고리로서 활용을 하는 것 그리고 응용 분야에서 활용을 하는 것 이렇게 세 가지로 구분할 수 있겠습니다. 생성형 이미지 모델의 여러 가지 분야 활용 분야를 한번 말씀을 드리면 첫 번째 스타일 트랜스퍼 두 번째 인페인팅 세 번째는 이미지 에디션 네 번째는 슈퍼 레졸루션 이렇게 네 가지가 대표적이 되겠습니다. 스타일 트랜스포러라는 거는 이미지의 스타일을 다른 이미지에 적용하는 방법입니다. 지금 보시는 것처럼 원래는 그냥 사진인데 이 사진을 특정한 화가의 화풍처럼 변경해 줘라고 하면 비와 같은 그림 또는 씨와 같은 그림 또는 디와 같은 그림이 이제 만들어지겠죠. 디와 같은 그림은 이제 뭉크의 절규라는 굉장히 유명한 그림이지 않습니까? 그러면 원래 사진과는 다르게 어떤 색감이라든지 화풍이 이 뭉크의 그림처럼 이제 만들어지는 것이죠. 이것을 스타일 트랜스포라고 표현합니다. 인페인팅 같은 경우에는 지금 현재 동영상에서 그 보시는 바와 같이 특정 부분을 이미지에서 임의로 삭제를 하더라도 그 이미지가 어느 부분이었는지 어떤 것이었는지를 추정을 해 가지고 다시 복원을 하는 것입니다. 그래서 이미지에 손상된 부분이나 누락된 부분을 복원하거나 채우는 방법이라고 할 수 있겠습니다. 이미지 에디션 같은 경우는 이미지를 변경하거나 개선하는 방법입니다. 오른쪽 그림에 애니메이션에서 보시는 것처럼 원래는 사진인데 이 사진의 얼굴에 있는 사람들의 눈썹을 더 위로 올린다든지 검정색 눈동자를 양쪽으로 굴린다든지 이제 좋은 표현으로 조작을 하는 방식이죠. 슈퍼 레졸루션이라는 거는 저해상도 이미지를 고해상도 이미지로 변환하는 방법입니다. 이거는 특히나 과거에 굉장히 해상도가 낮았을 때 촬영된 원본 영상을 이런 AI 기술 이미지 생성 기술을 통해서 고해상도로 복원함으로써 여러 가지 역사적 사료 또는 추억들을 이제 복원할 수 있는 방법이 되겠죠. 또한 이미지 생성뿐만 아니라 최근에는 멀티모달 생성형 모델들도 연구가 되어 있고 활용 사례들이 나타나고 있습니다. 대표적으로 텍스트 투 이미지 또는 텍스트 투 비디오 또는 이미지 투 비디오가 있겠습니다. 텍스트 투 이미지 같은 경우에는 텍스트를 입력으로 사용을 해서 이미지를 생성하는 것입니다. 오른쪽 그림에 있는 이런 포스터는 이 아래에 있는 인스트럭션이라고 표현을 하죠. 이 문장을 통해서 생성된 이미지를 뜻하고요. 여러분들도 챗gpt나 달리를 쓰시면서 이런 것들을 한 번씩 다 해보셨을 겁니다. 여기에 더해서 텍스트 비디오라는 거는 텍스트를 입력으로 해서 비디오를 생성하는 겁니다. 사실 비디오라는 거는 스냅 샷으로 촬영된 이미지의 여러 프레임의 연속적인 결합이기 때문에 이미지를 생성하는 것과 비디오를 생성하는 것 자체는 큰 틀에서는 공통적인 부분이 많다라고 할 수 있겠습니다. 이미지 2 비디오 같은 경우에는 이미지와 프롬프트 텍스트를 사용해서 비디오를 생성하는 겁니다. 원본 이미지를 주고 이거에 대한 어떤 인스트럭션을 주면 여기에서 나오는 이런 과학자 또는 그 중세의 어떤 사람들이 사진인데 손을 이렇게 흔들어 주세요라는 인스트럭션을 통해서 손을 흔드는 모습을 볼 수가 있는 것입니다. 여기까지가 생성 모델에 대한 자연어 처리 비전 관련된 간략한 개요였고요. 지금부터는 생성 AI 모델의 활용 사례를 설명을 드리도록 하겠습니다. 언어 지능 측면에서는 챗gpt와 지피티 시리즈를 설명을 드릴 것이고요. 이미지 관련해서는 달리 3와 테이블 브리퓨전에 대해서 설명을 드리겠습니다. 챗gpt는 GPT 3.5 그리고 gpt4 기반의 챗봇형 LLM 서비스고요. 2022년 11월 gpt3의 데모 형태의 서비스로 최초로 시작을 했습니다. 불과 1년 3개월 정도 지났는데 너무나도 폭발적으로 지금 현재 발전을 하고 있죠. 단순 대화라든지 문서 요약, 자기소개서 첨삭 등의 다양한 기능을 제공하고 있고요. 프롬프트를 통해 요구 사항을 입력해서 동작을 하는 원리입니다. 단일 모델을 이용해서 다양한 기능을 가능하게 하는 이제 API 서비스고요. 인스트럭션 튜닝과 같은 프리 트레이닝 이후에 추가적인 학습을 진행함으로써 보다 더 사용자가 요구하는 것을 명확하게 구현할 수도 있게 되었습니다. 프롬프팅은 LS 랭귀지 모델에게 원하는 작업과 실제 입력 값을 제공하는 방식으로 이제 예시를 주는 것입니다. 우리가 공부를 배울 때 또는 아이를 가르칠 때 하는 방식과 동일하지 모델의 테스크와 출력문을 제어하는 것이고요. 프롬프트의 구성 요소는 크게 세 가지입니다. 인스트럭션, 데모 스트레이션 인풋입니다. 인스트럭션은 태스크 수행을 위해서 구체적으로 지시하는 것이고요. 오른쪽 예시를 보시면 다음 예시를 보고 리뷰가 영화에 대해서 긍정적인지 부정적인지 판단해 줘라고 한 뒤에 답변에 대해서까지 확실하게 인스트럭션을 주죠. 니가 해야 되는 답변은 긍정 또는 부정으로만 판단해줘 뉴트럴 다시 말하면 중립은 없다라는 것입니다. 이런 식으로 인스트럭션을 주고 데모스트레이션 다시 말하면 이걸 이제 퓨샷 러닝이라고도 표현을 하는데요. 해당 태스크의 실제 예시인 입력과 출력 쌍을 줍니다. 입력을 영화 너무 재미없어요라고 하면 이거는 부정이다. 시간 가는 줄 모르고 봤어요라고 하면 이것은 긍정이다 라고 몇 개의 샘플을 준 다음에 마지막으로 인풋을 줍니다. 자 배우들 연기가 너무 좋았어요. 여기에 대해서 레이블 또는 긍부정은 무엇이니라고 물어보면 챗지피티가 여기에 대해서 긍정이라고 답변을 해줄 수 있다라는 뜻이죠. 이러한 챗지피티는 사용자 요청에 따라서 필요한 기능을 호출하여 사용을 하는데 요새 리트리벌 어그맨티드 제너레이션이라는 표현을 들어보셨을 겁니다. 단지 학습을 하는 데 있어서 사용된 데이터에는 포함되어 있지 않은 정보라면 외부 정보가 필요하기 때문에 이 경우에 챗gpt는 오픈 에아가 마이크로소프트의 투자를 받은 회사이기 때문에 빈 검색 엔진을 통해서 웹 검색을 하게 됩니다. 또는 코드를 실행을 해야 될 경우에는 파이썬 코드를 작성하고 거기에 대한 결과물을 이용을 합니다. PDF 데이터를 입력으로 받을 경우에는 PDF를 펄싱을 해서 텍스트 데이터로 변환을 합니다. 예시를 보시면 2월에 제주도 여행을 가고 싶은데 혼자서 조용히 다녀올 만한 곳이 있을까 필요하면 검색해서 알려줘 라고 물어봤을 때 사실 2024년 2월에 어떤 곳을 가고 싶은지에 대해서는 잘 모를 수도 있으니까 그러면 여러 장소와 활동을 추천드립니다라고 하면서 서치를 통해서 문서를 먼저 검색을 하고 그 검색에서 요약을 해서 리턴을 해주는 방식으로 사용이 됩니다. 챗츠피티는 웹상에서만 접근 가능하기 때문에 서비스가 활용이 불가능했는데 지피티 3.5와 4는 API 콜을 통해서 활용이 가능했습니다. 또한 동일 모델에 대해서 지속적인 훈련과 업데이트를 진행하기 때문에 API 네이밍 컨벤션을 통해서 활용 가능합니다. 지금 보시는 예시처럼 지피티 40613이라고 표현이 되면 지피티4 모델을 기반으로 했고 출시일이 2023년 6월 13일 버전이라는 뜻입니다. 지피티 3.5와 4의 API는 API에 따라서 다양한 요금을 책정하고 기능을 제공하고 있습니다. 지피티 4는 기본적인 API로서 다양한 활용이 가능한데 지피티4 32k 같은 경우에는 gpt4의 API 대비 긴 입력과 출력이 가능합니다. 바꿔 말하면 기본 API에서는 대략 8192개의 토큰까지를 입력을 할 수 있다면 gpt4 32k 같은 경우에는 3만 2768토큰까지도 입력이 가능합니다. 이것은 수행 테스크가 긴 문서를 필요로 하는 경우에 사용이 가능하고 법률과 금융 문서를 요약하는 데 굉장히 유용하게 사용될 수 있습니다. 지피티 4 비전은 이미지 데이터를 입력을 할 수 있습니다. 이미지와 텍스트 입력을 동반하는 경우에 사용이 가능하고 이미지 캡셔닝 같은 기능을 사용하는 데 있어서 필요한 에피아라고 볼 수 있겠습니다. 지피티를 활용한 서비스에서는 예를 들어 스펙이라는 이제 서비스 같은 경우에는 AI를 이용해서 영어 회화를 도와주는 애플리케이션입니다. 사용자의 입력문에 대해서 지피티 API를 이용해서 답변을 생성을 하는데 자연스러운 응답을 구성해 주고 영어와 한국어의 이해와 생성이 가능하고 필요할 경우에는 내부 에피아를 이용해서 학습을 유도할 수도 있습니다. 여러분들이 많이들 아마 사용하실 금융 서비스인 토스 같은 경우에는 AI를 이용해서 경제 뉴스를 요약하고 분석해 줍니다. 경제 뉴스에 대한 요약을 제공하고 해당 뉴스로 인한 기업 주가 영향도 분석을 해 줌으로써 자동화된 서비스를 제공하고 있고요. 대량의 뉴스를 분석할 수가 있고 주식 서비스를 이용할 경우에는 여기에 대한 사용자의 추가적인 어 분석 정보를 제공해 줄 수 있게 됩니다. 역시 여러분들이 많이들 쓰고 계시는 배달의 민족 같은 경우에도 AI를 이용한 메뉴를 추천합니다. 사용자가 본인이 원하는 메뉴와 관련된 상황을 입력을 하게 되면 각 사용자에 대한 적절한 메뉴를 추천하는 것이 가능해질 뿐만 아니라 메뉴에 대해서 안내를 통해서 구체화된 추천도 역시 가능하게 됩니다. 하이퍼 클로바 스를 활용한 서비스도 존재합니다. 클로바 포 라이팅이라는 서비스는 네이버 블로그를 작성하는 보조 도구로서 사용이 됩니다. 글 초안을 작성해 줄 수가 있는데요. 사용자가 제시한 키워드를 기반으로 블로그 글에 초안을 작성해 주고요. 또는 블로그에 글감을 추천하는 기능은 사용자가 제시한 키워드를 바탕으로 작성된 글의 목차를 작성하게 됩니다. 사용자별 어휘와 말투에 적합한 블로그 글을 작성하게 될 수 있게 되죠. 이미지 관련해서는 달리와 스테이블 디퓨전을 이용해서 많이들 이제 그 서비스가 되고 있는데 달리는 텍스트 투 이미지를 위해서 제한된 모델이고요. 달리 쓰는 이미지 내에서 더 나은 캡셔닝을 생성하기 위해서 제안된 모델입니다. 오픈 AI에서 제공하는 API를 통해 사용 가능하고요. 챗집 비티를 통해서도 유료 결제를 통해 사용 가능합니다. 달리를 챗지피티를 이용해서 사용하는 예시를 한번 보여드리는 겁니다. 여기서 있는 유라고 되어 있는 부분이 우리가 프롬프트를 입력하게 되는 부분이 되겠고요. 이렇게 프롬프트를 입력을 하게 되면 사진을 한 장만 주는 것이 아니라 보통 한 4장 정도를 3장 또는 4장을 샘플로써 생성을 해서 제공을 해줍니다. 여기서 보시는 것처럼 대화형으로 만들 수도 있겠죠. 궁금한 표정을 하고 있는 간단한 이모티콘을 그려줘라고 했을 때 이러한 이모티콘은 그려졌지만 여기 보면 입 대신에 물음표가 있으니까 입이 없으니까 이상하다 손으로 궁금함을 표현하고 있는 이모티콘으로 다시 그려 달라라고 하면 거기에 대해서 대응을 해서 이제 다시 사용자가 원하는 이미지를 생성해 줄 수 있습니다. 마찬가지로 뭘 깨닫는 것처럼 놀란 표정을 그려달라, 무언가를 깨닫는 표정으로 그려 달라 이런 식으로 계속적으로 스텝 바이 스텝으로 사용자의 요구 사항을 반영해서 생성되는 이미지를 개선시켜 줄 수 있는 기능도 제공을 합니다. 스테이브 디퓨전 같은 경우에는 레이턴트 디퓨전 모델은 스테빌리티 AI와 럼 웨이에서 제안된 모델이고요. 현재 사용되는 스테이브 디퓨전의 기반이 되는 모델입니다. 컨디셔닝 메커니즘을 통해서 이미지뿐만이 아니라 다양한 조건을 통해서 이미지를 생성을 하게 됩니다. 이거는 뒤에서 디퓨전 시리즈 설명을 드릴 때 더 말씀을 드리겠습니다. 이 허깅페이스의 스태빌리티 AI 같은 경우에는 지속적으로 새로운 모델과 코드를 오픈 소스로 공유하여 직접 사용이 가능합니다. 아까 보여드렸던 달리 같은 경우에는 에피아를 통해서 클로드 된 모델이고 우리는 활용만 할 수 있지만 스테이브 비퓨전은 직접 이거를 이용을 해서 코드까지도 활용을 할 수 있는 오픈 소스 모델이라는 뜻입니다. 스태빌리티 AI 홈페이지를 통해서 다양한 이미지의 생성 경험이 가능하고 유료로 결제할 경우에는 사용자가 굳이 코드까지 내가 학습시킬 필요 없이 나는 그냥 내가 원하는 이미지만 이것저것 많이 만들어 보고 싶다라는 목적을 가지고 있다라고 하면 유료 결제를 할 경우에는 더 많은 기능을 경험할 수 있는 이 서비스입니다. 또한 스테이블 디퓨전은 웹 UI를 통해서 사용자 서버에 이거를 구성할 수가 있습니다. 바꿔 말하면 내가 어떤 서비스를 구현하는 데 있어서 스테이블 디퓨전을 활용을 해서 나의 서비스에 녹여낼 수 있다는 뜻이죠. 사용자가 생성 파라미터를 조절 가능하거나 새롭게 다운받은 모델을 적용할 수 있거나 데이터를 추가로 학습할 수 있거나 익스텐션을 통해서 공개된 방법을 추가할 수 있는 여러 가지의 확장 기능을 제공합니다. 여기까지 해서 생성 인공지능 특히 언어 지능과 시각 지능에 대한 개괄적인 개요와 활용 사례들을 말씀을 드렸습니다. 네 이것으로 해서 1강의 강의를 마무리하도록 하겠습니다. 감사합니다."
}