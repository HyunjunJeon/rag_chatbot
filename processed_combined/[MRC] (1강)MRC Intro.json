{
  "lecture_name": "[MRC] (1강)MRC Intro",
  "source_file": "[MRC] (1강)MRC Intro_103.mp4_2025-12-04-104400319.json",
  "text": "네 안녕하세요 카이스트 서민준입니다. 여러분이 들으신 이 수업은 머신 웨딩 컴프레션이라 불리는 수업인데요. 어 좀 궁금해하실 수도 있을 것 같아요. 이게 무슨 수업일까 뭘 하는 수업일까 하나의 슬라이드로 설명할 수 있을 것 같아요. 보시다시피 이 수업을 들으시고 여러분은 저런 질문이 주어졌을 때 저런 답변을 해줄 수 있는 그런 머신러닝 모델을 만드시게 될 겁니다. 실제로 저희 수업을 다 들으시고 나서 챌린지를 진행하실 땐 저 모델의 정확성을 가장 높게 달성하는 팀이 이기는 형태의 챌린지를 진행하시게 되고요. 이 수업을 다 들으시고 나면은 이런 모델을 어떻게 만들 수 있는지 아시게 될 테니까요. 한번 같이 잘 따라와 보시면 좋겠습니다. 네 그러면은 강의 시작하도록 하겠습니다. 네 첫 번째 강의 머신 리딩 컴프레션 인트로와 파이썬 베이직에 대해서 다루도록 하겠습니다. 네 저희 그래서 오늘은 크게 첫 번째 섹션에 세 가지를 볼 텐데요. MRC에 대해서 먼저 간략하게 설명을 드리고 그리고 언어 처리를 하거나 일반적인 NLP에서 항상 필요한 모든 분들이 알고 계셔야 할 유니코드와 토크나이제이션에 대해서 간략하게 인트로를 알려드리고요. 그다음에 저희가 들여다볼 MRC 데이터셋에 대해서 좀 더 자세히 알아보도록 하겠습니다. 네 먼저 엠알씨 인트로입니다. 엠알씨라 하는 것이 무엇인지 알아보고 그리고 저희가 종류랑 평가 방법을 좀 보도록 할게요. 혹시 엠알씨라고 들어보신 적 있으신가요? 이제 머신 리딩 컴프레션의 약자인데 이제 한국어로 굳이 의역을 하자면 기계 독해라고 부를 수 있을 것 같아요. 기계 독해에서는 저희가 지문이 주어지고 이 주어진 지문을 이해하여 그리고 주어진 질의를 답변을 하는 추론하는 문제라고 보시면 될 것 같습니다. 그래서 밑에 보시다시피 왼쪽에 컨텍스트라고 쓰여있는 저 문서가 보이시죠? 저게 지문인데요. 그 주어진 지문 같은 경우는 서울특별시에 대한 위키피디아에 수록된 문서죠. 그래서 서울이 대한민국의 수도고 최대 규모의 도시이고 소재지가 시청이 어디에 있고 등등의 정보가 담겨 있는 문서입니다. 그리고 이 문서에 대해서 사용자가 질문을 던질 수 있겠죠. 예를 들면은 서울의 GDP가 세계 몇 위야 이렇게 물어볼 수가 있을 텐데요. 이랬을 때 저희가 만들고자 하는 모델은 이 두 개를 인풋으로 가지고 최종 답변은 세계 4위입니다라는 답변을 내줄 수 있는 게 목표입니다. 그럼 여기서 약간 좀 궁금해하실 내용이 있을 텐데요. 아까 맨 처음에 보여드렸던 검색창에다가 질문을 넣고 답변을 주는 거와 약간 살짝 다르죠 그렇습니다. 이게 보시면 저희가 먼저 지문이 주어졌다고 가정을 하고 질문을 던진 다음에 답을 낼 수 있는 모델을 만들고 그다음에 저 지문이 없이 저 지문이 또는 아주 거대한 하나의 문서가 아니라 위키피디아 전체라고 했을 때 어떻게 저런 질문을 답할 수 있을지를 보는 거를 섹션 2에서 저희가 들어가도록 할 겁니다. 이번 섹션에서는 보시다시피 질문이 주어지고 이 지문에 대한 질문을 답할 수 있는 모델을 만드는 것을 저희가 목표로 합니다. 그래서 조금 더 저희가 들여다보면요. 사실 말씀드린 것처럼 저렇게 질문이 들어왔었을 때 실제로는 지문이 어떤 지문이 관계가 있는지를 알기 쉽지 않을 수 있습니다. 그래서 저렇게 질문 들어오면은 서치 엔진을 통해서 지문을 찾고요. 그다음에 그 지문 내에서 답변을 찾는 방식으로 실제로는 진행이 됩니다. 그리고 이런 MRC 같은 경우는 실제로 다양한 곳에 쓰이고 있는데 보시다시피 구글 같은 또는 네이버에서 여러분의 질문을 던지면 답을 낼 수 있는 그런 엔진으로도 쓰이고요. 그리고 좀 더 나아가서는 어떠한 대화 시스템 저희가 핸드폰이든지 그게 아니면은 그게 또 다른 어떤 그런 요즘에 많이 유행하는 그런 인공지능 스피커에서 대화를 할 때도 여러분이 질문을 던지면 그 질문에 대한 답을 해주기 위해 관련된 지문을 찾아오고 그 찾은 지문에서 답을 더 세부적으로 찾는 방식으로 보통 진행이 됩니다. 이제 엠알씨를 접근하는 방법론이 여러 가지가 있을 텐데요. 이제 그중 저희가 조금 오늘 특히 오늘과 다음 렉처에 아주 자세하게 들여다볼 부분은 이제 익스트랙티브한 형태입니다. 그래서 이런 익스트랙티브한 형태에서는 질문에 대한 답이 항상 주어진 지문에 세그먼트나 스팸으로 존재를 하게 됩니다. 가장 큰 예 중 하나가 시앤 데일리 메일이라는 데이터 셋인데요. 보시다시피 저희가 그 질문 퀘스천 퍼듀 x n 프레스 체인지 어겐스트 앤트 이리 히 라이어 사이즈 이렇게 써 있잖아요. 그럼 저기 보시면 저기서 답변이 NTT 193인데 이게 항상 컨텍스트 내에 존재를 해야 한다는 그런 조건이 있습니다. 또한 약간 이런 경우는 보시다시피 근데 저희가 질문을 던진다기보다는 질문에 중간에 어떤 단어를 빼고 그거를 알아맞히는 형태로 게임이 진행이 되잖아요. 그래서 이런 걸 보통 클로스 테스트라고 하는데 이제 엄밀하게는 퀘스천 앤서링은 아니고요. 퀘스천 앤서인 같은 경우는 아주 비슷하지만 저 질문이 더 이상은 저 빠진 단어 알아 맞추는 방식이 아니라 이제는 실제로 질문 형태로 들어오게 돼요. 그래서 영어로 보시면은 바이 메인 컴퓨테이션 프로 컴퓨테이셔널 컴플렉스 피어 이렇게 써 있고요. 이거에 대한 답변이 헤 디프커티라고 써 있는데 이거에 대한 답변이 항상 저 컨텍스트 지문 안에 존재한다는 가정으로 문제를 저희가 진행을 하게 됩니다. 이런 방식을 채택하는 데이터셋 같은 경우는 스쿼드와 콜 쿼드 뉴스큐에 내추럴 퀘스천 같은 영어 데이터 셋 및 한국어 데이터셋 여러 개가 있고요. 그리고 이제 조금 다른 방식의 퀘스천 엔트링 데이터셋이 있는데요. 저희가 지금까지는 답변이 항상 지문 내에 존재한다고 가정을 했다면 사실 꼭 지문 내에 존재한다는 가정이 맞다는 건 아니에요. 사실 어떤 경우에는 답변이 지문 내에 없을 수도 있겠죠. 그래서 어떤 경우는 조금 더 디스크립트 내레이티브한 앤서 데이터셋이라고 불릴 수 있는 즉 답이 지문 내에서 추출할 수 있는 스팸 형태가 아니라 아주 폼이 자유로울 수 있는 또는 생성된 센테스 형태를 가지고 있는 경우가 많습니다. 그래서 보시면 이런 데이터셋의 예제가 ms 마커나 내리티브 QA인데요. 여기서 퀘스천이 와이드 레이처 CSN 라이언 어블리게이션 인듀얼라고 써 있고요. 이거에 대한 답변이 보시면 웨이처 컬스 라이트 오브리게이션 인 이렇게 쭉 내려가죠. 이 엔서가 위에 주어진 지문 내에 어디에도 포함돼 있지 않거든요. 하지만 이 답변 자체가 맞을 수도 있겠죠. 그래서 보시면 이런 답변을 생성을 해내는 형태의 테스크로 보통 진행이 됩니다. 그리고 마지막으로는 조금 최근에는 많이 쓰이고 있지는 않지만 특히나 이런 방식은 사실 좀 퀘스처 엔서링을 모델을 만드는 차원에서는 조금 적합하지 않기 때문에 쓰이지 않고 있어요. 근데 또 하나의 방법론은 머티포 초이스 데이라 세트라고 할 수 있는 질문이 주어졌을 때 가능한 여러 개의 초이스를 주고요. 그 초이스 내에서 에이전트가 또는 그 머신이 고르는 방식의 형태가 되는 데이터 셋이 또 있습니다. 그래서 이런 경우의 예제가 엠씨 테스트 레이스 얼크 이런 경우에 데이터셋들이 있는데요. 보시면 좀 다르죠. 이제 저희가 질문이 wise 네임 o TV making tro 이렇게 질문이 나왔을 때 예전과 같이 어떤 주어진 지문 내에 존재하는지 또는 지문 내에 없다 하더라도 프리폼으로 제너레이트 하는 형태가 아니라 보시다시피 가능한 초이스가 여러 개 주어지고요. 이 경우는 4개가 주어지죠. a랑 b랑 c랑 d 그리고 이 중에 하나를 고르는 방식으로 문제를 진행하게 됩니다. 사실 MRC라는 데이터 셋은 언제부터 시작했느냐를 정의하는 건 사람마다 조금 다르긴 하겠지만 2013년에 나왔던 엠씨 테스트 방금 보여드렸던 멀티플 초이스 테스트를 시작점 중 하나로 보는 분들이 대다수고요. 그렇게 봤었을 때 이제 엠씨 테스트는 사실 많은 분들이 수능이나 이런 시험에서 찾아볼 수 있는 그런 지문 이해 지문 답변 그런 문제들이랑 비슷하죠 이런 형태로 시작을 해서 저희가 딱 보시다시피 매해 갈 때마다 더 많은 데이터셋을 공개를 하고 사람들이 만들고 또 쓰이게 됐어요. 그래서 상당히 지금도 아주 활발하게 연구가 일어나는 분야고요. 무엇보다 MRC라는 테스크는 말씀드린 바와 같이 주어진 질문에서 질문에 대한 답변을 하는 방식이지만 이거를 응용을 하게 되면은 지문이 주어져 있지 않은 상태에서 질문이 들어와도 그 질문에 관련이 있는 지문을 웹상에서 찾아가지고 답변을 줄 수 있는 형태로 즉 퀘스천 앤서링 시스템을 만들 수 있기 때문에 상당히 유용해서 커뮤니티나 리서치 커뮤니티나 아니면 또는 산업계 윈더스트리에서도 아주 많이 애용되고 있고 상당히 많은 분들이 연구하고 있는 분야입니다. 그래서 보시다시피 2018년쯤부터는 아주 많은 수의 이런 MRC 데이터셋들이 공개되는 걸 보실 수가 있고요. 그러면 MRC 데이터셋에서 가장 어려운 점들이 무엇일까요? 저희가 이런 테스크를 할 때 실제로 문제 즉 이 문제를 해결하기 위해 정말 신경을 써야 될 부분들이 여러 가지가 있는데요. 이제 그중 하나는 단어들의 구성이 유사하지는 않지만 동일한 의미의 문장을 이해해야 될 때입니다. 그래서 보시다시피 일종의 페어 프레이징 즉 같은 문장 같은 의미의 문장이지만 다른 단어로 이루어져 있는 경우를 말하는 건데요. 어 저 질문을 보시면 이제 페어 페이징이라는 저 박스의 질문을 보시면 와이즈 더 네임 포 더 퍼 후 셀렉트 폴더 미션 이렇게 써 있고요. 이 패시지에 보시면은 컬리 셀렉티드 포 미션 이렇게 써 있어요. 근데 이제 밑에 또 패사지 투에 보시면은 제임스 코 후 애프터 리트리빙 샘플즈 이즈 더 찬스 투 고 백 인 타임 투 나인틴 나인스 앤 파인드 인포메이션 어바웃 이렇게 써 있죠. 패시지 1이랑 2가 둘 다 답변을 갖고 있지만 패세지 원 같은 경우 비교적 좀 쉬운 지문이라 볼 수 있어요. 왜냐하면 저희가 퀘스천에 존재하는 단어와 매치하는 단어들이 패시지에도 존재를 하죠. 세닥티드라든지 미션이라든지 이런 단어들을 저희가 클루로 사용을 해서 쉽게 답변을 낼 수 있을지도 모르지만 모델 입장에서 하지만 이제 패시지 2에서는 보시다시피 직접적으로 저런 셀렉티드라든지 미션이라는 단어들이 나오지가 않습니다. 그래서 이것들이 결국에는 다른 단어를 활용함으로써 좀 페어 프레이징이 어려워진 부분들이 있는 거죠. 특히나 사람도 그렇게 생각할 수 있지만 모델 입장에서는 더 단어가 달라지게 되면은 의미를 갖다고 판단하기 어려울 수 있습니다. 그리고 또 하나의 챌린지는 콜 레퍼런스 레졸루션이라는 이슈인데요. 콜 레퍼런스라는 거는 우리나라로 치면은 그 사람 그것 이런 방식으로 어떤 물건이나 어떤 사람이나 어떤 존재를 이제 지칭하는 그런 용어인데요. 이제 이런 것들을 저희가 활용을 했었을 때 이런 것들이 지문 내에 나왔을 때 실제로 이게 뭐를 지칭하는지를 알기 쉽지 않을 수 있는데 그게 무엇을 지칭하는지를 알아야 지문을 아주 완전히 이해를 할 수 있는 경우가 많습니다. 따라서 이런 코어 레퍼런스 지칭하는 그런 것들을 resove하는 즉 찾아내는 그런 테스크 상당히 중요하다고 볼 수 있습니다. 그리고 또 하나의 챌린지는 MRC에서 이제 저희가 지문이 주어졌을 때 지문 내에 답변이 존재하지 않을 수도 있다는 점이죠. 오른쪽의 예제를 보시면은 퀘스천 원의 위치 러스 페이스 시그니피컨 어퍼지션이라고 돼 있고요. 이거에 대한 답변이 무엇일까요? 이런 모델에 저희가 그런 질문과 질문을 넣게 되면 보통 답변이 저 레이 LS라는 답변이 나오는 경우가 많아요. 왜냐하면 저 레이r LS라는 답변이 모델 입장은 상당히 그럴듯한 답변인데 실제로는 답변이 아닙니다. 즉 이 질문에 대한 답변을 하고 있지 않는 것이죠. 사실은 이 질문에 저 질문에 대한 답변이 없습니다. 근데 이런 경우가 모델 입장에서는 근데 상당히 여러 가지 그런 문법적으로나 여러 가지 요소 때문에 답변이 존재하는 것처럼 보여서 답변을 내는 경우가 많고 저희가 모델을 제대로 만든다면 실제로는 저런 질문이 모델한테 주어졌을 때 답변을 내주는 것이 아니라 모델이 답변이 뭔지 모르겠다고 하는 것이 좀 더 맞겠죠. 마찬가지로 퀘스천 2도 워스 더 네임 9인 세븐 트이라는 질문인데 이것도 마찬가지로 사실은 저 바 이거 프로텍션 액 9인틴 폴리는 실제로 저 질문에 대한 답변이 아닙니다. 하지만 저 트이이라는 단어를 보고 모델이 투이디를 찾는 거죠. 그냥 이게 나인틴 더디 7 트디가 아니라 하더라도 트이디를 찾고 내보내는 경우가 많았습니다. 그래서 이런 경우도 사실 상당히 모델 입장에서는 까다로운 경우라고 볼 수가 있고요. 그래서 이런 경우를 어앤트리블 퀘스천스라고 하는데 결국엔 노앤서인 퀘스천들에 대해서 답변을 주는 그런 페일러 케이스들이 많고요. 또한 이제 특히 최근에 많이 대두가 되고 있는 챌린지인데요. 어떠한 질문에 대한 답변을 주기 위해서는 경우에 따라서는 다양한 정보들을 여러 군데 퍼져 있는 다양한 정보들을 취합을 해서 머티악 리즈닝을 통해서 답변을 내야 되는 경우가 있습니다. 즉 이 질문에 대한 답을 하기 위해서는 문서 하나만 봐서는 답변을 할 수가 없는 것이죠. 그래서 보시다시피 이런 질문 자체가 물론 이런 형태에서는 지금 트리퍼드처럼 돼 있긴 한데요. 빅 옥 트리 스테이 파크 로 키드 앤 즉 이 빅 옥트리 스테이 파크가 위치한 장소를 찾는 것인데 올바른 답변은 미국입니다. 유나이 스테이트 아메리카인데 이거를 찾을 수 있으려면 보시면은 다큐멘트 1 2 3 전부 다 활용을 해야 돼요. 왜냐면은 이제 비국 트리스테이 파크에 대한 정보는 다큐먼트 원에 있고요. 이게 거 커스터 플레인에 있다는 걸 알 수가 있고 다큐먼 2에서는 거 커스터 플레인이 사우드 유나이드 스테이트에 있다는 걸 알 수가 있고요. 다큐먼 3에서는 사돈 유나리 스테이츠는 유나이드 스테이트 아메리카에 있다는 걸 알 수가 있죠. 이거를 복합적으로 저희가 활용을 해서 맨 마지막인 미국이라는 답변이 될 수가 있게 됩니다. 다음으로는 저희가 이런 MRS의 챌린지들을 알아봤고요. 이제는 MRC의 평가 방법에 대해 좀 저희가 알아보도록 할게요. 사실 모든 모델은 저희가 만들게 되면은 어떻게 평가할지를 정의하는 것이 중요하겠죠. MRC는 크게 평가할 수 있는 방법이 두 가지가 있습니다. 이그젝 매치랑 프1 스코어가 있고요. 그리고 실제로 이 두 개 같은 경우는 앞서 말씀드렸던 MRC의 방법 중에서 두 가지의 방법에 많이 쓰이는데요. 익스트랙티브 엔서 즉 답변이 지문 내에 존재하는 경우랑 머터포 초이스 앤서 즉 주어진 초이스 중에 답변을 고르는 그런 방식이 쓰이고요. 그중 나머지 하나인 프리폼 앤서 형태는 이 방법을 쓰기가 좀 힘듭니다. 이작 매치라고 하는 거는 사실상 여러분들이 아시는 정확성 에퀼시랑 똑같다고 보시면 될 것 같아요. 그래서 예측한 답과 그리고 그 데이터 셋에서 주어진 그라운트 루스와 정확하게 일치하는지 보고 일치하게 되면 1점을 주고요. 일치하지 않으면 0점을 줍니다. 그래서 결국 일치하는 샘플의 비율을 찾는 거죠. 그래서 저희가 뭐 총 샘플의 개수가 100개라고 했는데 그중에서 일치하는 개수가 80개다 그러면 아주 간단한 계산인 80%가 이그젝 매치 또는 에퀼시의 스코어가 됩니다. 물론 이렇게 하면은 가장 큰 단점 중 하나는 답변이 조금만 달라도 점수를 못 받는 그런 문제가 생기겠죠. 이거 이런 문제를 결국에는 해결하기 위한 매트릭이 프1 스코어입니다. 보시면 저희가 예측한 답과 그라운트 루스 사이에 오버랩을 좀 소프트하게 계산을 해 가지고 조금 겹치면 파셜 스코어를 주는 거죠. 그래서 보시다시피 프리딕션이 이제 폴 5 데이즈인데 그라운트로스가 만약 5 데이즈였다고 한다면은 EM 스코어 같은 경우는 두 개가 똑같지가 않죠. 폴 5 데이즈랑 5 데이즈는 만약에 여러분이 파이썬에 이 퀄리티를 테스트하게 되시면 당연히 퍼스가 나올 거고요. 그렇기 때문에 EM 스코어는 0점이 되는데 F1 같은 경우는 겹치는 단어가 여러 개 있기 때문에 파셜 스코어를 받게 돼서 0.8점을 얻게 됩니다. 하지만 방금 말씀드린 그런 매트릭은 어떤 디스크립트반 엔서에는 쓰이기 힘든데요. 가장 큰 이유는 보통 디스크립트반 엔서 같은 경우는 아주 완벽하게 일치하는 경우를 찾기 쉽지가 않고요. 그렇기 때문에 대부분의 답이 0점이겠죠. 그러면 F1을 쓸 수 있지 않을까라는 말씀을 하실 수도 있긴 한데 프1도 사실 쓸 수는 있습니다만 이제 조금 더 많이 쓰이는 게 F1 같은 경우는 단어의 오버렛만 보다 보니까 좀 답변 자체에 어떤 언어적인 부분에서 잘 됐나를 좀 보기 힘든 게 있거든요. 그렇기 때문에 실제로는 블루나 루지를 많이 씁니다. 이제 루지 l 같은 경우는 실제로 예측한 값과 그라운트 사이에 오버랩을 보긴 합니다만 이제 그 오버랩을 보는 방식이 단어마다 보는 것뿐만이 아니라 이제 이거에 스코어에 그 정의에 따라서 이제 어떻게 보면 앵그램 즉 여러 개의 단어가 겹치는지 안 겹치는지를 r게스트 커먼 s시퀀스라는 그런 개념으로 이제 찾게 되고요. 블루도 비슷합니다마는 이제 블루 같은 경우는 실제로 저 n이라는 숫자를 정의해서요. 결국에는 엔그램을 실제로 비교를 해가지고 n그램 레벨에서 비교를 해가지고 m그램끼리 겹치는 그런 비율을 계산하게 됩니다. 그래서 보시다시피 실제로 네렉티브 QA 같은 저런 센텐스 또는 디스크립트 엔서 기반의 데이터 셋 같은 경우는 루즈 엘이랑 블루 1 블루 포를 사용하는 걸 볼 수가 있는데요. 그래서 루즈 l 같은 경우는 가장 길게 커머시 시퀀스가 얼마인가 총 길이에 비해서 예를 들면 단어의 길이가 15인데 정답의 단어의 길이가 15인데 거기서 프리딕션과 정답과 겹치는 단어의 서시퀀스의 길이가 10이라고 한다면 15분의 10이 되겠죠. 그러면 3분의 2 즉 67%가 될 거고요. 블루원과 블루 포 같은 경우는 이제 1그램 또는 4그램 레벨에서 몇 개가 겹치는지를 보고 그 겹치는 개수의 비율대로 점수를 계산하게 됩니다. 당연히 이제 저 숫자가 올라가면 올라갈수록 겹치기 쉽지가 않으니 점수는 내려가게 되겠죠. 다음으로는 저희가 이제 지금까지 MRC의 간단한 소개를 봤고요. 이제 다음으로는 유니코드와 토크나이제이션에 대한 소개를 다루도록 하겠습니다. 사실 이 두 개는 MRC뿐만이 아니라 어떠한 종류의 언어 처리를 하시게 되든 상당히 중요한 주제고요. 오늘 배우신 내용을 통해서 당연히 엠알씨 챌린지에서 도움이 되시길 바라고 또 파이썬 일반적인 다루는 그런 스킬에도 도움이 되기를 바랍니다. 먼저 유니코드입니다. 유니코드라는 것은 전 세계의 모든 문자를 일관되게 표현하고 다룰 수 있도록 만들어진 문자 셋인데요. 각 문자마다 숫자 하나에 매핑하게 되어 있습니다. 그래서 보시다시피 저희 유플러스라고 쓰여 있는 앞에 저 캐릭터는 유니코드를 뜻하는 접두어고요. 뒤에 있는 ac00은 16진수로 나타낼 수 있는 코드 포인트입니다. 즉 저 ac00 하나당 저 ac00에 해당하는 저 숫자 하나당 한 캐릭터에 해당한다고 보시면 될 것 같고요. 그래서 오른쪽 예제 보시다시피 캐릭터 에 같은 경우는 유니코드 상으로 유플러스 0041이 되고요. 한글 가 같은 경우는 유플러스 ac00이 되고 처음 보는 이제 표현하기 힘든 문자들도 웬만한 문자들은 전부 다 유니코드가 할당되어 있습니다. 이제 유니코드랑 조금 다른 이제 방법론으로 유티프에이라는 이제 인코딩이 있는데요. 이제 인코딩이라는 건 결국은 문자를 컴퓨터에서 저장 및 처리할 수 있도록 이진수로 바꿔주는 겁니다. 실제로 유니코드를 이런 인코딩을 활용을 해서 많이 쓰이고 있는데요. 유티프에트는 이제 현재 가장 많이 쓰이는 인코딩 방식이고 문자 타입에 따라서 다른 길이의 바이트를 할당한다는 상당히 다이나믹한 방식을 활용을 하고 있습니다. 이게 왜 좋냐면은 저희가 예를 들면 영어를 쓰게 되면은 영어는 보통 스키 내에서 모두 보통 해결이 되거든요. 알파벳을 말하는 거죠. 스키 같은 경우는 저희가 캐릭터의 개수가 256개로 제한을 하고 있기 때문에 바이트 하나 즉 2의 8승 개수만 필요합니다. 그래서 저희가 문자를 1바이트로 모든 걸 나타낼 수 있습니다만 문제는 이제 다른 언어들을 저희가 쓰기 시작하면 사실은 더 많은 비트가 필요하게 되겠죠. 그래서 그때그때 필요할 때마다 바이트를 추가 할당하는 방식으로 효율적인 문자 인코딩을 하게 됩니다. 그래서 이제 2바이트부터는 아라빅이랑 히브류 또는 유럽에 있는 대부분의 언어들을 커버하게 되고요. 세 번째 바이트부터는 이제 비앤피 그래서 사실상 현대 대부분의 글자들을 포함하게 되고 이 4바이트부터는 다른 것들 다른 것들 중에 이모지도 포함이 돼 있습니다. 그래서 이모지도 실제로 유니코드 상에서 존재하고 이걸 utf8으로 인코딩을 하여 활용하는 경우가 많습니다. 네 파이썬에서 유니코드 다루는 건 다 따라서 상당히 중요한 네 스킬인데요. 이제 파이썬 2랑 3리가 좀 많이 달라요. 그래서 여러분이 하실 때에도 상당히 유의하셔야 되는 게 혹시나 이제 어떻게 다루는지에 대한 웹 검색을 하셔 가지고 투에 대한 정보를 가져오게 되시면 3에서는 통하지가 않습니다. 파이썬 3부터는 스트링 타입을 이제 유니코드를 표준으로 사용을 하고 있어요. 그리고 이제 중요한 몇 가지 그런 명령어가 있는데 그중 하나는 ord라는 명령어고요. 오른쪽에 보시다시피 ord라는 명령어를 사용을 해서 이제 하나의 캐릭터에다가 적용을 하게 되면은 이 캐릭터를 코드 포인트 숫자로 변환하게 됩니다. 그래서 a를 넣게 되면 65가 되고요. 실제로 65는 스키에서도 똑같이 쓰이는 utf8 인코딩이기 때문에 이제 똑같은 숫자고요. 이제 가 같은 경우는 한국어다 보니까 상당히 숫자가 높죠. 아까 말씀드린 것처럼 바이트 3까지는 가야 한글이 커버가 되고요. 그리고 CHR이라는 또 명령어가 있는데요. 이건 반대 개념을 보시면 될 것 같습니다. 그래서 숫자를 넣어주시면 그 숫자에 해당하는 캐릭터를 가져오게 되고요. 물론 이런 명령어를 쓰시는 경우가 아주 많지는 않을 텐데 다만 어느 정도 어떤 방식으로 돌아가는지를 알고 계시면 이 프로젝트를 진행하실 때 아주 많은 도움이 되실 겁니다. 유니코드의 중요한 속성 중 하나는 실제로 한글이 상당히 많은 부분을 차지한다는 건데요. 한자 다음으로 많은 개수를 차지하고 있습니다. 그래서 여러분들이 좀 궁금해하실 수도 있는데 어떻게 한글이 그렇게 많은 개수를 차지하나 이 이유는 사실은 완성형으로 한글을 표현할 때 생기는 이슈인데요. 사실 한글은 좀 더 엄밀하게 얘기하면 기아와 같은 초성 이제 이런 중성 종성 방식으로 저희가 그 문자를 분해를 할 수가 있는데 이렇게 되면 사실은 개수가 그렇게 많지는 않겠죠. 가능한 개수가 하지만 이렇게 저희가 분해를 하지 않고 기윽 아 그리고 니은 합치면 간이 되겠죠. 간을 하나의 글자로 보게 되면은 가짓수가 너무 많아지고요. 이렇게 가짓수를 저희가 카운트를 하게 되면은 만 개가 넘어가게 됩니다. 이걸 이제 완성형이라고 볼 수 있는데 이제 이런 방식이 장점이 많기 때문에 그 저희가 활용을 하고 있습니다마는 이제 가장 큰 문제는 결국에는 이런 방식으로 접근하게 되면은 너무 그 개수가 많아진다는 문제가 있죠. 오른쪽에 보시다시피 한국어를 다룰 때 CHR 같은 것들이 그대로 이제 적용이 되고요. 보시다시피 CHR을 활용해서 저런 기획이나 아 같은 거에 좀 어플라이를 하게 되면 보시다시피 이제 숫자를 넣어도 기아가 나오게 되고요. 또 가에 해당하는 숫자를 넣게 되면은 이제 가가 나오게 될 텐데 재밌는 점은 저 이제 덧셈을 해서 저렇게 기억에 해당하는 그 그 숫자와 아에 해당하는 숫자를 둘 다 이제 씨치알로 바꿔준 다음에 플러스를 해줘도 가가 나온다는 이제 그런 걸 보실 수가 있고요. 어 그다음에 어 랭프에 대한 부분을 좀 보시면은 여기서 조합형과 완성형의 차이가 나오는데요. 보시다시피 저희가 봤을 때 같아 보이긴 하지만 실제로 내부적으로는 다르게 처리가 돼 있다고 보시면 될 것 같아요. 그래서 조합형의 경우는 실제로 조합이 된 기획과 아가 합쳐진 조합이기 때문에 랭스를 저희가 계산하게 되면 투가 되게 2가 되게 되고요. 완성형 같은 경우는 저 하나를 글자로 본다고 말씀을 드렸죠. 그러다 보니까 랭스를 계산하게 되면은 랭스가 1이 나오게 됩니다. 그래서 이 부분은 저희가 눈으로는 사실 판단하기 쉽지가 않아요. 그래서 보시다시피 랭스를 보든지 다른 방법으로 판단을 해야 되는 경우가 많습니다. 다음으로는 토크나이징인데요. 어떤 텍스트와 긴 텍스트가 들어왔었을 때 상당히 중요한 것 중 하나가 텍스트를 토큰 단위로 나눈 거라 볼 수가 있습니다. 가장 여러분이 생각하기에 가장 심플한 방법은 뭘까요? 당연히 스페이스를 기준으로 나누는 거겠죠 띄어쓰기 기준으로 띄어쓰기 기준으로 나누는 것은 사실 오랫동안 쓰였던 방법 중 하나인데요. 하지만 요즘 들어서 사실 이게 그렇게 효율적이지 않다고 보통 일반적으로 인식을 하고 있는 경우가 많고요. 그 띄어쓰기가 중요한 딜리미터 즉 나누는 기준이긴 하지만 조금 더 들어가게 된다면은 형태소나 서브 월드 등의 형태로 기준을 바꿀 수도 있습니다. 그래서 이 서브 월드를 예를 들어 보시면요. 왜 띄어 쓰기가 나쁜지를 알 수가 있는데 저희가 만약에 문장이 아버지가 방에 들어가신다라는 문장이 있다고 해볼게요. 보시다시피 아버지 가방에 들어가신다라는 문장이 있었을 때 저희 띄어쓰기로 저것을 나누게 되면은 아버지가 한 단어가 되고 가방 애가 한 단어가 되고 들어가신다가 한 단어가 되겠죠. 하지만 이렇게 이런 방식으로 나누게 되면은 단어가 너무 커져 가지고 단어끼리의 비교가 어려워지게 됩니다. 그래서 좀 더 잘게 자를 필요가 있는데요. 그 토크나이제이션 방법론 중 하나가 서브 월드 토크나이징이라는 방법론인데 결국에는 그 하나의 단어를 한 번 더 들어가서 더 잘게 쪼갠다는 의미죠. 그래서 보시다시피 가방이라는 단어를 가방 그리고 애로 나눴고요. 그리고 들어가신다라는 단어를 들어 가신다 이렇게 하나씩 나눈 걸 볼 수가 있습니다. 근데 또 보시다시피 이게 단순하진 또 않은 게 처음 봤을 때는 한 글자씩 나눠지나 볼 수도 있겠지만 아버지는 그대로 세 글자고요. 그리고 드러는 두 글자죠. 다른 글자들은 전부 다 한 글자인 걸 보실 수가 있고요. 따라서 이게 어떤 길이 기반으로 하는 것은 아니고 자주 나오는 단어인지 아닌지를 보고 나누는 방식이라고 보시면 되고 또 두 번째로 중요한 거는 저 샵 샵이라고 표시돼 있는 게 있죠. 저게 어떤 걸 의미하냐면은 실제로 이 단어와 즉 이 현재 토큰과 그 전 토큰이 원래 텍스트에서는 하나의 단어였는데 두 개로 또는 그 이상으로 나눠졌다는 거를 의미합니다. 그래서 이렇게 토크나이즈를 하게 되면은 좋은 점은 저 샵 샵 방을 보시면 아 이게 어떤 그 바로 직전에 스페이스가 있었던 게 아니라 즉 띄어쓰기가 있었던 게 아니라 어떤 다른 글자가 있었구나라는 걸 알 수가 있고 그럼 반대로 저런 토크나이즈가 된 후에 저 단어들을 봐도 원래 문장을 리커버하기가 쉽겠죠. 샵 샵이 없으면 띄어 쓰고 샵 샵이 있으면 붙여 쓰고 하면 되니깐요. 네 실제로 여기서 쓰였던 서버와 토크나이징 방법론은 이 버트라는 모델에서 제안했던 토크나이제이션 방법이라고 볼 수 있을 텐데요. 보시면은 이제 그 어떤 모델에 해당하는 토크나이저가 항상 있고요. 왜냐하면 모델이 학습할 때 했던 방법 토크나이즈 했던 방법들과 똑같이 여러분이 사용하실 때 토크나이즈를 해야 되기 때문에 토크나이제이션 방법론은 모델의 일부라고 보시는 게 가장 좋습니다. 그래서 보시다시피 코드상에서도 저희가 모델을 불러올 때 버터 토크나이저를 가져오고요. 이게 버터 토크나이저가 해당하는 모델의 이름이 밑에 써 있죠. vt 베이스 BT LNG 케이스트 이렇게 이게 모델의 이름이라고 한다면 이 버트 토크나이저는 이 모델에 귀속된 아주 유니크한 토크나이징 방식이라고 보시면 될 것 같습니다. 물론 버트에서 활용했던 토크나이제이션 방법이긴 하지만 조금 더 이제 일반적인 방법론으로 좀 정리를 하자면 이런 방법론을 저희가 보통은 바이 페어 인코딩이라고 하는데요. 저런 단어를 나누는 방식 자체를 데이터 드리븐으로 간다고 보시면 될 것 같아요. 그래서 오른쪽에서 보시면은 저런 문장에서 시작해서 aa a b d aaa bac라는 문장이 있다고 한다면은 여기서 자주 나오는 캐릭터 시퀀스 두 개짜리씩 새로운 문자로 교체를 해주는 겁니다. 보시면 저거 같은 경우는 a가 두 번 나오죠. 왼쪽에 그리고 중간에도 또 a가 두 번 한 번 더 나오고요. 그래서 이거를 문자가 동시에 두 번 나오니까 이거를 자주 나오는 문자니 우리가 하나의 단어로 인식하자 해서 z라는 단어를 만들게 되고요. 저 z라는 단어는 실제로는 aa인 거죠. 이렇게 하고 나니까 또 다시 보니 a랑 b가 또 연속으로 있는 단어를 보실 수 있죠. 에비를 이제 그다음에는 와라는 단어로 대체하게 돼 가지고 실제로 넣어주게 되면 세 번째인 제와 디 제와 에이스가 되고요. 마지막으로는 어쩌면 저희가 제 와이라는 걸 또 자주 나오니까 하나의 단어로 대체해 줄 수 있겠죠 그래서 zy를 저희가 x로 대체하게 되면은 맨 마지막에 x dy xac가 됩니다. 그럼 저 경우는 x라는 단어는 사실상 글자 4개짜리 단어라고 보시면 되고요. 이런 방식으로 아까 보시다시피 어떤 단어들은 글자가 3개 즉 아버지 같은 단어가 되고요. 서브 월드 토크나이제이션 하고 난 다음에도요 어떤 경우는 저런 a나 c나 d처럼 글자가 하나짜리가 단어가 되는 경우가 됩니다. 그래서 이거를 왼쪽에 보시면은 그거를 좀 더 전문적인 용어로 바이그램이라고 하는데 또는 바이트 페어라고 하는데요. 결국은 매 스텝마다 바이트 페어를 시켜가지고 단어로 치환하는 방식이라고 생각을 하시면 됩니다. 저희가 예전에는 이런 단어를 정의를 할 때 조금 더 레귤러 익스프레션 같은 사람이 직접 고안한 그런 룰을 활용을 해서 단어를 저희가 토크나이즈를 했어요. 근데 이제 이런 방식은 결국은 사람이 직접 룰을 짜기 때문에 한계가 있다고 일반적으로 요즘에는 다 동의를 하고 있고 이런 바이트 페어 인코딩 같은 데이터 드리븐 방법론으로 접근하는 게 더 일반적이게 됐습니다. 자 마지막으로 저희가 데이터 셋을 좀 더 살펴보도록 할게요. 그래서 오늘 저희가 좀 더 자세하게 살펴볼 데이터 셋은 콜 쿼드라는 데이터 셋입니다. 아까 저희가 설명드렸던 보여드렸던 영어 퀘스천 앤서링 MRC 데이터 셋 같은 경우는 스쿼드라는 데이터 셋이었고요. 이런 데이터 셋과 비슷한 형태로 한국어 버전으로 만든 것이 콜 쿼드입니다. 콜 쿼드는 이제 엘지씨엔스에서 개발한 데이터 셋이고요 보시면은 상당히 비슷한 형태를 띠고 있는데 영어 MRC와 실제로 이 도면은 제가 처음에 보여드렸던 도면이긴 하고요. 서울특별시에 대한 질문이죠. 거의 아주 비슷한 형태를 띠고 있기 때문에 영어에서 쓰이는 모델을 그대로 가져와서 한국어에도 쓸 수 있도록 된 점이 상당히 많은 분들에게 실제로 또 빠르게 이 데이터셋에서 작업을 시작할 수 있도록 하는 데 도움을 주었습니다. 조금 더 디테일한 부분들을 보시면요. 콜 코드 같은 경우는 이제 한국어 위키피디아 1550개의 문서를 가져와서 실제로 거기에 하위 1649개 건의 문서들을 클라우드 소싱을 통해 제작을 했고요. 여기서 6만 3952개의 질의응답 사항으로 장을 얻고 이것을 데이터셋에 활용을 하고 있습니다. 물론 이거를 3등분을 했죠. 학습 데이터랑 데브 데이터랑 테스트 데이터 이렇게 학습 데이터가 약 6만 건이고 데브랑 테스트가 6천 4천건 정도 됩니다. 스쿼드와 마찬가지로 라이센스가 상당히 좀 자유롭게 돼 있어 가지고 누구나 데이터를 내려받고 학습한 모델을 제출할 수가 있고요. 그리고 공개된 리더 보드의 평가받을 수가 있었습니다. 그래서 이런 방식 방법론이 결국은 객관적인 기준을 가진 연구 결과 공유가 가능해진다는 점이 상당히 큰 장점이라고 보실 수 있고요. 사실 콜코드 버전이 2개가 있는데 버전 1과 2.0이 있고요. 2.0 같은 경우는 1.0보다 조금 더 문서의 길이가 길고 단순하게 자연어 문장뿐만이 아니라 복잡한 표나 리스트를 포함하는 HTML 형태로 돼 있고요. 그래서 많은 경우에는 문서 전체의 구조에 대한 이해가 필요하고 혹시나 이제 아시는 분들께 첨언을 드리자면 이거는 영어 데이터셋의 내추럴 퀘스처즈와 상당히 형태가 비슷합니다. 실제로 콜코드를 들여다보시면 이런 리더보드가 오른쪽에 보이고요. 보시다시피 점수 EM과 F1 익숙하시죠? 아까 저희가 커버를 했던 그런 리더보드의 매출액들이 존재를 하고 국내 다수의 회사들이 또는 학교에서 참여를 최근까지도 하고 있습니다. 콜 코드 같은 경우는 사실 스쿼드의 수집 방법과 상당히 비슷한 방법을 실제로 따라갔는데요. 먼저 대상 문서를 이제 수집을 했고요. 아까 말씀드린 것처럼 한국어 위키 PDR를 활용을 했는데 여기서 이제 문단 단위로 정제를 해서 이미지랑 표랑 URL을 제거를 했고요. 또한 짧은 문단이나 수식이 포함된 문단은 제거를 했습니다. 그 다음으로는 이 문서들을 크라우드 워커라고 할 수 있는 사람들에게 보여주고 이 문서에 대해서 어떤 질문을 할 수 있을 것 같은지를 물어보는 거죠. 이런 방식을 통해 질문을 생성을 하고요. 그리고 다른 크라우드 워커에게 이 질문에 대한 답이 무엇인지를 물어보고 그럼 오리지널이 질문을 만든 사람이 생각한 답변과 같은지를 확인하는 방식으로 상당히 버리피케이션을 할 수가 있겠죠. 이게 얼마나 좋은 질문인지를 이런 방식으로 약 7만 쌍의 문제와 답변을 생성을 했고요. 어쨌든 중요한 점 중 하나는 사실 방금 말씀드렸던 그런 버피케이션 과정을 포함해서 양질의 질의응답 사항을 생성할 수 있도록 가이드라인을 제공하는 것이 상당히 중요하다고 볼 수 있겠습니다. 그러고 난 다음에 저희가 2차 답변 태깅 즉 이거를 이차 그 두 번째 사람이 자세히 봄으로써 결국엔 답변을 버리피케이션 하는 과정을 거쳤다. 이게 세 번째 2차 답변 태깅이라고 불릴 수 있는 그런 과정이고요. 실제로 이 콜 코드를 활용할 수 있는 방법 여러 가지가 있을 텐데 아까 보여드렸던 웹사이트에서 접속을 하셔가지고 데이터 셋을 다운로드 받으실 수 있어요. 근데 사실 보통 조금 더 추천드리는 방법 그리고 이 수업에서 저희가 좀 더 적극적으로 활용할 방법은요. 허깅페이스라는 이제 NLP 라이브러리가 있는데 이제 여기서 만든 데이터셋을 정확하게 말하면 만든 게 아니라 정제한 데이터셋을 접근하는 방법을 저희가 추천을 드려요. 실제로 상당히 편하게 되어 있고요. 보시다시피 허깅페이스의 트랜스포머즈라는 라이브러리를 먼저 설치를 한 다음에 저런 두 줄의 라인으로 바로 다운받을 수가 있습니다. 그래서 로드 데이터셋이라는 펑션을 먼저 인포트를 하시고요. 그다음에 데이터 셋 이름을 입력하시면 되는데 이 경우는 콜 코드 같은 경우는 버전 1.0은 스쿼드 언더벌 콜 언더바 비원으로 쓰시면 되고 그리고 당연히 저희가 트레인만 가져오고 싶다 하면 스플릿을 지정해 주셔 가지고 저렇게 가져올 수가 있습니다. 그리고 이게 단순하게 다운받기 쉬운 것뿐만이 아니라 어 그 가장 큰 장점 중 하나는 이런 방식으로 데이터 셋을 가져오시게 되면은 스쿼드나 콜 쿼드나 와 같은 MRC 데이터셋을 다 비슷한 방식으로 만들어 놨기 때문에 여러분이 어떤 모델을 콜쿼드를 위해서 만든다 하더라도 아주 쉽게 다른 데이터 셋에 적용을 할 수가 있습니다. 그리고 넘파이 펜더 파이토치 트랜스포 투 등과 호환이 되고요. 그리고 접근 가능한 모든 데이터셋이 메모리 맵이 돼 있고 캐시가 돼 있어 가지고 데이터를 로드하면서 생기는 어떤 그런 비효율적인 메모리 공간 부족이나 전처리 과정 과정 반복에 등의 번거로움 등을 피하실 수가 있고요. 저희가 불러온 데이터셋은 콜 코드 원이지만 콜 코드 버전 2도 불러올 수가 있고 다만 이제 말씀드리고 싶은 부분은 저희가 이 수업에서는 좀 콜쿼드 위주로 보게 되지만 실제로 여러분이 수행하실 챌린지는 콜쿼드랑 비슷하지만 다른 저희가 자체 제작한 한국어 퀘스천 앤서링 데이터 셋입니다. 한 예시를 좀 더 자세하게 들여다볼게요. 사실 아까 보셨던 영어 예시랑 상당히 비슷한 걸 아실 수가 있는데 실제로 콜코어 데이터셋 내부를 보시면 알렉산더 헤이그라는 타이틀을 가지고 있는 문서가 있고 여기에 실제 지문은 알렉산더 메이거스 헤이그 2세는 미국의 국무 장관을 지낸 미국의 군인 관료 및 정치인이다 이렇게 쭉 질문이 가는 걸 볼 수가 있죠. 그리고 이 지문에 종속되는 질문이 여러 개가 있는데 첫 번째 질문은 미국 군대 내 두 번째로 높은 직위는 무엇인가 이렇게 물어보고요. 이거에 대한 답변으로 먼저 텍스트가 주어지고요. 이 텍스트는 아까 말씀드린 것처럼 콜 쿼드도 스쿼드와 마찬가지로 익스트랙티브 한 형태를 띠고 있기 때문에 항상 지문 내에 답변이 존재합니다. 미국 육군 부참모총장이죠. 그리고 또 하나 주어지는 중요한 단서는 이 답변 셋에 앤설스타트라고 하는 저 숫자인데요. 보시면 204라고 되어 있죠 저게 의미가 무엇이냐면은 저 미국 육군 부참모총장이라는 답이 지문 내에서 몇 번째 캐릭터의 시작을 하는지를 알려주는 건데요. 이게 중요할 수 있는 이유가 사실 저 답변이 한 번만 나온다면 사실 문제는 아닐 거예요. 하지만 경우에 따라서는 답변이 당연히 지문 내에서 여러 개가 나올 수가 있겠죠. 근데 그 답변을 유추할 수 있었던 문장이 사실은 하나만일 수도 있어요. 즉 한 문장에서는 이게 답변으로 활용될 수 있는 문장이었고 다른 텍스트 같은 경우는 실제로 그게 나오긴 했지만 답변을 유추할 수 없는 그런 문장일 수 있겠죠. 그래서 이런 것들은 사실 학습할 때 상당히 중요한데요. 저희가 특히나 학습을 할 때 슈퍼비전을 정말 제대로 주기 위해서는 익스트랙티브 QA 데이터 셋 같은 경우는 중요할 수가 있기 때문에 이제 그 스쿼드나 콜 쿼드 같은 경우 엔서 스타트라는 저 숫자를 주어지게 됩니다. 물론 저 숫자가 주어지지 않아도 어느 정도 모델의 학습은 가능하고 이제 이런 경우를 숫자가 주어진 경우를 스트 슈퍼비전이라고 보시면 되고 숫자가 주어지지 않은 경우를 좀 더 디스턴트 한 슈퍼비전이라고 보시면 될 것 같아요. 실제로 이거를 여러분이 주피터나 아니면 터미널에서 프린트 하게 하시게 되면은 이렇게 JSON 형태로 나오게 되고요. 딕셔너리 형태로 나오게 되고 보시다시피 nsus라는 키가 있고 NSS에 해당하는 밸류는 리스트가 돼 있는데 어 보시면은 앤설 스타트와 텍스트가 이렇게 있고 이 각각의 리스트인 이유는 답변이 여러 개가 존재하는 경우도 있기 때문입니다. 이제 사람마다 질문에 대한 답변을 좀 다르게 해석할 수도 있겠죠. 하지만 많은 경우에는 답변이 하나고 실제로 학습할 때는 어차피 저희가 답변을 하나만 볼 거기 때문에 트레이닝 데이터에서는 저 랭스 앤서 스타트나 텍스트에 저 리스트의 랭스가 하나고요. 다만 밸리데이션이나 테스트 데이터에서는 교향곡만이 답변이 아니라고 한다면은 그런다면 다른 것도 답변으로 인정을 해줘야 되니 저 리스트가 랭스가 하나가 아니라 2개 또는 3개 이상의 답변을 포함하는 리스트일 수도 있습니다. 실제로 이걸 좀 통계를 들여다보시면 콜 쿼드의 질문 형태 중에서 가장 많은 부분을 차지하고 있는 게 구문 변형인데요. 아까 말씀드렸던 페어 페이징과 비슷하다고 보시면 될 것 같아요. 어떤 좀 구문이 살짝 단어나 이런 것들이 변경이 돼 가지고 조금 답변하기 어려운 방법으로 만든 것이고 오른쪽에 보시면 좀 더 어휘 변형 쪽이 있는데 이제 이쪽 같은 경우는 유의어나 또는 이제 좀 더 일반 상식을 활용하는 문제들이 있고요. 또는 여러 문장의 근거 활용이 있는데 이거는 20%를 차지하고 있기는 하지만 실제로 이 챌린지를 하시다 보시면 여러 문장의 근거를 활용하는 게 맞긴 하지만 모델이 그 근거를 활용하지 않고도 답변을 내는 걸 보실 수도 있을 거예요. 그리고 조금 더 어려운 쪽으로 논리적 추론 관련된 그런 질문들도 있습니다. 네 마지막으로는 답변 유형인데요. 보시다시피 예상할 수 있는 범위이긴 하겠지만 이제 콜코우더의 답변 유형은 크게 대상 인물 시간 장소 방법 그리고 원인으로 나눠지는데요. 그래서 사실 원인이나 방법 같은 경우는 조금 더 까다로운 문제라고 볼 수 있지만 비교적 차지하는 퍼센테이지가 낮기 때문에 대부분이 시간 장소 인물 대상과 같은 좀 비교적 상당히 구체화할 수 있고 정의하기가 쉬운 형태가 답변이라고 보실 수 있겠습니다. 첫 번째 수업은 여기까지고요. 저희가 다음 수업에는 실제 모델에 대한 강의를 진행을 하고 실습도 포함하도록 하겠습니다. 네 감사합니다."
}