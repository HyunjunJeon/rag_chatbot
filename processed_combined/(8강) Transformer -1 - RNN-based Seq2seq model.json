{
  "lecture_name": "(8강) Transformer -1 - RNN-based Seq2seq model",
  "source_file": "(8강) Transformer -1 - RNN-based Seq2seq model_50.mp4_2025-12-04-103606302.json",
  "text": "네 여러분 안녕하세요 저희 어 머신 러닝 라이프 사이클 강의를 하고 있습니다. 그래서 이번 시간부터 앞으로 이제 세계의 렉처 동안에 트랜스포머라는 모델을 배우는 시간을 갖도록 하겠습니다. 사실 어 여러분들 그 뉴럴넷 많이 요새 사용하신다고 그러고 이제 인공지능이라고 소위 말해 가지고 그런 많은 모델들이 시중에 나와 있는데 요새 가장 잘 되는 모델이 요 트랜스포머고 여러분들이 들어봤던 대부분의 모든 스테이트 오디 ALT 모델들 챗gpt를 포함한 그 모든 모델들이 다 요 트랜스포머 기반으로 된 것들이 많이 있습니다. 그래서 사실 인공지능을 한다라는 말이 사실은 요새는 트랜스포머 모델을 갖다가 쓴다라는 것과 동일한 의미로 사용된다고 생각할 수 있을 만큼 요 트랜스포머가 인공지능 딥러닝 머신 러닝에서는 굉장히 중요한 모델입니다. 그래서 어 오늘은 그 트랜스포머를 배우기 위해서 알앤엔에서부터 시작을 할 거예요. 리커런트 뉴럴 네트워이라는 그런 RNN이라는 모델에서 시작을 해서 이 RNN의 문제점이 뭔지 이 문제점을 해결하기 위해서 트랜스포머를 어떻게 이제 개발하게 되는지 이 어떤 기술적인 역사적인 그런 트레젝토리를 여러분들이 훑어가면서 이 RNN이 뭐고 그거에서 발전된 게 뭐고 그래서 어떻게 트랜스포머까지 가게 됐는지를 이해를 하게 될 겁니다. 그래서 그거를 이제 먼저 보도록 하겠습니다. 먼저 RNN이란 RNN이란 뭐냐면요 자 여러분들 그 뉴럴 네트워크를 저번 시간에 이어서 쭉 배웠잖아요. RNN은 뭐냐면은 이 뉴럴 네트워크은요 저희가 여태까지 배웠던 뉴럴 네트워크는 기본적으로 인풋 투 아웃풋 예측입니다. 그런데 인풋이랑 아웃풋이 시간에 따라 변하지 않는다고 생각을 해요. 이 인풋과 아웃풋이 스테틱한 어떤 성질을 가지고 있습니다. 딱 고정되어 있어요. 근데 세상의 모든 데이터들이 그렇게 고정되어 있지는 않잖아요. 예를 들어서 문장이라든지 아니면 비디오라든지 이런 거는 시간에 따라서 변하고 그리고 문장도 시퀀스드 된 데이터예요. 즉 시계열 데이터라고 그러는데 기본적으로 이 문장이 그 수많은 단어들의 나열로 이루어졌잖아요. 그 월드로 되어있는 단어로 이루어지는 어떤 시퀀스드 된 성질을 가지고 있습니다. 그래서 이렇게 시퀀스드 된 데이터일 경우에 그 데이터의 그런 그 큰 그 긴 데이터들을 기억하는 어떤 오퍼레이션이 필요해요. 그래서 나온 게 RNN이거든요. 그래서 이 RNN을 갖다가 도식하면은 이런 식으로 생각할 수 있어요. 그래서 RNN이라는 블록이 있고 인풋이 들어왔을 때 리커런트한 커넥션이 있어요. 그래 가지고 인풋이 다시 본인의 아웃풋으로 라고 그러니까 아웃풋이 다시 본인의 인풋으로 이렇게 들어가는 이 분홍색의 리커런트한 커넥션이 있다고 가정을 하는 거죠. 그래서 도식화를 해보면은 먼저 인풋이 엑스원이 들어갔어요. 그러니까 스원은 예를 들어서 문장이라고 생각을 해볼게요. 마이 네임 이즈 수 이런 문장이 있어요. 그러면은 그 문장을 갖다가 시퀀스 데이터로 나타내면은 각각의 그 단어들이 이 각각의 x가 되겠죠. my namase so 하면은 첫 번째로 마이가 들어가겠죠. 그래서 마이가 인풋으로 들어가고 그다음에 그 인풋을 통해서 히든 스테이트가 나오고 그다음에 마이 다음에 네임이죠. 마이 네임 그래서 네임이 RNN에 들어가서 이 마이랑 네임을 기억한 히든 스테이트 h2가 나오고 이즈가 그다음에 들어가겠죠. 이즈가 들어가서 마이 네임 이즈를 다 기억하는 치3가 나오고 이렇게 해서 문장 끝까지 쭉 이 시퀀스 된 데이터를 처리할 수 있는 어떤 뉴럴넷이 필요해요. 그래서 만든 게 요 리커런트 뉴럴 네트워크입니다. 그래서 이 RNN의 식을 보면요. 이 RNN을 프라고라고 했을 때 기본적으로 이 RNN은 이 인풋 스티랑 여기 스1이기 때문에 티라는 인덱스를 갖다가 붙였어요. 스티랑 그 전 단계의 히든 스테이트인 티 마이너스 원을 인풋으로 갖고 아웃풋으로는 그 다음 단계의 히든 스테이트 티를 내뱉는 이런 펑션이라고 생각하시면 돼요. 그래서 사실 이 단계에서 봅시다. 인풋은 x2랑 h1이죠. 그래서 아웃풋이 h2가 나왔어요. 그거를 그냥 이렇게 쓴 거예요. 인풋이 x티랑 ht 마이너스 1이 들어가면은 아웃풋은 ht가 나옵니다. 그리고 이걸 갖다가 무수한 번을 반복을 해 가지고 우리가 시퀀스 된 데이터를 프로세싱 하는 거죠. 그리고 여기에 리커런트한 커넥션이 있어요. 그게 무슨 말이냐면요. 이렇게 어 자신의 그 아웃풋을 다시 본인의 인풋으로 받는다는 거예요. 그리고 이 같은 알앤엔을 써서 그 시퀀스 된 그 문장에 있는 그 단어를 갖다가 처리합니다. 이게 되게 중요한 개념이에요. 이 아래에는 항상 같은 웨이 파라미터 더블유를 써 가지고 시퀀스 안에 있는 그 각각의 단어들을 갖다가 처리를 하게 됩니다. 뒤에서 좀 더 자세히 볼 거예요. 그래서 알엔 어 리커런트 뉴럴 네트워크는 시계열 데이터를 처리하기 위해서 만들어진 모델이에요. 자 근데 이 알엔에 장점도 있지만 단점도 있어요. 먼저 장점은 아까 앞 슬라이드에서 설명한 것처럼 그 데이터가 가변적인 길이가 있을 때 즉 길이가 뭐 5가 될 수도 있고 6이 될 수도 있고 10이 될 수도 있고 이렇게 다양한 길이가 들어왔을 때 이런 인풋 시퀀스를 처리할 수 있는 장점이 있어요. 왜냐하면은 그 인풋 시퀀스를 각각의 그 엘레먼트대로 엑스 원 엑스투 엑스를 이렇게 나눠 가지고 그거를 갖다가 안으로 안에 그 인풋으로 받아서 히든 스테이트로 내보내기 때문이죠. 그리고 입력이 많아져도 모델의 크기는 증가하지 않습니다. 왜냐 항상 같은 웨이 파라미터 더블유를 쓰기 때문이죠. 그래서 이론적으로 t 시점에서 수행된 계산은 여러 단계의 이전 정보를 사용할 수 있습니다. 무슨 말이냐면 이 그림에서 이 h3은 실제로 x1 x2 x3에 대한 모든 정보를 가지고 있고 마찬가지로 이 치티는 x1부터 스티까지의 정보를 가지고 있다는 거예요. 이론적으로 티 시점에서 수행된 계산은 그 앞에 있는 모든 인풋의 정보를 압축하는 어떤 벡터가 되죠. 네 그래서 이거를 가능하게 하는 이유는 RNN이 모든 t 모든 타임 스텝에서 같은 웨이 파라미터를 사용해 가지고 디자인 되기 때문입니다. 이게 장점이에요. 근데 중요한 거는 단점이에요. 왜 RNN이 나쁘냐 이 RNN이 단점을 많이 가지고 있기 때문에 트랜스포머가 나온 거거든요. 먼저 이게 리커런트한 커넥션이기 때문에 리커런트 한다는 거는 자신의 아웃풋이 다시 자신의 인풋으로 들어간다는 거예요. 그것 때문에 컴퓨테이션이 느려요. 그리고 병렬화도 힘들어요. 왜 그럴까 기본적으로 생각을 했을 때 예를 들어서 스 3이 여기서 들어가기 위해서는요. 엑스원이랑 스투가 앞에서 들어가 있어야 돼요. 그러니까 이게 시퀀셜하게 엑스원 들어가고 스투 들어가고 스3 들어가고 이렇게 하나하나 하나하나씩 들어가서 처리가 되어야 되기 때문에 병렬화가 힘들어요. 엑스원부터 3까지 엑스 1 2 스트리 다 한 번에 넣을 수가 없다는 거죠. 그쵸 그리고 그래 가지고 이거 두 개의 단점이고 그리고 이 두 가지를 이제 좀 더 심도 있게 볼 텐데요. 그 RNN은요. 훈련 중에서 베니싱 그레디언트 문제를 겪습니다. 바닐라 RNN이라고 하는데 이 바닐라가 뭐냐면요. RNN에 아무것도 얹지 않은 기본 RNN이라는 거예요. 그래서 바닐라 SM띵 이러면은 바닐라가 약간 기본적인 아이스크림이잖아요. 초코 아이스크림, 딸기 아이스크림 뭐 이런 거는 아이스크림에다가 맛을 넣은 건데 바닐라 아이스크림은 기본 아이스크림이잖아요. 그래서 이런 것처럼 바닐라 어떤 모델 하면은 기본적인 모델이라는 뜻입니다. 그래서 바닐라 아레에는 베니싱 그레디언트 문제가 있고 바닐라 아레에는 종종 시퀀스 내에 롱텀 디펜던시를 모델링하는 데 실패한다. 이 두 개가 사실 연결되어 있습니다. 네 그래서 그거를 뒤 슬라이드에서 좀 더 볼 거예요. 그래서 실제로는 어 여러 단계 이전의 정보에 접근하기 힘듭니다. 즉 무슨 말이냐면요. RNN을 이용해서 굉장히 긴 문장을 처리한다고 해 봐요. 내 이름은 김수경이고 저는 이화여자대학교에 있고 그 전에는 스탠푸드 리서치 인스튜디오에 있으므로 블라블라블라 이렇게 썼어요. 그러면은 그 문장을 쭉 아레나을 이용해서 처리를 하면은 앞에 문장 저의 이름은 김수경 이거를 갖다 잊어버린다는 거예요. 그러니까는 가장 최근에 들어온 정보만 기억하고 앞에 건 다 잊어버린다는 거예요. 그게 요 두 개 빨간색 2개의 점 때문에 그렇습니다. 그걸 좀 더 자세하게 볼게요. 자 그래서 오늘은 뭘 배울 거냐면요. RNN이 문제가 많다고 그랬는데 첫 번째로 베니싱 그레디언트 혹은 익스플로딩 그레디언트 문제가 있어 가지고 롱 텀 디펜던시가 없다 이 점에 대해서 배워볼 거예요. 그래서 이거를 보완하기 위한 모델이 엘스티엠이랑 지알륜인데 이게 뭔지도 배울 거예요. 그리고 두 번째 모델은 매니 투 매니 알에는 입력 출력 시퀀스의 길이가 다를 때 유연하게 대응하기 어렵다. 이거는 이 뒷부분에서 배울 거예요. 무슨 말이냐면 기본적으로 아래엔 쓰려면은요. 매니투 맨이어야 돼요. 무슨 말이냐면 인풋이랑 아웃풋의 길이가 똑같아야 돼요. 예를 들어서 인풋 길이가 10개다 그러면은 아웃풋의 길이도 10개여야 돼요. 내 이름은 김수경입니다. 그러면은 인풋 길이가 4개죠. 그럼 아웃풋은 my name is soo 이렇게 4개로 똑같이 정해져야 된다는 거예요. 근데 대부분 이렇지가 않잖아요. 그래서 이거를 갖다가 해결하기 위해서 나온 모델이 시퀀스 투 시퀀스 모델입니다. 그리고 오늘은 다루지 않겠지만 다음 시간에 다룰 이슈는요. LSTM이랑 GRU 오늘 배울 요 두 개의 모델마저도 사실은 롱텀 디펜던시를 처리하기가 어려워요. 그래서 나온 게 트랜스포머의 근간 모델인 어텐션 모델입니다. 그래서 이거는 다음 시간에 배울 거예요. 오늘은 이 두 개의 부분에 대해서 배울 겁니다. 자 먼저 익스플로딩 베니싱 그레디언트 문제 그래서 이 RNN을 갖다가 요 f가 RNN이거든요. 이 RNN을 쭉 펴 가지고 보면은 이런 모양이 되는 거를 볼 수가 있어요. 그래서 x1 x2 x3가 시퀀스드 데이터예요. 뭐 예를 들어 문장이라고 그러면은 im g 뭐 이런 월드로 이렇게 나열된 데이터가 되겠죠. 그런데 이 RNN은요. 기본적으로 왜 RNN이 잘 동작 그러니까 RNN이 그 문장을 기억하는 데 성공적일 수가 있냐면은 이 RNN은 항상 같은 웨이 파라미터를 이용합니다. 즉 요 엑스원에도 똑같은 웨이 스투에도 똑같은 웨잇 3에도 똑같은 웨이 엑스의 그 티가 달라져도 같은 웨잇 파라미터를 이용을 해요. 여기 그 wh라고 쓰고 블스치라고 쓴 게 뭐냐면은 스에서 요 그 RNN 안으로 들어가기 위한 플리 커넥티드 네트워크이고 전 단계의 히든 스테이트에서 RNN으로 들어가기 위한 플리 커넥티드 레이어는 WHH죠 그래서 RNN의 식을 써주면 기본적으로 되게 심플해요. 인풋 스티에다가 웨잇 곱하고 그다음에 전 단계 히든 스테이트에다 웨잇 곱하고 더해 가지고 액티베이션 펑션 치워줘서 다음 단계 히든 스테이트로 내보내는 겁니다. 그런데 여기에서 핵심은 이 x의 티에 티가 바뀌어도 이 똑같은 블랑 블스h를 쓴다는 게 핵심입니다. 그렇죠 그러면은 여기에서 그레디언트 문제가 생기는데요. 예를 들어서 한번 봅시다. 여기에서 우리가 백 프로파게이션을 해야 되잖아요. 전 단계에 우리 로스를 그 앞의 단계로 이렇게 흘러 들어가야 돼요. 그래서 실제로 포워드 패스는 이 왼쪽에서 오른쪽이라고 생각을 하면 백 쿼드 패스는 즉 백프로파게이션은 뒤에서 앞으로 이렇게 쭉 가는 거예요. 요 빨간색 라인이 백프로파게이션 패스예요. 자 여기서 보면은 이 RNN의 식이 이런 식으로 정의가 되어야 되는데 우리가 백 프로파게이션을 할 때는 우리가 우리 그 업스트림이랑 다운스트림 배웠잖아요. 이 아웃풋인 치티를 기본적으로 인풋인 치티 마이너스 원에 대해서 미분을 해야 돼요. 우리 백 프로파게이션 할 때 배웠던 거 그대로 써먹은 거예요. 그래서 치티에서 티 마이너스 원으로 백 프롭을 할 때 이 식을 보면은 이 식을 그대로 치티 마이너스 원에 대해서 미분을 하면 어떻게 될까요? 먼저 이 탄젠트 치를 미분해서 안에 있는 거 그대로 넣어주고 치티 마이너스 원이 있는 항 이 항에 대해서 치티 마이너스 원에 대해서 미분해서 블치치가 밖으로 나오겠죠. 이게 그 미분 값이에요. 그래서 이 앞에 첫 번째 항은 괜찮은데 이 WHH를 곱하는 게 문제예요. 왜 그런지 볼게요. 자 이렇게 한 번 백프롭 하는 건 좋았어. 그런데 우리가 예를 들어서 이렇게 3개의 타임 스텝을 갖다가 페프롭을 한다고 그러면은 굉장히 많은 편미분 방정식을 풀어야 돼요. 예를 들어서 로스가 엘티라고 생각을 해봐요. 아웃풋이 이렇게 쭉 나왔어요. yt 예를 들어 y 3이 아웃풋이에요. 그러면은 여기서 생긴 로스를 로스를 쭉 그레디언트가 흘러나가서 이 앞 단계까지 이렇게 가야 되는 거예요. 그래서 이거를 갖다가 백 프롭을 한번 보면은 사실 이 로스 LT를 여기에 이 로스죠 이 엘티를 갖다가 그 우리의 그 파라미터인 블치치에 대해서 미분을 해야 돼요. 우리 그래야지 우리가 그래디언트 디센트를 푸니까 그래서 로스를 갖다가 웨이 파라미터에다가 이렇게 미분을 한다고 그러면은 당연히 이 로스를 바로 이렇게 웨이트에다가는 그렇게 미분을 못 하니까 편미분을 이용해 가지고 먼저 첫 번째 ht에 대해서 미분하고 치티를 ht 마이너스 원에다가 미분을 하고 그거를 또 그 전 단계의 치에다가 미분을 하고 이런 식으로 쭉 편미분 방정식이 생기고 마지막에 치원을 갖다가 요 블치치에 대해서 미분을 하게 돼요. 그래서 보시면 여기서부터 여기까지가 다 같은 식인 거를 볼 수가 있어요. ht를 ht 마이너스 1에 대해서 미분을 하되 이 t는 1부터 어 마지막 단에 타임 스텝까지 이렇게 되는 겁니다. 그래서 이렇게 쭉 곱하는 거예요. 그리고 마지막에 요 텀이 있고 잘 따라오고 계시죠? 그냥 미분만 쭉 해준 거예요. 자 그러면은 여기서 눈치가 빠르신 분은 눈치 챌 수 있겠지만 이 두 번째 항 즉 치케를 치케 마이너스 원에 대해서 미분한 거를 우리가 아까 앞에서 계산한 식을 갖다가 넣어줄 수가 있어요. 요 탄젠트 미분의 블치치 이거를 티번 곱한 거예요. 그렇죠 이걸 티번 곱하면은 이 항을 갖다가 티번 곱한 값은 이렇게 밖으로 나올 수가 있죠. 그래서 이 로스를 갖다가 웨이 파라미터에 대해서 미분한 식은 이렇게 돼요. 자 이걸 한번 보면요. 여기에서 눈여겨봐야 될 게 이 WHH가 무려 t 마이너스 1번이나 계속 곱해집니다. 그게 문제예요. 자 여기서 보시면은 요 앞에 항은 괜찮아요. 탄젠h를 갖다가 미분한 거예요. 그래서 예를 들어서 우리가 앞에 배웠던 내용 다시 리캡을 하면은 파란색이 요 탄젠트 치죠. 이 파란색을 미분한 게 보라색이 이 미분 값이에요. 요 앞에 항이 이렇게 생겼어요. 그러면은 보시면은 예를 들어서 여기 탄젠트h 안에 들어 있는 이 값이 사실 이렇게 갓 큰 값이 될 수가 있잖아요. 이 큰 값이 되거나 작은 값이 되면은 여기에서 그 값에 따라서 미분 값이 0이 될 가능성이 많아요. 그렇죠 그래 가지고 베니싱 그레디언트 프로블럼이 생기게 됩니다. 즉 이 탄젠트 h의 그 변수로 들어가는 값이 굉장히 크거나 작을 때 그 미분 값이 0이 되기 때문에 그 웨입 값의 그런 미분값이 즉 그레디언트가 거의 0에 가까운 값이 돼버리는 이런 베네신 그레디언트 문제가 생깁니다. 그리고 이게 사실 더 큰 문제입니다. WHH를 티 마이너스 1번 곱해줬죠. 근데 사실 우리가 생각할 수 있는 게 이 WHH는 같은 값이에요. 우리가 같은 WHH를 계속 이용한다고 그랬어요. 그래서 이렇게 동일한 행렬이 반복적으로 계속 곱해지면은요. 이 블치치가 굉장히 큰 값이거나 굉장히 작은 값이면 문제가 돼요. 예를 들어서 큰 값이면 즉 WHH의 파라미터가 1보다 크면은 얘를 갖다가 계속 곱하면은 기울기가 폭발하게 돼요. 그레디언트가 폭발하게 돼요. 뭔 말이냐 하면은 예를 들어서 WHH가 가령 1.5라고 생각을 해봐요. 1보다 큰 값이에요. 근데 1보다 큰 1.5라는 값을 t 마이너스 1번 계속 같은 값을 곱해요. 예를 들어서 1.5를 갖다가 10번을 곱한다고 그래요. 그러면은 굉장히 큰 값이 나오잖아요. 즉 기울기가 폭발하는 거죠. gradent가 너무 커 그래서 익스플로딩 그레디언트 프로블럼이 생겨요. 그리고 반대로 WHH가 1보다 조금만 작으면 예를 들어서 이게 0.9예요. 그러면은 0.9를 100번을 곱해 그럼 거의 0이 돼버리겠죠. 즉 이 블치치가 거의 1이 아니면 일보다 조금 크거나 작으면 그레디언트가 그 티가 큰 값에 대해서는 폭발을 하거나 베니싱 되는 그런 문제가 생깁니다. 따라서 이 그래디언트가 거의 0 아니면은 굉장히 크기 때문에 이게 학습이 될 수가 없어요. 로스가 제대로 프로파그레이 될 수가 없습니다. 특히 여기 이렇게 써 있는 티 값이 크면 클수록 이 그레디언트가 업데이트가 잘 안 돼요. t 값이 크다는 거는 뭐예요? 그 시퀀스가 굉장히 길다는 거죠. 예를 들어서 비디오의 그 길이가 길다든가 아니면은 문장의 길이가 길 때 이 앞쪽에 있는 그 문장 그러니까는 그 시퀀스 데이터에서 앞부분에 있는 데이터의 패턴은 제대로 학습을 하지 못하는 이런 문제가 생깁니다. 자 그래서 여러분들이 그 웨이 이니셜라이제이션 할 때 이거 배웠죠. 너무 작은 가중치를 딥러닝에 여러 번 멀티플라이 하면은 그 값이 거의 소멸돼서 0에 수렴하게 되고 아니면은 너무 큰 가중치는 극단적인 값으로 이렇게 발산하게 되죠. 이게 바로 그레디언트 배니싱 그레디언트 익스플로링 프로그램입니다. 그래서 RNN을 이용하면은 긴 시퀀스에 대해서는 이렇게 잘 러닝이 안 되는 어 베니싱 그레디언트랑 익스플로딩 그레디언트에 문제가 생기는 게 굉장히 심각합니다. 그래서 우리가 웨잇 이니셜라이제이션 할 때 하비어 이니셜라이제이션 배웠잖아요. 이거는 우리가 그 이니셜라이제이션을 어떤 값으로 하면은 딥러닝에서 그래도 어느 정도 제대로 그 베니싱 그레디언트나 익스플로딩 그레디언트 문제를 해결할 수 있다라는 거였는데 하지만 이거는 사실 딥모델이 그렇게 딥하지 않을 경우에 해당되는 거예요. 즉 이 이니셜라이제이션을 우리가 옵티멀 하게 해도 레이어를 되게 여러 개 쌓으면 결국은 같은 웨이 값을 여러 번 곱하고 하면은 어 어떤 순간에는 그 웨잇 값들이 베니싱 되거나 익스플로딩 되는 문제가 생길 수밖에 없습니다. 그래서 우리의 그 알앤엔 같은 경우에는 사실 그 알앤엔에 들어가는 시퀀스의 랭스를 갖다가 우리가 조절할 수가 없습니다. 굉장히 어떤 때는 긴 시퀀스를 넣어야 될 수가 있어요. 그러면은 같은 웨이 그 시퀀스의 개수만큼 곱해지는 거잖아요. 그래서 결국은 발산하거나 소멸되게 되고 그래서 딥러닝 모델을 RNA을 이용해서 학습하는 게 어렵다는 거죠. 그래서 여기서 써있는 것처럼 요 스가 정확히 1이 아닌 한 즉 웨이 값이 정확히 1 1이 아니면은 어 스의 케이스는 발산하거나 수렴합니다. 즉 발산하는 거는 익스플로딩 그레디언트고 0으로 수렴하는 거는 배니싱 그레디언트죠. 그래서 여기에서 케이라고 말한 거는 우리의 뉴럴넷의 댑스입니다. 그래서 뎁스를 되게 깊게 싸면은 결국은 딥러닝 모델은 그레디언트가 플로우를 잘 할 수가 없다. 근데 RNN 같은 경우는 제가 말씀드린 것처럼 인풋 시퀀스가 마치 케 뎁스처럼 작용을 하는 겁니다. 왜냐면은 같은 웨잇을 쓰기 때문에 만약에 인풋 시퀀스가 3개를 갖다가 들어왔으면은 이거는 같은 레이어를 3개를 쌓는 거랑 같은 거고 예를 들어서 인풋 시퀀스가 100개가 들어왔으면은 사실 100번을 쌓는 거랑 똑같은 거예요. 그러니까 결국은 그 그레디언트가 베니싱 되거나 익스플로딩 될 수밖에 없는 거죠. 그래서 그러면은 이제 문제가 있죠. 그럼 어떻게 해야 될까요? 그럼 한번 기울기의 폭발 사례를 먼저 보도록 합시다. 익스플로딩 그레디언트 예를 들어서 소위 말하면 이런 거죠. 백프롭을 할 때 우리가 로스가 뒤에서부터 쭉 앞으로 가는데 백 프롭의 각 스텝에서 우리가 WI을 갖다가 곱해주는 거예요. 첫 번째 스텝 그러니까 백 프롭이니까 뒤에서부터죠. 첫 번째 스텝에서는 이 WI WHH 한 번 곱하고 두 번째 스텝에서는 두 번 세 번째는 세 번 이렇게 계속 곱해가면은 이 with 예를 들어서 1.5예요. 그러면 1 5 3번 곱하면은 익스플로링 되는 거죠. 그래서 기울기 폭발할 때 그럼 어떻게 이걸 해결할까 그래서 사람들이 생각한 게 그냥 그래디언트 클리핑입니다. 그래서 클리핑 하면은 그러니까 그 어떤 수보다 크면 그냥 잘라주는 거죠. 그 수보다 커지지 않도록 그래서 그 그래디언트를 계산을 한 다음에 그 그레디언트가 특정 트레숄드를 최댓값으로 클리핑이 됩니다. 그래서 예를 들어서 그레디언트가 뭐 예를 들어 0.9보다 크다 그러면은 다 0.9로 맞춰주는 거죠. 그래서 여기 식이 나와 있죠. 그래서 그레디언트 클리핑 할 때는 우선 그레디언트가 요 쥐예요. 쥐가 만약에 트레숄드보다 크면은 이 쥐를 갖다가 어 어느 정도 이게 쥐의 그 절대값으로 나눠서 축소시킨 다음에 트레숄드로 클리핑 해 줍니다. 네 그래 가지고 어 이런 식으로 이렇게 그레디언트가 크면 다 이렇게 세츄레이션 되게 다 클리핑 되게 어 해결을 하려고 노력을 할 수가 있어요. 자 근데 어 사실 이게 되게 근본적인 해결은 아닙니다. 그러면은 이제 그래디언트 베니싱 프로블럼을 볼게요. 아까는 그레디언트가 점점 점점점점 커져 가지고 발산하는 거였는데 이번에는 그레디언트가 점점점점점점 줄어들어서 0에 가까운 경우를 한번 보도록 할게요. 또 이제 백 프롭을 해야 되니까 이 마지막 아웃풋 와 단계에서부터 그레디언트가 쭉 흘러 들어가겠죠. 가장 가까운 타임 스텝 내에서는 WHH를 한 번 곱하고 두 번째는 두 번 곱하고 제일 그 아웃풋에서 먼 데에서는 3번 이렇게 곱했어요. 그러면은 예를 들어서 웨치치가 0.5다 그러면은 0.5 3번 곱하니까 이 마지막 단에서는 거의 그레디언트가 0이 되겠죠. 그래서 이후 다음 인풋의 초기 인풋에서의 그 로스는 초기 스테이지로 잘 전달되지가 않습니다. 왜냐하면 초기 스테이지로 가면 갈수록 웨이 파라미터를 여러 번 곱하고 그 웨이 파라미터가 예를 들어서 1보다 작은 값이면은 여러 번 곱하면 곱할수록 작아지기 때문이죠. 그래서 이게 그레디언트 베니싱 프로그럼이에요. 그러면은 그래서 근본적으로 이 그레디언트 베니싱 익스플로딩 프러블럼이 굉장히 큰 문제인데 이거를 갖다가 어떻게 해결할 수 있을까 이 문제 때문에 어 그 첫 번째 그러니까 그 시퀀스 데이터의 앞쪽 부분은 다 잊어 먹는데 어떻게 첫 그 앞쪽 부분의 시퀀스를 잘 기억하는 모델을 만들 수 있을까 그 아이디어가 요 엘레스티엠입니다. 자 그래서 그 엘레스티엠을 배워보기에 앞서서 요 아레엔 구조를 다시 한번 살펴볼게요. 요 아레엔 구조가 기본적으로 이 왼쪽 그림이에요. 바닐라 아레엔이죠. 이 오른쪽에 그 플리 커넥티드 레이어를 넣어 가지고 이렇게 구조를 다시 만들어 보면 사실 이 플리 커넥티드 레이어는 여기 그 스티에서 블xh를 곱하고 ht 마이너스 1에서 WHH를 곱해 가지고 서로 더하는 이 3개의 부분을 이렇게 플리 커넥티드 레이로 바꿀 수 있는 겁니다. 그래서 사실은 이 왼쪽 그림이랑 오른쪽 그림이랑 같은 거예요. 이렇게 간단하게 표현하려고 오른쪽으로 이렇게 나타낸 겁니다. 그래서 여기서 이렇게 써놨죠. 간단하게 요 웨이트 매트릭스 블치치 블스 이거 대신에 그냥 요 플리커넥터드 박스를 이용하도록 할게요. 자 그래서 이 바닐라 아앤엔이 플립 커넥티드를 통과하는 과정에서 기울기 손실 문제가 있는 거예요. 기본적으로 그러니까는 기본적으로 우리가 왜 이 베니싱 그레디언트 문제가 생기냐면요. 이렇게 백프롭을 할 때 이 빨간색 선을 따라서 그래디언트가 흘러가게 되는데 이 플리 커넥티드 단에서 더블h씨를 너무 많이 곱해주기 때문에 요 그레디언트가 없어지거나 익스플로드 하는 거죠. 그래서 결국 이 플리 커넥티드가 문제예요. 이거를 갖다가 그레디언트가 항상 요 플리커넥티드를 통과하니까 문제가 생기는 거거든요. 그러면은 이거 어떻게 해결해야 되나 요 플리커넥티드 안 통과하면 안 되나 그래서 만든 게 엘스tn입니다. 그래서 이 플리 커넥티드가 문제라서 이를 방지하기 위해서 이 프리 커넥티드를 통과하는 그레디언트 패스를 갖다가 없애주기 위해서 요 셀 스테이트라고 부르는 이 새로운 히든 스테이트랑 프리 커넥티드 계층을 우회하는 고속도로를 한번 뚫어 줄 거예요. 그러니까는 이렇게 아웃풋에서 인풋으로 갈 때 굳이 플리 커넥티드를 통과하지 않고도 아웃풋으로 갈 수 있게 이렇게 씨라는 스테이트를 만들어서 고속도로를 뻥 뚫어주는 거죠. 그래서 실제로 요 셀 스테이트가 업데이트될 때는요. 요 셀 스테이트가 하는 일은 롱텀 메모리를 저장하는 어떤 장기 기억 장치 같은 역할을 해요. 그래서 우리가 여기서 여러 가지의 게이트를 많이 다룰 거예요. 먼저 포켓 게이트라는 걸 달아가지고 이 포켓 게이트가 하는 일은요. 얼마나 많이 지금까지 현재 들어온 정보 이 스티랑 ht 마이너스 1을 통해서 들어온 이 빨간색 패스를 통해서 들어온 정보가 장기 기억 장치에 얼마나 저장이 될지 그거를 갖다가 컨트롤하는 게 이 포켓 게이트입니다. 이 포켓 게이트가 열리면은 이 xt랑 ht 마이너스 1의 정보가 욜로 흘러들어가지 않겠죠 그래서 얘가 열리면 열릴수록 이 현재 정보가 잊어버려질 거예요. 그래서 포켓 게이트라고 정한 거고 그다음에 인풋 게이트는 뭐냐 하면은 반대예요. 현재의 정보가 얼마만큼 장기 기억 장치인 c라는 셀에 기억될 것인지 그거를 컨트롤하는 인풋 게이트가 있습니다. 그리고 마지막으로 아웃풋 게이트를 달아 가지고 현재 정보가 어 그 장기 기억 장치에 있는 정보들과 결합해서 얼마나 어 웨이 파라미터를 곱해 가지고 아웃풋으로 내보낼지 즉 치티랑 CT를 갖다가 컴비네이션 하고 스티도 콤비네이션 해 가지고 얼마나 현재 상태에서 아웃풋을 낼지를 갖다가 컨트롤하는 이 아웃풋 게이트를 추가합니다. 그래서 이 포켓 게이트 인풋 게이트 아웃풋 게이트를 이렇게 넣어줘 가지고 이 RNN에서 롱텀 메모리를 기억하지 못하는 단점을 잘 고쳤어요. 그래서 전반적으로 입력 xt 얘랑 이전의 히든 스테이트인 ht 마이너스 1 얘랑 이런 게 잘 콤비네이션 돼 가지고 그게 다음 히든 스테이트 ht 그리고 다음 셀 스테이트 시티를 갖다가 결정할 뿐만 아니고 이전 값을 유지하거나 새로운 값으로 업데이트할지도 결정합니다. 즉 기본적으로 인풋이 이렇게 들어왔을 때 얼마만큼 잊어버릴지 얼마나 기록할지 어떻게 아웃풋을 낼지를 결정한다는 거예요. 그래서 요 아까 앞에 있는 그 포겟 인풋 아웃풋의 오퍼레이션을 쭉 식으로 나타낸 겁니다. 자 그래서 이게 에스티엠이고 이 셀 스테이트를 새로 만듦으로써 사실 플리 커넥티드를 통과하지 않아도 어 그 전에 정보가 다음 정보로 이렇게 흘러갈 수 있게 되죠. 그래서 베니싱 그레디언트 문제를 일부는 어느 정도는 해결을 할 수 있었어요. 그리고 확실히 좋아진 건 뭐냐면은 바닐라 RNN보다 롱 레인지 인포메이션을 더 잘 보존할 수 있어요. 즉 예를 들어서 문장이 굉장히 긴다고 생각하세요 제 이름은 김수경이고 블라블라블라 그러면은 RNN은 앞에 있는 정보 제 이름은 김수경이고 롤을 완전히 잊어버리게 돼요. 그러니까 롱레인지 인포메이션은 잘 저장을 못하는 단점이 있었어요. 근데 LSTM 같은 경우는 이렇게 얼마나 더 잊어버리고 저장할지를 결정하기 때문에 롱레인지 인포메이션을 훨씬 더 잘 저장할 수 있는 장점이 있습니다. 네 그리고 만약에 우리가 포켓 게이트를 1로 해가지고 하나도 안 포겟 한다고 이렇게 결정을 해버리고 인풋 게이트를 0이라고 그래 가지고 모든 인풋을 갖다가 다 통과하게 만든다면은 RNN이랑 똑같이 되겠죠 네 그래서 어느 정도 베니싱 그레디언트 익스플로딩 그레디언트 문제를 해결을 했지만 여기서 중요한 거 이 모델이 완벽한 건 아니에요. 이 모델이 그렇다고 해서 롱레인지 디펜던시를 완전히 해결하지는 못합니다. RNN보다는 훨씬 낫지만 완전히 해결하지는 못했어요. 그리고 GRU라는 게 또 있는데 이거는 LSTM의 약간 변형 형태라고 생각하시면 됩니다. 게이티드 리커런트 유닛이라고 그러는데 이거는 엘st엠이랑 똑같아요. LSTM이랑 똑같은데 LSTM에서는 셀 스테이트가 있었잖아요. 근데 히든 스테이트도 있고 셀 스테이트도 있으니까 너무 배울 게 많다는 거예요. 그래 가지고 모델이 너무 복잡해진다. 그래서 아 그러면은 굳이 셀 스테이트 만들지 않고 이 h 스테이트를 두 갈래로 나눠서 한 갈래는 셀 스테이트처럼 쓰자 하는 게 이 GRU의 아이디어입니다. 그래서 여기 써있는 것처럼 LSTM처럼 어 따로 이렇게 추가적인 셀 스테이트 씨를 갖다가 만들지 않고 이 씨를 갖다가 두 갈래로 나누어서 한쪽 갈래는 어 셀 스테이트 씨로 쓰는 거예요. 그래서 기본적으로 LST엠이랑 비교했을 때 이 GRU는 셀 스테이트가 없기 때문에 LST엠보다 훨씬 적은 파라미터를 이용하게 되죠. 하지만 이 치를 갖다가 두 갈래로 나눠서 하나는 하이웨이처럼 사용하기 때문에 이런 그래디언트 익스플로딩 베니싱 그레디언트의 문제를 엘스엠이랑 똑같이 해결할 수 있다라는 거죠. 자 그래서 사실 요 엘스티엠 되게 복잡하잖아요 식도 되게 어떻게 보면은 되게 밉게 생겼고 하지만 걱정하지 않아도 됩니다. 우리는 파이토치가 있죠 텐서플로우도 있고 이 파이토치 텐서플로우에 LSTM RNN 이런 것들이 다 기본적으로 인플리멘트 되어 있어요. 그래서 이 쓰는 방법은 굉장히 쉽습니다. 이 엔 엔 그러니까 뉴럴 네트워 라이브러리를 불러서 엘스티엠 이렇게 불러오면 쉽게 여러분들이 인플리멘트 할 수 있습니다. 그래서 어 그 텐서플로우 다큐멘테이션에 보면은 어떻게 쓰는지 잘 설명돼 있고요. 여러분들 시간 나실 때 한번 해 보셨으면 좋겠습니다. 자 그래서 이제 이거는 어떤 실질적인 인플리멘테이션 가이드인데요 어 엘스티엠은 당연히 알앤엔보다는 훨씬 좋아요. 롱레인지 디펜던시를 어느 정도 완화했기 때문에 그래서 실제로 알엔은 안 씁니다. 똑같은 모델 만들 때 RNN 안 쓰고 LSTM 씁니다. 그래서 뭐 논문 봤을 때 뭐 RNN 썼다 이렇게 쓰여 있지만 실제 코드 보면은 LSTM을 쓴 게 어 대부분입니다. 그래서 뭐 요새는 엘스티엠이랑 알앤에랑 같은 의미로 많이 쓰입니다. 그리고 엘스티엠이랑 지알유는 같은 확률로 쓰이는 것 같아요. 만약에 우리가 뭐 컴퓨터가 되게 좋은 게 없다거나 GPU 리소스가 없다 이러면은 LSTM은 좀 무거울 수 있어요. 그래서 좀 가볍게 시퀀스 모델링을 하고 싶으면은 LSTM보다 GRU를 쓰는 게 좋습니다. 왜냐하면은 적은 파라미터를 가지고 있기 때문에 에스티엠보다 그리고 어 요새는 실은 엘스티엠이랑 쥐알유 이런 거는 그렇게 많이 쓰지 않고 모든 모델이 요 트랜스포머라는 모델로 대동단결되고 있어요. 그래서 뭐 무거운 자연어 처리 엔알피나 뭐 비디오 처리 이런 거에 대해서는 트랜스포머가 요새 더 널리 사용되고 있습니다. 그래서 트랜스포머는 본격적으로 이제 다음 강의에서 다룰 예정이에요. 여기까지가 이제 RNN의 어떤 친구들 RNN 계열 RNN LSTM GRU에 대해서 배워봤고 그다음에 이제 대장정이 남았습니다. 시퀀스 투 시퀀스 모델입니다. 이거는 어 우리가 배운 요 알앤엔 계열의 친구들을 이용해 가지고 시계열 데이터를 처리하는 모델링 방법 중에 하나입니다. 그래서 이 모델을 설명하기 위해서 우리가 이그잼플 테스크로 가져올 테스크에 대해서 설명을 해 볼게요. 다양한 매니 투 매니 NRP 문제 중 즉 자연어 처리 문제 중에 한 언어로 이루어진 문장을 다른 언어의 의미로 번역하는 작업인 머신 트랜슬레이션을 고려해 볼게요. 머신 트랜슬레이션은 기본적으로 번역이에요. 그래서 이 스페인어를 잉글리시로 번역하는 이런 테스크를 생각을 해볼게요. 그랬을 때 이제 매니투 매니 RNN은 기본적으로 바닐라 RNN의 테스크라고 생각을 하면 돼요. 그래서 어 예를 들어서 스1 스2 3가 이렇게 인풋으로 들어가면은 순차적으로 거기에 해당되는 아웃풋인 y1 y2 y3가 나오는 테스크가 매니 투 맨이죠. 뭐 예를 들어서 바이너리 클래시피케이션이다 그러면은 이 아웃풋 와에다가 시그모이드를 붙여서 우리가 바이너리 클래시피케이션을 할 수도 있고 아니면 리그레션 넘버 형태로 아웃풋이 나오길 바란다. 그러면은 액티베이션 펑션 안 넣고 그냥 와 그대로 쓰면 되겠죠. 그래서 기본적으로 알앤에는 매니 투 매니 테스크예요. 매니투 메이가 뭘까요? 설명을 드리자면은 인풋이 맨이면 아웃풋이 맨이라는 거예요. 즉 인풋과 아웃풋의 사이즈가 똑같을 때 매니투맨이라고 그래요. 예를 들어서 인풋이 사이즈가 타임 스텝이 3개예요. 엑스원 엑스투 엑스트 예를 들어서 문장으로 생각하면은 ims라는 게 되겠죠. 그리고 아웃풋은 똑같이 3개의 기류를 가지고 있는 그 시퀀스 데이터라고 생각하면 돼요. im 수를 한국말로 번역하면 나는 수경입니다. 이렇게 3개의 똑같은 인풋이랑 똑같은 아웃풋 길이를 갖는 케이스라고 생각하시면 됩니다. 그래서 첫 번째 시도를 한번 해볼게요. 메니 투 매니 RNN 예를 들어서 스페인어를 영어로 이렇게 번역하는 테스크를 생각을 할게요. 먼저 비보가 들어가면 아이가 나오고 그다음에 엔이 들어가면 리브가 나오고 이렇게 순차적으로 인풋을 넣었을 때 아웃풋이 나오게 인풋 스티를 넣었을 때 아웃풋 와티를 넣는 테스크를 생각을 할게요. 이 테스크를 보면 문제가 보이실 거예요. 문제가 보이시나요? 여러분들이 만약에 그 스페인어를 할 수 있다면은 훨씬 더 문제가 쉽게 보일 거예요. 자 그 문제가 뭐냐면요. 사실 매니투 매니 테스크를 RNN을 이용해서 푸는 거는요. 사실 1대 1 관계를 가정을 해요. 무슨 말이냐면은 인풋 x 티를 넣었을 때 아웃풋 스티가 인풋 xt에 번역된 형태여야 돼요. 그쵸 그래가지고 예를 들어 가지고 비보를 나타내는 단어가 잉글리시로 그러니까 영어로 이렇게 딱 나와야 된다는 거예요. 그런데 이 머신 트랜슬레이션의 경우에 사실 언어마다 문법이 다르잖아요. 그래서 인풋으로 넣은 단어랑 똑같은 시멘티컬한 의미를 갖는 단어가 아웃풋으로 나올 수가 없어요. 어순이 다르게 나타날 수도 있고 아니면은 문장의 길이가 언어마다 다를 수도 있고 예를 들어서 한국말로 하면은 다섯 단어로 끝나는 게 영어로 하면은 10단어로 끝난다 뭐 이렇게 문장의 길이가 다를 수도 있어요. 따라서 일대 열 매칭은 불가능하다는 거예요. 머신 트랜슬레이션에서 그래서 여기 쓰인 것처럼 입력에 기반해서 출력하는 건 사실은 불가능할 수도 있어야 돼요. 그렇죠 예를 들어서 아이 리브 블라블라블라라는 영어 문장을 스페인어로 하면은 비보가 먼저 나와야 되는데 이 비보는 사실 리브라는 뜻이에요. 그런데 사실 인풋으로 리브를 받지도 않았는데 어떻게 비보라는 거를 예측할 수 있냐는 거예요. 즉 입력에 기반해서 출력하는 게 머신 트랜슬레이션에서는 불가능하다. 그래서 이렇게 생각할 수 있어요. 각 입력 토큰에 대해서 이렇게 입력 토큰에 대해서 출력 토큰을 생성하는 것은 사실은 불가능해요. 왜냐면은 머신 트랜슬레이션은 1대 1 대응이 아니니까 단어 대 단어가 일대일 대응이 아니니까 그러면 어떻게 해야 될까 더 나은 아이디어가 있을까요? 그래서 생각한 게 인코딩 디코딩 스트럭처예요. 자 여러분들 이렇게 생각해 보면 사람이 번역을 하는 거 한번 생각을 해봐요. 그러면 사람은 어떻게 번역을 할까? 사람이 번역을 하는 테스크를 생각을 해보면은 여러분들이 예를 들어서 영어를 듣거나 읽고서 그거를 한국말로 번역을 할 때 어떻게 해요? 한 문장을 다 듣고 그다음에 그걸 생각해 가지고 한국말로 번역을 하죠. 하나 한 단어 단어별로 실시간으로 번역을 하지 않는단 말이에요. 그래서 그 아이디어에 기반한 게 이 인코딩 디코딩 스트럭처입니다. 그래서 기본적으로 아이디어는 똑같아요. 예를 들어서 이렇게 문장 하나가 쭉 들어와요. 그 앤 어쩌고저쩌고 저쩌고 그러면은 이 인코더 단에서 이 문장 전체에 대한 정보를 배웁니다. 그래서 첫 번째 비보가 들어가면은 이제 비보에 대한 인코딩된 정보를 갖다가 치원으로 배우고 인이 들어오면은 비보인 이 두 개를 다 합친 정보를 h2로 배우고 이런 식으로 순차적으로 이 h 파라미터를 업데이트해 가면서 이 인풋 문장에 대한 전체적인 벡터 히든 벡터를 배웁니다. 그다음에 이제 다 문장을 읽어드렸으면 사람이 다 문장을 들은 거랑 똑같은 효과를 이어 알레 모델도 가지고 있어요. 그 문장에 대한 모든 정보를 히든 스테이트에다가 저장을 하게 되겠죠. 자 그러면은 이제 우리는 전체 입력 시퀀스의 의미를 포함하는 임베딩을 가지고 있겠죠. 그 인베딩은 마지막 단계의 히든 스테이트에 저장이 돼 있을 거예요. 그런 다음에 요 인베딩에 해당하는 히든 스테이트에서 시작해서 하나씩 하나씩 단어를 뽑아가는 이 출력을 생성하는 디코더를 구축을 해요. 즉 문장을 다 읽었어 그래서 그 문장에 대한 정보를 내 머리에 가지고 있다면은 그 문장을 가지고 이제 본격적으로 번역을 하는 거죠. 그 번역을 하는 게 이 디코딩입니다. 그래서 그 이렇게 인코딩 디코딩 구조를 이용해서 인코딩은 문장을 읽어 가지고 그걸 저장을 하고 디코딩은 저장된 문장을 받아들여서 한 단어씩 이렇게 해석을 트랜슬레이션을 하는 거죠. 그리고 이 모델을 갖다가 트레이닝 시킬 때는요. 인코더 디코더 전체에서 나온 그 로스 값을 이용해 가지고 인코딩 파트도 트레이닝 시키고 디코딩 파트도 트레이닝 시킵니다. 즉 로스가 어 디코더에서부터 인코더까지 이렇게 쭉 플로우 돼 가지고 전체 모델을 다 한꺼번에 학습을 하는 거죠. 그러면 이제 디코더를 배울게요. 이제 디코더 단계에서는 실제로 우리가 인코더의 마지막 히든 스테이트를 받아들이죠. 그러면 인코더의 마지막 히든 스테이트는 인풋으로 받은 모든 문장에 대한 정보를 가지고 있을 거예요. 그래서 그 문장을 받아들여서 그다음에 한 단어씩 이제 번역을 해가는데 여기서 오토 리그레시브라고 했어요. 이 오토 리그레시브가 뭐냐면요. 기본적으로 이렇게 아웃풋으로 단어를 예측했잖아요. 그 단어가 다시 다음 단계의 인풋으로 들어간다는 거예요. 그래서 예를 들어서 이렇게 인코더의 마지막 히든 스테이트가 들어왔어요. 디코더 단에서 그러면은 디코더는 이제 자 이제 너 번역해 라는 테스크를 줘야 돼요. 그거를 어떤 특별한 토큰으로 sos 토큰으로 줄게요. 예를 들어서 이 sos라는 특이한 스tl트 오브 센턴스라는 토큰을 주면은 이 디코더가 아 이제 번역을 해야 되겠구나라는 걸 알게 되죠. 그래서 이 에오스라는 토큰을 주면은 이제 이 문장을 읽고서 첫 번째 단어를 예측을 할 거예요. 와 1 h 그러면은 이 예측한 단어를 갖다가 다음 단계의 인풋으로 넣어요. 예를 들어서 해석이 아이라는 게 해석이 나왔어요. 그러면은 이 해석된 아라는 예측 값이 다음 단계 에스티엠의 인풋으로 이렇게 들어가는 거예요. 그러면은 그 다음 단어를 예측하겠죠. 예를 들어서 엠이라는 거를 예측을 했어요. 그러면은 엠이 또 다음 단계의 인풋으로 들어가서 그 다음 단어를 예측하고 이렇게 아웃풋이 다음 단계의 인풋으로 들어가는 거를 오토 리그레시브 제너레이션이라고 그래요. 그래서 여러분들 지금 제너레이티브 생성형 AI 모델 많이 쓰고 계실 텐데 뭐 챗gpt나 등등 이런 게 다 오토 리그레시브하게 예측이 되고 있습니다. 그래서 여기 있는 텍스트를 읽어보면 각 단계에서 히든 스테이트 그리고 레스트 아웃풋을 준 상태에서 다음 아웃풋 토큰을 결정합니다. 즉 어떤 펑션에서 하는 일은 전 단계의 히든 스테이트를 받는 것뿐만 아니고 전 단계에서 예측한 와 1 h까지 인풋으로 받아서 그다음에 아웃풋으로는 그 다음 단계의 히든 스테이트를 예측을 하게 돼요. 그래서 이런 것들이 오토 리그레시브 하게 된다라는 거죠. 그리고 사실 이거 좀 프랙티컬한 가이드인데요. 학습할 때 우리가 특별한 기술을 써요. TC fsin이라고 그래요. 이게 뭐냐면요. 실제로 우리가 학습 초반에는 예를 들어서 학습 초반에 아이엠 어 걸이라는 문장을 우리가 해석을 해야 돼요. 그러면은 초반 학습 단계에서는 당연히 이 모델이 학습이 안 됐으니까 예를 들어서 첫 번째 문장이 아이가 안 나오겠죠. 그러니까 학습이 안 됐으니까 되게 랜덤한 단어가 나올 거예요. 그러면은 그 랜덤한 단어를 그 다음 단계에 넣으면은 그 다음 단계의 단어도 당연히 틀린 단어가 나오겠죠. 그러니까는 초반에 틀린 단어가 나오기 시작하면은 그 후반은 완전히 다 틀리게 된다는 거예요. 그래서 이거를 방지하기 위해서 학습 단계에서는요. 예측하는 아웃풋을 바로 넣지 않고 정답 값을 넣어요. 그래서 아이엠 어 걸이라는 걸 예측을 하기 위해서 첫 번째 y1이 아이가 안 나오더라도 그라운드 트로스인 아이를 갖다가 다음 단계의 인풋으로 넣는다는 거죠. 예를 들어서 첫 번째 단어가 생뚱맞게 뭐 독이라는 게 나왔어요. 그래도 정답이 아라는 걸 아니까 아이를 넣고 그다음에 m이 나오도록 예측을 하는 거죠. 그래서 이게 티처 포싱이라고 그래요. 왜 티처 포싱이냐면은 선생님이 학생을 가르칠 때 초반에는 굉장히 쉬운 이그 샘플만 가지고 가르치잖아요. 예를 들어서 제가 뭐 수학을 갖다가 아기들한테 가르칠 때 처음에 덧셈 펠젠 같이 쉬운 거를 가리키고 그다음에 난이도를 올려서 덧셈 뺄셈 다음에 나눗셈을 가리키고 그다음에 곱셈을 가리키고 그다음에 점점점점 해서 미분 적분까지 가리켜야지 애들이 학습이 되지 초반부터 미분 적분을 가리키면은 당연히 애들이 학습이 안 되는 거죠. 그래서 그거에 기인해 가지고 학습 단계에서 초반에는 적어도 정답을 갖다가 인풋으로 넣어주면서 이 모델 입장에서 쉽게 트레이닝하게 이렇게 우리가 가이드를 해준다는 거예요. 그래서 티처 포싱이라는 테크닉을 씁니다. 그리고 학습 단계에서는 이렇게 했지만 인퍼런스 단계에서는 즉 학습이 전체가 다 끝난 다음에 우리가 이 모델을 가지고 테스트할 때는 실제로 예측한 값을 이렇게 인풋으로 넣어줍니다. 왜냐하면은 우리가 이 학습이 끝난 다음에 이 모델을 갖다가 해석 모델 그러니까 번역 모델로 쓰고 싶잖아요. 근데 실제로 우리가 번역을 할 때는 당연히 정답 값이 없죠. 번역을 하기 전이니까 그러니까 이 모델이 예측한 거를 예측한 값 그대로를 오토 리그레시브하게 다음 단계의 인풋으로 넣어줘야 된다는 거죠. 그래서 이 오버를 한 시퀀스 시퀀스 모델을 보면은 다음과 같습니다. 이렇게 인코더 단에서 이렇게 인풋 시퀀스인 엑스원 투 스트를 이렇게 인풋으로 받아서 인코딩 벡터를 만들고 인코딩 벡터를 넣어 가지고 아웃풋을 이렇게 오토 리그레시브하게 예측하는 식으로 여기가 인코더 이 뒷부분이 디코더처럼 이렇게 되어 있는 특성을 가지고 있습니다. 그래서 이거의 장점은 뭐예요? 인풋 시퀀스의 길이가 아웃풋 시퀀스의 길이보다 뭐 길어도 상관없고 짧아도 상관없고 임의의 랭스가 인풋으로 들어와도 임의의 랭스의 아웃풋을 잘 번역할 수 있는 특징을 가지고 있습니다. 그래서 시퀀스 시퀀스 모델 이런 식으로 되어 있는 걸 봤고요. 그다음에 이제 이 시퀀스 투 시퀀스 모델을 코드로 짜는 걸 한번 볼게요. 그래서 이 펑션이 조금 복잡하니까 간략하게 이제 같이 따라오시면서 각각의 그 펑션들을 보시면 됩니다. 그래서 이 시퀀스 투 시퀀스 모델은 기본적으로 3개의 파트로 나뉩니다. 첫 번째는 인코더 두 번째는 디코더 인코더 디코더가 다른 클래스고 그 인코더 디코더 클래스를 불러와서 시퀀스 투 시퀀스 모델로 만드는 이 시퀀스 투 시퀀스 모델 부분이 있습니다. 그래서 인코더 디코더 시퀀스 시크 모델 이 세 가지를 짤 거예요. 먼저 인코더는 되게 쉬워요. 그냥 여기 그 이니셜라이제이션 부분에서는 우리 변수들을 이렇게 정의를 해 준 거고 이 포워드가 사실 진짜 펑션인데 기본적으로 요 스가 요 시퀀스 되는 데이터예요. 스1 스2 그러니까 문장 하나가 x라고 생각하면 돼요. 요 스를 갖다가 우선 인베딩을 해요. 벡터화 시킨 다음에 우리가 임베딩 벡터로 만든 다음에 그냥 이 파이토치에서 이미 되어 짜져 있는 LSTM 펑션을 불러와 가지고 요 인베딩을 넣습니다. 이 부분을 한 거예요. 요 LSTM 부분에 임베딩을 넣은 거고 그다음에 그 엘스티엠의 아웃풋은 두 개가 있어요. 엘스티엠에서 나오는 요 와1 와 2에 해당하는 아웃풋 아웃풋이랑 그다음에 히든 스테이트가 또 아웃풋으로 나옵니다. 히든 스테이트 그리고 이게 엘스티엠이기 때문에 셀 스테이트도 아웃풋으로 나옵니다. 근데 우리는 사실 시퀀스 투 시퀀스 모델이니까 이 인코더 단에서는 히든 스테이트만 나오면 돼요. 그래서 아웃풋은 버리고 히든 스테이트랑 셀 스테이트를 아웃풋으로 내보낼게요. 그래서 인코더는 기본적으로 엘스티엠이고 스를 받아서 아웃풋이랑 히든 스테이트랑 셀 스테이트를 내보내는데 우리는 시퀀스 투 시퀀스 모델이니까 이 히든 스테이트랑 셀스테이트만 아웃풋으로 내보낸다 쉽죠. 그다음에 디코더는 사실 여기에서 조금 미스리딩한 게 있을 수 있는데 여기에 디코더에서 이 x의 의미는 사실은 그 하나의 월드입니다. 하나의 단어를 x라고 생각하시면 돼요. 그래서 이 디코드 단에서 하는 일은 뭐냐면요. 먼저 아까 인코더랑 똑같이 이 x라는 단어를 받아서 인베딩 벡터로 보내요. 인베딩을 시킵니다. 그런 다음에 또 여전히 똑같이 LSTM을 이용해 가지고 그 아까 그 인코더 단에서 우리가 예측을 한 히든 스테이트랑 셀 스테이트를 받아서 단어랑 같이 인풋을 넣은 다음에 즉 인풋은 인베딩 그 단어랑 그 어 인코더 단에서 아웃풋으로 내뱉은 히든 스테이트랑 셀 스테이트예요. 이 3개를 갖다가 인풋으로 받아서 여기에서 예측하는 건 똑같이 얘가 LSTM이니까 아웃풋이랑 히든 스테이트 셀 스테이트 이 세 가지를 아웃풋으로 예측을 합니다. 그리고 우리의 그 아웃풋은 실제로 플리 커넥티드를 한 번 더 통과시켜서 프리딕션으로 만듭니다. 그래서 얘가 디코더예요. 그래서 디코더도 여전히 LSTM이에요. 하나의 LSTM 그래서 디코더를 한 번 패스했을 때 나오는 아웃풋은 우리의 그 프리딕션 월드 그러니까 번역된 하나의 단어랑 그리고 요 엘스티엠 단에서 나온 히든 스테이트랑 셀스테이트입니다. 그래서 인코더 디코더는 기본적으로 엘스티엠이에요. 자 이제 시퀀스 투 시퀀스가 약간 트리키합니다. 이 시퀀스 투 시퀀스에서는 어떤 일을 하냐면요. 기본적으로 인코더랑 디코더를 연결을 시켜야 돼요. 그렇죠 그래서 이 시퀀스 투 시퀀스에서는 앞에서 정의된 인코더랑 디코더를 불러와요. 그런 다음에 여기에서는 실제로 소스가 뭐예요? 우리가 번역하고자 하는 문장 그게 돼요. 그거를 갖다가 우리가 번역을 했을 때 나오는 아웃풋으로 바꿔야 돼요. 예를 들어서 이 스페인 문장을 영어로 번역한다 그러면은 이 소스는 스페인 문장이 되겠고 이 아웃풋은 영어로 번역된 문장이에요. 그래서 먼저 인코더 엘스티에이로 이 소스를 태워 가지고 어 이 인코더를 통해서 히든 스테이트를 배워요. 히든 스테이트랑 셀 스테이트 그런 다음에 이 포 루프가 중요한데 이게 오토 리그레시브하게 제너레이션 하는 거예요. 이렇게 인코더를 통해서 히든 스테이트랑 셀 스테이트가 나왔잖아요. 그다음에 이 디코드를 통해서 오토 리그레시브하게 이제 번역하는 게 조금 복잡해요. 그걸 좀 볼게요. 먼저 첫 번째 인풋은 뭐냐면은 타겟의 첫 번째 엘러먼트 여기 타겟 제로라고 되어 있죠. 이거는 뭐냐면은요. 우리가 번역을 할 때 첫 번째 단어가 되는 거예요. 그러니까는 아까 앞 슬라이스에서 제가 그 에오스 토큰이라고 그랬죠. 스타트 오브 디센턴스 여기서부터 문장이 시작돼야 돼라고 가르쳐 주는 어떤 토큰이 되겠죠 그게 첫 번째 토큰이에요. 그래서 타겟 제로 sos 토큰을 x라고 보낼게요. 이제 문장 번역이 시작되는 거예요. 그래서 이제 이 타겟 랭스를 이렇게 쭉 돌면서 디코더를 통해서 한 단어씩 우리가 제너레이션을 해 가야 돼요. 근데 이 디코더가 하는 일은 전 단계에서 우리가 어 제너레이트 한 전 단계에서 번역한 단어인 x를 인풋으로 받고 전 단계의 히든 스테이트랑 셀 스테이트를 받아서 아웃풋을 이렇게 내보내는 거죠. 그래서 그 아웃풋을 갖다가 아웃풋에 엘레먼트를 테이크를 해가지고 여기에서 어그맥스라고 한 거는요. 이게 사실 우리가 하나의 단어를 갖다가 표현할 때 원 핫 벡터를 써요. 그러니까는 특정 단어가 있는 엘러먼트만 원이라고 하고 1이라고 표시를 하고 나머지는 다 0이라고 하는 거예요. 그래서 아그맥스 원이라고 하면은 그 단어가 있는 그 인덱스의 그 단어를 갖다가 우리가 샘플링 하는 거예요. 그래서 기본적으로 이 디코더가 하는 일은요 그 전 단계의 셀 스테이트랑 그 전 단계의 예측 값을 가지고 그 다음 단계의 단어를 예측합니다. 이거를 오토 리그레시브하게 계속해요. 그래서 한 번 포루프 돌 때마다 단어 예측하고 그 다음 포루프에서 그 단어를 인풋으로 받는 오토 리그레시브한 제너레이션이 일어나는 거죠. 그래서 이거를 한 번 루프를 다 돌면은 우리가 번역 테스크를 한 번 끝내는 거고 그 번역 테스크 끝낸 다음에 아웃풋을 이렇게 리턴하는 식으로 되어 있습니다. 그래서 어 뭐 시간적인 여유가 되면은 실제로 이 코드를 한번 짜보시는 것도 재밌을 것 같습니다. 그래서 조금 빠르게 진행을 했는데요. 이번 시간에는 사실 트랜스포머를 배우기 위한 어떤 전 단계라고 보시면 됩니다. 사실 알앤엔 LSTM 뭐 이런 거를 모르고 트랜스포머를 바로 들어갈 수는 없거든요. 그래서 알앤엔에서부터 시작해서 그거의 단점 그거의 단점을 보완하기 위한 LSTM 단점이 뭐였어요? 그 롱 텀 디펜던시가 없다는 거죠. 그래서 그거를 보완하기 위한 LSTM과 GRU를 배웠고 그거를 이용해서 시퀀스 투 시퀀스 모델을 어 구조를 이렇게 배우고 실제로 짜보는 것까지 배웠습니다. 그래서 다음 시간에는 시퀀스 투 시퀀스 모델의 단점과 그거를 보완하기 위한 어텐션 모델 즉 트랜스포머 모델의 어떤 할머니급 되는 그런 모델이죠 그런 거를 이렇게 어텐션 모델을 배워보도록 하겠습니다. 감사합니다."
}