{
  "lecture_name": "(5강) 모델 학습 파이프라인 이해하기 (2)",
  "source_file": "(5강) 모델 학습 파이프라인 이해하기 (2)_36.mp4_2025-12-04-10331090.json",
  "text": "안녕하세요. 도메인 공통 프로젝트 5강 모델 학습 파이프라인 이야기 두 번째 시작하도록 하겠습니다. 이번 강의에서는 더 엄격하게 모델을 검증할 수 있는 교차 검증 크레소 밸리데이션 프로세스에 대해 다뤄보겠습니다. 다음으로는 실제로 크로스 밸레이션을 구현할 때 사용하는 k 폴드 크로스 밸리데이션 이야기 내용을 다룰 예정이고요. 마지막으로는 교차 검증을 고려한 모델 학습 파이프라인 구현 부분을 다뤄보도록 하겠습니다. 첫 번째 교차 검증 프로세스 이해하기입니다. 먼저 이전 강의에서도 여러 번 언급했었던 모델 과적합에 대해서 이야기해 보겠습니다. 모델 과적합이란 훈련 데이터에 대해서는 예측을 잘하는 반면 검증 데이터나 새로운 데이터에서는 성능이 떨어지는 현상으로 다음 경우에서 주로 발생하게 됩니다. 모델이 훈련 데이터를 과하게 학습하는 경우입니다. 다음으로는 모델 복잡도에 비해 데이터의 크기가 너무 작은 경우입니다. 과적합이 발생한 모델은 모델 배포 이후 실제 데이터에 대한 예측 성능이 매우 좋지 않은 모습을 보여줍니다. 다음 예시는 분류 문제와 회귀 문제에서의 과적합 예시를 볼 수 있습니다. 먼저 왼쪽부터 보겠습니다. 먼저 두 개의 차원의 축에서 결정 경계를 그려내는 분류 문제입니다. 그림에서 볼 수 있듯이 클래스의 분포에 상관없이 결정 경계가 형성된 것을 볼 수 있습니다. 이 결정 경계는 훈련이 제대로 클래스를 분류하고 있지 않다라는 것을 확인할 수 있게 되고요. 이런 경우를 우리가 언더피팅 과소적합이라고 이야기를 합니다. 가운데에 있는 부분은 적절하게 피팅된 모델을 보여줍니다. 너무 과하게 클래스를 분류하고 있지도 않고 어느 정도 오차가 발생하는 상황에서 합리적인 결정 경계를 보여주고 있는데요. 이런 경우에 잘 학습된 모델이다라고 이야기할 수 있습니다. 다음은 오버피팅 현상이 발생한 모델의 결정 경계를 보겠습니다. 그림을 보시면 아시겠지만 동그라미 클래스 사이에 들어가 있는 스 스 모양의 클래스를 과하게 분류하려고 하다 보니 다음과 같이 복잡한 결정 경계를 형성을 하게 되는데요. 이런 경우를 우리가 과적합 오버피팅 되었다라고 이야기를 합니다. 이런 경우는 학습 데이터, 현재 주어진 학습 데이터를 잘 맞출지언정 우리가 새롭게 제공하는 검증 데이터 혹은 테스트 데이터에서는 좋은 성능을 낼 수 없습니다. 다음으로는 회귀 문제 예시를 좀 보겠습니다. 회귀 문제에서 언더피팅 과소적합된 경우에는 분포된 데이터 포인트를 잘 표현하는 어떤 곡선을 그려주어야 하는데요. 보여지는 그림에서 회기선은 단순히 단조 증가하는 회귀선을 보여줄 수 있습니다. 이 선은 주어진 데이터셋을 잘 표현하지 못하는 과소적합 형태의 회귀선을 보여주고 있습니다. 그다음 그림은 적절하게 학습된 회귀 모델을 보여줍니다. 점선으로 이루어진 회귀선은 주어진 데이터를 잘 표현하는 회귀선으로 판단할 수 있습니다. 다음으로는 오버피팅 된 회귀선을 보여줍니다. 해당 회귀선은 주어진 데이터셋을 너무 잘 학습하려고 하다 보니 모든 데이터 포인트를 지나가는 회귀선을 만들어 냅니다. 이런 경우에는 새로운 데이터가 포함된 검증 데이터 셋 혹은 테스트 데이터 셋이 나타났을 때 좋은 성능을 보이기 어렵습니다. 분류 회기의 오버피팅 케이스에서 볼 수 있듯이 제가 이전 페이지에서 언급한 대로 주어진 데이터에 비해 모델의 복잡도가 너무 높다라고 하는 표현은 이런 식으로 너무 복잡한 결정 경계 혹은 너무나 복잡한 회귀선을 만들어낸다라는 부분에서 말씀드렸던 부분입니다. 그렇다면 모델 성능에 악영향을 끼칠 수 있는 과적합은 모델 적합 시에 혹은 배포 전에 발생 여부를 어떻게 탐지할 수 있을지 알아보겠습니다. 이전에도 가볍게 언급을 했지만 모델 과적합 여부를 확인하는 방법은 모델이 학습할 때 사용한 트레인 데이터에는 존재하지 않는 uns 데이터에 대한 예측 양상을 관찰해 보는 것으로 확인해 볼 수 있습니다. 모델이 한 번도 학습하지 못한 새로운 데이터를 대상으로 예측하여 성능을 평가하고요. 학습 데이터 셋 트레인 데이터셋의 성능과 새로운 데이터셋 언시인 데이터셋의 성능의 비교를 통해서 모델의 과적합 여부를 판단할 수 있습니다. 예를 들어서 학습할 때 사용했었던 데이터가 치아와의 사진만으로 학습된 어떤 강아지 디텍션 모델이 있다고 해 보겠습니다. 만약에 이 주어진 데이터에서 강아지의 형상 혹은 강아지를 판단하기 위한 어떤 조건들 혹은 어떤 패턴들을 모델이 잘 학습했다면 오른쪽에 있는 치와와가 아닌 다른 종의 강아지 사진들도 잘 맞출 수 있을 겁니다. 하지만 모델이 적절하게 치화와 사진에서 강아지라고 하는 어떤 패턴과 피처를 찾아내지 못한 경우에는 제대로 맞추기 어렵겠죠. 방금 설명드렸던 부분은 일반적으로 트레인 데이터셋에서 검증 데이터셋을 분리한 뒤에 검증 데이터셋을 uncn 데이터로 사용한 케이스를 이야기합니다. 하지만 이번 강의에서는 교차 검증이라는 새로운 개념에 대해서 배워보겠습니다. 교차 검증 크로스 밸리데이션은 주어진 데이터 셋을 부분 집합 폴드로 나누고 이를 이용해 모델의 성능을 평가하는 방법입니다. 언시인 데이터에 대한 성능을 확인하기 위한 일반화된 방법론이다 정도로 이해하시면 되겠습니다. 과적합 탐지를 위한 모델의 일반화 성능을 평가하기 위해 사용되며, 학습 데이터 검증 데이터를 어떻게 샘플링하냐에 따라 교차 검증의 방법이 달라질 수 있습니다. 교차 검증의 핵심 내용에 대해서 다시 한 번 더 이야기해 보겠습니다. 전체 데이터를 학습에 사용할 학습 데이터와 성능을 확인할 검증 데이터 7 대 3 혹은 8 대 2 비율로 나눕니다. 검증 데이터는 언씬으로 가정하여 학습에 일체 활용하지 않고 학습 데이터로만 모델을 학습시킵니다. 학습 데이터에 대한 오차, 검증 데이터에 대한 오차 혹은 매트릭을 계산하여 모델의 일반화 성능을 추정할 수 있습니다. 이게 일반적으로 사용하는 홀드아웃 밸리데이션입니다. 하지만 이런 홀드아웃 밸리데이션의 한계점이 있습니다. 데이터를 어떻게 분할하느냐에 따라서 편향과 분산이 발생할 수 있게 되는데요. 예를 들어 단일 분할 방금 예시에서 봤던 것처럼 단일 분할에서 학습 검증 세트가 원본 데이터의 분포를 제대로 반영하지 못할 수 있습니다. 예를 들어서 특정 분할에서만 모델이 과하게 잘 되거나 과도하게 성능이 떨어질 수 있어서 모델의 성능 추정이 불안해진 경우가 있다라는 건데요. 이걸 조금 더 쉽게 이야기를 하면 내가 불리한 검증 데이터 셋에 포함되어 있는 샘플들이 충분히 전체 데이터셋의 분포를 포함하지 못한다면 혹은 표현하지 못한다면 모델이 제대로 검증되기 어렵다라는 뜻입니다. 모델의 일반화 성능에 대해 신뢰할 만한 추정치를 얻기 어렵게 된다라고 이해하시면 됩니다. 특히 데이터셋이 작은 경우 검증 세트에 충분한 데이터를 할당해야 하면서도 학습 데이터가 부족해져 모델이 약해질 수 있습니다. 일반적으로는 학습 데이터가 많으면 많을수록 모델이 더 많은 패턴을 학습할 수 있고 그로 인해 모델의 성능이 올라갈 수 있기 때문입니다. 따라서 데이터를 여러 분야로 나누거나 학습 검증 데이터셋을 여러 번 샘플링하여 검증하는 교차 검증법이 일반화 성능을 파악하기 위해 활용됩니다. 교차 검증을 위한 과적합 여부를 확인해 보겠습니다. 적합된 모델에 대해서 학습 데이터 검증 데이터에 대해서 평가를 합니다. 일반적으로 학습 데이터에 대한 오차는 감소하는 반면 검증 데이터에 대한 오차는 증가하게 됩니다. 이런 패턴을 보이는 경우가 오버피팅이고요. 교차 검증은 과적합 판단뿐만 아니라 사실 모델의 일반화 성능을 판단하기 위한 도구로서 사용이 됩니다. 또한 과적합을 방지하기 위해서는 다른 방법들을 고려할 수 있습니다. 모델이 가진 웨이트들이 너무 커지지 않게 혹은 일부의 웨이트를 0으로 만들어 버리는 정규화 신경망 모델에서 특정 노드의 활성화를 제한하는 드롭 아웃 혹은 밸리데이션 스코어 혹은 밸리데이션 로스가 개선되지 않는 경우를 최적점으로 생각하여 모델 학습을 조기 종료하는 얼리 스타핑 등이 있습니다. 그럼 교차 검증이 필요한 이유에 대해서 이야기해 보겠습니다. 모델의 일반화 능력을 평가하기 위한 목적이 있습니다. 교차 검증을 통해 모델이 새로운 데이터에 얼마나 잘 일반화되는지 평가할 수 있습니다. 단일 훈련 테스트 분할 혹은 단일 훈련 검증 분할만 사용하는 경우 특정 데이터 분할의 과적합 위험이 있습니다. 평가의 신뢰성을 증가시킬 수 있습니다. 데이터 셋의 여러 부분을 테스트하여 모델 평가의 신뢰성을 높일 수 있습니다. 다양한 데이터 분할에서 모델의 성능을 확인하게 됩니다. 데이터를 효율적으로 사용할 수 있게 됩니다. 교차 검증은 데이터를 최대한 활용하여 모델을 평가합니다. 왜냐하면 여러 개의 폴드로 분할해서 각각의 폴드를 반복적으로 검증 데이터로 사용하기 때문입니다. 특히 데이터셋이 작을 때 매우 유용합니다. 다음은 교차 검증의 종류에 대해서 이야기해 보겠습니다. 이전에 데이터를 샘플링하는 방법에 따라 교차 검증의 종류가 달라진다고 말씀드렸었는데요. 첫 번째로는 이전에도 설명드렸던 스트레티 파이드 교차 검증입니다. 이전에 설명드렸을 때는 스트레티 파이드를 매우 간단하게 간략하게 설명을 드렸었는데요. 이번 단계에서는 조금 더 자세히 그림과 함께 설명을 드리도록 하겠습니다. 클래스 라벨 혹은 타겟의 분포를 유지하면서 샘플링하는 교차 검증 방법입니다. 다음은 타임 시리즈 스플릿 교차 검증입니다. 여러분들이 타임 시리즈 데이터를 학습하는 경우 시계열 데이터의 특성에 맞게 시간 순서에 따라 샘플링을 하는 교차 검증 방법입니다. 이제 실제로 모델 학습에 사용하는 케 폴드 교차 검증에 대해서 이해해 보겠습니다. 케이 폴드 교차 검증은 앞서 설명드렸던 것처럼 데이터를 무작위의 동일한 크기를 갖는 케 개의 부분 집합 폴드로 나눕니다. 그 중 1개의 폴드를 검증 데이터로 나머지 폴드를 학습 데이터로 사용합니다. 최종적으로 케번의 새로운 학습 및 검증을 수행하여 각 폴드가 한 번씩 검증 데이터로 사용됩니다. 여기에서 케이는 일반적으로 5를 사용하게 됩니다. 숫자 5를 사용하게 되는 파이 폴드 크로스 밸리데이션의 경우 트레인 데이터는 80%, 검증 데이터는 20%의 비중을 가지게 됩니다. 케이폴드 교차 검증에서는 케번만큼의 반복으로 얻은 성능 지표들의 통계량을 계산하여 일반화된 모델 성능을 추론하는 방식을 사용합니다. 여기에서 사용하는 통계량들은 중심 통계량을 나타낼 수 있는 평균 혹은 메디안과 같이 중위수를 사용하게 되고요. 모델이 검증 데이터에서 어느 정도 수준의 성능을 가지는지 파악하는 데 사용됩니다. 혹은 산포도 표준편차와 같은 어떤 다른 통계량 값을 기반으로 해서 성능을 확인할 수도 있습니다. 각 모델의 성능이 검증 데이터에 따라 얼마나 일관적인지 강건성을 파악하는 데 사용됩니다. 각 폴드에서 얻은 모델 성능 지표가 낮은 표준 편차를 가진다면 모델의 성능이 안정적으로 나온다. 높은 표준 편차를 가진다면 모델 성능이 불안정하거나 특정 데이터에 민감하구나라고 판단할 수 있습니다. 이런 경우에는 어떤 데이터셋 어떤 특정 폴드에서 민감한지를 파악해서 우리가 추가적으로 분석해 볼 수 있는 기회를 얻을 수 있습니다. 케이 폴드 교차 검증을 사용할 때 고려해야 하는 부분인데요. 제가 적절한 케 값을 한 5 정도로 사용한다고 말씀을 드렸는데요. 그러면 이 5라는 숫자가 왜 나왔을까 이거를 이야기를 한번 해 보겠습니다. 기본적으로 케 폴드는 k1의 학습과 검증을 한 후 결과를 내기 때문에 이 k 값이 너무 많이 커지면 k1 만큼 모델을 학습해야 한다는 것을 의미합니다. 또한 k가 너무 커질 경우 검증 데이터 셋의 비중이 작아지게 됩니다. 예를 들어서 텐 폴드 크로스 밸류에이션의 경우 10개의 폴드로 조각을 내기 때문에 검증 데이터 셋은 전체의 10% 정도를 차지하게 됩니다. 그러면 이때는 이런 이야기를 해봐야 되는 거죠. 과연 그 10%의 검증 데이터셋이 충분히 전체 데이터셋을 잘 표현을 하는가 그렇기 때문에 여러분들이 사용하는 데이터의 크기 그리고 모델의 복잡도 혹은 모델의 학습 수렴 시간 이런 것들을 모두 고려해서 적절한 케이 값을 선택을 해야 됩니다. 이러한 과정에서 일반적으로 선택되는 값이 4 혹은 5라고 생각하시면 됩니다. 그리고 독립적인 모델 구성을 하셔야 되는데요. 폴드마다 서로 영향을 주는 구조로 구성하면 성능이 왜곡될 수 있습니다. 그렇기 때문에 여러분들이 각 모델 학습을 위해 사용하는 전처리 예를 들어서 스케일링 인코딩과 같은 작업들은 폴드 내에서 개별적으로 반복적으로 수행해 주셔야 됩니다. 데이터의 종류나 라벨 불균형 여부에 따라 스트레티 파이드 타임 3 스플릿 같은 방법을 똑같이 적용할 수 있습니다. 스트레티 파이드 케 폴드를 자세히 보겠습니다. 스트레티 파이드 케 폴드는 클래스 분포를 균등하게 유지하며 폴드를 나누는 방식이라고 설명을 드렸었는데요. 스트레티 파이드 케 폴드는 클래스 불균형 문제가 있는 데이터셋을 다루는 경우에 유용합니다. 전체 데이터에서 라벨의 비율이 다음과 같다고 했을 때 우리가 케이폴드를 통해서 데이터를 스프릿을 하게 되면 특정 폴드에 특정 라벨이 몰리거나 혹은 극단적인 경우 존재하지 않는 경우가 발생할 수 있습니다. 그렇기 때문에 클래스 라벨을 고려해서 폴드를 나누는 것이 매우 중요합니다. 예시에서 보시면 레이블 1, 레이블 2의 비중에 맞게 각 폴드들이 잘게 쪼개져 있는 거를 확인하실 수가 있고, 서로 색깔이 다른 것으로 어떤 데이터셋이 어떤 부분이 검증으로 사용되는지 어떤 부분이 학습으로 사용되는지 확인하실 수 있습니다. 이런 식으로 4개의 폴드를 쪼개서 각각의 폴드에 대해 평가를 하고 그 평가를 모아서 성능 평가를 하게 됩니다. 다음은 타임 3D 스플릿 케이폴드입니다. 시계열 데이터의 특성을 고려한 케이폴드라고 앞에서 설명을 드렸었는데요. 시계열 데이터는 시간 순서에 의존성이 있기 때문에 과거 데이터를 이용을 해서 미래 데이터를 검증을 하게 됩니다. 타임 시리즈 스플릿 케 폴드의 단점 중에 하나는 초기 분할의 데이터 양이 적습니다. 왜냐하면 시간 순서 의존성을 반영을 하려고 하다 보니 첫 번째 폴드에 대해서는 학습 데이터가 적을 수밖에 없기 때문입니다. 하지만 모델이 배포 시점의 데이터의 예측 성능과 유사한 평가를 할 수 있다라는 부분에서 장점이 있습니다. 케이폴드 교차 검증의 특징을 정리를 해 보겠습니다. 장점은 모든 데이터가 한 번씩 검증에 사용되므로 전체 데이터셋을 검증 데이터로 사용할 수 있습니다. 데이터가 분할에 치중되지 않는 일반화된 성능 추론을 가능하게 합니다. 단점으로는 복잡한 모델 데이터의 개수가 많은 경우 케이 값이 증가함에 따라 걸리는 시간과 계산량이 증가됩니다. 데이터의 개수가 적은 경우 클래스 분포가 매우 불균형한 경우 특정 폴드에 클래스가 없거나 적어 성능 지표가 왜곡될 수 있습니다. 다음은 교차 검증을 고려한 모델 학습 파이프라인 구현에 대해서 다뤄보겠습니다. 이전에 트레인 밸리데이션 데이터를 분할할 때 사용했었던 사이킬런 모듈로 케 폴드, 스트레티 파이드, 케이 폴드를 사용할 수 있습니다. 사이킬런을 간단하게 또 설명을 드리면 파이썬 기반의 대표적인 머신 러닝 라이브러리로 분류, 회귀, 클러스터링, 차원 축소, 모델 선택, 전처리 등 다양한 기능을 제공하고 있고요. 여러분들이 케이 폴드, 스트레티 파이드, 케이폴드 타임 3 스플릿 등을 활용하기 위해서는 모델 셀렉션 패키지 안에 있는 클래스들을 사용하시면 됩니다. 예제 데이터를 다음과 같이 설정해 놓고 진행해 보겠습니다. 예제 데이터는 천개의 샘플 그리고 10개의 특성 컬럼을 가지고 있는 매트릭스입니다. 예측 값인 y는 900개의 제로 클래스, 100개의 원 클래스로 이루어집니다. 먼저 케이폴드 스트레티 파이드 케이폴드의 사용 방식은 다음과 같습니다. 우리가 이전에 배웠었던 트레인 테스트 스플릿과는 약간 다른데요. 트레인 테스트 스플릿 같은 경우는 입력으로 전달한 데이터셋을 직접 분할하여 반환하도록 되어 있었습니다. 하지만 케이폴드는 반복적으로 폴드를 생성하기 때문에 실제로 그 데이터를 직접 분할하는 것이 아니라 분할된 데이터의 인덱스를 반환합니다. 왼쪽의 예시를 보시면 앤스프리치는 5로 설정했습니다. 이는 파이 폴드 크로스 밸리데이션을 하겠다라는 의미이고요. 앤 스프릿츠라고 하는 인자에다가 전달을 합니다. 실제로 사용할 때는 폼을 사용하게 되는데요. 폼은 라인의 오른쪽을 보시면 케프 닷 스플릿이라고 하는 메소드를 호출합니다. 여기에 x와 y를 전달하게 되고 반환하는 값은 트레인 인덱스와 밸리데이션 인덱스를 반환합니다. 이 반환받은 인덱스를 기반으로 앞서 설정한 데이터셋의 인덱싱을 통해 트레인 밸리데이션 데이터를 샘플링할 수 있습니다. 이어서 스트레티 파이드 k 폴드의 예시도 나오는데요. 사용 방법 자체는 k 폴드와 동일합니다. 하지만 다른 부분이 있습니다. 스트레티 파이드 k 폴드는 말 그대로 스트레티 파이드이기 때문에 y로 전달된 값에 클래스 비중에 따라 각 폴드를 분할하게 됩니다. 그래서 오른쪽에 출력되는 내용을 보시면 케 폴드 폴드별 라벨 분포를 봤을 때 그래도 얼추 비슷한 비중으로 분할이 되기는 하지만 정확하게 분할되지 않는 것을 보실 수가 있습니다. 하지만 스트레이디 파이드 케폴드의 라벨 분포를 보시면 완벽하게 분할이 되는 것을 보실 수가 있습니다. 그럼 파이토치에서 케이폴드 교차 검증을 어떤 식으로 사용하는지 예시 코드를 보도록 하겠습니다. 이 예시에 사용할 파이토치 모델은 간단한 MLP 모델이고요. 오른쪽의 예시를 보겠습니다. 이전 페이지에서 봤던 것과 같이 스케 낫 스플릿이라고 하는 부분을 보시면 입력 스와 스트레티 파일을 사용하기 위해 전달하는 레이블 와를 전달합니다. 동일하게 트레인 인덱스, 벨 인덱스라고 하는 인덱스를 반환받고요. 이 받은 인덱스를 텐서 데이터셋이라는 클래스로 샘플링된 스와 와 값을 담아 데이터셋 객체를 만들어 냅니다. 동일하게 밸리데이션 데이터셋에 대해서도 텐서 데이터셋을 만들고 생성한 이 데이터셋 객체를 데이터 로더 클래스로 감싸서 모델 학습에 사용할 수 있도록 설정합니다. 이어서 예시로 사용할 심플 클래시 파이어 모델을 정의하고요. 그다음 모델에서 사용할 로스 함수, 크로스 엔트로피 그리고 모델에서 사용할 옵티마이저, 아담 옵티마이저를 설정합니다. 네 그다음 포문을 통해 정해진 애폭만큼 모델을 학습하게 됩니다. 각 데이터는 트레인 로더, 밸리데이션 로더를 통해서 입력 데이터와 라벨을 전달받게 되고요. 이 입력과 라벨즈는 모델을 통과시켜 순전파를 계산하고 계산한 결괏값을 기반으로 로스를 계산한 뒤에 계산된 로스를 역전파를 통해 모델을 학습시키도록 합니다. 이런 식으로 각 폴드에 대해서 학습을 진행을 하고 이후에 검증을 진행하게 됩니다. 앞서 모델을 학습한 뒤엔 모델 검증이 일어나게 되는데요. 모델을 검증 모드로 변환한 뒤에 평가 지표 로스 혹은 매트릭으로 이 모델의 성능을 계산을 합니다. 계산한 로스 값을 평균 내어 폴드 벨 로스라고 하는 필드에다가 저장을 합니다. 벨 로스 나누기, 벨 서브셋을 하기 때문에 여기에 저장되는 값은 평균 로스 값이라고 생각하시면 됩니다. 각 폴드에서 학습한 모델 그리고 학습한 모델을 검증한 검증 스코어 등을 로스와 에큐러시 같은 매트릭을 저장한 다음에 이 결과값들을 모아서 성능을 평가해 볼 예정입니다. 왼쪽에 있는 코드를 수행을 하면 오른쪽에 있는 출력문과 같이 각 폴드별로 밸리데이션 로스가 얼마나 나왔는지 에큐러시가 얼마나 나왔는지 확인하실 수가 있습니다. 저장한 폴드별 로스와 에큐러시의 평균 표준편차를 토대로 이 모델의 일반화 성능을 평가합니다. 각 폴드의 에큐러시들은 90이었고요. 평균 에큐러시도 90이었습니다. 각 폴드의 로스는 다음과 같이 나왔고 평균 로스는 0.3458이 나왔습니다. 표준편차는 0.0144로 그리 크지 않은 수치를 보여줍니다. 이전에도 여러 번 언급했지만 이런 밸리데이션 이런 검증 로직에서는 폴드 간 전처리, 모델, 가중치 등의 학습 데이터 외의 정보가 전달되는 데이터 리키지를 주의하셔야 됩니다. 이런 문제는 생각보다 자주 발생하고 배포 후에 발견됩니다. 배포 후에 발견되면 발생할 수 있는 문제는 비즈니스 성과에 영향을 끼칠 수 있기 때문에 반드시 주의하셔야 됩니다. 잘못된 예제로는 이전에도 언급했었던 데이터를 분할하기 이전에 스케일링을 처리하는 예시가 있고요. 그 이후에는 모델을 초기화하지 않고 모델을 반복적으로 계속 이어서 학습하는 부분에 대해서도 보여주고 있습니다. 오른쪽에 있는 예시는 여러분들이 각 폴드마다 스케일러를 어떤 식으로 적용해야 되는지에 대한 예시를 보여줍니다. 스트레t 5드 k 폴드에서 트레이닝 인덱스, 밸리데이션 인덱스를 받아 각 데이터 샘플들을 샘플링하고 각 데이터 샘플 중 트레인 데이터셋에 대해 먼저 스케일러 핏 트랜스폼을 적용을 합니다. 이후에 밸리데이션 데이터에는 트랜스폼만 적용하게 됩니다. 이런 식으로 스케일링이 완료된 엑스트레인 스케일드 엑스파일 스케일드 이 데이터를 토치 텐서로 변환한 뒤 텐서 데이터셋으로 만든 다음 데이터 로더를 통해 모델 학습에 사용할 수 있도록 만들어 줍니다. 시계열 데이터에서는 더욱 주의해야 됩니다. 전체 데이터를 랜덤하게 스플릿하거나 전처리를 하게 되면 데이터 유출, 데이터 리퀴즈 현상이 발생할 수 있습니다. 많은 시계열 문제는 시점에 관련된 피처를 사용하므로 성능 해석의 오류가 발생합니다. 1개월 잘못된 예를 살펴보겠습니다. 밸리데이션 데이터셋에 포함되어 있는 일자는 1일 2일 6일 9일입니다. 트레인 데이터셋에 포함되어 있는 데이터는 3일, 4일, 5일, 7일, 8일 10일입니다. 여기서 모델이 학습할 때 3일, 4일, 5일, 7일, 8일 10일의 데이터를 학습을 하게 될 텐데 이때 사용하는 피처들이 각 시점에 사용할 수 있는 어떤 피처들을 사용하게 될 겁니다. 이렇게 되면 발생할 수 있는 문제는 밸리데이션 데이트에 포함된 1일 2일, 6일 9일 데이터들의 피처들이 이미 트레이닝 데이터 셋의 피처로 추가가 되기 때문에 관련된 통계량 값들이 노출이 될 수 있습니다. 그렇기 때문에 오른쪽에 있는 올바른 예와 같이 타임 시리즈 스프릿과 같은 폴드 방식을 사용을 해서 과거 데이터를 밸리데이션 데이터에 넣지 않도록 주의해야 됩니다. 예시를 보시면 학습 데이터에는 1, 2, 3, 4일 데이터가 포함이 되고요. 밸리데이션 데이터에는 5일, 6일 데이터가 포함이 됩니다. 요약을 해 보겠습니다. 이번 강의에서는 교차 검증 크로스 밸리데이션 프로세스에 대해서 이해해 보았습니다. 단순히 학습 데이터에만 잘 맞는 모델은 새로운 데이터의 일반화되기 어렵습니다. 데이터를 여러 개의 부분 폴드로 나누어 모델을 반복적으로 평가해 일반화 성능을 추정하는 방법이었습니다. 단일 트레인 테스트 스플릿으로는 평가가 불안정하고 모델이 운 좋게 높은 검증 성능, 일반화 성능을 낸 것처럼 보일 수 있습니다. 일반적으로 교차 검증을 할 땐 케이폴드, 스트레이디, 5 k 폴드, 타임 3 스프릿트 등 다양한 방식을 사용할 수 있습니다. k 폴드 교차 검증에서는 데이터를 k개의 폴드로 나누고 각 폴드를 한 번씩 검증용으로 사용하면서 모델을 k1 학습하게 됩니다. 전체 데이터를 효율적으로 사용하고 안정적인 평가가 가능합니다. 교차 검증을 고려한 모델 학습 파이프라인 구현에서는 사이킬러의 k 폴드, 스트레트 파이드 케이 폴드의 예시를 보았고, 데이터 리키즈 방지를 위해 폴드별 전처리나 혹은 시계열 데이터를 사용하는 경우 타임 스리드 스프릿을 이용해 데이터가 유출되지 않도록 주의해야 된다는 부분도 이야기했습니다. 이번 강의는 여기까지고 수고하셨습니다."
}