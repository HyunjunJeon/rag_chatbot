{
  "lecture_name": "[MLforRecSys] (5강) 마르코프 연쇄 몬테카를로 방법 I",
  "source_file": "[MLforRecSys] (5강) 마르코프 연쇄 몬테카를로 방법 I_97.mp4_2025-12-04-104506875.json",
  "text": "네 안녕하세요 여러분 이번에는 저희가 마르코프 연쇄 몬테카를로 방법에 대해서 저희가 학습을 진행하고자 합니다. 본 방법론으로 저희가 가기 전에 여러 가지 샘플링 방법부터 사실 배울 예정인데요 그러한 것을 우리가 배우는 이유는 우리가 앞에서 생성 모델을 결국 진행을 할 때 PX라는 것을 정확하게 계산하지 못하기 때문에 우리가 여러 가지 좀 문제들이 발생을 했었습니다. 자 피스라는 것은 사실 우리가 뭐 정확하게 계산하지 못하는 그 이유는 여러 가지 또 인티그랄이 들어가기 때문이기도 했었는데요. 자 그러한 문제를 좀 우리가 어떻게 또 베리션 인퍼런스 말고 샘플링 기반으로 또 어떻게 하면 좀 해결할 수 있을지 그거를 저희가 살펴보도록 하겠습니다. 자 그래서 이번에는 다음과 같이 몬티컬러 어프레시메이션 리젝션 인포턴 샘플링 을 저희가 배운 다음에 그다음에 MCMC의 기초에 대해서 저희가 살펴보고 넘어가도록 하겠습니다. 먼저 몬데칼롤러 오프레시메이션을 저희가 보도록 하겠습니다. 얘는 이그젝타게 좀 계산이 되지 않거나 아니면 굉장히 이글s탁게 계산되긴 하지만 너무 오랜 시간이 걸릴 것 같다 그럴 때 우리가 랜덤 샘플링을 통해서 근사하는 방법입니다. 예를 들어서 우리가 다음과 같은 베이시안 가우시안 미처 모델을 한번 본다고 가정하겠습니다. 자 그러면은 그때 우리가 다음과 같은 포스테리어 여기서 지라는 것은 파이지 람다 뮤를 다 포함하는 것을 의미합니다. 아시겠죠 자 그러면은 그거에 대해서 우리가 계산을 해야 되는데 이 부분이 사실은 분모 부분이 또 쉽지가 않다는 거예요. 분모 부분이 왜 결국엔 분모 부분을 계산하기 위해서는 이거를 가져와서 얘를 우리가 엑셀을 제외한 지 뮤 그다음에 람다 파이에 대해서 다 인티그랄을 해줘야 되잖아요 그렇죠 즉 여기 나와 있는 뭐 뉴머레이터는 분자는 어떻게 우리가 뭐 곱하고 하면은 뭐 가능할 수도 있죠 즉 얘는 우리가 이렇게 쪼개서 쓴다라고 하면은 우리가 이거 곱하기 이거 곱하기 이거 곱하기 이거 곱하기 이거 하면은 대략적인 형태를 알 수 있습니다. 분자는 근데 분모는 이걸 계산하기 위해서는 지에 대해서 인티그럴이 들어가는데 그때 여기서 지는 이거 하나만 나타내는 지가 아니라 요거 이 4개 레이턴트 베리어를 다 나타내는 그 질을 우리가 생각해야 되고 이 4개에 대한 인테그럴이 들어가다 보니까 얘가 쉽지 않게 되는 것입니다. 즉 분모는 우리가 모르는 경우가 굉장히 많다라는 겁니다. 자 그랬을 때 우리가 이러한 분모를 모를 때도 이런 거를 좀 쉽게 계산할 수 없을까라는 거예요. 무슨 말이냐면 결국 분모는 뭐예요? 여기서 분모가 왜 필요합니까? 분모가 필요한 대부분의 이유는 결국 노말라이징 콘선 때문입니다. 즉 얘를 우리가 적분했을 때 제에 대해서 적분했을 때 1이 나오잖아요. 그렇죠 그렇죠 그래서 그러면 얘도 마찬가지로 z에 대해서 접근했을 때 1이 나와야 돼요. 그러면 그렇게 1이 나오도록 하려면 노멀라이즈가 되어 있어야 되는 거예요. 그렇죠 마치 우리가 뭐 디스크리드로 정하면 5 7 9가 있어요. 이거 합하면 1 아니잖아요 그쵸 합이 1이 되려면 어떻게 해야 됩니까? 5 더하기 7 더하기 9로 이렇게 나눠줘야 돼요. 그렇죠 5 더하기 7 더하기 9 그다음에 여기도 5 더하기 7 더하기 9로 다 나눠줘야 됩니다. 이런 것들이 여기서는 계산이 되지만 방금 예시에서는 이런 거는 계산하기가 굉장히 어렵다는 겁니다. 우리는 그때 그러면은 이것만 우리가 접근이 가능할 때도 이것만 접근이 가능할 때도 뭔가 이 전체를 계산을 할 수가 있을까 라는 얘기예요. 즉 분자와 같이 실제로 우리는 pg VX를 만약에 계산하고 싶다고 하겠습니다. 근데 우리가 PGVX를 정확히 계산을 못하고 이 피지바스에 대응 이제 비례하는 피지 콤마스는 우리가 만약에 안다라고 가정할게요. 자 그때 피지바스를 우리가 계산할 수 있을까 라는 얘기를 하고 있는 거다 또는 여기서 우리가 샘플링을 할 수가 있을까 아시겠죠? 이러한 점을 한번 살펴보시면 결국 베레셔널 인퍼런스랑 MCMC 그리고 이 두 가지가 양대 산맥으로 우리가 생각하시면 되겠습니다. 물론 두 개의 장점만을 결합한 또 다른 추론 방법들도 존재합니다만 기본적으로 그렇게 우리가 베리샤 인퍼런스랑 그 엠씨엠씨 두 개가 있다라고 우리가 생각하시면 되겠습니다. 자 그러면은 그러한 엠시엠시로 우리가 넘어가기 전에 그러한 샘플링 기반의 방법론에 대한 일단 좀 기본적인 이해를 하고 그다음에 엠씨엠씨로 넘어가도록 하겠습니다. 첫 번째는 몬테카롤로 어프로치메이션입니다. 자 이거는 굉장히 많이 쓰여요. 사실 여러분들께서 브에 논문을 보더라도 몬델칼를로 오곡시메이션 또 다른 논문들을 보더라도 몬델칼를로 오프시메이션을 했습니다라는 말들이 엄청 그냥 문장 하나로 써져 있고 자세한 내용은 설명 안 되어 있습니다. 자 얘는 결국 어떤 걸 하고자 하는 거냐면요. 자 우리가 만약에 다음과 같이 프라는 함수가 있다고 하겠습니다. 뭐 프 제는 뭐 제 제곱일 수도 있고 어떤 거든 사실 될 수 있는 겁니다. 자 그러한 f z에 대한 기댓값을 우리가 f에 대한 기댓값을 알고 싶다고 할게요. 그러면 기댓값의 정의를 그대로 쓰면 intigr의 f p z DZ가 됩니다. 제가 컨테너스한 랜덤 베리어블이라고 하면 인티그럴 디스크린 하다고 하면 서메이션 되는 것뿐이에요. 그렇죠 자 그러면 여기서 인티그럴이 들어갑니다. 근데 여기서 도 이 f z가 어떻게 생겼고 pz가 어떻게 생겼냐에 따라서 이 인티그랄이 계산이 될 때가 있고 안 될 때가 있어요. 이 f랑 p의 모양에 따라서 그리고 많은 경우에 리얼 우리가 정말로 실질적으로 다루는 형태는 뭐 에프도 굉장히 복잡한 뉴럴 네트워크를 다루게 되고 피지도 우리가 굉장히 좀 복잡한 형태를 따르게 되기 때문에 얘가 사실은 계산이 정확하게 안 되는 경우가 대부분입니다. 즉 인트렉터블 한 상황이 대부분입니다. 자 그러면 얘를 우리가 어떻게 계산을 할 수 있을까라는 얘기예요. 이거를 계산하기 위해서 우리가 인티그라를 하지 않고 샘플링을 통해서 우리가 계산하겠다는 겁니다. 이렇게 즉 LG의 샘플을 뽑아서 그거를 이 프 제에다가 넣는 거예요. 그렇죠 그러면은 이렇게 FZL이라는 게 l개가 나옵니다. 그거를 우리가 평균 내겠다 지를 우리가 pz에서 지를 l기를 뽑아요. 그리고 그 l기에 대해서 우리가 얘를 계산해서 익스펙테이션을 취해주겠다. 그때 지를 pz에서 피 제에서 지를 아이아이디하게 샘플링 하면은 즉 동일한 상황에서 독립적으로 우리가 샘플링을 할 수만 있다면 그때는 얘가 얘를 잘 근사할 수 있다라는 것입니다. 물론 샘플의 개수가 많긴 해야죠. 자 그래서 그거를 한번 실제로 어떤 성질을 가지는지 한번 볼게요. 일단 이게 몬데카를로 오프시멘션입니다. 즉 굉장히 쉽게 말하면 그냥 인티그라를 서메이션으로 바꾸는 거예요. 파이나 한 샘플을 통해서 대신에 이 파이나 한 샘플은 아이아이디하게 뽑힌 샘플이어야 합니다. 아시겠죠? 그러면은 이러한 우리의 추정치는 우리 이러한 값은 실제로 어떠한 특징을 갖고 있냐 이거에 대한 기댓값은 실제로 그 에프에 대한 기댓값이랑 동일합니다. 이거에 대한 베리언스는 여러분 그 정의 그대로 한번 써보면 이렇게 나오게 되겠죠. 정의를 빌렸으면 그렇죠 그 말은 무슨 말이에요? 일단은 샘플의 개수가 굉장히 적으면 엘이 몇 개 안 되면 이 베어리언스가 큽니다. 그렇죠 그 까닭에 우리가 여기서 이 익스펙테이션 센서에서는 우리가 정확하게 근사할 수 있더라도 베리언스가 크면 또 리얼월드에서는 좀 쓰기 어려워요. 그래서 우리가 충분한 양의 샘플만 우리가 뽑는다면 그때는 배런스도 작은 좋은 추정 방법이 된다라는 게 몬테칼로 어포티메이션입니다. 자 이거에 대해서는 여러분들께서 한번 이 유도 과정을 제가 짧게나마 여러분들께서 좀 쉽게 따라갈 수 있게 적어놓긴 해가지고요. 한번 참고하실 분들은 한번 참고해서 보시면 되겠습니다. 네 여기서 또 굉장히 또 한 가지 중요한 포인트는 여러분 어떤 거냐면 어 지금 보시면은 결국 중요한 게 뭐인 것 같아요? 정확하게 우리가 몬테칼를로 오프시메이션을 하기 위해서 중요하다고 생각되는 게 과연 뭘까요? 어떤 걸까요? 여러분 여기서 우리가 좀 중요하다라고 말할 수 있는 거는 결국 어떤 게 되냐면 여기 나와 있는 것처럼 샘플의 개수 일단 이게 굉장히 중요한 요소가 됩니다. 그리고 생각보다 여기서 지금 나오고 있지 않은 거는 디멘전이에요. 디멘전 즉 실제로 이 g라는 게 갖고 있는 이 지라는 게 실제로 몇 차원인지 그렇죠 그러한 차원이 더 중요할 수가 있는데 그 차원은 우리의 밸런스나 우리의 익스펙테이션에 영향을 미치지 않습니다. 샘플이 무진장 많으면 사실은 괜찮다 라는 얘기를 하고 있습니다. 그래서 우리가 이러한 몬테칼를로 오프리시메이션을 많이 쓰는 이유기도 합니다. 샘플링만 많이 할 수 있으면 그때는 문제가 많이 해결이 됩니다. 그런데 이러한 샘플링은 여러분 생각보다 호락호락하지 않습니다. 그 이유는 무엇이냐면 우리가 이러한 핏이 를 정확하게 알고 있다고 가정하겠습니다. 만약에 이런 가우시안 분포라고 정확히 알고 있다고 할게요. 즉 PC는 뭐 루트 2파이 시그마 분의 1에 익스포넨셜에 뭐 마이너스의 시그마 제곱 분의 스 마이너스 뮤의 제곱 이런 식으로 가오션 분포의 피디프를 정확히 안다고 하겠습니다. pz는 이렇게 생겼다 그러면 가우시안 PDF를 아는 거랑 샘플링이랑 연결 지을 수 있으시겠네요 여러분 즉 PDF를 안다고 쳐요. 가우시안 PDF가 이렇게 생겼다고 알겠습니다. 그래서 가우시안 분포에서 샘플링을 어떻게 할 건가 쉽지 않거든요 첫 번째 두 번째 방금은 우리가 가우시안 분포의 PDF를 정확히 안다라는 가정이었습니다. 즉 피제는 아까 우리가 쓴 것처럼 보면 루트 2파이 뭐 시그마 제곱 분의 1에 그쵸 익스포넨셜에 뭐 우리가 엑스 마이너스 뭐 그렇죠 이 시그마 제곱 분의 엑스 마이너스 뮤의 제곱 이런 식으로 됩니다. 자 그러면은 사실 이거는 우리가 노멀라이징 콘서트예요. 적분했을 때 1이 되도록 하는 거 근데 우리가 앞에서 본 것처럼 노멀라이징 콘서트를 우리가 실제로는 모르는 경우가 많다. 여기서도 얘를 모른다고 할게요. 이것만 알아 그러면 그때는 어떻게 샘플링 할 건가라는 문제입니다. 그때 어떻게 할 거냐 자 그래서 지금부터 우리가 한 개씩 볼 건데 뭘 볼 거냐면요. 첫 번째 일단 우리가 샘플링 할 수 있는 정확한 피제트를 알고 있을 때 우리가 어떻게 샘플링 할 건가 왜 그것도 쉽지 않다라는 겁니다. PDF 할 때 두 번째 정확한 pg는 아니지만 이거는 모르지만 분자는 안다 노멀라이징 콘서트를 제외하고 난 다음 얘를 피트다이라고 하겠습니다. 이때 어떻게 할 건가 샘플링을 자 얘를 하기 위해서 우리가 인버스 CDF라는 걸 배울 거고요. 피틸다 지를 우리가 여기서 샘플링하기 위해서 리젝션 샘플링이라는 걸 배우겠습니다. 자 그리고 실제로 여기서 피틸다 지를 구하는 이유가 뭐예요? 여기서 결국 이 익스펙테이션 값을 계산하기 위함입니다. 여기서 보시면 그렇죠 대부분의 경우에 이렇습니다. 익스펙테이션 값을 구하기 위해서 그러면은 우리가 피틀다 g를 통해서 어떻게 하면은 이 피틀다 지만 알 때 정확한 피지를 모르는 겁니다. 피틀라 지만 알 때 즉 가우시안 피디프로 예를 들면 이텀은 모르고 이것만 알 때라는 거예요. 그때 우리가 어떻게 하면은 또 익스펙테이션을 구하게 할 건가 그거는 인포턴스 샘플링으로 보겠습니다. 즉 피지를 할 때 전체 PDF를 할 때는 리액션 우리가 인버스 3D 방법 피틀다 지만 할 때 여기서 샘플링하는 방법은 리젝션 샘플링 그냥 피트다 지만 할 때 우리가 여기서 익스펙테이션 구하는 거는 인버턴 샘플링으로 하나씩 배워 나가겠습니다. 그다음에 저희가 엠씨엠씨에 대한 아주 기본적인 내용만 보고 마치도록 하겠습니다. 자 여기서 먼저 우리가 인버스 CDF 샘플링을 한번 살펴보도록 하겠습니다. 자 우리가 일반적으로 알고 있는 PDF 일반적으로 PF를 아는 분포에 대해서도 샘플링 하는 게 쉬운 건 아니에요. 그때 우리가 어떻게 샘플링 할 거냐라는 겁니다. 그때는 다음과 같은 과정을 거칩니다. 즉 먼저 유니폼용 콤마일에서 값을 하나 뽑아요. 유니폼 용화면에서 값을 하나 뽑고 그다음에 걔를 트랜스포메이션 시켜줍니다. 어떻게 트랜스포메이션 시키는지는 뒤에서 볼게요. 즉 우리가 만약에 가우시안 분포에서 샘플링을 하고 싶다 그러면은 그에 대응되는 함수로 우리가 얘를 트랜스포메이션 시켜 줍니다. 그러고 나면은 걔가 가오션 분포를 따르는 변수로 바뀌게 됩니다. 결론은 이겁니다. 결론은 일단은 0 콤마 1 스탠다드 유니폼 유니폼 0 콤마 1에서 값을 샘플링합니다. 값을 샘플링해요. 그다음에 걔를 이렇게 FX 인버스 유로 우리가 바꿔줘요. 즉 우리가 만약에 가오샹 분포를 따르게 만들고 싶다라고 하면 하면은 여기 나와 있는 FX는 CDF입니다. CDF 크뮬러티브 디스트리션 펑션 CDF의 인버스 즉 가우시안으로 만약에 만들고 싶다면 가우시안 CDF의 인버스 함수를 우리가 구해서 트랜스포메이션 시켜주면 된다는 겁니다. 그러면 여기 나와 있는 x는 어떤 걸 따른다 가우시안 분포를 따르게 된다는 거다. 그 이유를 한번 볼게요. 자 우리가 결국 얘가 어떤 분포를 따르는지 궁금한 거예요. 그렇죠 얘가 얘가 어떤 분포를 따르는지 즉 아니 얘가 가우시안 시df의 인버스를 이렇게 취했는데 그럼 얘가 왜 가우시안 분포를 따르는 거냐 그게 궁금한 거잖아요. 그럼 얘가 어떤 분포를 따르는지 우리가 보자는 거예요. 얘가 아시겠죠? 지금 얘가 이렇게 왔습니다. 그러면 가우시안 CDF의 인버스 가우시안의 인버스 CDF를 우리가 가져왔습니다. 그거에 우리가 또 큐미러티브를 본 거예요. x까지의 모든 것을 우리가 누적시킨 겁니다. 얘가 어떤 분포 따르는지 그러면 얘는 양변에 우리가 만약에 프엑x를 취한다고 하면은 이렇게 취할 수가 있겠죠. 양변에 취하면 그러고 나면은 얘는 뭐예요? 얘는 유니폼이잖아요. 그렇죠 유니폼에 여기 와까지의 CDF는 그냥 y입니다. 그래서 얘는 이거예요. 즉 FX 인버스에 대한 CDF는 그냥 FX 되는 겁니다. 즉 가우시안 가우시안에 대한 인버스 CF를 우리가 취하면 그거의 큐뮬러티브는 가우시안 큐뮬러티브인 거고 그럼 얘를 우리가 다르게 생각하면 즉 이거에 대한 딱 얘만 생각하면 크뮬러티브가 아니라 얘만 생각하면 그때는 크뮬러티브가 아니라 가우시안 PDF가 되는 거죠. 그래서 정리하면은 우리가 0 콤마 1을 구하고 0 콤마 1에서 유니폼하게 랜덤 샘플링을 하고 그거를 에프엑스 인버스로 트랜스포메이션 시켜주면 우리가 원하는 분포를 따르도록 만들 수 있다는 겁니다. 예를 들어서 익스포넨셜 분포를 따르는 랜덤 베어러블를 우리가 샘플링한다고 할게요. FX는 이렇게 생겼다고 합니다. FX 익스포넨셜 분포 익스포넨셜 분포는 애초에 x가 0 이상일 때만 정의가 되기 때문에 x가 0 이상일 때만 우리가 이렇게 정의하겠습니다라고 인디케이터가 그냥 써져 있는 것뿐입니다. 얘를 그냥 생략하고 그냥 x는 0 이상으로 괄호를 쳐서 표현해도 됩니다. 자 이거에 대한 CDF를 구하는 거는 여러분 뭐 CDF는 구하면 되잖아요 그렇죠 그럼 마이너스 무한에서부터 실제로 0부터 하면 되겠지만 마이너스 무한에서부터 x까지의 누적된 거니까 여기서 우리가 FX DX를 하면 되겠습니다. 그러면 이거를 우리가 적분 구하면 이렇게 나오겠죠 그러고 나서 우리가 얘를 한번 정리를 한번 해보자는 거예요. 정리를 어떻게 우리가 정리를 할 거냐면 여기서 얘에다가 이 x 쪽이랑 이 FX를 이용해서 우리가 관계성을 바꿔주면은 이렇게 관계가 나오게 된다는 거예요. 아시겠죠? 자 그러면은 우리가 지금 이게 어떻게 되는 건지 한번 봅시다. 무슨 말이냐면은 우리가 다시 한 번 보면은 여기에다가 이 FX에다가 우리가 만약에 유를 보겠습니다. 자 그러면은 우리가 1 마이너스 유는 익스포넨셜의 마이너스 랍니다 스가 되죠. 그렇죠 자 그다음에 여기서 로그를 씌워주고 로그를 씌워주고 그럼 로그가 1 마이너스 유가 유가 되고 마이너스 람다로 나눠주고 하면은 얘가 이제 새로운 트랜스포메이션이 된 결과가 나오는 겁니다. 아시겠죠? 얘가 ex FX 인버스 u라고 우리가 부르는 거죠. 그러면은 얘가 어떤 분포를 따른다 얘가 익스포넨셜 분포를 따르더라라는 얘기가 되는 거예요. 왜 아까 앞에서 우리가 애초에 에프엑스 인버스 유는 에프엑스 인버스 유는 우리가 우리가 원래부터 찾고자 했던 그 프스를 따르게 된다라고 보지 않았습니까 그렇죠 그래서 여기서도 우리가 에프엑스 인버스의 유는 뭐 어떤 분포를 따른다 이런 에프엑스를 따른다 즉 익스포셜 분포를 우리가 따르게 된다 라는 겁니다. 이 샘플들이 그러면 우리는 익스포넨셜 분포 PDF만 알아도 우리는 이렇게 샘플링을 할 수 있게 되는 겁니다. 물론 얘가 뭐 항상 가능한 건 아니에요. 일단 이 문제의 단점이 뭘까요? 여러분 이 문제의 단점 이러한 방식의 단점은 첫 번째로는 가장 큰 단점은 결국 정확한 PDF를 알아야 된다는 거예요. 그쵸 정확하게 PX가 뭔지 또는 뭐 p제가 뭔지 이걸 우리가 알아야 된다고요 이거 그렇죠 그래야지 우리가 거기서 샘플링을 어떻게든 트랜스포메이션 시켜서 구한다는 겁니다. 즉 우리가 여기서 가우시안 PDF로 예를 들면 가우시안 PDF에 그 분모 텀까지 우리가 다 알고 있어야지만 얘가 가능하다라는 뜻입니다. 자 또 다른 문제점은 이게 항상 또 가능하지 않아요 사실 우리가 여기서 뭘 계산했어요? 여기 CDF의 인버스를 계산했습니다. 이 CDF의 인버스가 항상 계산 가능하지 않아요 계산이 안 되는 경우도 사실은 많습니다. 예를 들어서 뭐 제너럴라이즈 감마 분포라든지 이런 것들은 또 우리가 인버스 CDF를 계산하는 게 쉽지가 않아요. 자명하지가 않습니다. 그 까닭에 이러한 인버스 CF 방법은 특정한 분포에서만 가능하고 그다음에 특히나 우리가 노멀라이징 콘서트까지 이미 다 알고 있다라는 가정 하에서 이게 가능하다는 겁니다. 근데 아까 우리가 본 것처럼 노멀라이징 콘서트를 우리가 모르는 경우도 많습니다. 이런 거 우리가 모를 때 많잖아요. 여기서 값을 샘플링 하고 싶은데 여기 분자만 아는 거예요. 그럼 이거 모르잖아요 그럼 어떻게 할 거냐 그럴 때 우리가 다른 방법으로 리젝션 샘플링을 쓰겠다라는 겁니다. 이제부터는 그러면 두 번째 챕터 리젝션과 인포턴스로 넘어가도록 하겠습니다. 자 그래서 우리가 리액션 샘플링을 배우기 시작하는 겁니다. 아시겠죠? 인벌스 CDF가 맞는 건 아니다. 인벌스 CDF는 아마 여기 통계학과나 아니면은 통계학과 관련된 수업을 이미 학부 때 들으신 분들은 인사 학년 때 배웠겠지만 그게 전부는 아니라는 겁니다. 결국 우리가 목표로 하는 것은 이런 상황입니다. 이런 상황 노멀라이징 콘서트 여기 ZP를 모를 때 즉 우리가 뭐 가우시안 PDF 같은 경우는 분모를 몰라도 분자만 안다고 했을 때 그냥 분자 적분하면은 그 분자 적분한 걸 ZP라고 두면은 제피 쉽게 구할 수 있지 않냐 그러면 제피를 모르는 상황이 뭐가 있냐라고 생각할 수도 있지만 앞에서 우리가 본 것처럼 이런 거 이거 피스 어떻게 계산할 거예요? 분모 이거를 지뮤 람다 파이에 대해서 적분해야 되는데 쉽지가 않거든요. 자 그러한 상황처럼 노말라이징 콘서트를 모르는 상황이 사실 대부분입니다. 우리는 그래서 우리가 이거를 못하니까 배려자 인퍼런스를 하기도 했었고 근데 그거에 대한 또 다른 방법 샘플링 기반의 방법을 저희가 보고 있는 겁니다. 첫 번째는 리젝션 샘플링입니다. 결국 우리가 여기서 가정하는 거는 피틸다 지만 알고 있다고 가정하는 거예요. 제피는 모르고 피틸다 지만 우리가 안다고 가정했을 때 여기서 우리가 어떻게 값을 샘플링 할 거냐 라는 얘기를 하고 있는 겁니다. 왜 우리가 어쨌든 샘플링만 할 수 있으면 여기서 우리가 여기서 PC에서 샘플링만 할 수 있으면 어떻게든 이걸 뭐 계산을 할 수 있으니까 그렇죠 근데 여기서 샘플링을 우리가 하는 게 어렵다였습니다. 실제로 여러분 베레션 인퍼런스를 한번 기억하시더라도 qg qg는 결국 p 제바 x를 우리가 추론하는 거였죠. 그럼 qg를 우리가 샘플링하는 게 쉽지 않았습니다. 그쵸 그래서 우리가 그런 거를 어떻게 샘플링 할 거냐 이것만 알 때 그러면 리젝션 샘플링을 할 건데 어떻게 할 거냐면 피틀다 지만 우리가 알고 있습니다. 제피는 몰라요 피틀다 지만 알 때 이 피틸다 지를 여기서 빨간색으로 한번 생각하시면 됩니다. 그랬을 때 이 전체를 덮을 수 있는 KQG를 우리가 하나 생각해 보자는 거예요. 즉 qg라는 게 proposal dsion입니다. 그러면 거기에서 qg 자체는 우리가 뭐 여기 나와 있는 피틸다 지보다 어떤 부분에서 또 작고 그럴 수 있죠. 근데 그걸 케베 늘린다는 겁니다. 케베 늘렸을 때는 모든 지에 대해서 모든 지에 대해서 KQG가 다 크기를 원한다는 겁니다. 이런 걸 우리가 잡자는 거예요. 그러한 k를 우리가 잡을 수 있겠죠. 케이가 사실 크기만 하면 이거 잡을 수 있잖아요. k가 10만 100만 넣어버리면 이거 하는 거 어려운 일이 아닙니다. 물론 그렇다고 k를 무진장 키우면 안 되는 이유도 뒤에서 말씀드리겠습니다. 어쨌든 다시 돌아와서 리젝션 샘플링은 이러한 프로포션을 정하는데 프로포절만 정할 뿐만 아니라 이런 케이도 정해야 됩니다. 이 조건을 만족하면 자 그러고 나면 우리가 이렇게 샘플링 할 수 있습니다. 즉 여기서 우리가 제 제로를 q 지에서 샘플링합니다. 즉 qg는 우리가 그냥 마음대로 정한 거예요. 가우시안 분포 이렇게 그러다 보니까 q지에는 qg는 이왕이면 우리가 샘플링을 이미 할 수 있는 분포를 잡는 게 당연히 좋겠죠. 그렇죠 그러면 qg를 우리가 qg에서 g 제로를 샘플링합니다. g제로 샘플링 했어요. q g에서 샘플링한다라는 말은 여러분 큐지에서 샘플링한다라는 말은 여러분 한번 생각해 보시면 가끔씩 큐지에서 샘플링하면 이런 와 값이 샘플링 된다라고 생각하시는 분들이 있는데 그게 아니라 y 값은 우리가 라이크드인 거고 이거 그렇죠 PDF 값인 거고 이 x축에서 값이 하나 나온다 이 PDF에 우리가 비례해서라고 생각하시면 되겠습니다. 여기서 우리가 제 제로를 샘플링을 하나 시작을 합니다. 자 그러면은 여기 나와 있는 제세로는 우리가 큐에서 샘플링을 하게 되고요. 그러면 큐가 이렇게 있다고 할 때 큐에서 우리가 이 x축에서 샘플링이 된다고 생각하셔야 됩니다. 이 y축에서 샘플링이 된다고 착각하시는 분들이 가끔 있는데 여기 q 제가 있으면 q 제에 여기 도메인에서 우리가 값이 하나 딱 샘플링 된다 이 PDF에 비례해서 그렇죠 그러면 여기 제 제로가 샘플링 됐다라고 가정하면은 얘를 쫙 올리면 어디까지 올라가요? kq 제제까지 올라갑니다. 여기까지 0부터 여기까지 그렇죠 여기까지 올라갑니다. 그러면은 우리가 지금 찾고자 하는 것은 그 범위에서 값을 하나 더 우리가 샘플링 할 거예요. 즉 제 제로를 샘플링 했습니다. 그다음에 또 뭘 한번 샘플링한다 제 제로에서부터 케큐 제제로까지는 우리가 유니폼하게 샘플링합니다. 자 여기 제 제로가 샘플링 된 건 유니폼 한 게 아니에요. 우리는 가장 그럴듯한 곳에서 샘플링이 되고 있는 겁니다. 그러고 나서 여기에 세로축으로는 유니폼하게 값을 하나 뽑습니다. 유제로라는 걸 하나 뽑는다고 할게요. 예를 들어 유제로가 여기 있다라고 할 수도 있겠죠 그렇죠 그 유제로가 만약에 피틀다 지로보다 만약에 유제로가 여기 있다고 할게요. 그럼 피틀다 지로보다 크죠 그때는 샘플을 우리가 리젝션 합니다. 어 얘는 좀 옳지 못한 샘플이다. 근데 유제로가 이 피틀라 지 안으로 들어온다 그러면 우리는 이 유제로를 남겨 놓을 겁니다. 즉 여기 나와 있는 회색 영역의 유제로가 속하게 되면 그건 우리는 제거하고 흰색 부분에 있는 것들만 남기겠다는 겁니다. 그래야지 우리가 비틀다시에 가까운 것을 근사할 수가 있게 됩니다. 이 방법으로 우리가 리젝션을 진행하는 거예요. 즉 우리가 유0로를 뽑는데 제제로 뽑고 유제로 뽑는데 그게 이 영역을 벗어나면 우리는 리액션 하고 그게 아니면 그대로 유지시킨다 어셉시킨다라는 말입니다. 자 그러면 이거 어셉 될 확률을 한번 계산해 봅시다. 어셉 될 확률 자 어셉트 확률은 우리가 이렇게 계산할 수 있겠죠 그렇죠 자 우리가 z라는 샘플을 만약에 만들었어요. z라는 샘플을 만들었으면 그거는 이렇게 KQG만큼의 영역이 있는 거고 또 여기는 피틀다 지로그만큼의 영역이 있는 겁니다. 그러면 케큐 지분의 피틸다 지만큼이니까 이렇게 그 제트가 샘플링 된 제트가 어습될 확률은 이렇게 되겠죠 즉 이미 제가 샘플링이 됐어요. 이렇게 제 제로처럼 그때 걔가 어셉 될 확률은 우리가 이렇게 구할 수가 있다는 겁니다. 자 그러면은 우리가 얘를 모든 지에 대해서 그쵸 지도 샘플링 할 거니까 모든 지에 대해서 우리가 구한다고 치면은 이렇게 구할 수가 있게 되겠습니다. 그렇죠 이렇게 약분하고 그러면 이것만 쫙 하고 남게 되는 것이죠 아시겠죠? 여러분 그리고 여기서 한번 보면은 결국 어셉된 확률을 보면은 k가 크면은 KQG가 다 지금 분모에 있는 겁니다. 자 그러면 한번 보면은 케이가 크면 분모가 커지니까 이건 작아지는 거죠. 어셉 될 확률이 작아진다는 겁니다. 그럼 케이는 가능하면 작으면 작을수록 좋다는 거예요. 아시겠죠? 여러분 자 그런 상황이기 때문에 우리가 케이를 또 막 키우면 안 되기는 합니다. 그리고 얘가 저희가 나중에 보겠지만 하이디맨션으로 가면 갈수록 제가 이제 하이드맨션으로 가면 갈수록 여기 나와 있는 q지는 이러한 비틀다이랑 유사한 형태를 쓰면 좋은 거예요. 만약에 좀 많이 다르다 그러면은 어세텀스 레잇이 좀 쉽지가 않습니다. 네 그러면 여러분 여기서 조금만 더 몇 가지 살펴보도록 하겠습니다. 어셉이 될 확률은 우리가 앞에서 본 것처럼 이렇게 그렇죠 될 수가 있습니다. 그러고 나서 그러면 우리가 제가 주어졌을 때 어셉이 될 수 있는 확률은 앞에서 봤던 것처럼 제가 가능한 거는 이 범위 그쵸 그중에서 어셉이 되는 건 여기까지 봐야 되니까 거기까지 우리가 유저 광고를 생각하면 되겠죠 그래서 이렇게 우리가 표현할 수 있습니다. 그렇죠 얘가 제가 주어졌을 때 어셉p이 되는 경우입니다. 자 그다음에 큐지랑 피 어셉턴스 바지 우리가 방금 위에서 계산했던 거 두 개를 곱하면은 이렇게 나오게 됩니다. 그러고 나면은 또 우리가 지금 알고 있는 게 뭐예요? 케이랑 피 어셋이랑 곱하면은 피틸다지를 노말라이징 한 거예요. 얘는 뭡니까? 제 핀이에요 제핀 그렇죠 노멀라이징 콘서트 그렇죠 그 말은 지금 무슨 말이냐면 우리가 이렇게 구성을 하면은 p 어셉턴스가 여기 있고 큐지가 여기 있고 큐지는 우리 우리가 정하는 거니까 그렇죠 그다음 피 어스턴스 바지를 구하면은 걔는 뭐가 된다 피지의 우리가 추정할 수 있는 재료가 된다라는 말이 됩니다. 아시겠죠? 자 이렇게 하면은 우리가 리젝션 샘플링을 통해서 이 피지에서 값이 샘플링 되는 것을 우리가 묘사할 수 있다라는 겁니다. 네 이거를 또 우리가 이렇게도 해석을 할 수가 있습니다. 여기 한번 보시면은 제가 어셉 되는 것과 그다음에 제가 어셉 됐는데 또 여기 나와 있는 제 제로 이하인 거 그쵸 이런 식으로도 우리가 한번 해석하면은 결국에는 뭘 알 수 있냐면 우리가 이 z가 어셉된 즉 우리가 어셉된 것들만 남겨놨을 때 그게 어떠한 CDF 분포를 따르냐를 보면은 그게 어떤 분포를 따른다 그 z 제로에 대한 CDF 분포를 따른다라는 얘기를 하고 있는 겁니다. 즉 이렇게 우리가 결국 해석을 하게 되면은 우리가 리젝션 샘플링을 통해서 보다 더 이 피지에 대한 근사치를 잘 추정할 수 있게 된다라는 것을 지금 얘기하게 되는 것입니다. 그러면 여기서 우리가 얼마만큼의 인터레이션이 필요할까요? 즉 샘플링을 몇 번을 해야 될지 한번 생각해 보도록 하겠습니다. 즉 어셉이 될 확률이 이겁니다. 이만큼이에요. 그러면 여기 나와 있는 게 우리가 노멀라이징 콘서트 ZP라고 하기로 했습니다. 자 그러면은 만약에 어셉이 될 확률이 20%다 그러면 우리는 몇 번 해야 돼요 샘플링을 다섯 번 해야죠 그래야지 한 번 어셉 될 거니까 그렇죠 즉 우리가 한 번 샘플링을 하기 위해서는 하나의 샘플을 어셉 하기 위해서는 총 몇 번 샘플링을 해야 됩니까 이거에 역수범만큼 하면 되겠죠 그게 바로 여기 나와 있는 것처럼 제 피 분의 케이라고 나와 있는 겁니다. 이거에 역수라서 자 여기서 우리가 만약에 뭐 q랑 피를 정말 정확하게 잡아놨으면 그때는 뭐 우리가 한 번만 진행해도 되겠지만 그게 아니라 q랑 피가 만약에 굉장히 좀 다르다 라고 하면은 그때는 어떤 과정을 거치냐면 굉장히 많은 우리가 샘플링을 사실 해야 됩니다. 왜 q랑 피가 만약에 굉장히 다르다고 하면은 사실 케이가 커질 수밖에 없잖아요 왜 큐가 여기서는 kq가 피를 다 덮어야 되니까 근데 만약에 예를 들어서 큐가 이상하게 생겼어요 큐를 우리가 잘못 잡았습니다. 큐를 이렇게 잡았어요. 그러면은 우리가 여기서도 결국 얘를 덮어야 되니까 어떻게 해야 돼요 키를 엄청 늘려야 되는 겁니다. 그럼 이렇게 되는 거예요 그쵸 그럼 케이가 엄청 늘어나게 되면은 여기서는 지금 어떻게 되겠습니까 어셉 될 확률이 굉장히 낮은 거예요. 이 전체에서 어셉될 확률이 이거밖에 안 되는 거니까 굉장히 낮아지는 문제가 된다. 그래서 케이가 작아지면 작아질수록 좋다. 그리고 k가 작으려면 q가 피랑 사실 유사해야 된다 그래서 사실 p에 대한 좀 어느 정도의 정보가 있으면 좀 많은 도움이 되겠죠. 자 그래서 이게 하이 디맨션으로 가면은 또 이 문제는 더욱더 커지게 됩니다. 한 가지 예로 다음과 같은 우리가 디디멘션의 가우지 분포를 한번 생각해 볼게요. 디디멘전 자 그때 우리의 타겟은 피제입니다. 즉 여기서 우리가 샘플링 하는 거예요. 여기서 우리가 실제로 그냥 피 z를 알고 있다라고 그냥 가정하겠습니다. 뭐 얘를 우리가 모르고 여기서 이 분모 부분은 모르고 여기 나와 있는 분자 부분만 알고 있다라고 가정해도 사실 상관없어요. 자 여기서는 그냥 편의상 우리가 피 제 이걸로 가정하겠습니다. 디디멘전 프러포즈를 우리가 똑같이 이렇게 잡았다고 할게요. 를 즉 큐는 피랑 거의 유사하게 잡았는데 그때 분산만 지금 다른 겁니다. 그럼 여기서 분산을 한번 보면은 분산이 q에 대한 분산이 피보다 커야 될까요 아니면 작아야 될까요? 자 가급적이면은 가급적이면은 우리가 얘가 분산이 얘보다 큰 게 좋겠죠 왜 그래야지 만약에 피가 이렇게 생겼고 q가 분산이 크다면 이렇게 생겼겠죠 그렇죠 이렇게 생겼겠죠 자 그때 케이를 우리가 여기서 곱해주면은 이렇게 올라가게 되는 형태가 됩니다. 그래야지 우리가 덮을 수가 있겠죠. 분산이 커야지만 그렇죠 만약에 분산이 안 크다 그러면 뭐 이렇게 됐다 이렇게 여기만 뾰족하고 나머지는 우리가 다 작다. 그럼 사실 여기서는 우리가 거의 0에 가까운 값이 되니까 k가 또 엄청 커져야 되는 겁니다. 그렇죠 그 까닭에 우리는 분산이 더 큰 q를 잡도록 하겠습니다. 좀 더 널찍하게 우리가 다 포함하게 하기 위해서 그러면 우리가 여기서 k를 얼마로 잡을 거냐 k만 이제 잡으면 되는 거예요. k만 그렇죠 케이만 잡으면 우리가 어셋 될 확률을 구해 가지고 그다음에 어셉 할지 리젝 할지 정해가지고 어셋 된 것들만 우리가 모으면 이 피지를 추정할 수가 있게 되는 겁니다. 자 그러면은 여기서 우리가 k를 어떻게 잡을 거냐 케이는 우리가 이런 식으로 잡는 게 가장 옵티멀 하겠죠 k는 뭐예요? 이 식을 만족해야 돼 더 커야 돼 근데 k 자체는 너무 또 안 크면 좋겠어 즉 이 식을 만족하는 최소한의 k를 그냥 찾고 싶은 거예요. 근데 왜 케이가 그러면 옵티멀한 게 요거일까요? 여러분 왜 요거일까요? 한번 생각을 한번 해보시면은 자 만약에 여기서 결국 가장 큰 값만 봅시다. 우리가 만약에 여기 빨간색이 q라고 할게요. 파란색이 피입니다. 그럼 우리가 결국 q에다가 k를 곱해서 피를 덮으려면 뭐만 보면 돼요 이 부분이 결국 덮이는지를 봐야 됩니다. 그래서 이렇게 쫙 올려줘야 돼요. 이 부분의 차이를 봐야 돼요. 이 부분의 차이를 우리가 보려면 결국 지금 0에서의 값 x가 지금 윈도 0입니다. 얘가 0이에요. 그러면 x가 0일 때의 값만 보면 되는 거예요. 그럼 이게 요게 되는 거예요. 이게 이게 됩니다. 그렇죠 이게 되는 것이고 그다음에 얘도 마찬가지로 이것만 딱 남게 되는 거예요. 그 가장 큰 값은 그러면 얘가 얘가 얘보다 결국 커야 되니까 그렇죠 그래서 케이가 이렇게 잡히는데 그게 이 변수뿐만 아니라 모든 디멘션에 대해서 다 그게 성립해야 되니까 그게 디번만큼 우리가 곱해지는 겁니다. 그래서 차원이 늘어나면 늘어날수록 이 k는 굉장히 커질 수 있다. 그래서 리젝션 샘플링은 하이디맨션에서 잘 작동하지 않을 수 있다라는 얘기를 지금 하는 겁니다. 그다음 우리가 샘플링은 인폴턴 샘플링을 한번 배워보도록 하겠습니다. 자 인폴턴 샘플링은 또 리젝션 샘플링하고는 약간 달라요. 인폴턴 샘플링은 우리가 바로 익스펙테이션을 바로 추정하는 방법입니다. 아시겠죠? 지금 무슨 말이냐하면은 실제로 우리가 알고 싶은 거는 이런 익스펙테이션을 알고 싶은 경우가 많아요. 그렇죠 얘를 우리가 알고 싶은데 이거를 우리가 정확하게 계산을 못 하니깐 여기서 피제에서 우리가 어떻게든 값을 샘플링해서 그렇죠 값 샘플링해서 우리가 근사해서 구하겠다라는 컨셉이 대부분인 것뿐입니다. 그렇죠 자 우리는 원래 알고 싶은 건 보통 익스펙테이션 구하고 싶어요. 샘플링해가지고 자 그러면 그때 우리가 이 익스펙테이션 자체를 우리가 바로 추정하면 안 될까라는 게 여기 나와 있는 인폴턴 샘플링입니다. 인퍼턴 샘플링 관련해서는 저희가 뒤에서도 바이러스가 있는지 없는지 그다음에 이거에 배리언스가 어떤지 그런 것들을 저희가 살펴보겠지만 그래도 굉장히 좀 약간 간략하게 결론 위주로만 좀 심화된 내용이라서 결론 위주로만 살펴보고 넘어가도록 하겠습니다. 자 일단은 여기서 인버턴 샘플링도 뮤지션 샘플링하고 컨셉은 비슷해요. 프로포절을 우리가 고릅니다. 샘플링 기반의 방법은 뒤에서 우리가 엠씨엠씨도 배우겠지만 이러한 프로포절 큐를 우리가 일단은 고르고 시작을 합니다. 자 그러면 우리가 익스펙테이션을 이렇게 정의할 수가 있고 q를 이렇게 위아래로 곱하면 되겠죠 그렇죠 그다음에 우리가 만약에 샘플링을 한다라고 가정하겠습니다. 샘플링을 하고 한다라고 가정하면은 이렇게 또 우리가 표현을 할 수 있겠죠. 자 큐에서 샘플링 한다고 가정하니까 q가 딱 없어진 겁니다. 이렇게 q에서 우리가 l 겔을 랜덤하게 샘플링 한다는 거예요. 아이아이디 하게 그러면 이렇게 우리가 된다라는 거는 몬테칼로 어프렉시메이션이었습니다. 그렇죠 그러면 우리가 여기서 이 큐브네피 얘를 우리가 알로 한번 정리를 하겠습니다. 얘를 우리는 인포턴스 웨이트라고 생각할 수 있어요. 즉 무슨 말이냐면 우리가 키에서 샘플링을 할 겁니다. 큐의 샘플링을 해서 이렇게 기댓값을 구할 거예요. 근데 큐는 어디까지나 우리가 프로포절이야 그쵸 우리는 실제로는 피에서 샘플링 해야 되는 건데 우리는 피에서 샘플링을 못 하니까 큐라는 프로포절에서 샘플링 하는 것뿐입니다. 그러면 q는 당연히 피랑 다를 거잖아요. 그러면은 그 두 개가 다음의 정도를 그러한 다름의 정도를 코렉션 교정해 줘야지 그게 여기 나와 있는 q 분의 p 그게 여기 나와 있는 인포턴스 웨이트가 되는 게 됩니다. 얘는 우리는 RL이라고 적을게요. 자 이러한 에스티메이터는 언 바이러스입니다. 즉 여기에 대해서 우리가 익스펙테이션을 취하면 얘가 쫙 나와요. 익스펙트을 취하면 자 근데 이거의 문제가 뭘까요? 지금까지 제가 말한 논리의 문제점 제가 지금까지 말한 논리의 문제점이 없으면 인버턴스 샘플링 좋은 거예요. 익스펙테이션 우리가 취하면 즉 어떻게 생각하면 우리가 무수히 많은 샘플을 잘 구하면 그때는 이 정확한 익스펙테이션 값을 구할 수 있다라는 뜻이 되는 겁니다. 자 이 방법의 문제점은 뭘까요? 자 뒤에서 우리가 그 보겠지만 일단은 베리언스가 비교적 좀 큰 편입니다. 자 여기 나와 있는 베리언스를 한번 볼게요. 아까 우리가 구한 즉 인버턴 샘플링에서는 우리가 얘를 실제로 우리의 에스티메이트로 하겠다는 겁니다. 지금 우리가 이 익스펙티즘 구하고 싶은데 그거를 우리가 이걸로 생각하겠다 얘를 우리는 익스펙테이션의 근세 값으로 생각하겠다라는 겁니다. 아시겠죠? 자 그러면 이거에 우리가 일단 베리언스를 또 구하면 이거에 대한 배려언스를 구하면은 우리가 이거 베리언스 구하겠습니다. 그러면은 이것도 여러분들께서 제가 라인 바이 라인으로 최대한 적어 놨습니다. 한번 따라가시면 바로 이해가 되실 것 같고요. 그래서 요 부분 이 부분이 나오는데 자 이 부분은 우리가 큐세트라는 걸 그냥 한번 곱해주는 거예요. 왜 qz 적분하면 1이니까 1 곱하는 거랑 똑같으니까 그래서 등호가 있는 겁니다. 그러고 나서 여기 부등호가 있는데 얘는 이제 코시 부등식입니다. 즉 이런 식이 만족한다는 거예요. 예 이것도 지금 우리가 있고 여기도 있는데 결국에는 이런 형태로 우리가 쓸 수 있다라는 얘기입니다. 그러면 그때 우리가 또 어떤 얘기를 하고 싶은 거냐면 얘가 증오가 되는 조건은 결국에 여기 나와 있는 에랑 비가 서로 비례 관계일 때 즉 여기서는 보면은 이 큐지랑 그렇죠 이 qg랑 이 fp가 서로 비례 관계일 때 그러면 이게 딱 등호가 성립합니다. 이게 딱 등호가 성립한다는 말이에요. 아시겠죠? 그러면 얘가 딱 등호가 성립하면 뭐예요? 얘가 여기로 가니까 베리언스가 굉장히 작은 게 나오는 겁니다. 그러면은 언바이스트 에스티메이터이면서 익스펙테이션 센서에서는 정확한 값을 우리가 추정하면서 베리언스도 작으니까 어 인폴턴 샘플링 정말 최고다라고 생각할 수 있지만 여기까지의 문제점은 뭐다 아니 그럼 선생님 여기 큐제트를 프 피세에 비례하게 그냥 키세츠 잡으면 되는 거 아니냐 이게 옵티멀한 프로포절인 것 같다. 그럼 이걸로 하면 되는 거 아니냐 이거의 문제점 우리는 피세트를 부릅니다. 지금 보시면 얘는 피세트를 우리가 안다라고 가정했을 때 그렇죠 피세트를 아니까 q 세트에서 샘플링하고 그걸 이제 피에 넣어 가지고 피세트 구하고 실제로 이거 우리는 몰라요. 피 모르니까 지금 이 고생하고 있는 겁니다. 그렇죠 피를 모르고 우리는 뭐까지 안다 보통 피틸다까지만 노말라이징 콘서트 빼고 피틸다까지만 아는 경우가 대부분이에요. 그래서 사실 이러한 분석은 좀 옳지 못하다 옳지 못하다기보다는 현실적이지 않다. 실제로 우리가 피틸다를 가지고 그래서 똑같이 한번 해볼 수가 있어요. 피틸다 즉 피라는 건 이렇게 우리가 모델링하고 큐라는 거를 이렇게 우리가 모델링 하면 우리가 뭐 예를 들어서 이렇게 앞에는 거의 똑같은데 피 대신에 피틀다 들어가고 큐 대신에 큐틸다가 들어간 다음에 노멀라이징 콘서트가 여기 있는 것뿐입니다. 자 이런 상황으로 가면 그때는 언 바이어스 에스티메이터가 사실 안 돼요. 정확히 구해보면 그런 이유로 임폴턴 샘플링은 또 그만의 문제점이 존재하긴 한다. 즉 정리하면은 인폴턴 샘플링 같은 경우는 우리가 바로 기댓값을 추론할 수 있는 샘플링 방법입니다. 그때 우리가 피틸다라는 것과 큐틸다 사이에 이 레이시의 차이를 보고 이 큐틸다 에서 샘플링 된 거를 우리가 콜렉션 시켜주는 효과가 있는 거예요. 왜 큐틀즈에서 뽑은 게 정확하지 않으니까 그쵸 그런 코렉션을 시켜주는 효과가 있고 그걸 기반으로 우리가 추정하는 형태가 됩니다. 실제로 우리는 이거 모릅니다. 그쵸 이거 모르잖아요. 여기까지만 우리가 아는 거예요. 실제로 그래서 기댓값을 우리가 정확하게는 모르고 여기 얘는 어쨌든 우리가 또 상수라고 생각할 수 있겠죠. 상수에 비례해서 특정한 값에 비례하는 우리가 기댓값만 얻을 수 있다 뿐입니다. 정리하면은 우리가 리젝션 샘플링 같은 경우는 우리가 그 이러한 프제에 대한 기댓값을 구하고 싶을 때 어떻게 했나요? 그때 여기 나와 있는 피지를 우리가 모델링을 했습니다. 근데 피지를 모델링 하고 싶은데 그 피지를 우리가 덮는 qg라는 걸 우리가 가져온 거예요. 그래서 KQG 정확하게는 qg 자체는 PC를 못 덮어도 k를 곱했을 때는 PC를 덮도록 하는 그렇죠 실제로 우리가 pg를 모르고 피틀다 지만 안다고 했을 때 그렇죠 그때 우리가 얘를 덮는 KQG를 가져와서 여기서 우리가 얘를 활용해서 pg를 우리가 추론을 하고 그렇죠 PC에서 우리가 샘플링 할 수 있게 되면서 기댓값을 구하게 된 형태였습니다. 그래서 여기서의 옵티멀한 qg는 사실 pg랑 같으면 가장 좋은 거죠. 현실적으로는 뭐다 KQG가 이 PT 다시보다 크도록 덮을 수 있도록 우리가 q를 정한다는 겁니다. k가 작더라도 KQG를 했을 때 피틀다 지를 덮을 수 있는 게 우리의 목표가 되는 것이고요. 인포턴스 샘플링은 아까 봤죠. 베리언스가 0이 되는 게 언제다 얘가 이런 형태일 때 그래서 프제랑 pz를 곱한 값이 결국 qg의 가장 좀 이상적인 값이 되겠습니다. 여기까지 하면은 우리는 리젝션 샘플링과 인포턴스 샘플링을 본 거예요. 그러면 우리는 이제 정확한 노말라이징 콘텐츠를 알지 못한다고 하더라도 거기에서 값을 샘플링 할 수 있는 방법 그다음에 우리가 마찬가지로 정확한 노멀라이징 콘서트를 모른다고 하더라도 즉 피지를 모르고 피틀다지만 안다고 하더라도 그걸 기반으로 우리가 익스펙테이션을 추론할 수 있는 임포턴스 샘플링까지 살펴봤습니다. 자 그런데 이런 리젝션 샘플링과 인포턴 샘플링은 사실 좀 하이드맨션에서 잘 안 되는 경우가 많고 이거에 좀 더 진보된 버전 엠씨엠씨로 저희가 넘어가도록 하겠습니다. MCMC는 마코브 체인 몬테카롤로의 약자입니다. 리젝션 샘플링과 임포턴스 샘플링은 결국에 굉장히 하이드벤션으로 우리가 즉 제가 굉장히 고차원의 공간이 존재하는 거라고 한다면 그때는 정확하게 리젝션 샘플링과 인버턴 샘플링을 하기가 쉽지가 않습니다. 반면 엠씨엠씨도 엠씨엠씨도 물론 그런 문제가 있긴 해요. 하지만 상대적으로 괜찮다 라고 생각해 주시면 되겠습니다. 자 여기 엠시엠씨도 비슷해요. 리액션 샘플링과 인포트 샘플링하고 큰 정신은 동일합니다. 여기서도 저희가 프로포절을 골라요. 큐라는 프로포절을 고릅니다. 자 그런데 여기서 이 프로포절이 우리는 어떻게 되냐면 현재의 스테이트에 따라서 계속해서 바뀝니다. 그리고 우리가 그동안 샘플링 했던 거를 다 기록을 해요. 그래서 그러한 이제 과거를 통해서 우리가 가장 최적으로 가려면 또 어느 곳으로 이동을 해야 될지 우리가 정할 수가 있게 됩니다. 자 무슨 말이냐면 인포턴 샘플링하고 리젝션 샘플링은 뭐랄까요? 좀 과거의 샘플들을 기반으로 해서 업데이트되는 게 있지 않아요. 우리가 여기서 애초에 여기에서 값을 하나 뽑고 지제로 뽑고 그다음에 여기에서 우리가 유니폼 한 개 뽑은 다음에 어 그러면은 여기에 속하는지 여기에 속하는지 봐서 어셉할지 리젝 할지 정합니다. 그다음에는 어떻게 해요 여기서 어셉이 됐든 리젝이 됐든 상관없어요. 다시 여기에서 샘플링 하나 하고 다시 위로 올려서 여기에서 우리가 값을 좀 유니폼하게 뽑아서 어셉할지 리식할지 정합니다. 그렇죠 반면에 MCMC는 우리가 그동안 봐왔던 샘플들을 기록해 놓는다. 그래서 지금 우리가 결국 pg를 추정하기 위해서는 지금까지는 이랬는데 어디로 가야 될지를 우리가 계속해서 이동하는 겁니다. 즉 우리가 큐지라는 거를 고정시켜 놓으면 큐지를 이렇게 잡았습니다. 그러면은 우리가 이 프로포즈이 만약에 이상하면은 어 제1 제2 제3 여기서 이제 샘플링을 해요. 그럼 어셉 할지 리지 할지 막 정합니다. 그러면은 피지를 정확하게 추정하기 좀 어려워요. 근데 이 현재의 상황에 따라서 현재 제1이 이렇게 뽑혔습니다. 그러고 나서 이걸 기반으로 우리가 그다음에 제2는 어디에 좀 있을 것 같다라고 우리가 업데이트를 시켜주고 또 거기서 z2를 뽑고 또 우리가 제 3로 이동하고 그렇게 우리가 현재의 상황에 따라서 계속해서 우리가 프로포즈를 업데이트해 나간다고 하면은 더 빠르게 우리가 추정을 할 수가 있게 되겠죠. 자 그래서 이거를 그러면 우리가 어떻게 할 거냐 마코브 체인을 기반으로 해서 우리가 진행할 겁니다. 자 이거는 저희가 조금만 있으면 다음 주에 바로 진행을 하도록 하겠습니다. 네 여러분 고생 많으셨습니다."
}