{
  "lecture_name": "(1강) 머신러닝 경진대회 입문하기(1)",
  "source_file": "(1강) 머신러닝 경진대회 입문하기(1)_12.mp4_2025-12-04-103036616.json",
  "text": "안녕하세요. 도메인 공통 프로젝트 1강 머신 러닝 경진 대회 입문하기 시작하겠습니다. 이번 강의에서는 대회 배경 지식 습득하기 학습을 위한 프로세스 알아보기 좋은 모델을 위한 프로세스 알아보기 더 높은 성능을 위한 프로세스 알아보기 경진대회를 대하는 마음가짐 에 대한 내용을 다뤄보려고 합니다. 강의를 시작하기에 앞서 먼저 제 소개를 드려보겠습니다. 저는 데이터 분석가부터 AI 사이언티스트 그리고 머신러닝 엔지니어 등을 이어서 현재는 데이블이라고 하는 광고 추천 엔진을 만드는 회사에서 머신러닝 소프트웨어 엔지니어로 일을 하고 있는 강천성이라고 합니다. 이전에는 부스트캠프 AI 테크의 멘토로서 활동도 했었고요. 그리고 외부 커뮤니티 활동인 캐글 코리아 페이스북 그룹 운영진도 담당하고 있습니다. 머신 러닝 경진대회 입문하기입니다. 이 강의는 머신 러닝 경진 대회에 입문하는 초보자들을 위한 과정입니다. 여러분들이 이전 과정에서 학습한 지식들을 바탕으로 실제로 문제를 풀 수 있는 첫 번째 단계이고요. 여러분들은 다음과 같은 질문을 스스로에게 던지며 데이터 문제 해결 능력을 키우게 됩니다. 어떻게 문제를 접근해야 할까 어떻게 데이터를 살펴보고 처리해야 할까 어떤 데이터를 선정해야 될까 어떻게 모델의 성능을 고도화할 수 있을까 이런 질문들을 여러분들에게 던지면서 진행을 하시게 될 겁니다. 그렇다면 왜 머신 러닝 경진대회로 여러분들이 공부를 해야 되는지 혹은 도전을 해야 되는지에 대해서 이야기를 해보겠습니다. 책이나 강의 혹은 다른 사이드 프로젝트 등 머신 러닝을 공부하는 방법에는 다양한 방법들이 있습니다. 근데 왜 이 강의에서는 혹은 우리 과정에서는 경진대회를 통해서 배우려고 하는 걸까요? 여러분들이 이 과정에서 얻고자 하는 것들은 AI 분야에서 사실 직업을 얻고 싶어 하는 거겠죠. 그렇다면 현업에서 신입에게 요구하는 역량들이 어떤 것들이 있을지 이야기를 한번 해보겠습니다. 실제로 제가 회사에서 뭐 주니어들을 채용을 하거나 뭐 주니어뿐만 아니라 이제 경력직 분들을 채용한다고 했을 때도 공통적으로 요구되는 역량들이 있습니다. 뭐 대표적으로는 데이터를 다뤄 보았는가에 대한 데이터 관련 경험 그리고 여러분들이 어 다른 팀원과 협업을 해 봤는지 협업 경험 그리고 당연하게도 AI 직군에 있으면 머신 러닝 AI 딥러닝 기초 그리고 여러분들이 이 기초를 기반으로 각 프로젝트를 진행하면서 모델들을 학습하는 이런 실험들을 관리하는 경험들 뿐만 아니라 이런 모델들의 또 성능을 여러분들이 이끌어 내야 될 텐데요. 그 과정에서 사용되는 실전 테크닉 이런 것들이 요구되게 됩니다. 이런 경진대회는 실제 산업에서 풀어야 하는 문제들을 포함하고 있는 경우들이 많습니다. 이는 여러분들이 현업 수준으로 문제를 풀기 위해 고민해야 한다는 것을 의미합니다. 만약 여러분들이 관심 있는 데이터 분야에 대회가 열린다면 이보다 좋은 기회가 있을까요? 예를 들어서 뭐 저의 분야인 광고 추천 혹은 추천 쪽에 관심이 있는 분들이라 해 보겠습니다. 뿐만 아니라 우리 과정에는 CV NLP와 같이 다른 분야에 있는 분들도 계시지만 각자 한번 상상을 해볼게요. 내가 있는 이 트랙에 관심 있는 그 분야의 대회가 열린다고 해봤을 때 여러분들이 이걸 통해서 이력들을 쌓아간다면 이건 아주 좋은 여러분들의 이력이 될 수 있을 겁니다. 대부분 여러분들이 프로젝트를 진행을 하시게 되면 혼자 하기보다는 팀으로 진행하시게 될 겁니다. 여러분들이 팀원과 수월하게 협업하기 위해 실험 관리에 신경을 써주셔야 되는데요. 또한 경진대회는 일반적으로 다양한 사람들과 아이디어와 코드를 공유하며 진행하게 됩니다. 이는 다른 사람의 코드를 통해 실전 테크닉을 간접적으로 경험하는 기회가 될 수 있습니다. 관심 있는 분야의 대회를 참여하여 본인의 커리어에 맞는 데이터 경험을 쌓을 수도 있고 대회를 진행하면서 놓치기 쉬운 머신러닝 딥러닝 기초를 다질 수 있게 됩니다. 실제로 저의 경우에도 대회를 진행을 하면서 내가 알고 있었던 머신 러닝 딥러닝 이론 혹은 뭔가 모델 학습 프로세스 이런 부분들을 잘못 알고 있었던 것들을 좀 고치는 경험도 했었고요. 여러분들이 이런 것들을 반복을 하다 보면 많은 신경을 혹은 많은 정성을 쏟지 않아도 자연스럽게 이제 여러분들이 사용하고 있는 체화되는 기술 그런 역량을 가지게 됩니다. 다음은 일반적인 경진대회 진행 프로세스에 대해서 한번 이야기해 보겠습니다. 뭐 제가 경진 대회 진행 프로세스라고 이야기를 했지만 실제로 여러분들이 현업에 오셔서 하게 되는 머신 러닝 프로세스와 똑같습니다. 첫 번째는 eda 및 인사이트 얻기입니다. 물론 현업에서는 인사이트가 어느 정도 이미 확보된 상태로 시작할 수 있긴 한데요. 만약에 인사이트가 없다 하더라도 우리가 데이터를 주기적으로 계속 바라보면서 아 이런 부분이 좀 고려되면 좋겠는데 이런 식으로 시작을 하게 됩니다. 그래서 eda eda 같은 경우는 우리가 탐색적 데이터 분석이라고 해서 데이터를 하나하나 뜯어보면서 각각의 컬럼들이 어떤 패턴을 갖고 있는지 어떤 분포를 갖고 있는지 이런 것들을 들여다보는 거라고 생각하시면 될 것 같고요. 여기에서는 단순히 시각화 혹은 어떤 통계량을 나타내는 그런 기술뿐만 아니라 도메인에 따라 다양한 방법으로 데이터를 탐색하셔야 됩니다. 이디에를 통해 인사이트를 얻었다면 여러분들이 그다음 진행해야 될 곳은 피처 엔지니어링입니다. 이제 피처 엔지니어링도 사실 도메인에 따라 되게 다양한 방법으로 진행이 될 수 있는데요. 단순하게 생각을 한번 해볼게요. 예를 들어서 여러분들이 누군가에게 어떤 아이템을 혹은 어떤 물건을 추천을 해준다고 한번 해볼게요. 그러니까 이 유저가 이 아이템을 구매할 것 같아 혹은 아이템을 선택을 해서 뭐 그다음 액션을 할 것 같아 뭐 이런 뭔가 문제를 우리가 푼다고 한번 해볼게요. 그렇다면 이제 우리가 만들 수 있는 피처는 어떤 것들이 있을까라고 했을 때 어떤 유저에 대한 구매 이력 뭐 그 구매 이력이라는 것도 사실은 여러 가지 윈도우가 있을 것 같아요. 이 사람이 최근 일주일 동안 구매했던 이력 혹은 이 사람이 어떤 뭐 추천된 아이템을 처음 확인을 하고 실제로 구매까지 이루어지기에 평균 일수 평균 시간 이런 것들을 여러분들이 피처로 만들어서 모델에 전달할 수가 있겠죠. 이런 식으로 만든 피처들을 우리가 이제 모델 개발을 통해서 모델을 학습을 하게 됩니다. 모델 개발에는 또 다양한 방법들이 있을 것 같아요. 우리가 비정형 데이터를 다루는 브 엔엘피 이런 분야에서는 여러분들이 실제로 파이토치 혹은 텐서플로우와 같은 딥러닝 프레임워크를 기반으로 이제 딥러닝 모델을 정의를 하시게 될 거고요. 혹은 정형 데이터를 사용하는 쪽 같은 경우는 물론 딥러닝 모델을 쓸 수도 있지만 트리 기반 모델이 되게 가성비가 좋습니다. 어 연산량도 적고 성능도 실제로 좋은 경향이 있기 때문이에요. 그래서 각각의 영역에 맞게 그리고 목적에 맞는 모델들을 선택을 해서 그 모델을 학습하는 단계라고 생각하시면 될 것 같고요. 모델을 학습했다면 이제 그 모델에 대한 그리고 우리가 이번 단계에서 생성한 피처에 대한 성능을 확인하는 단계가 되겠습니다. 검증 데이터셋 혹은 테스트 데이터셋에 대한 성능을 확인을 하고 그 결과를 기반으로 여러분들이 그다음 액션을 어떤 것들을 할지 디스커션을 하거나 혹은 피드백을 진행을 하게 됩니다. 사실 여기에서 디스커션이라고 하는 것들은 일반적인 경진대회 플랫폼에서는 디스커션 탭 혹은 논의 탭 혹은 어떤 게시판이 있어서 그 게시판에서 어 나는 이런 것들을 해봤는데 어 이게 내 생각보다 좀 성능이 안 좋네 그래서 이거를 공유를 해보는 거예요. 코드와 함께 공유를 해 봐서 내가 무언가 잘못 해봤을까 뭐 이런 식으로 여러분들이 글을 올리면 다른 팀에 있는 혹은 다른 유저들이 이제 작성을 해 주겠죠. 이 부분에서 실수한 것 같아 이걸 한번 고쳐서 해보면 잘될 것 같은데 이런 식으로 댓글을 달아주고 그걸 기반으로 다시 또 한 바퀴 돌리면서 여러분들이 이 프로세스를 반복적으로 진행하게 됩니다. 다음은 대회 배경 지식 습득하기입니다. 일반적으로 경진대회는 문제와 함께 이 문제를 우리가 왜 해결해야 하는지에 대한 배경을 포함합니다. 배경을 이해하고 문제를 푸는 것과 그렇지 않은 것은 큰 차이를 만들어 낼 수 있습니다. 이는 여러분들이 데이터를 깊게 이해하는 것을 돕고 문제 해결을 위한 힌트를 제시해 줄 수 있는데요. 먼저 대회에서 제시하는 문제와 배경을 기반으로 몇 가지 단계를 통해 대회를 시작해 보겠습니다. 대회에서 제시하는 문제가 명확한가 혹은 추가적으로 좀 숨어 있는 문제나 이런 것들이 있어서 추가적인 문제 정의는 필요 없나 어떤 방식으로 모델링을 해야 될까 어떤 모델이 적절할까 추가적으로 학습이 필요한 도메인 지식은 없나 있다면 어떻게 학습해야 할까 이런 식으로 말이에요. 다음은 대회에서 제시하는 평가 지표를 이해하는 부분입니다. 일반적으로 대회 평가 지표는 고정이 되어 있어요. 예를 들어서 정확도 혹은 정밀도 혹은 이제 재현율 뭐 이런 것처럼 분류에 대한 평가 지표로 되어 있는 경우도 있을 거고요. 혹은 ms 혹은 엠에 RMSE와 같이 어떤 이제 회귀 평가 지표를 기반으로 되어 있는 경우도 있습니다. 그러나 여러분들이 대회를 진행할 때 이런 정해진 평가 지표로만 모델을 평가한다면 좋은 성능을 얻지 못할 수가 있습니다. 예를 들어서 우리가 대회를 진행하면서 간과하는 부분 그리고 혹은 실수를 하는 부분이 있어요. 이제 대회를 진행할 때 보여지는 점수 리더보드가 있습니다. 리더 보드에는 우리가 테스트 데이터셋에 대한 성능을 볼 수 있는 부분인데요. 리더보드에 보여지는 점수는 그 테스트 데이터셋 전체에 대한 점수는 아닙니다. 일반적으로는 테스트 데이터셋의 30% 많으면 50% 정도로 이제 일부를 샘플링을 해서 그 일부 데이터에 대한 스코어를 계산을 해서 보여주는데요. 그렇다면 여러분들이 리더보드에 보이는 그 점수만을 올리는 방향으로 모델을 튜닝을 하게 되면 그 샘플링 된 테스트 데이터에서 샘플링된 서브 데이터셋을 최적화하는 방향으로 여러분들이 모델을 학습을 그리고 모델을 개선시키게 됩니다. 이런 경우에 이제 그 샘플링된 데이터셋 샘플과 그 나머지 데이터셋 샘플의 분포가 약간 다른 경우 여러분들의 최종 모델의 성능은 좋지 않을 수 있다라는 겁니다. 그렇기 때문에 대회에서 이야기하는 하나의 평가 지표를 보는 것 그것을 타깃을 하는 건 되게 좋은 방법일 수 있지만 제가 좀 추천드리는 방법은 모델의 전반적인 성능을 평가할 수 있는 다른 어떤 평가 지표를 추가로 정의를 하고 모델을 최적화하는 것을 추천을 드립니다. 이 부분은 사실 뭐 제가 대외로 예시를 들어서 말씀을 드렸는데 현업에서도 동일합니다. 여러분들이 하나의 평가 지표로 모델을 평가하는 것이 유효하지 않을 수 있고요. 당연히 풀고자 하는 문제에 따라 혹은 데이터가 가지고 있는 어떤 문제 예를 들어서 데이터가 불균형하다거나 혹은 어떤 피처가 되게 희소하다 그러니까 희소하게 구성이 되어 있다거나 이런 것들에 따라서 추가적인 지표를 사용해야 할 수도 있습니다. 다음은 학습을 위한 프로세스를 알아보겠습니다. 이전에 제가 다이어그램으로 이 단계들을 여러분들이 반복할 거예요라고 했었던 부분에 처음인 이da입니다. eda 중요성은 데이터를 이해하고 그 데이터의 품질을 평가하고 여러분들이 사용할 수 있는 변수 간의 관계를 분석하는 부분에서 중요성이 매우 두드러지는데요. 여러분들이 이 데이터를 이해하는 과정에서 이 데이터가 가지고 있는 구조 그리고 변수들의 기본 통계량들을 확인하는 단계를 거치게 됩니다. 데이터 품질 평가 부분에서는 결측값을 확인을 하거나 이 피처의 통계량을 기반으로 봤을 때 이상치가 존재를 해서 이 이상치를 어떻게 처리할 건지 이상치를 탐색하는 부분이 있고요. 변수 간 관계를 분석하는 부분에서는 이제 변수 간의 상관관계를 분석한다거나 그리고 변수 간 관계를 시각화하는 되게 다양한 방법들이 있습니다. 이런 것들을 통해서 어떤 변수가 어떤 변수에게 어떻게 영향을 끼치는지 이런 것들을 확인하는 것이 중요하고요. eda에서 여러분들이 찾아낸 이런 정보 인사이트를 기반으로 앞으로의 데이터 전처리 계획을 어떻게 진행할 것인지 세울 수 있습니다. 다음은 피처 엔지니어링입니다. 피처 엔지니어링은 변수 표현을 향상시켜서 모델 예측력을 향상시키는 데 매우 중요한 역할을 합니다. 여기에서 변수 표현이란 여러분들이 가지고 있는 이 변수들을 모델이 더 잘 학습할 수 있도록 표현을 뭔가 이제 표현되는 방식을 변경한다라고 여러분들이 이해하시면 되는데요. 실제로 베리어블 레프레젠테이션이라는 용어로 우리가 이야기를 합니다. 그다음엔 데이터 변환을 통해서 모델 학습의 용이화를 하는데요. 여기에서 데이터 변환이란 일반적으로 우리가 사용하는 머신러닝 딥러닝 모델들은 수치 형태로 입력이 들어와야 됩니다. 근데 만약에 내가 가지고 있는 피처가 문자열이라면 예를 들어서 나라 국가를 이제 뜻하는 어떤 텍스트가 있다고 해 보겠습니다. 한국 뭐 일본 중국 미국 뭐 이런 식으로 이제 문자열이 들어 있는 경우에는 모델이 직접적으로 이퓨처를 학습할 수가 없게 됩니다. 그래서 여기서 데이터를 좀 가공을 해서 수치 형태로 바꾼 다음에 모델이 학습을 할 수 있도록 이제 변경하는 작업을 하게 되고요. 데이터 정제를 통해서 모델 안정성 향상 부분에서는요. 이 피처들이 예를 들어서 되게 한쪽으로 치우친 분포를 가진 경우가 있습니다. 만약에 우리가 어떤 사람의 키 혹은 뭐 사람 이제 대한민국에 사는 시민들의 평균 이동 거리 이런 것들을 우리가 어떤 피처로 만들었다고 해볼게요. 그러면 대부분의 수치들은 앞쪽에 있을 거예요. 이게 평균에 가까운 쪽에 있을 거고 또 몇몇 사람들은 이제 아웃라이어겠죠 그런 분들은 저 오른쪽에 꼬리에 가 있을 겁니다. 많은 이동을 하거나 혹은 키가 좀 많이 크신 분들은 오른쪽 이제 끝에 가 있는 꼬리 긴 꼬리를 형성하는 쪽에 이제 기여를 하시게 될 거예요. 이런 식의 분포를 가진 피처는 모델이 이 퓨처의 패턴을 학습하기에 적절하지 않을 수 있습니다. 그렇기 때문에 우리가 이런 피처들을 어떻게 잘 가공을 해서 이쁜 분포 형태로 바꿔주는 식으로 정제를 하는데요. 이런 과정을 통해서 모델의 안정성이 향상될 수 있습니다. 피처 엔지니어링의 주요 작업으로는 새로운 변수를 생성을 하거나 기존 변수를 변형을 한다거나 혹은 결제 값을 처리하거나 이상치를 수정하는 등 데이터를 전처리하는 작업들이 포함되어 있습니다. 다음은 좋은 모델을 위한 프로세스에 대해서 알아보겠습니다. 이제 여러분들이 경진 대회 AI 경진 대회 혹은 현업에 나가면 가장 많이 하는 고민 중에 하나 어떤 모델이 가장 좋은가 이 부분에 대해서 이야기를 해 보겠습니다. 노프리 런치 시오엠이라는 게 있습니다. 간단하게 말하면 모든 머신러닝 알고리즘이 모든 문제에 동일한 성능 좋은 성능을 보일 수 없다라는 뜻인데요. 예를 들어서 우리가 일반적으로 이야기하는 소타 가장 높은 성능을 가진 어떤 딥러닝 모델이 있다고 해 보겠습니다. 그럼 과연 그 모델을 이제 어떤 데이터셋에 학습을 시키든 그 모델이 항상 성능이 좋을까라고 하면 그렇지 않다라는 겁니다. 데이터의 규모 혹은 데이터의 분포 그리고 데이터의 형태 이런 것들에 따라서 여러분들이 가장 좋은 모델을 쓰더라도 가장 좋은 성능이 나오지 않을 수도 있고요. 가장 좋은 모델은 아니지만 우리가 가지고 있는 데이터의 적절한 랭킹이 낮은 그런 모델을 사용했을 때 가장 좋은 성능을 보이는 경우가 있습니다. 그렇기 때문에 여러분들이 이 모델을 선택을 하실 때는 여러 가지 상황에 따라 모델을 선택하시게 되는데요. 사실 현업이나 여러분들이 경진대회를 하실 때는 대략적으로 어떤 모델을 사용할지에 대한 선택지는 이미 정해져 있기는 합니다. 그래서 여러분들이 어 내가 지금 풀려고 하는 문제 도메인에 따라서 어떤 모델들을 많이 사용하는지 조사를 먼저 하신 뒤에 그 모델에서부터 시작하시는 것을 추천을 드리고요. 문제 유형으로 대표적으로는 분류 회귀 클러스터링 등이 있습니다. 물론 이 유형에 없는 다른 유형들도 있으니 그 부분은 참고해 주시면 감사하겠습니다. 다음으로는 제가 이제 이런 상황에서는 이런 것들이 좋아요라고 추천을 해드리는 내용을 좀 이야기를 해볼 건데요. 여러분들이 정형 데이터를 다룬다면 딥러닝보다는 트리 기반 모델이 좋은 경우가 많습니다. 물론 반드시 정형 데이터일 때는 트리 기반 모델이라기보다는 일반적인 분류나 회귀일 때 정도로 여러분들이 이해해 주시면 좋을 것 같아요. 왜냐하면 실제로 어떤 추천 모델링 같은 경우는 입력 데이터가 정형 데이터이지만 실제로 사용하는 모델들은 딥러닝 모델을 사용하는 경우가 있기 때문이에요. 그래서 일반적으로는 트리 모델을 쓰지만 항상 이런 건 아니다 정도로 이해해 주시면 감사하겠습니다. 트리 기반 모델은 높은 예측 성능을 가지고요. 특히 적은 데이터나 피처 수가 적을 때 강한 성능을 보여줍니다. 그리고 유연한 하이퍼 파라미터 조정 등이 가능한데요. 뭐 이 부분 같은 경우는 딥러닝 모델보다 트리 기반 모델의 학습 시간이 훨씬 짧고 그리고 조정할 수 있는 하이퍼 파라미터들이 많기 때문에 여러분들이 유연하게 조정을 할 수 있다라는 거고요. 해석 용이성 여러분들이 트리 기반 모델을 학습을 하게 되면 이 모델을 구성할 때 어떤 피처에서 얼마나 많은 정보를 얻었는지 이런 특징 중요도 등을 제공을 합니다. 그래서 우리가 이런 피처 인포턴스를 기반으로 모델을 해석하실 수 있게 됩니다. 그리고 방금도 제가 언급을 드렸지만 빠른 학습 및 빠른 추론 속도를 제공하기 때문에 실제로 여러분들이 이 트리 모델을 기반으로 서비스를 제공을 할 때 지피유가 아닌 시피유로도 충분한 서비스 품질을 유지할 수 있게 됩니다. 대표적으로는 랜덤 포레스트, 스지 부스트, 라잇 지비엠 캣 부스트 등이 있습니다. 다음으로는 여러분들이 이미지 텍스트 오디오와 같은 비정형 데이터를 다룬다면 이제 딥러닝 기반 모델을 사용하시게 될 겁니다. 입력 데이터의 복잡한 패턴 인식에 강한 성능을 보이고요. 고차원 표현을 자동으로 학습하는 능력들이 있습니다. 뿐만 아니라 딥러닝 기반 모델은 똑똑하신 분들이 미리 만들어 놓으신 프리트레인드 모델을 이용한 전이 학습이 가능합니다. 그래서 여러분들이 프리트레인드 모델을 가져와서 약간의 레이어를 추가해서 여러분들의 테스크에 맞게 조정하는 것으로 빠른 성능 향상을 기대할 수 있습니다. 대표적인 모델로는 비주얼 트랜스포머 트랜스포머 웨이브 넷 뭐 이런 것들이 있습니다. 마지막으로는 제가 많이 강조하고 싶은 부분인데요. 실험 정신입니다. 결국 여러분들이 앞에서 많은 고민을 통해 어떤 모델을 그리고 어떤 방식을 할지 선택을 한 뒤에 실험을 진행을 하시게 될 텐데요. 결과적으로는 여러분들이 진행하신 그 실험에 결과 혹은 성능을 기반으로 가장 좋은 모델을 선택하는 것이 현실적이면서도 합리적입니다. 그렇기 때문에 다양한 모델을 직접 실험해 보고 그 결과를 바탕으로 최적의 모델을 선택하는 것이 중요합니다. 다음으로는 대회 목표입니다. 대회를 통해 우리가 만들고자 하는 모델은 과적합되지 않은 일반화된 모델입니다. 여기에서 과적합되지 않은 일반화된 모델이란 과거 데이터를 잘 맞추는 모델이 아니라 미래를 잘 맞추는 모델이 필요합니다. 그럼 과적합되지 않은 일반화된 모델을 얻기 위해서는 우리가 엄격하게 모델을 검증을 해야 되는데요. 그렇다면 어떻게 엄격하게 검증을 할 수 있을까요? 검증 프로세스 구축 단계를 여러분들이 꼼꼼히 살펴보셔야 됩니다. 첫 번째로는 검증 데이터를 분할하는 부분이 있을 거고요. 그리고 검증 데이터를 한 번 분할하는 것뿐만 아니라 데이터를 여러 개로 쪼개고 그 쪼갠 데이터들을 돌려가면서 번갈아 가면서 검증 데이터를 바꿔가는 교차 검증을 고려할 수 있고요. 그리고 이 검증 데이터를 구성하는 과정에서 여러분들이 데이터 누수를 방지할 수 있어야 됩니다. 그리고 여러분들이 데이터를 분할을 할 때 뭐 분류 같은 경우는 레이블 이 라벨의 이 비율을 잘 유지해 주는 것이 매우 중요합니다. 그렇지 않으면 여러분들이 불리한 이 검증 데이터에 되게 일부의 이 라벨만 포함되는 경우가 있을 텐데요. 그런 경우일 때 검증이 제대로 이루어지지 않을 수 있습니다. 그렇기 때문에 균형 잡힌 데이터 분할이 매우 중요합니다. 검증 프로세스에서 흔히 하는 실수 몇 가지를 말씀드려 보겠습니다. 전처리 시 검증 데이터를 언씬한 상태를 보장하지 못하는 경우입니다. 이 부분이 제가 이전 페이지에서 언급한 이제 데이터 유출 상태를 이야기를 하는 건데요. 여러분들이 데이터를 전처리를 할 때 어 전 검증 데이터를 분리한 뒤에 전처리를 하는 것이 아니라 그 이전에 여러분이 전 처리를 하는 경우 검증 데이터의 정보가 학습 데이터에 녹아 들어가게 됩니다. 이 부분 같은 경우는 우리 이후 강의에서 조금 더 자세히 다뤄보겠습니다. 다음은 과적합을 방지할 방법을 고려하지 않은 경우입니다. 과적합 같은 경우도 우리 이후 강의에서 좀 더 자세히 다뤄 보겠지만 각각의 모델들은 이런 과적합들을 방지할 방법들 장치들을 가지고 있습니다. 이 부분들을 여러분들이 충분히 고려하는 것을 추천을 드리고요. 혹은 적절하지 않은 평가 지표를 선택하는 경우도 검증 프로세스에서 흔히 하는 실수일 수 있겠습니다. 다음으로는 더 높은 성능을 위한 프로세스에 대해서 알아보겠습니다. 첫 번째로는 하이퍼 파라미터 선택입니다. 여러분들이 모델을 선택하는 것도 중요하지만 각 모델별로 사용하는 하이퍼 파라미터의 종류를 잘 선택하고 어떤 값을 고르는지도 매우 중요합니다. 물론 트리 기반의 모델들은 어느 정도 비슷한 하이퍼 파라미터들을 가지고 있어서 여러분들이 이전에 트리 기반 모델을 써보셨다면 그렇게 어렵지 않을 겁니다. 하지만 우리가 고려해야 되는 모델이 여러 개이고 그리고 모두 실험을 통해 평가하고자 한다면 이런 것들을 자동화할 필요가 있겠죠. 다음은 앙상블입니다. 모델 앙상블은 학습된 모델 여러 개의 예측 값을 혼합하여 더 좋은 결과를 만들어 내는 기법입니다. 각 모델의 약점을 보완하고 강점을 결합하여 더 좋은 예측 성능을 얻을 수 있는 방법 중에 하나입니다. 단순히 예측 값을 평균 내거나 섞는 것만으로도 성능 향상을 기대할 수 있는 기법입니다. 마지막으로 경진대회를 대하는 마음가짐에 대해서 이야기해 보겠습니다. 경진대회의 장점이자 단점은 점수로 순위를 매길 수 있다는 점입니다. 하지만 이 부분에 대해서 한번 생각해 보시면 좋을 것 같아요. 경진대회에서 얻고자 하는 것이 무엇인가요? 그리고 우리들의 목표가 어떤 것인지 한번 생각해 보겠습니다. 우리가 이 경진대회에서 얻고자 하는 것들은 여러분들 개개인의 성장입니다. 점수를 잘 받는 게 뭐 중요하지 않다라고 말하는 건 사실 맞지 않는 것 같은데요. 저는 여러분들의 개개인의 성장에 좀 더 집중하면 좋겠다라는 말씀을 드리고 싶습니다. 그래서 나보다 잘하는 사람을 만났을 때 질투하거나 좌절하기보다는 더욱 적극적으로 소통해 보는 것을 추천을 드립니다. 나보다 잘하는 사람은 어떤 노력을 했고 그리고 나보다 잘하는 이유가 있을 것이다 뭐 예를 들어서 나보다 더 많은 시간을 투자했고 혹은 나보다 더 많은 어떤 논문을 읽었고 혹은 어떤 케이스들을 공부했기 때문에 그런 이 사람이 성장해 왔었던 흐름 혹은 경험들을 공유를 좀 받아보는 거를 추천을 드립니다. 그래서 그 방식들을 사실 그대로 따라 하기보다는 나만의 방식으로 재해석해서 피드백을 해보고 아 나는 앞으로 이런 식으로 해봐야겠다 이런 식의 접근이 더 좋다고 저는 생각을 해요. 다음으로는 성장이란 무엇인가에 대해서 이야기를 해볼 건데요. 내가 성장했는지를 알아보기 위해 할 수 있는 가장 좋은 방법은 이제 과거의 나와 현재의 나를 비교해 보는 것입니다. 쉽게 말해서 여러분들이 각각의 레벨 혹은 각각의 강의들을 지나쳐 갈 때 이제 일주일 2주 단위로 여러분들이 진행을 하시게 될 텐데요. 일주일 전 2주 전 혹은 한 달 세 달 전, 반 년 전과 같이 차근차근 과거로 되돌아가 보는 것을 추천드립니다. 물론 단기간에 여러분이 성장을 못 느낄 수도 있기는 합니다. 근데 조금이라도 개선된 것이 있거나 새로운 능력이 생겼다면 그것이 성장이라고 생각을 하고요. 중요한 것은 한 번에 많이 성장하는 것이 아니라 꾸준히 성장하는 것이 중요합니다. 실제로 저의 경우에도 회사에서 어떤 일을 할 때 어떤 프로젝트를 할 때 마법처럼 짠짠 하고 나오지 않아요. 그 과정에서 되게 많은 고생을 하고요. 많은 고민을 합니다. 그런 다음에 이런 프로젝트가 끝났을 때 저도 이제 돌아보는 거예요. 아 이 프로젝트를 시작하기 세 달 전에는 과연 내가 어떤 생각으로 이 프로젝트를 시작했었을까 이 정도 수준까지 만들 수 있을 거라고 생각했었을까 만약에 그렇지 않았다면 저는 또 그 3개월 동안 많은 성장을 했다라고 생각할 수 있겠죠. 네 이번 강의는 여기까지입니다. 강의 들어주셔서 감사드리고 다음 강의에서 뵙겠습니다."
}