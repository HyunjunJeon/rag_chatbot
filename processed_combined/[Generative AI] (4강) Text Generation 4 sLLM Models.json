{
  "lecture_name": "[Generative AI] (4강) Text Generation 4 sLLM Models",
  "source_file": "[Generative AI] (4강) Text Generation 4 sLLM Models_89.mp4_2025-12-04-104120649.json",
  "text": "생성형 AI 4강 강의 텍스트 제너레이션 SLM 모델에 대해서 지금부터 시작하도록 하겠습니다. 우선 세 가지 정도의 파트로 구분이 되어 있는데요. 첫 번째는 오픈 소스 엘르램에 대해서 설명을 드리고 특히나 오픈 소스이기 때문에 엘르램 관련된 라이센스 문제에 대해서 언급을 좀 드리도록 하겠습니다. 그리고 대표적인 오픈소스 엘르램인 라마에 대해서 설명을 드리고요. 그 이후에 셀프 인스트럭션을 활용해서 개발된 알파카와 그와 관련된 변종들 그리고 마지막으로 엘엘램 평가 엘엘엠을 만들었을 때 엘엘엠이 어떤 특정한 테스크에 대해서 얼마만큼 그 테스크를 잘 수행하고 있는지 아닌지에 대한 평가 지표들에 대해서 소개를 하고 마무리를 하도록 하겠습니다. 첫 번째 오픈 소스 엘르램에 대한 내용입니다. 우선 엘르램 라이센스 프로블럼 먼저 말씀드리고 라마에 대해서 말씀드리도록 하겠습니다. 오픈 소스 라이센스라는 것은 소프트웨어의 코드 공개를 통해서 복제하고 배포하고 수정하는 것에 대해서 어느 정도까지를 허용할지에 대한 명시적인 권한을 부여하는 겁니다. 예를 들어서 리눅스는 gnu GPL 라이센스를 가지고 있는데 이 말은 무슨 얘기냐 하면 소스 코드가 완전히 공개되어 있어서 사용자 또는 회사에서 자유롭게 해당하는 리눅스를 수정할 수도 있고 또한 본인이 수정한 소프트웨어에 대해서 배포도 가능합니다. 타인에게 사용을 허락할 수도 있다라는 얘기죠. 그래서 리눅스 기반의 다양한 OS가 개발 및 상용화가 되었고요. 그중에 가장 대표적인 OS가 바로 우분투라고 보시면 되겠습니다. 오픈소스 라이센스는 다른 소프트웨어를 활용하여 개발을 진행할 경우에 해당하는 소프트웨어의 라이센스를 고려할 필요가 있습니다. 그러한 라이센스를 위반하는 경우에는 법적 윤리적 경제적 이슈가 발생하고요. 예를 들어서 MIT 라이센스 같은 경우에는 자유로운 복사와 배포는 가능하지만 유료화는 불가능하다. 다시 말하면 해당 라이센스를 가진 소프트웨어는 누구나 자유롭게 쓸 수는 있지만 그걸 가지고 돈을 벌 수 없다라는 얘기입니다. 씨씨바이스에 4.0 라이센스 같은 경우에는 자유로운 복사 배포 그리고 유료화까지도 모두 가능하다라는 얘기입니다. 이 말은 무슨 얘기냐 누군가가 또는 여러분들께서 새로운 소프트웨어를 개발했습니다. 그런데 그 개발한 소프트웨어가 MIT 라이센스를 가지는 a라는 소프트웨어를 사용하고 있다면 이 여러분들이 만든 소프트웨어는 활용한 소프트웨어가 엠아티 라이센스를 가지고 있기 때문에 유료화를 할 수가 없습니다. 반면에 소프트웨어 비 같은 경우에는 씨씨바스a 라이센스를 가지고 있기 때문에 활용한 여러분들이 만드신 소프트웨어는 이걸 통해서 수익을 창출할 수도 있다라는 얘기입니다. 그래서 반드시 오픈 소스 라이센스는 항상 소프트웨어가 어떠한 라이센스, 어떠한 허용 범위까지를 가지고 있는지를 명확하게 인지하고 계셔야 됩니다. 머신러닝 분야에서의 라이센스 같은 경우에는 머신 러닝과 딥러닝 분야 특성을 고려해서 라이센스를 검토를 해야 됩니다. 머신 러닝 또는 딥러닝은 크게 세 가지 관점에서 라이센스가 존재하는데요. 첫 번째 학습 데이터, 두 번째는 학습과 추론에 사용하는 코드, 세 번째는 사전 학습 모델입니다. 각 요소별로 라이센스와 저작권을 검토할 필요가 증가하고 있고요. 학습 데이터나 코드로 인해서 라이센스를 변경해야 되는 가능성이 존재하고 그럴 경우에는 모델의 상용화가 불가능할 수도 있습니다. 예를 들어 한번 얘기를 해 보겠습니다. 저작권이 존재하지 않는 사전 학습 데이터에 대해서 사전 학습을 시켜서 엘엘엠에를 만들었습니다. 그리고 엘엘엠에는 상용 라이센스를 가지고 있습니다. 그런데 이런 모델에 대해서 파인 튜닝을 하는 데 있어서 파인 튜닝의 저작권이 존재하는 데이터를 사용했다면 이렇게 엘엘엠을 다시 한 번 파인 튜닝한 llma1 같은 경우에는 상용 라이센스를 사용할 수 없다라는 의미입니다. 특히나 최근에는 LS 랭귀지 모델 학습 시에 사용된 학습 데이터에 대해서 저작권 문제가 부상되고 있습니다. 특히나 웹사이트라든지 또는 언론사들이 여기에 대해서 가장 적극적으로 문제를 제기하고 있는데요. 저작권이 존재하는 데이터를 가지고 학습한 모델은 상업적으로 활용이 사실은 불가능합니다. 그런데 최근에 이러한 저작권 예전에 이러한 저작권에 대한 이슈가 그렇게 심각하게 대두되지 않았을 때는 굉장히 많은 언어 모델들이 인터넷에서 크롤링이 가능한 모든 텍스트 데이터를 다 긁어다가 썼지요. 그러다 보니 여기 보시는 것처럼 오픈 AI도 여러 가지의 저작권 소송에 직면해 있고요. 대표적으로 뉴욕 타임즈가 마이크로소프트나 오픈 AI에 본인들의 기사를 아무런 허락 없이 크롤링을 통해 불법으로 도용해서 자사의 수조 원의 손해를 입혔다면서 소송을 제기한 경우도 있습니다. 그렇기 때문에 이러한 LLM 모델 같은 경우에는 추가 비용에 대한 발생, 법적 이슈에 대한 부분들도 고려가 돼야 되는 부분입니다. 오픈 소스와 클로즈 엘엠에 대해서 한번 말씀을 드려보자면 오픈소스 엘램 같은 경우에는 모델의 자유로운 학습과 상업화를 위한 필수 요소가 되겠습니다. 학습 그리고 배포 그리고 유료화 또는 상업화에 자유로운 라이센스를 보유한 LLM을 활용해야 된다라는 뜻이고요. 이걸 통해서 기업별 요구 사항에 맞춘 파인 튜닝이 가능해지고 또는 본인들의 민감한 정보를 활용한 파인 튜닝도 가능해집니다. 이러한 민감 정보 같은 경우에는 외부의 클라우스드 LLM을 활용하는 게 불가능해지는데요. 예를 들어 아래에 있는 그림을 예시로 보시겠습니다. 기업 내부망에서 기업의 용도에 의해서 LLM을 사용하자고 할 때 내부 데이터를 이용해서 파인튜닝을 추가적으로 할 수가 있습니다. 이렇게 학습한 데이터는 지피티 API를 통해서 내부 데이터를 반출할 수가 없기 때문에 결국은 자체 보유한 LLM을 사용할 수밖에 없고 그렇게 되면 대안은 오픈소스 엘르램밖에 될 수가 없는 것이죠. 오픈소스 엘르램으로 대표되는 모델이 라마입니다. 메타에서 공개한 라마인데 라마 원 발표 이전에도 사실 오픈 소스 엘르램이 없었던 건 아닙니다. 친칠라라든지 고퍼 지피티 네오 엑스 옵트 파이피아 뭐 이런 것들이 있었는데 이런 오픈소스 엘엠 같은 경우에는 모델 웨이트에 접근이 가능하지 않거나 또는 상업적으로 활용이 가능하지 못한 것들이어서 완전히 자유로운 사용이 조금 불가능했습니다. 표에서 보시다시피 gpt4가 MMR 평균적으로 86.5점을 기록하고 있는데 그나마 높은 친척가는 67.5점 그리고 웨이트에 접근이 가능하고 상업적인 활용까지 가능한 지피티 네오스 같은 경우에는 사실 절반에도 미치지 못하는 낮은 성능을 나타내고 있기 때문에 실제 서비스에 활용하는 데는 많은 어려움을 겪었습니다. 그래서 일부 빅테크 회사들을 중심으로 해서 엘엠을 연구하고 서비스를 개발하는 게 진행이 되어 왔고요. 이러한 엘엠 사전 학습은 사실은 현실적인 장벽이 존재합니다. 어떠한 장벽이냐 사전 학습 데이터를 확보하고 전처리하는 데도 시간과 비용이 들고요. 학습 인프라를 구축하는 데 있어서도 에이백 요새는 에이백을 주문하면 10개월 정도 기다려야 겨우 받을 수 있다라고 하는데 에이백을 한두 대가 아닌 256대 클러스터를 통해서 학습을 하기도 합니다. 또한 사전 학습 하이퍼 파라미터를 설정하고 진행하는 부분들까지 고려를 해야 되기 때문에 여기 보시는 것처럼 표에서 지피티 13베언에 대해서 대략적으로 1.3억 원이 들고, GPT 70빌리언 같은 경우에는 대략 35억 원 가까운 돈이 사전 학습에 필요하다는 뜻입니다. 여기에 더해서 모델의 학습이 불안정하기 때문에 추가적인 엔지니어링 비용 발생까지 고려하면 사실은 작은 규모의 스타트업들에서는 이거를 본인들만의 엘엘엠을 학습하고 활용하고 서비스하기가 굉장히 현실적으로는 어려운 부분이 존재하는 것입니다. 그래서 메타에서 라마라고 하는 연구 목적 활용이 가능한 오픈 소스 LLM을 공개를 했습니다. 라마는 기존의 고퍼나 업트나 지피티 네오 엑스와 같은 LM 오픈소스 엘램 모델보다 성능이 상대적으로 높은 반면에 모델 웨이트와 상업적 활용을 모두 가능하게 허용한 코드입니다. gpt4에 비해서는 성능이 높다라고 할 수는 없지만 어찌 되었든지 간에 모델 웨이트 다시 말하면 학습 파라미터에 대해서 직접적인 접근이 가능하고 상업적인 활용이 가능하다라는 것 때문에 굉장히 라마를 기반으로 하는 또 여러 가지 파생 모델들이 나오고 있습니다. 모델 공개를 위해서는 사전 학습 데이터를 이용하는데 공개된 사전 학습 데이터만 이용했을 뿐이지 메탈 내부 데이터 다시 말하면 사용자들이 페이스북을 통해서 재 생성한 여러 가지 콘텐츠들은 전혀 활용하지 않았다라고 밝히고 있습니다. 라마는 기존의 오픈 또는 클로스트 엘레램 대비 높은 성능을 달성하고 있고요. 모델 크기 대비로 해서도 높은 성능을 달성합니다. 그래서 palm 540빌리언하고 라마의 65빌리언을 비교를 해 봤을 때 그렇게 떨어지지 않는 성능을 나타내고 있다라는 것을 볼 수가 있어서 대략 한 10분의 1 정도의 크기로서도 유사한 성능을 확보할 수 있다라는 장점을 가지고 있습니다. 높은 성능의 원인으로서 이제 예전에 한 연구에서 친첼라 스케일링 로우라는 거를 이제 발표한 적이 있었는데요. 결국은 더 많은 데이터로 더 오래 학습했기 때문에 굉장히 당연한 것 같은데 당연한 사실이지만 이거를 다시 한번 연구로 밝혀낸 겁니다. 기존의 LLM 같은 경우에는 제한된 사전 학습 자원 내에서 최적의 학습 조건을 사용합니다. 이게 바로 친찰라 스케일링 로고요. 사전 학습 자원이 예를 들어서 a 10 256대로 10일 동안 학습할 수 있다 또는 그 비용으로 10억을 사용할 수 있다라고 하고 학습 조건이 모델이 얼마만큼 큰지 모델의 파라미터 수 그리고 학습 데이터의 건수라고 했을 때 이 친찰라 스케일링 로우는 동일 자원에서 모델 성능을 가장 높이는 학습 데이터 수와 모델 크기의 관계식입니다. 이거를 간단하게 해석해 보자면 정해진 사전 학습 예산 존재 시에는 결국 모델 크기와 학습 데이터는 반비례 관계에 있다라는 것입니다. 그리고 그 모델 크기와 학습 데이터는 대략 한 1 대 21.6 정도가 최적이다라는 것을 실험적으로 이제 확인을 한 건데요. 이 말은 이제 이후에 LLM을 학습할 때 모델 크기별 학습 데이터를 설정하는 데 있어서 굉장히 많이 활용이 되었습니다. 그래서 모델 크기 대비 21.6배 크기다라고 하면 여기서 보시는 바와 같이 원 빌리언 모델을 천억 개의 데이터로 학습시킨 것 세븐 블리언 모델을 300억 건으로 학습시키는 것 이런 것들이 그 자원의 가장 최적화되어 있는 크기와 학습 데이터 수의 조합입니다. 그랬을 때 퍼플렉스트라는 낮으면 낮을수록 우수한 성능을 봤을 때 13빌리언의 모델을 10억 건의 데이터로 활용을 했을 때 가장 우수한 성능이 나타나더라라는 것을 확인을 한 것이고요. 그래서 대략 한 21배에서 22배 정도의 학습 데이터 모델 크기 대비 학습 데이터를 사용해 왔습니다. 그런데 라마 같은 경우에는 친첼라 스케일링 now 이상의 데이터를 학습을 했습니다. 학습 예산 내에 최적 비율을 사용하지 않았는데 여기서는 예산을 결정하는 것이 아니라 제한을 두는 것이 아니라 의도는 이렇습니다. 엘엘엠을 활용할 때는 학습의 예산을 최적화하는 것이 중요한 것이 아니다. 결국은 모델이 한 번 학습이 되면 그 학습된 모델을 가지고 추론을 계속적으로 서비스를 할 거기 때문에 추론할 당시의 비용을 최소화하는 것이 중요하다. 이 말은 무슨 얘기냐 결국은 추론 비용은 건당 돈을 받게 되는데 그 한 건 추론할 때 모델의 크기가 클수록 사용하는 코스트가 높아집니다. 그렇기 때문에 작은 모델을 더 오래 학습시키는 것이 모델 배포 관점에서는 효율적이라는 겁니다. 그래서 오른쪽 표에 보시는 바와 같이 친칠라는 10테라계의 파라미터를 가지고 있으면 토큰을 거기에 21.6배 정도를 사용을 했는데, 라마 같은 경우에는 7빌리언 정도의 파라미터를 가졌음에도 불구하고 약 1테라바이트의 토큰을 사용을 했습니다. 결국은 비율이 1 대 142 정도가 됐었고요. 라마 2 같은 경우에는 이거를 더욱더 늘려가지고 1대 285 정도를 했는데 결국은 이렇게 학습시켰더니 성능이 더 좋아지고 그러면 큰 모델을 사용하는 것보다 작은 모델을 오래 학습시켜서 좋은 모델로 만들어 놓고 추론하는 과정에서는 비용을 적게 산출하는 것이 더 효과적이지 않겠느냐라는 의도입니다. 그래서 라마 1 2는 더 많은 데이터로 결국은 학습을 해서 높은 성능을 달성했다라는 게 결론이고요. 라마 1은 연구 목적만 활용이 가능하지만 라마투는 월간 700억 건까지는 상업적으로도 활용이 가능합니다. 그래서 상업용 오픈 소스로서의 다양한 활용 가능성의 장을 열어준 게 바로 이 라마 모델이라고 보시면 되겠습니다. 그러면 지금부터는 두 번째 꼭지로서 라마의 이후에 나타난 알파카와 그에 관련된 모델들을 한번 보시도록 하겠습니다. 우선 오픈 소스 LLM을 위해서 데모스트레이션 데이터라는 것은 LLM의 실제 서비스 활용을 위해서는 프리 트레이닝이라는 사전 학습 그리고 셀 슈퍼라이즈 파인 튜닝이라는 에프티 그리고 리퍼스트먼트 러닝, 위큐먼 피드백이라는 세 단계가 필요하다는 거를 이전 시간에 한 번 언급해 드린 적이 있습니다. 라마투는 상업적 활용이 가능한 프리트레인드 엘엘램이기 때문에 상업적 활용을 위해서는 공개된 슈퍼바이스트 파인 튜닝 테스크에 대한 데이터 그리고 알치프에 대한 학습 데이터가 필요합니다. 문제는 무엇이냐? 요 에프티와 알프 학습용 데이터 구축 비용이 매우 높습니다. 왜냐 결국은 사람을 고용을 해서 건당 다 모두 비용을 지불하고 만들어야 되는데 미국으로 치자면 아마존 미케니컬 터크라는 데서 사람들을 고용해서 한 건의 레이블링당 얼마씩을 제공하는 이제 그런 내용들이 있는 거죠. 그래서 어노테이터를 고용하고 데이터 구축 가이드라인을 제작하고 데이터를 검수하는 데 있어서 여전히 비용이 많이 듭니다. 아래 그림에서 보시면 라마 2 모델에 대해서 액세스가 가능하더라도 슈퍼바이즈 파인튜닝과 알엘치프를 하기 위해서 필요한 추가적인 학습 데이터를 구축하는 것이 어지간한 스타트업이나 작은 회사 규모로서는 불가능하다라는 뜻입니다. 이런 데몬스트레이션 데이터는 다음과 같은 필수적인 요건을 만족시켜야 됩니다. 첫 번째 다양성인데요. 다양성이라는 거는 프롬프트는 사용자들의 다양한 요청 사항을 담고 있어야 됩니다. 어떠한 요구 사항을 사용자가 나중에 활용 관점에 하는지를 모르기 때문에 사용자가 어떠한 형태의 요청을 하더라도 거기에 대해서 적절하게 대응할 수 있는 능력을 길러야 된다는 뜻이지요. 두 번째 적절성 답변은 프롬프트에 대응하는 적절한 내용을 포함해야 됩니다. 바꿔 말하면 할루시네이션이 없어야 된다라는 뜻과 일맥상통하고요. 내가 뭔가를 물어봤을 때 그 질문에 연관된 답변을 해주어야 된다라는 얘기입니다. haffnes라고도 표현하겠죠. 안전성 SFT 역시 지난 시간에 잠깐 언급해 드렸던 것처럼 답변은 혐오나 차별이나 위험에 대한 표현을 담지 않아야 된다라는 것입니다. 그리고 데이터 크기는 대략 1만 건 이상이 필요하다라고 되어 있고요. 이 데이터 크기가 그냥 대충 만든 데이터 1만 건이 아니라 굉장히 고품질의 양질의 데이터를 충분히 확보하는 것이 중요한 이슈가 되겠습니다. 그러다 보니 요 셀프 인스트럭션을 통해서 결국 핵심은 이렇습니다. 셀프라는 내용이 들어갔다는 얘기는 모델한테 인스트럭션 자체를 데몬스트레이션 자체를 만들도록 하겠다. 사람이 개입해서 데몬스트레이션 데이터를 만드는 것이 아니라 고품질의 데몬스트레이션 데이터를 확보할 수 있는 자동화된 데이터 구축 방법론을 제공하겠다라는 것입니다. 그래서 GPT API를 이용해서 데이터를 구축함으로 인해서 사람을 쓰지 않겠다는 얘기고요. 휴먼 어노테이터 수준의 데이터를 구축하는 게 가능해지면서 휴먼 어노테이터 대비 적은 비용이 소모가 됩니다. 이 셀프 인스트럭트는 크게 몇 가지의 그 스텝으로 구성이 되는데요. 첫 번째는 프롬프트 풀입니다. 데이터 수집을 위해서는 초기에 프롬프트 풀을 확보하는 게 매우 중요한데요. 이거는 휴먼 어노테이션을 통해서 175개를 확보를 했습니다. 이 초기의 최초의 논문에서는요 또한 다양한 테스크에 대해서 프롬프트 앤서 페어를 구축을 합니다. 오른쪽의 예시처럼 인스트럭션은 다음 규칙에 부합하는 단어를 알려줘 한 다음에 이게 이제 요청 사항이 되겠고요. 인컨텍스트 워닝의 샘플로서는 공란 알 공란 입니다. 그러면 정답으로써는 haart heard hears와 같이 첫 번째가 h이고 세 번째 자는 에이고 네 번째 글자가 아인 총 다섯 글자로 되어 있는 단어들을 이제 리턴을 하게 되는 것이죠. 이런 식의 풀을 확보를 합니다. 여기서의 풀이라고 하는 거는 전수로 만드는 게 아니라 일부를 사람이 어쨌든 최초 시작은 사람이 하겠다라는 뜻이지요. 두 번째 단계는 인스트럭션 제너레이션 단계입니다. 이 말은 추가적인 프롬프트를 생성하는 단계입니다. 기존 풀 내에 프롬프트 8개를 샘플링을 해서 인 컨텍스트 러닝에 활용을 하는데요. 각각의 태스크에 적합한 인스트럭션 구조를 사용합니다. 이 말이 무슨 얘기냐면 자 다음 예시를 보고 새로운 작업을 생성해 줘라고 하는 게 요청입니다. 그런 다음에 기존의 풀에서 8가지의 테스크를 샘플로 주고요. 보라색으로 표시된 테스크를 만들어내게 하는 겁니다. 이거를 LNM이 만들어내는 겁니다. 여행 예산을 짜줘 라는 테스크가 사람이 만든 게 아니라 엘엘엠이 위에 있는 8개의 샘플을 통해서 만든 테스크라는 뜻이지요. 세 번째는 클래시피케이션 테스크의 아이덴티피케이션입니다. 생성된 인스트럭션의 분류 문제 여부를 판단하는 단계이고 이걸 왜 하냐면 논문에서는 향후 단계에서 분류 문제인지 아니면 단순히 난 클래시피케이션 문제인지에 따라서 다르게 진행한다라는 뜻입니다. 고정된 인 컨텍스트 러닝을 이용을 하는데 오른쪽 예시처럼 보시면 다음 작업들이 분류 문제인지 판단해줘라고 했을 때 내 직업과 적성을 고려할 때 적절한지 알려줘라고 하면 테스크는 클래시피케이션이고요. 사람의 주민등록번호를 알려줘라고 하면 테스크는 넌 클래시피케이션입니다. 그런 다음에 어 여행 예산을 짜줘 라는 게 주어졌을 때 얘는 클래시피케이션인지 난 클래시피케이션인지를 이제 구분하라고 하는 것이죠. 여기서 지금 파란색은 테스크 난 클래시피케이션까지 포함되어야 됩니다. 그러면 생성된 인스트럭션에 부합하는 답변을 생성하는 단계가 이제 인스턴스 제너레이션입니다. 고정된 인 컨텍스트 러닝 샘플을 이용을 하는 것인데요. 여기서 보시는 것처럼 다음 예시를 보고 적절한 답변을 생성해줘라고 했을 때 다음 뉴스를 요약해줘라고 하고 뉴스 원문을 주고 아웃풋을 요약문을 주면 인스트럭션에 여행 예산을 짜줘라고 한 다음에 인풋의 여행 정보를 주면 아웃풋의 여행 예산에 대한 답변을 주는 것입니다. 근데 여기서 아웃풋 퍼스트냐 인풋 퍼스트냐가 구분되는 이유는 뭐냐면 상식적으로 생각했을 때는 인풋을 먼저 내고 그다음에 아웃풋을 내는 게 맞을 것 같지 않습니까? 그런데 논문에서 이 사람들이 해봤더니 클래시피케이션 테스크 같은 경우에는 뭔가 인풋을 주고 클래시피케이션을 하라 그러면 특정 클래스에 편향되는 질문들이 나온답니다. 긍부정 판단을 할 때 있어서는 긍정에 대한 답변이 나오는 질문들이 너무 이제 많이 나오는 이러한 상황이 되는 것이죠. 그래서 먼저 긍정인지 부정인지를 먼저 판단을 하게 하고 그 답에 맞게 질문을 생성하는 역방향으로 수행하는 부분입니다. 그래서 여기서 클래시피케이션 테스크냐 해서 그 대답이 예스라고 하면 아웃풋 긍정 또는 부정 클래스를 먼저 생성하고 다시 인풋을 생성하는 것이고요. 그게 아닐 경우에는 인풋을 먼저 생성하고 아웃풋을 생성하는 것입니다. 그런 다음에 마지막 단계는 필터링과 포스트 프로세싱 단계입니다. 데이터의 다양성과 품질 확보를 위해서 후처리를 하는 단계라고 생각하시면 되겠고요. 무조건 LLM이 만든 이러한 테스크와 데이터를 믿고 맡기는 게 아니라 기존 테스크 풀 내의 데이터와 일정 유사도 이하인 데이터만 테스크 풀로 추가를 하는 것입니다. 왜냐하면 이미 테스크 풀에 있는 데이터를 굳이 더 반복할 필요는 없으니까요. 그리고 텍스트로 해결할 수 없는 테스크 여기서는 이제 언어 모델이었기 때문에 이 텍스트만으로서는 해결할 수 없는 테스크 이미지 즉 이미지와 그래프 데이터가 필요한 테스크는 제거를 하는 과정도 거치게 됩니다. 그리고 난 다음에 마지막 단계가 슈퍼바이즈드 파인 튜닝입니다. 셀프 인스트럭스를 통해서 생성한 데이터를 이용해서 슈퍼바이즈 파인 튜닝을 학습하는 것이고요. 이렇게 함으로 인해서 휴먼 어노테이션 데이터 없이 물론 풀을 만들 때 약간의 사람의 공수는 들어갔습니다마는 그 과정 이외의 과정에서는 사람의 개입 없이 생성한 데이터를 이용을 해서 LLM을 슈퍼 파이즈 파인튜닝 하는 게 학습 진행이 가능해진다라는 얘기입니다. 알파카는 2023년에 스탠포드에서 발표한 LLN 셀프 슈퍼바이즈 파인튜닝 학습 프로젝트입니다. 그래서 앞서 지금까지 설명한 셀프 인스트럭스 방식으로 생성한 데이터를 이용해서 라마의 슈퍼바이즈 파인튜닝 학습을 했고요. 초기에 150개의 풀을 이용을 해서 5만 2천개의 SFT 학습 데이터를 LLM을 이용해서 생성합니다. 그렇게 한 다음에 라마의 세븐 b이언 훈련을 진행을 한 게 알파카고요. 그래서 결국은 라마를 텍스트 다빈치 003 코드를 이용을 해서 이 175개의 셀프 인스트럭션 시드 테스크를 만들고요. 그런 다음에 이걸 통해서 역시 마찬가지로 52케이의 인스트럭션 팔로잉 이그젬프를 만들어서 라마를 추가적으로 학습시킨 게 알파카 세븐 빌리언이라고 보시면 되겠습니다. 알파카는 GPT API를 이용해서 슈퍼바이즈 파인튜닝 데이터를 생성하고 학습하는 프레임워크라고 보시면 되겠고 데이터 생성하는 에피아의 종류와 성능에 따라서 데이터의 품질이 결정됩니다. 당연히 지피티 4를 사용했을 때가 지피티 3.5를 사용했을 때보다 더 성능이 높고요. 단 한계는 API가 수행하지 못하는 태스크들은 SFT 학습으로서는 성능 개선에 한계가 있습니다. 대표적으로 대학 수학 문제를 푸는 것 그리고 다국어 이해 능력 같은 경우에는 API가 제대로 수행을 하지 못했기 때문에 지에스엠 그리고 여기 있는 타이 큐에이 같은 이 두 가지들은 그렇게까지 성능이 확장이 되지는 않는 것을 볼 수가 있을 겁니다. 다만 API가 잘 이해하는 코드 생성과 같은 문제에서는 성능이 매우 뚜렷하게 성능이 개선됐다라는 것을 확인할 수 있었습니다. 라마와 알파카 모두 발표된 이후에 수많은 오픈 소스 LLM 연구가 발표가 되었는데요. LLM을 이용한 생성 기반으로서는 알파카 비쿠나 코알라, GPT 4 뭐 이런 모델들이 있고 프리트레인드 엘르램을 연구하고 발표하는 데는 뭐 팔콘이나 스테이블 에램, 미스트리 같은 이제 회사들이 있을 수 있다고 말씀드리겠습니다. 알파카 이후에 오픈소스 엘르램의 성능이 굉장히 클로즈 에르램에 근접해 가고 있고요. 그러므로 인해서 여기 보시는 것처럼 gpt4 터보가 1249라는 스코어를 이용을 했을 때 모델 웨이트와 상업적 활용이 모두 접근 가능한 비큐나 33밀리언이 별 차이가 안 나는 약 한 10% 좀 안 되게 뒤처지는 성능으로 따라가고 있는 것을 보실 수가 있겠습니다. 오픈 소스를 통해서 공유와 연구 확산을 통해 지속적인 발전이 이루어지고 있습니다. 지금부터는 LLM 모델에 대한 평가 방법론에 대해서 소개를 해드리도록 하겠습니다. LLM을 평가한다라는 얘기는 무슨 얘기냐 하면 얼마나 우리의 목적에 맞게 LLM이 주어진 테스크를 잘 수행하고 있느냐를 평가하겠다는 뜻입니다. 그렇기 때문에 LLM 평가는 기존 테스크 수행 능력 평가와는 다소 차이점이 있는데요. 기존의 테스크를 수행하는 능력은 평가 목적이 모델이 해당하는 테스크를 수행하는 능력을 측정하는 것이고요. 평가 데이터 역시 특정한 테스크에 대한 데이터입니다. 평가 방법론은 테스크 평가의 파이프라인과 계산 방법론을 이용을 하는 것인데 엘엔 평가라는 거는 어떠한 테스크가 주어지는지를 모르는 상황에서 범용적인 테스크 수행 능력을 평가를 해야 되고요. 그렇기 때문에 데이터 자체도 특정 하나의 구체적인 테스크가 아니라 여러 가지의 테스크가 섞여 있는 범용적인 능력 평가 데이터가 필요합니다. 방법론 역시 각 태스크별로 상이하기 때문에 이러한 부분을 고려해서 평가가 진행되어야 합니다. 엘엘램을 평가하고 활용하는 목적은 첫 번째 테스크를 수행하는 능력을 보는 것입니다. 다양한 테스크에 대해서 적절한 답변을 출력할 수 있는가 두 번째 안정성에 대한 평가입니다. 답변 내에 위험하거나 편향된 내용은 없는가 수행 태스크의 범위는 사실상 한정되어 있지 않습니다. 그래서 태스크 관점에서는 코드를 작성하거나 스토리를 생성하거나 제안서를 작성하거나 자기소개서를 수정하거나 문서를 요약하거나 사용자의 감정에 공감을 해주거나 굉장히 많은 테스크를 커버할 수가 있겠고요. 능력 관점에서는 이게 과연 이 테스크를 객관적인 사실 판단을 잘하는 모델인지, LLM이 논리적인 추론을 잘하고 있는지 또는 수학적 추론을 잘하고 있는지, 일반 상식에 대해서 충분한 정답을 알고 있는지 이런 것들을 이제 포함하게 됩니다. 다만 안정성 범위 관련해서는 다소 모호한 정의가 있습니다. 왜냐하면 예를 들어 너 잘났다라는 표현을 했을 때 이게 과연 앞뒤 문맥을 봤을 때 정말로 부러워서 그러는 건지 또는 비꼬는 문장인 건지를 알 수가 없을 것이고요. 사회적 편향 관점에서도 편향의 기준에 대해서 어떻게 정의할 것이냐, 얼마만큼 강하게 또는 얼마만큼 약하게 편향을 정의할 것이냐에 따라서 달라지는 것이고, 유용성도 어떤 사람은 특정 답변을 충분히 유용하다라고 느낄 수 있겠지만 다른 사람은 동일한 답변에 대해서도 그리 유용하지 않다라고 답변할 수 있기 때문에 유용한 답변이 무엇인가에 대해서 정의하는 것도 중요하게 생각되어야 합니다. 그래서 LLM 평가를 하기 위해서는 결국은 범용적인 테스크 수행 능력을 평가하기 때문에 평가 목적에 따라서 각 데이터를 구축하고 활용합니다. 대표적으로는 mmlu라는 데이터가 있고요. 이거는 메시 멀티태스크 랭귀지 언더스탠딩의 약자입니다. 결국은 글자 그대로 언어를 이해하는 데 있어서 여러 가지 테스크에 대해서 잘하고 있는지를 평가하는 것이고요. 엘램의 범용 테스크를 수행하는 능력을 평가하는 평가용 데이터 셋입니다. 다양한 평가 목적에 따른 데이터를 수집하고 통합한 데이터의 묶음이고 총 57개의 테스크로 구성이 됩니다. 그 테스크 안에서는 생물, 정치, 수학, 물리학, 역사, 지리, 해부학 이런 것들이 포함이 되죠. 객관식 형태로 평가가 진행이 되기 때문에 정답 보기를 생성하면 맞춘 것으로 간주를 합니다. 예를 들어서 사실 수학 같은 경우에는 객관식도 있고 주관식도 있을 수 있겠지만 데이터셋 자체는 객관식으로 구성이 되어 있고요. 공원에 30명의 농구 선수가 있다라고 했을 때 한 팀당 5명의 선수를 배정해야 하면 전체 팀 수를 계산하는 올바른 방법은 이라는 질문에 대해서 비처럼 30을 5로 나누어서 6개 팀이 보인다. 이러한 추론이 정답인데 모델이 이 추론에 대해서 문제에 대해서 비를 선택하게 되면 정답을 맞춘 것으로 간주하는 것입니다. 일반 상식 능력 같은 경우에는 평가 목적에 따라서 각 데이터를 구축하고 활용하는데요. 대표적으로 헬러스웹 같은 데이터는 사람이 가지고 있는 상식을 평가하는 데이터셋입니다. 사람은 매우 쉽게 해결 가능한 테스크로 구성이 되어 있고요. 에르램의 일반 상식 보유 능력을 평가하는 것입니다. 주어진 문장에 이어질 자연스러운 문장을 선택하는 것이고 이것도 역시 객관식 형태로 평가를 진행합니다. 예를 들어 한 남자가 발로 칼라를 돌리면서 손을 위아래로 흔들어 칼을 손질하고 있다. 이때 카메라는 점점점 했을 때 뒤에 이어질 문장이 가장 자연스러운 거는 비번 다양한 각도에서 남자를 보여주며 남자가 집중하는 모습을 보여준다. 누가 봐도 이거는 a b, c d 중에서 b번의 항목이 가장 자연스러운 문장의 흐름이죠. 그러면 LLM이 b를 선택하면 맞춘 것, b를 선택하지 못하면 맞추지 못한 것으로 처리해서 평가를 진행하는 것입니다. 세 번째 코드 생성 능력 같은 경우에는 휴먼 이밸류에이션이라는 엘엠의 코드 생성 능력 평가 데이터 셋이 있는데요. 함수명과 닥 스트링을 입력을 합니다. 닥스트링은 해당 함수의 수행 과정과 의도하는 결과물을 명시하는 것이고요. LLM이 생성한 실제 코드와 결과물을 이용을 해서 평가를 진행을 하는데 실행 결과물이 실제 값과 일치하는 것일 때는 맞춘 것으로 간주합니다. 그래서 여기서 보시는 것처럼 부스트 캠프라는 인풋이 있을 때 여기에 대해서 스트링이 몇 개가 글자 수가 몇 글자인가라고 했을 때 정답은 9개죠. 그러면 LLM이 코드를 생성을 해서 그러면 코드 생성에 대한 코드는 좀 다를 수 있겠지만 결과물 자체가 실제 값하고 동일하면 일치한다면 이것은 맞춘 것으로 간주하겠다라는 뜻입니다. 이러한 LLM을 평가하는 데 있어서 LLM 이밸류에이션 하니스라는 이제 자동화된 LLM 평가 프레임웍이 있습니다. 이거는 mmlu, 헬러스w HLM 등과 같이 다양한 벤치마크 데이터를 이용을 해서 평가를 가능하게 하고요. 평가 방식은 다음과 같습니다. 여러 개의 케이샷 이그잼플과 함께 LLM에 입력을 주면 각 보기 문장을 생성할 확률을 계산하는 것이고요. 확률이 가장 높은 문장을 예측 값으로 사용을 해서 정답 요부를 활용하는 것입니다. 여기에서의 평가 데이터셋 요소는 고정된 퓨샷 이그젬플이고요. 강건한 평가 로버스트 한 평가를 위해서 동일한 이그잼플을 보통은 사용을 합니다. 그리고 인스트럭션은 해당 테스크에 대한 묘사이고요. 초이스는 정답 문장을 포함하는 보기 문장입니다. 이거는 mmlu나 헬러 스업 데이터와 동일하죠. creat an서는 정답 문장이고요. 그래서 하나의 모델에 대해서 평가가 가능하고 이걸 통해서 특정 LLM의 특정 테스크에 대한 지표를 산출할 수 있을 뿐만 아니라 동일한 테스크에 대해서 모델 간의 비교도 가능하게 되는 것입니다. 다음은 gel이라는 평가 지표 g2bl은 창의적인 글쓰기 능력을 평가하는 것인데요. LLM 활용에 상당수는 정답이 존재하지 않는 테스크입니다. 창의적 글쓰기 테스크 같은 경우에는 자기소개서를 수정한다든지 광고 문구를 생성한다든지 어투를 변경한다는 것들이 있겠습니다. 이러면 실제 생성문을 이용해서 정성적인 품질을 평가를 해야 됩니다. 그렇다면 결국은 사람이 어노테이터로 개입을 해서 휴먼 이밸류에이션을 해야 되는데 높은 비용과 긴 시간이 소모된다라는 단점이 있습니다. 또한 파일럿 테스트를 해야 되고 다양한 모델에 대해서 평가가 어렵다는 단점이 있습니다. 지 베리에이션이라는 건 이 쥐는 이제 지피티의 약자라고 보시면 되겠는데요. 지피티 4를 이용해서 생성문을 평가하는 방식입니다. 창의성이나 다양성이 중요한 테스크에 활용이 가능하고요. 정답문이 존재하지 않아도 평가가 가능합니다. 평가 방법에 대해서 한번 말씀을 드리면 우선 첫 번째는 평가 방식에 대해서 인스트럭션을 구성을 합니다. 아래에 있는 인스트럭션은 뉴스 기사의 요약문을 평가하기 위한 인스트럭션이 되는 것이고요. 두 번째는 평가 기준을 제시합니다. 일관성은 1점부터 5점 그래서 일관성이 무엇인지와 그 일관성이라는 게 어떠한 기준에 의해서 점수가 매겨져야 되는지에 대한 설명을 크라이테리어로 제시하는 겁니다. 세 번째는 평가 단계 생성입니다. 오토 체인 오 포트를 통해서 모델이 스스로 평가 단계를 정의하는 것이고요. 여기서 오토 체인업 포트라는 거는 모델 스스로 추론 관계를 구축하는 프롬프트 방식입니다. 여기서 보신 것처럼 첫 번째 단계에서는 뉴스 원문을 주의 깊게 읽고 주제와 키포인트를 탐색했다. 두 번째는 요약문을 읽고 원문과 비교했는데 이때 주제와 키포인트를 잘 포착했는지를 확인했다. 문장이 논리적이고 명확한지를 확인했다. 이런 단계 세 번째는 그래서 일관성 점수를 1점부터 5점 사이에 어떤 점수로 부여할 것인지 이거를 직접 ch인 업 소트 과정을 통해서 만들어내는 것입니다. 1번부터 3번까지의 이 문장을 다시 프롬프트로 사용을 해서 각 요약문에 대한 평가를 진행을 하는 게 네 번째 단계입니다. 그래서 지피티4는 프롬프트 뉴스 원문 생성된 요약문 이것을 입력을 해서 점수를 생성하게 됩니다. 이렇게 지피티4 API 비용만으로 정성적인 점수가 이제 산출이 되게 되는데요. 공통된 입력은 인스트럭션과 이밸레이션 크라이테리어 오토 체인 너브 파우트 데이터별 입력은 뉴스 아티클과 써머리 모델이 생성한 서머리가 되겠죠. 이랬을 때 지피티4한테 이게 정말 인스트럭션대로 잘 요약이 됐니라고 물어봤을 때 점수가 3점이다 이렇게 이제 뱉어 주는 겁니다. 사람이 평가를 해둔 데이터 셋과 비교를 했을 때 휴먼 이밸루에이션 스코어와 굉장히 상관성이 높아야 됩니다. 자동 평가 방식인데 좋은 평가 방식이라면 사람이 5점을 준 요약문에서는 모델도 엘르램도 5점을 줘야 되겠고 사람이 1점을 준 요약문에 대해서는 엘르램도 1점을 줘야 됩니다. 그래서 이러한 기준을 가지고 봤을 때 기존 평가 방법론 대비 평가 데이터를 이용해서 별도로 학습을 한 유니 이베와 거의 유사할 정도로 매우 높은 점수 또는 그보다 이상의 점수를 얻어내고 있는 것을 보실 수가 있겠습니다. 다만 여기서는 역시 활용 모델에 따라서 성능 차이가 존재하는데요. gpt4를 사용할 때가 GPT 3.5를 사용할 때보다 더 높은 성능 다시 말하면 이러한 평가 모형으로서 사용되는 기반 LLM이 성능이 좋아야지만이 평가 결과도 좋다라는 어찌 보면 당연한 결과라고 할 수 있겠습니다. 이러한 주입을 할 때 주의사항은 명확한 평가 기준이 있어야 됩니다. 평가 기준에 따라서 모델이 평가를 진행하기 때문에 그렇고요. 평가 모델을 선택하는 것이 이제 필요합니다. 모델의 성능에 따라서 평가 결과물의 신뢰도가 결정이 되는데 sLLM 스몰 사이즈의 LLM을 사용할 경우에는 LLM 자체에 대한 모델의 성능이 높지 않기 때문에 점수에 대한 신뢰도가 하락하게 됩니다. 따라서 gpt4 터보 등 안정적 결과물 산출이 가능한 모델을 선택하는 게 필수적이고요. 일부 평가 점수 신뢰도 확보를 위해서 일부 데이터에 대해서는 사람이 직접적으로 검수하는 과정도 충분히 고려가 되어야 합니다. 결론입니다. LLM 모델과 평가에 관련해서 말씀을 드리면 라마 등장 이후에 오픈 소스 LLM의 연구와 공개가 가속화가 되었고 이러한 오픈소스 LLM을 사용할 때는 활용 목적별로 라이센스를 확인하는 게 필요합니다. 상업적 활용 시에는 아파치와 같은 해당 라이센스를 보유한 엘램을 활용할 수 있으나 외부 유출이 불가능한 데이터를 사용할 때는 오픈 AI API 등의 활용에 제약이 있습니다. 추가 학습을 필요할 경우에는 오픈 에아 파인튜닝 에피아나 오픈소스 엘엘엠을 직접 학습하는 것이 가능하고 또한 슈퍼바이즈 파인튜닝 학습 데이터 구축 시에는 지피티4 등을 이용해서 효율적인 셀프 인스트럭트 방법론과 같은 방식으로 모델 성능을 개선할 수가 있습니다. 엘르램 성능 평가 시에는 평가 데이터셋 별 특성이 다양하기 때문에 평가 목적에 맞는 데이터셋을 활용해야 되겠고요. 창의적인 글쓰기를 능력을 평가할 때는 지피티4 등을 이용해서 모델을 이용해서 다시 한 번 모델을 평가하는 지이벨 같은 방식을 통해서 휴먼 이밸루에이션 방식을 대체할 수가 있겠습니다. 여기까지 해서 4강의 강의를 마치도록 하겠습니다. 감사합니다."
}