{
  "lecture_name": "(8-1강) Generative Models",
  "source_file": "(8-1강) Generative Models_47.mp4_2025-12-04-10372153.json",
  "text": "네 안녕하세요. 오태리입니다. 이번 시간에는 생성 모델에 대해서 공부해 보도록 하겠습니다. 사실 생성 모델은 그 범위도 넓고 깊이가 있는 분야라서 어 1시간만으로 커버하기에는 좀 타이트하지만 중요한 생성 모델의 개념 위주로 공부해 보도록 하겠습니다. 네 생성 모델은 여러 의미로 중요한 인공지능 모델링 기법입니다. 아무래도 이제 비주얼 데이터 자체가 눈에 직접 보이기도 하고 어 흥미롭기 때문에 이런 생성 모델이 먼저 응용으로 사용되는 것이 컴퓨터 비전 분야인데요. 어 이번 시간에는 생성 모델이 무엇이고 어떤 것들이 있는지 한번 공부해 보도록 하겠습니다. 생성 모델에 들어가기에 앞서서 생성 모델을 통해서 우리가 달성하고 싶은 목표를 먼저 이해해 보도록 하겠습니다. 우리가 보통 다루고 있는 이 학습 데이터셋은 굉장히 복잡한 실제 세계에 많은 프로세스를 거쳐서 이렇게 이미지나 비디오 같은 데이터로 발현이 되게 됩니다. 어 아무래도 이제 물리 세계의 어떤 프로세스들로 인해서 먼저 이 말이 태어나야 될 거고 그다음에 말이 이 시기에 이 상황에 이 앞에 딱 존재를 해야겠죠. 이것들을 만드는 이 데이터 하나하나를 만드는 그 프로세스는 어떻게 보면 굉장히 복잡한 프로세스를 거쳐서 이제 운명처럼 이 데이터가 발현이 되게 되는 겁니다. 그런데 우리가 사는 이런 물리 세계는 정말 너무 복잡하죠. 그래서 이걸 다 모델링하는 게 꽤 어려우니까 이게 정확하게 뭔지는 모르지만 어떤 확률 분포 p 데이터라는 표현으로 간단한 확률 모델로 이제 표현을 하게 됩니다. 여기서 피 데이터는 이 세상에 존재하는 모든 데이터를 샘플링 할 수 있는 궁극적인 분포인 거죠. 그래서 만약에 이 피 데이터를 알고 있다고 가정을 하면은 이 세상에 있는 모든 데이터가 어떻게 만들어지는지와 그리고 테스트 타임에도 발생할 그 데이터에 대해서 모두 예측이 가능하기 때문에 정말 만능적인 분포를 우리가 알고 있다라는 것과 동일한 얘기가 됩니다. 당연히 이런 분포는 이제 실제로 표현도 어렵고 신이 아닌 이상은 액세스 자체가 불가능하겠죠. 그래서 이런 상황에서 우리가 어 피 데이터에 대해서 조금이라도 이해하고 그리고 피 데이터로부터 데이터를 샘플링할 수 있는 즉 생성할 수 있을 정도로 저 분포를 아는 것이 이제 생성 모델의 첫 번째 목표입니다. 이제 이걸 위해서는 우리가 피 데이터 분포를 사용할 수 있는 형태로 표현할 수가 있어야겠죠. 그래서 우리가 직접 피 데이터를 액세스 할 수 없는 상황에서 오직 이 샘플 된 그 데이터만 가지고 있을 때 이런 샘플된 학습 데이터들로 이 피 데이터라는 디스트리뷰션을 근사하는 피 모델 디스트리뷰션을 찾는 것이 생성 모델의 궁극적인 목적이라고 생각할 수가 있을 것 같습니다. 네 조금 더 구체적으로 정리를 하면은 어 여기서 우리가 다룰 수 있는 어떤 디스크립션을 표현하는 모델링은 뭐 컨볼루셔널 뉴러 네트워크라든지 유닛 또는 트랜스포머 등의 어떤 파라미터릭 패밀리들이 있을 거고 그다음에 그것들을 학습하는 방법도 몇 가지 알려진 것들로만 선택해서 우리가 사용을 해야 될 텐데요. 어 이렇게 디자인을 몇 가지를 정하게 되면은 우리가 다룰 수 있는 모델에 대해서 한정이 되게 됩니다. 여기에 붉은색으로 표시된 어 부분이 이러한 모델 패밀리로 인해서 한정된 그런 영역들을 나타낸다라고 이해하면 될 것 같습니다. 그래서 실제로는 이 피 데이터하고 갭을 정말 좁힐 수 있는 그런 건지는 모르지만 정해진 바운더리 내에서는 최선을 다해서 이런 근사 모델을 찾아내서 이 갭을 좁히는 형태로 학습이 진행이 되게 됩니다. 그래서 생성 모델의 아키텍처나 방법론도 더 연구가 진행이 돼서 이 영역을 점점 더 확장함으로써 조금 더 이 피 데이터라는 원래 트루 디스트리션에 조금 더 가까운 그런 생성 모델을 찾으려는 시도가 생성 모델의 연구 주제라고 할 수가 있겠습니다. 그럼 이런 복잡하고 어려워 보이는 생성 모델을 왜 공부하는지 궁금할 수가 있을 텐데요. 어 생성 모델은 여러 가지 의미로 매우 중요합니다. 여기 오른쪽에 있는 샘플들은 이제 최근 생성 모델들을 기반으로 생성한 합성 데이터들인데요. 어 정말 리얼리스틱하죠. 그래서 이런 데이터를 사용자가 컨트롤할 수 있는 형태로 마음대로 생성할 수 있다라고 하면은 미디어 산업 등의 서비스로도 이제 활용할 수도 있겠고 그다음에 아래와 같은 비디오 모델의 경우에는 너무 현실을 잘 반영해서 마치 물리적인 효과도 이해하면서 생성한 것과 같은 그런 효과를 보여줍니다. 그래서 마치 시뮬레이터와 같죠 그래서 손으로 만든 그런 시뮬레이터가 아니라 데이터로 학습한 시뮬레이터로서 활용될 수 있다면 정말로 실제로 구현되는 어떤 현상들이 우리가 손으로 다 디자인할 수 없는 것조차도 다 반영이 된 그런 시뮬레이터로서 활용이 될 수가 있을 거고요. 그러면은 그런 시뮬레이터를 통해서 정말 현실적으로 도움이 되는 디시전 메이킹이나 어떤 로봇의 행동 같은 것을 제어하는 등의 여러 가지 테스크들을 수행하는 데 응용할 수가 있을 겁니다. 그리고 이 정도 레벨로 데이터를 생성할 수 있다라고 하면 어 정말 데이터가 어떻게 만들어지는지 그 숨은 메커니즘과 관계성을 다 이해하고 그다음에 데이터를 만들었다고 볼 수도 있겠죠. 이 왼쪽에 보면은 리차드 파인만의 명언을 볼 수가 있습니다. 어 내가 만들지 못하는 건 이해하지 못한다라는 명언처럼 이 정도 레벨로 데이터를 진짜 잘 생성할 수 있다라고 하면은 이미지나 비디오에 대한 이해도도 상당 수준 높다라고 볼 수도 있겠죠. 그래서 이런 생성 모델링을 잘하는 모델이 결국에는 인식이나 분석 모델에 필요한 지식을 충분히 갖고 있고 유리한 그런 모델일 수 있기 때문에 매우 스트롱한 리프랜테이션 러닝 방법으로도 보고 있습니다. 그래서 이렇듯 성공적인 생성 모델링이 의미하는 임팩트는 매우 크기 때문에 많은 사람들이 생성 모델링에 대해서 관심을 가지고 연구를 진행하고 있습니다. 어 또 다른 목적으로는 이제 퍼셉셜 러스나 어드버세얼러스에서 본 것처럼 학습된 기준을 갖는 어떤 로스 펑션으로 활용될 수도 있습니다. 네 종종 내가 풀려는 문제가 리그레션인 문제가 있는 경우들이 있는데요. 그때 입력하고 출력의 관계하고 상관없이 무조건 일반적인 리그레션이나 클래시케이션 러스로 학습하려는 경우들이 종종 있습니다. 근데 이렇게 학습을 진행하면 평균적인 그런 값만 출력하고 좋은 성능이 안 나오는 경우들도 좀 있어요. 이런 모델이 도출되는 경우는 보통은 이렇게 문제의 어떤 데이터를 자세히 보면은 그 관계가 1 대 1이나 이제 매니 2 1과 같은 그런 관계가 아니라 이렇게 이제 원 투 매니라든지 또는 이제 매니투 매니와 같은 이런 관계를 가진 경우들이 많습니다. 그래서 이런 경우들에 대해서는 제너레이티브 모델링을 하지 않으면은 어 이 관계를 제대로 학습할 수가 없습니다. 그냥 평균적인 이 정도면 충분히 잘했어라는 식으로 로스를 낮추다가 세츄에이션 되는 포인트로 멈추기 때문입니다. 이런 현상이 발생하는 이유는 어떤 입력에 대해서 다양성이라든지 분포를 학습하는 게 아니라 하나의 어떤 평균적인 결괏값을 예측하고 그만두기 때문입니다. 그래서 지금까지 왜 생성 모델이 중요한지 살펴봤는데요. 이제 한번 본격적으로 생성 모델들에 대해서 살펴보도록 하겠습니다. 네 이 강의에서는 최근에 제네이티브 모델의 발전 흐름을 포커스하기 위해서 어 웬만한 수식들을 최대한 사용하지 않고 컨셉트 위주로만 살펴보려고 하는데요. 어 생성 모델의 기본적인 모델링 시작을 비교하고 이해하기 위해서 첫 부분은 조금 더 수식적인 부분들을 살펴보고 넘어가도록 하겠습니다. 먼저 이런 확률 분포에 대해서 조인트 디스크립션을 표현을 할 때 우리가 정확한 이그젝트 관계죠. 체인을 통해서 요 조인트 디스트리뷰션을 이렇게 분해해서 팩터라이즈 된 폼으로 표현할 수가 있습니다. 이때 요 어 이렇게 표현하는 방법을 체인룰이라고 부릅니다. 그때 체인룰을 보면 여기서 각각 컨디셔널 밸류어블로 걸린 그 변수가 랜덤 밸류어블이 여기 앞쪽에 이렇게 존재를 하고 이렇게 조건부 확률로서 x 2를 표현하고 그다음에 그다음 밸류어블은 또 이 x1 하고 x2가 여기에 이렇게 조건으로 들어가서 x3가 나오게 되고 이런 식으로 사슬 관계처럼 하나하나씩 꼬리를 물면서 앞서 선언된 어떤 그 랜덤 밸류어블들이 뒤쪽에서 이 조건부 확률로서 그다음 단계를 정의하는 식으로 이렇게 체인룰이 전개가 되게 됩니다. 그래서 이거는 이 두 개의 표현이 정확하게 동치인 등가 관계입니다. 그리고 또 베이스 룰이 있습니다. 우리가 어떤 조인트 디스크리션의 어떤 분모에 이렇게 한쪽 디스트레션을 이렇게 분모로 나눠주는 형태로 해서 이렇게 어떤 조건부 확률을 정의를 할 수가 있고요. 그다음에 여기서 조건부 확률에서 이제 x y의 랜덤 밸류어블의 순서를 바꿔서도 이렇게 표현할 수 있는 것이 이제 베이스 룰이었죠. 그다음에 컨디셔널 인디펜던스 관계에 대해서도 한번 설명을 하도록 하겠습니다. 컨디셔널 인디펜던스는 이제 어떤 조건이 주어졌을 때 그때 상황에서 이 스하고 와라는 랜덤 밸류어블이 서로 독립인 경우에 서로 상관이 없는 경우에 대해서 이 컨디셔널 인디펜던스라고 부릅니다. 그러면 확률 분포에서는 우리가 컨디셔널 인디펜던트인 경우에는 이 x하고 y가 위쪽에서 x 콤마 y 그다음에 기분 z 일 때는 스하고 와를 각각 팩트라이즈 된 폼으로 곱해 곱하기 형태로 꺼내서 사용할 수가 있고 또는 여기서의 경우에는 이제 컨디셔널 인디펜던스니까 조건부로 들어갔을 때는 와하고 상관이 없이 상관이 없는 피스 기본 시라는 어 확률 텀하고 동치인 그런 형태가 되는 게 이제 컨디셔널 인디펜던스입니다. 그리고 여기서 중요한 이제 마르코프 어섬션 같은 경우는 이 컨디셔널 인디펜던스의 어떤 한 스페셜 케이스인데요. 여기서 마르코프 어썸션 퍼스트 오더의 경우에는 이렇게 시퀀셜한 어떤 컨디셔널 밸류어블들이 이렇게 주어진 상황에서 이 셀에는 바로 직전 단계의 랜덤 밸류어블하고만 어 컨디셔널이 디펜던트 하고 나머지 그 전에 있었던 어떤 이벤트들이나 랜덤 밸려블들에 대해서는 서로 상관이 없는 독립인 그런 형태를 의미합니다. 그래서 바로 직전 거에만 영향을 받는 그런 케이스에 대해서 퍼스트 오더 마르코브 어썸션이 적용된 그런 관계의 어 랜덤 밸류블들이라고 이해하면 될 것 같습니다. 네 처음 살펴볼 모델은 가장 간단한 제너리이티브 모델인 이제 오토리드레시브 모델에 대해서 살펴보도록 하겠습니다. 어 여기서 모토 리그레스브 모델이든 아니면 제네이티브 모델이든 보통 제네이티브 모델들은 전부 다 라이클 리드에서부터 모델링을 시작을 하게 됩니다. 여기서 이 라이클리우드의 역할은 만약에 제대로 잘 우리가 분포를 모델링하고 학습하거나 또는 찾았다라고 하면은 실제 데이터가 들어왔을 때는 높은 확률 값을 그다음에 좀 더 아티피셜하고 이제 일반적인 어떤 데이터셋에 존재하는 데이터가 아닌 것 같은 그런 데이터가 들어오면은 낮은 그런 우더 값을 출력을 해주는 그런 모델이라고 생각하면 될 것 같습니다. 근데 처음에 이런 PX를 우리가 만약에 뉴얼 네트워크 같은 걸로 모델링을 했다라고 하면은 그런 어떤 x가 실제 리얼 데이터인지 아닌지를 판단할 수 있는 그런 형태의 능력이 없겠죠. 그래서 이런 어떤 데이터가 들어왔을 때 그것들의 라이클류들을 맥시마이즈 하는 방향으로 학습하는 그런 오브젝티브 펑션에서부터 많이들 시작을 합니다. 그래서 일반적으로 이런 라이클리드를 맥시마이즈 하는 그런 형태로 학습이 진행이 된다라는 것을 기억해 두면 좋을 것 같고요. 그러면은 이제 x가 주어졌을 때 실제 데이터인 경우에 그랬을 때 이 PX가 높은 값을 출력하도록 하는 게 좋겠죠 그렇게 해서 맥시마이즈 한 오브젝티브 펑션에서부터 시작을 하게 됩니다. 근데 보통 이런 피스라는 하나의 덴시티를 가지고서는 직접 다루는 게 좀 어렵기 때문에 그것보다 다루기 좀 편한 그런 형태로 우리가 변환을 해서 사용을 합니다. 그래서 여기에서는 이 x가 이미지인 경우에 한해서 이 x를 이루고 있는 n개의 픽셀들을 각각 랜덤 밸류어블로 우리가 생각을 하고요. 그다음에 체인 룰을 이용해서 이렇게 팩트라이즈 된 폼으로 표현을 합니다. 그래서 여기서는 이제 아이 번째 픽셀 밸류를 이제 랜덤 밸류블로 생각을 했을 때 이 아이 번째 픽셀 밸류는 x 1에서부터 그 전까지 XI 마이너스 1까지 등장한 그런 픽셀 밸류들에 의해서 결정이 되는 그런 확률의 팩터라이즈 폼으로 이 PX를 정확하게 표현을 합니다. 근데 여전히 이 각각의 분포들을 보면 여기서의 디펜던시 관계들이 굉장히 복잡하기 때문에 이 픽셀 밸류들의 관계를 우리가 어떤 하나의 디스트뷰션으로 모델링하는 게 뭐 쉽지는 않을 수가 있습니다. 그래서 이럴 때 우리가 사용하는 거는 이 프로블리티 텀을 우리가 뉴럴 네트워크로 치환을 해서 한번 표현을 해보자라고 생각해 볼 수 있겠죠 네 그렇게 제한된 모델이 이제 픽셀 알앤입니다. 이 뒤에 있는 컨디셔널 프로버빌리티 텀을 이제 RNN으로 모델링을 해서 이 디펜던시를 쉽게 핸들링 할 수 있도록 모델링을 한 건데요. 여기 오른쪽에 보면은 여기에 있는 원들이 전부 다 다 픽셀이라고 생각을 해보면은 이때 이 이미지 픽셀들을 하나하나씩 이제 생성을 해내는 겁니다. 그래서 어 이 관계식에 의해서 이 다음 픽셀은 그 전에 있었던 픽셀에 서로 의존성이 있기 때문에 이 출력 값이 이 다음 값의 어떤 조건으로서 입력 조건으로서 반영이 되게 되고 이렇게 의존 관계들이 점점점 프로파게이션 돼서 다음 픽셀들을 결정하는 식으로 생성 모델이 모델링 되게 됩니다. 그리고 이 하나하나의 노드에 해당하는 픽셀에 해당하는 그 출력 값들은 이렇게 프로볼리티 디스비션을 갖는데 어떤 프로블리티 디스트션이냐면 각 픽셀에 해당하는 0에서부터 255 사이의 인텐시티 값 중에서 가장 그럴듯한 그런 확률 값을 출력해주는 구조로 뉴얼 네트워크가 모델링이 돼 있습니다. 그래서 이게 또 이제 확률 분포처럼 이제 표현이 되기 위해서 소프트 엑스 형태로 나와서 이것들의 합이 1인 그런 형태의 확률 값이 출력이 되게끔 만들어 놓고요. 그래서 이 피 x 기분 그다음에 기존의 히스토리에 대한 이 프로블리티 텀이 요 픽셀에 대한 거라고 가정을 하면은 이전에 있었던 그런 히스토리들이 전부 다 LSTM의 중간 히든 스테이트 또는 메모리로서 기억이 되고 그다음에 그 값들과 현재의 위치에서 그 값들을 이용해서 현재 위치에서 이런 인텐시티의 프로블리티 값을 출력을 함으로써 우리가 이 중에서 어떤 픽셀 값을 취할지 샘플링 할 수 있도록 유도를 하는 방식이 당연히 학습을 할 때는 이런 프로블리티 텀이 이렇게 LSTM으로 유도가 될 수 있기 때문에 얘네들을 다 결합을 해서 최종적으로 라이클 유드 하나를 이제 만들었을 때 그 라이클 유드가 실제 이미지 트레이닝 이미지를 잘 표현할 수 있는 형태로 러스를 주고서나 학습을 진행하게 됩니다. 그래서 결국에는 여기서 출력되는 그런 인텐시티들로 결정된 그런 하나의 이미지가 나왔을 때 그 이미지와 현재 주어진 어떤 트레이닝 이미지 사이에서의 차이를 매저를 해서 이제 러스로 사용을 해서 이 LSTM을 학습을 하게 되는 거죠. 이렇게 학습을 하게 되면 이런 이미지넷에 대해서 이렇게 그럴듯한 이미지들을 생성해내는 것을 볼 수가 있습니다. 또 이게 시퀀셜하게 우리가 이전에 있었던 인풋을 어 가지고서는 그걸 조건부로 해서 그다음 픽셀들의 인텐시티 값을 출력할 수 있기 때문에 이런 인페인팅과 같이 부분적으로 주어진 데이터에 대해서 조건부로 이제 그다음 출력을 생성하는 그런 형태의 쓰기에 굉장히 어 적합한 구조이죠. 그래서 이런 인페인팅에서도 굉장히 잘 적용될 수가 있다라는 것을 우리가 확인할 수가 있는 결과입니다. 네 지금까지 살펴본 모델이 이제 오토리스브 모델이라고 하는 굉장히 심플한 그런 생성 모델의 한 종류입니다. 그래서 이 방법이 아무래도 히스토리컬한 거를 조건부로 해서 다음 픽셀에 대한 정보를 샘플링을 하다 보니까 속도적인 측면에서는 굉장히 느린 게 좀 단점이 될 수가 있는데요. 그럼에도 불구하고 이제 프로볼리스틱 텀에 대해서 이제 직접적으로 뉴얼 네트워크가 어느 부분을 어프록시메이션을 하는지가 명료하고요. 그다음에 학습하는 그런 방법도 기존의 맥시멈 라이클루드 방법을 사용을 해서 우리가 학습을 할 수가 있기 때문에 확률 텀과 그다음에 생성 모델과의 관계를 이해하기에 굉장히 좋은 모델입니다. 그래서 이 모델에서부터 우리가 시작을 해서 생성 모델을 이해를 하면은 어 어떻게 하면 확률 텀과 그다음에 뉴얼 네트워크가 연결될 수 있는지 이해하기가 좀 편할 것 같습니다. 네 다음으로는 이제 오토 앤코더입니다. 이제 오토 앤코더의 경우에는 어 방금 전에 설명했던 어떤 프로블리텀하고는 좀 연관이 없는 조금 다른 형태의 모델인데요. 어 이 오토 엔코더의 기본적인 모티베이션은 어 굉장히 많은 트레인 데이터를 다 뉴럴 네트워크에 녹여 넣자라는 겁니다. 그래서 어 이렇게 트레인 데이터를 전부 다 컴프레션 하는 그런 형태의 모델이 됩니다. 이렇게 많은 데이터를 우리가 뉴럴 네트워크에다가 다 녹여 넣어서 컴프레션을 하기 위해서는 우리가 어떤 로스 펑션이 필요한데 이 오토 엔코더에서는 인풋이 들어가면 그 인풋을 그대로 리컨스트럭션을 하는 형태로 로스를 걸어주게 됩니다. 그래서 x가 들어오면은 x가 엔코더 디코더를 거쳐서 자기 자신을 스스로 리컨스석션을 하고 그다음에 오리지널 데이터하고 같냐 다르냐를 이렇게 에러나 엘트로스 같은 걸로 측정을 해서 어 리컨석션을 통해서 이 모델에다가 데이터를 전부 다 다 녹여 넣는 거죠. 근데 여기서 중요한 포인트는 만약에 뉴럴 네트워크의 모델이 충분히 크면 그 웨이트 파라미터들의 데이터들을 전부 다 다 메모라이제이션을 할 수도 있을 것 같습니다. 그런데 여기서 중요한 포인트는 이렇게 하이디벤저널 데이터가 들어왔을 때 그거를 훨씬 더 저차원의 로디벤저널 한 그런 벡터 스페이스에다가 이렇게 매핑하는 그런 형태로 학습을 하는 그 구조를 한번 생각해 보도록 하겠습니다. 이렇게 저차원으로 우리가 병목을 주는 것을 이제 바틀렉이라고 우리가 부르면요 이 바틀랙을 넣음으로써 이제 원래 샘플을 보거나 할 때 정말 중요한 특징만 골라내는 그런 형태로 엔코더가 학습이 진행이 되게 되고요. 그렇게 함으로써 이렇게 고차원 데이터를 정말 중요한 에센셜한 요소들만 컴프레션을 하는 형태로 학습이 진행이 되게 됩니다. 이때 이 엔코드하고 뉴얼 네트워크를 충분히 깊은 뉴얼 네트워크로 모델링을 해서 이제 학습을 하게 되는 거죠. 근데 이렇게 학습을 해서 이제 데이터를 한번 보면은 어 봤던 데이터에 대해서는 이 셀프 리컨덕션 에러가 굉장히 작을 겁니다. 왜냐하면 아무래도 봤던 것들은 손쉽게 어 다시 디코딩을 하기가 좋을 거기 때문에 굉장히 에러가 작을 거고 그다음에 못 봤던 데이터에 대해서는 에러가 크겠죠 그렇죠 못 봤던 데이터에 대해서는 이렇게 매핑을 해본 적이 없고 리컨 석션을 해본 적이 없으니까 상대적으로 에러가 클 수가 있습니다. 이런 식으로 우리가 어노말리 디텍션이라든지 여태까지 봤었냐 못 봤었냐 이런 것들을 판단하는 응용에서도 간단하게 사용이 가능한데요. 이런 역할이 결국에는 아까 설명했던 그런 라이클리오드 데이터에 대한 라이클 리드와 굉장히 유사한 기능이라고 볼 수가 있겠습니다. 그런 측면에서 이 모델도 그리고 데이터를 생성한다는 측면에서 셀프 복원을 한다는 측면에서 생성 모델이라고 볼 수가 있는데요. 결국에는 근데 이 모델이 충분히 크게 되면은 결국에는 이 데이터들을 전부 다 다 메모라이제이션에서 오버핑팅 되는 그런 문제들이 좀 발생을 합니다. 그거 외에도 여러 가지 좀 이슈가 있는데요. 이 오토앤 코더를 직접 제너레이티브 모델로 사용하기에는 조금 적합하지 않은 부분이 중간에 바틀랙에 사용을 했던 그런 인베이딩 벡터들을 우리가 사용해서 리얼리스트 네이버 서치 즉 이웃 탐색을 해서 가까운 어떤 벡터들을 갖는 그런 데이터들을 찾아보면은 생각보다 사람이 눈으로 보는 거 하고 좀 다르게 별로 의미론적으로 유사도가 있거나 그렇진 않습니다. 왜냐하면 우리가 엘트로스나 에론노스로 그냥 학습을 하기 때문에 그 내부의 내용이 무엇인지 콘텐츠는 상관이 없고 그냥 픽셀 인텐시티 값이 비슷하면 가까운 어떤 인베이딩이 할당이 되는 그런 구조로 학습이 되기 마련입니다. 그리고 당연하게도 그냥 러스 펑션 가지고 학습을 해서 어 데이터를 컴프레션 하고 그렇게 구현을 했기 때문에 프로볼리스틱한 그런 인터프리테이션이 아직까지는 없습니다. 그리고 이제 새로운 데이터를 우리가 샘플링하는 형식으로 생성형 모델로 활용을 하고 싶을 때에도 마땅하게 우리가 어떻게 샘플링 할 수 있는 그런 방법들이 없습니다. 왜냐하면 우리가 레이턴트 벡터에 대해서 샘플링해서 넣으려고 하면은 그 레이턴트 벡터가 어떤 영역에서 잘 정의가 되는지를 미리 알고 있어야 되는데 어 그거에 대한 정보가 그냥 없죠 그냥 어 엔코딩을 해서 엔코딩 된 그런 벡터를 가지고선 다시 디코더에다가 넣어서 출력을 만드는 그런 형태로 학습이 진행이 되기 때문에 따로 그 중간에 바틀랙 부분이 디자인되지 않았습니다. 그래서 샘플링하기가 어려운 거죠. 네 이런 단점들을 보완하고자 이제 베리에이셔널 오토앤 코더가 제한이 됩니다. 베리에이셔널 오토앤 코더는 이제 오토앤 코더하고 다르게 오토앤 코드는 픽스 벡터를 이렇게 매핑하는 형태로 학습이 진행되게 되고 이 픽스 벡터에 대해서 어떤 디자인도 지금 적용되어 있지 않은데요. 이 베레이션 오토앤 코더 같은 경우는 이 중간에 있는 이 바틀랙이 디스트비션이 되도록 학습을 진행을 합니다. 그래서 디스트비션을 갖는 어떤 특정한 리벡터를 우리가 구할 수 있는 그런 형태의 모델링을 취합니다. 베리에이션 오토앤 코더의 디자인에는 기본적인 언더라인 어섬션이 있는데요. 그 과정이 뭐냐 하면 각각의 트레인 데이터는 그 트레인 데이터에 각각의 대응하는 실제로 관찰되지 않지만 어떤 레이턴트 리플랜테이션 지라는 거에 의해서 이런 것들이 생성이 된다라는 가정을 깔고 있습니다. 그거를 그림으로 표현한 게 이 밑에 있는 다이어그램인데요. 여기서 x가 이미지고 그 x에 연관된 어떤 지라는 그런 레이턴트 팩터가 사용이 돼서 이 x를 결국에는 생성을 하는 데 사용이 된 거죠. 그래서 이 두 개의 관계를 이제 PXG g라고 해서 표현을 하게 되고요. 그다음에 이 지는 또 레이턴트의 그 나름의 어떤 프라이어 디스트리뷰션이 존재를 해서 이 프라이어 디스트리션에서부터 샘플링 되고 어 이런 근본적인 어떤 레이턴트가 이 엑스를 샘플링하는 데 사용이 되는 그런 형태로 모델링이 되어 있습니다. 여기서 이제 피세타의 경우에는 우리가 어 파라멘트릭하게 모델링한 어떤 그런 덴시티를 얘기를 하게 되는데요. 그 파라멘트릭한 덴시티를 퍼블리티 텀으로 조금 더 이렇게 생각을 해보면은 이런 식으로 표현되는 것과 같습니다. 그래서 이렇게 이해를 하면 될 것 같고요. 그래서 결국에는 어떤 조건부 확률인데 거기서 지라는 어떤 코드가 레이턴트 코드가 들어왔을 때 그 분포가 이렇게 간단한 가우시안 분포일 수도 있고 우리가 가우시안 분포를 사용해도 됩니다. 근데 실제로 이 지하고 x는 굉장히 콤플렉스 한 관계를 갖기 때문에 이 두 개가 연결이 되기 위해서는 그냥 임의의 어떤 형태의 가우시안 분포가 되면 되는 게 아니라 이 스하고 지하고 좀 연결이 있는 그런 연관성이 있는 그런 형태의 매핑에 의해서 어떤 또 다른 이제 지지가 이렇게 있고 그거에 의해서 스가 생성되는 그런 구조일 수 있겠죠. 그게 이제 합리적이겠죠. 그래서 우리가 정말 이제 제대로 된 트루 프라이어 디스트레이션을 알고 있다고 하면 여기서 z를 샘플링하고 이 지에 대해서부터 이제 x를 연결시켜서 이렇게 샘플링하는 그런 구조가 정확하게 잘 들어맞을 겁니다. 그래서 우리가 이러한 피 세타 스타라는 이 세타스타를 우리가 구할 수가 있으면 참 좋을 것 같은데요. 근데 이제 이거를 우리가 학습하는 방식을 이제 오토리그레시브 모델에서 본 것처럼 이런 식으로 라이클리드 트레인 데이터에 대한 라이클리오드를 맥시마이즈 하는 형태로 포뮬레이션을 할 수가 있습니다. 여기에 이제 프로블리티 텀을 우리가 표현하는 어떤 방식을 여러 가지 선택을 할 수 있는데 이런 디펜던시 관계를 우리가 가정을 하고 이런 베레이션 오토 인코더를 모델링을 시작하고 있었으니까 이거에 맞는 형태로 이 디스트리션을 표현하면은 이런 마지널라이제이션을 하는 그런 포뮬레이션이 나오게 됩니다. 그때 이런 레이턴스 지가 뭔지 모르기 때문에 그 모든 지를 다 고려를 했을 때 걔네들을 마지 라이즈 하면은 최종적으로 어 이 트레인 데이터 하나에 대한 어 라이클 루드를 우리가 도출할 수가 있게 되는 거죠. 그래서 우리가 이 라이클루드를 맥시마이즈 할 수 있으면 참 좋은데 이 인테그렐 때문에 실제로 이 모든 지를 고려를 해서 인테그레이션을 하는 것이 불가능합니다. 이게 계산이 안 돼요. 그래서 이거를 이제 맥시마이즈 하는 방식으로 구현할 수가 없습니다. 이게 참 안타까운데요. 그래서 이 모델을 가지고서는 이 세타 스타만 찾으면 참 될 텐데 이거를 구현하기 위한 오브젝티브 펑션을 유도를 할 수가 없습니다. 이 구조로는 여기서 한 가지 함정에 빠지지 말아야 되는 부분이 있는데요. 여기 인테그랄이 여기에 레이턴트 지에 대해서 모든 레이턴트에 대해서 전부 다 다 고려를 해서 마지얼라이제이션을 계산을 하게 되는데요. 그걸 통해서 라이클루드를 이렇게 계산을 하죠. 그때 어 이 모든 지를 다 알아야지만 된다라는 얘기가 아니라 이게 다 필요하다 다 중요하다라는 얘기가 아니라 실제로는 사실은 아까 설명했던 것처럼 이 엑스를 도출하는 그런 지가 따로 존재를 할 수가 있겠죠. 그렇죠 이렇게 1 대 1로 존재를 할 수도 있을 겁니다. 그거를 근데 우리가 정확하게 알 수 있는 방법이 없죠. 그래서 정확하게 모르기 때문에 이 지에 대한 분포로 표현을 하려고 하는 거고 그 분포를 표현을 하다 보니까 여기에서 이제 인테그럴이 들어가서 이 마지널라이제이션으로 라이클루드를 표현을 하게 된 겁니다. 그래서 실제로도 어떤 g가 딱 하나만 딱 존재를 하고 그거에 대해서만 실제로 그럴듯한 지이고 그게 x하고만 연결이 돼 있고 그러면은 이게 나머지 영역에 대해서는 전부 다 0이고 그 해당하는 스에 딱 코리스펀딩하는 대응하는 그 지만 1이 돼서 그냥 바로 이 값이 계산될 수가 있습니다. 근데 이렇게 하나로 이제 특정하기가 굉장히 어렵기 때문에 그래서 이제 분포로 표현을 한 거가 되는 거고요. 그래서 결국에는 이 디펜던시 그래프가 의미하는 바는 어 이 분포도 결국에는 이 x하고 z 사이의 연관성이 있으면 좋다라는 겁니다. 그래서 이제 수식적인 것만 보거나 이제 그림에 단순한 앱스트렉션만 보기보다는 맥락 자체를 좀 이해를 하고 보는 게 좋은데요. 근데 이제 문제는 이런 지하고 x 사이의 관계를 요 하나의 텀으로는 볼 수가 없기 때문에 이 스에서부터 지를 우리가 다시 추정할 수 있는 그런 형태가 되면은 참 좋겠죠. 근데 이게 이제 포스테리어가 되는데 그 포스테리어는 스가 주어졌을 때 그거에 대한 지를 우리가 추정을 할 수 있는 그런 분포예요. 근데 이 포스테리어 덴시티도 여기를 보면은 밑에 분모에 어 피스라는 데이터에 대한 라이클루드가 이렇게 들어가게 됩니다. 즉 이것 자체도 사실은 계산할 수 없는 그런 인트랙터블한 덴시티가 됩니다. 직접적으로 이걸 구할 수가 없는 게 또 요 피스 때문이고 이 피스는 또 마지널라이제이션이 안 돼서 계산할 수 없고 그래서 이렇게 꼬리를 꼬리를 물면서 굉장히 어려운 문제가 되는 거죠. 그래서 이걸 해결할 수 있는 방법이 이 g를 x에 해당하는 지를 잘 우리가 구하기 위해서 이런 식으로 포스테리어를 어프록시메이션을 하는 모델을 하나를 둬서 그 연결 관계를 끊어버리는 거죠. 그래서 ite트러블 한 부분을 다 끊어버려서 지가 주어졌을 때 x로 가는 그런 부분을 이제 디코더 네트워크로 모델링을 하고 반대로 스에서 이제 지를 추정해서 가장 그럴듯한 지들을 이제 구하는 부분을 이렇게 엔코더 네트워크로 어프록시메이션을 통해서 이제 모델링하는 식으로 엔코더 구조가 만들어지게 됩니다. 그래서 이제 x에서부터 로 z에서부터 x로 이런 식으로 관계를 만들어 나가는 거죠. 그렇게 했을 때 결국에 이거를 학습하는 그 방법은 스지가 주어진 그런 x에 대해서는 라이클루드를 맥시마이제이션을 할 수 있도록 하고 그다음에 이 큐에 대한 그거는 이 씨가 간단한 어떤 디스트션을 따르고 있을 때 그 디스트리션에 잘 따라가도록 이거를 프록시메이션을 해서 모델링을 하게 됩니다. 그래서 스가 지로 갔다가 시에서부터 다시 x로 갈 수 있는 그런 형태에서 이제 g에 대한 분포를 이제 q로서 중간에 대체를 해서 학습을 할 수 있게끔 유도를 한 거죠. 네 방금 전에 디펜던시 그래프를 이제 뉴얼 네트워크의 아키텍처로 표현을 해보면은 이렇게 인풋이 주어졌을 때 그때 먼저 엔코더를 통과를 해서 이제 뷰하고 시그마라는 어떤 프로벌리티 디스트션의 파라미터를 출력을 해 주게끔 만듭니다. 그다음에 이렇게 출력이 된 거가 이제 분포의 파라미터이기 때문에 거기서 하나의 레이턴트 벡터를 샘플링을 하고 그 샘플링 된 레이턴트 벡터를 디코더에다가 넣어줘서 최종적인 리컨스럭션을 하는 그런 구조로 구현이 되어 있습니다. 그리고 결국에는 이렇게 리컨스석션이 됐을 때 동일해야 된다라는 텀을 이제 러소 펑션으로 사용을 해서 최종적으로 학습을 진행을 하게 되는데요. 그때 여기 엔코더하고 디코더가 전부 다 뉴럴 네트워크라서 미분 가능한데 문제는 여기서 뮤하고 시그마가 간단한 가우시안 분포의 파라미터로 모델링이 됐다고 하더라도 가우시안 펑션이 이렇게 디퍼런셔블하게 만들기가 좀 쉽지가 않습니다. 그래서 여기서 리퍼런트레이션 트릭이라는 굉장히 간단하면서 이펙티브한 테크닉이 사용이 되게 되는데요. 그때 이제 이 입실론을 진짜 순수한 어떤 파라메트릭 하지 않은 가우시안 형태로 우리가 가우시안 노이즈로 이렇게 따로 빼고 그다음에 거기다가 이 시그마 파라미터를 곱하고 그다음에 이제 뮤를 오프셋처럼 더해주는 형태로 하면은 이 지를 바로 샘플링 할 수가 있다라는 이 수식을 이용을 해서 이제 노멀 디스트립션의 펑션을 바로 사용하지 않고 가오샹 펑션을 바로 사용하지 않고 이런 식으로 대체를 해서 리퍼라멘터라이제이션을 합니다. 그렇게 되면은 이제 이거는 그냥 선형성이 있기 때문에 미분 가능하죠. 그래서 백퍼파게이션에서 전체적으로 엔코더하고 디코더를 학습할 수 있도록 유도를 하게 됩니다. 이게 이제 베리에이션 오토 엔코더인데요. 이 베리에이션 오토 엔코더가 굉장히 스테이블하게 학습이 잘 됩니다. 근데 문제는 출력되는 그 결과가 굉장히 블러리하고 아직까지 모델링 캐패시티가 충분히 좋지가 않아요. 지금 굉장히 수식을 다 스킵하고서는 표현하기는 했지만 결국에는 이 오토 인코더라는 구조가 나오는 그 중간의 유도는 이제 베리에이셔널 로어바운드라는 어떤 직접적인 데이터 라이클리우드를 맥시마이즈 하지 못하니까 대신에 로어바운드를 유도를 해서 그 로어바운드를 맥시마이즈 하는 형태로 데이터 라이클리오드를 간접적으로 맥시마이즈 하는 그런 구조를 유도하다 보니까 이런 오토 앤코더 구조가 나온 겁니다. 근데 이거를 이제 이거하고 연관이 굉장히 깊은 모델인데 굉장히 성공적인 모델이 이제 디퓨전 모델이 있습니다. 이 디퓨전 모델은 요 베레이션 오토 앤 코드하고 굉장히 유사한 구조고 이제 유도도 굉장히 비슷한 형태로 이 유도가 되게 되는데요. 그때 여기서 레이턴스 지가 어떻게 얻어지냐면 어떤 데이터 스가 스지가 주어졌을 때 x 제로가 주어졌을 때 이 스 제로에서부터 점점 노이즈를 조금 조금씩 입혀서 최종적으로 가우시 디스트리션에 존재하는 그런 레이턴트 코드로 매핑을 하는 형태로 이루어지고 그다음에 이 뒤에서부터 다시 원래 이미지로 복귀할 때는 이 가우샷 노이즈를 디노이징 하는 형태로 이런 식으로 백으로 가는 형태로 구현되는 게 이제 리퓨전 모델입니다. 그래서 이 베레이션 오토 앤코더하고 조금 대응을 해보면은 여기서 이제 원래 이미지에서부터 레이턴트로 매핑되는 그 엔코더 부분이 뉴얼 네트워크가 아니라 단순히 가우시안 노이즈를 더해주는 형태로 심플리 파이 됐다라고 볼 수가 있을 것 같고요. 그다음에 반대로 디코더는 단계적으로 디노이징 하는 형태로 플로블리스팅 모델이 구현되어 있다라고 이해할 수가 있을 것 같습니다. 네 이제 본격적으로 이제 디노이징 디퓨전 프로블리스팅 모델에 대해서 좀 살펴보려고 하는데요. DDPM이라고 부르는 이 dfi 모델은 디노이징 하는 형태로 이미지를 생성하는 그런 생성 모델입니다. 먼저 시작하기 전에 좀 주의해야 되는 포인트 중의 하나는 베리에이션 오토앤 코드에서 이제 피를 원래 분포로 표기를 하고 그다음에 q를 조금 더 어프록시메이션 하는 그런 분포로 표현을 했었는데요. 여기서는 이제 표기가 좀 반대로 되어 있습니다. 그래서 이제 q가 원래 분포 그다음에 피 세터가 이제 어프록시메이션 하는 모델 분포로 이해를 하면 좋을 것 같습니다. 어 이렇게 한 이유는 이제 원래 논문을 좀 따라가기 위해서는 원래 노테이션을 사용하는 게 좋을 것 같아서 이렇게 반대임에도 불구하고 이렇게 사용을 하게 되었고요. 그래서 이 점을 잘 염두를 하고 한번 진행해 보도록 하겠습니다. 그래서 여기서는 이제 이 xt하고 x 제로가 있는데요. 이 x 제로는 우리가 샘플링한 이미지 또는 트레인 데이터의 이미지라고 생각하면 될 것 같습니다. 네 반대로 이제 스 티는 이제 제로민의 유닛 베리언스의 완전한 가우샷 노이즈 형태를 갖는 그런 레이턴트 코드를 의미를 합니다. 여기서 흥미로운 점은 이 레이턴트 코드가 원래 이미지의 디멘전하고 똑같은 사이즈라는 건데요. 그래서 이 이미지에서부터 노이즈를 점점 점점 더해서 이렇게 프로세스를 타서 최종적으로 xt 완전한 가우셔 노이즈처럼 되는 그 과정을 이제 포워드 프로세스라고 부릅니다. 이 포워드 프로세스는 방금 전에 본 것처럼 각 프로세스 이 q를 탈 때마다 가우시안이 점점 점점 가우시안 분포의 노이즈가 점점 점점 더해지는 구조로 이렇게 이루어져 있습니다. 여기서 베타는 미리 정의해 놓은 어떤 베리언스 스케줄에 의해서 컨트롤 되는 그런 파라미터입니다. 그래서 이거 하이퍼 파라미터라고 생각하면 될 것 같고요. 그럼 이제 포워드 프로세스가 있으면 당연히 리버스 프로세스도 있을 텐데요. 리버스 프로세스는 반대로 이제 가우션 노이즈에서부터 엑스제로까지 즉 샘플링 프로세스에 해당합니다. 이렇게 데이터를 샘플링하는 그런 형태가 되는데요. 근데 여기서 문제는 여기서 스티에서 티 마이너스 1까지 가는 게 어떻게 보면은 어 굉장히 노이즈 한 데서 이제 점점점점 디노이징을 해가는 그런 형태가 되게 됩니다. 그래서 이 디노이징을 하는 형태가 결국에는 어 어떤 큐라는 진짜 트루 분포가 있으면 참 좋았을 텐데 그 트루라는 그런 분포를 우리가 쉽게 에스티메이션하는 것은 거의 불가능하겠죠. 이게 뭐 가우시안이라고 가정하기도 굉장히 어렵고요. 그래서 요 큐라는 것을 우리가 직접 사용하는 것 대신에 요 피세타라는 모델을 도입을 해서 어프로치메이션을 해서 컨디셔널 프로벌리티를 만들게 됩니다. 그래서 한 스텝 한 스텝마다 이 p 세타가 결국에는 디노이징을 해서 이렇게 이미지를 점점점점 생성할 수 있게 도와주는 그런 역할을 하는 모델을 도입을 했다라고 볼 수가 있을 것 같아요. 그래서 이 p 세타는 우리가 단순하게 모델링을 하기 위해서 가우시안 형태로 모델링을 하고요. 그다음에 여기에 가우시안에 평균과 베리언스에 대해서 이제 베리언스는 좀 러너블 파라미터가 없는 형태의 굉장히 간단한 이런 형태로 스케일링을 이렇게 두게 되고요. 스케일링 오퍼레이션을 두고 그다음에 요 뮤에 대해서 기대하는 어떤 디노이징 된 그 결과 값에 대해서 m 세터라고 해서 이 출력을 이제 우리가 학습을 해서 디노이징을 유도를 하게 됩니다. 당연하게 이제 디노이징을 유도를 하기 위해서는 어떤 타겟 디노이즈 된 어떤 이미지가 있고 그다음에 그거에 해당하는 출력을 디노이징된 출력을 내도록 이런 식으로 러스 펑션을 만들어서 우리가 학습을 진행할 수가 있습니다. 사실은 여기까지 오기 위해서 사실 베리에이션은 오토앤 코드하고 비슷하게 이제 베리에이션은 로어바운드에서부터 라이클루드 맥시마이제이션을 직접 하지 못하니까 그거에 대한 로어 바운드를 만들고 그 로어바운드를 맥시마이즈 하는 형태로 트랙터블 러스 펑션을 유도하다 보니까 이런 형태로 나온 건데 여기서는 디테일한 것은 전부 다 스킵 하도록 하겠습니다. 이렇게 로스를 유도해 보니까 결국에는 디노이즈 된 그런 형태의 중간 t 스텝에서의 노이즈 이미지를 이렇게 출력하도록 학습을 진행하게 됩니다. 근데 여기서 이 디노이징 하는 이 출력을 만드는 부분을 자세하게 좀 살펴보면 현재 주어진 어떤 스텝에서 노이즈만큼을 빼는 형태로 즉 노이징을 우리가 예측을 해서 그 노이징 된 부분을 빼는 형태로 디노이징이 구현될 수가 있겠죠. 근데 이게 이제 리파라미터이션 트릭하고 굉장히 비슷합니다. 그래서 이제 이전 스텝에서 있었던 그 값에 대해 그래서 이제 노이즈만 추정을 해서 그 노이즈를 빼는 형태로 디노이징을 구할 수가 있다 에디티브 디노이징을 해서 구할 수가 있다라는 형태로 리퍼멘트레이션을 할 수가 있는데요. 이런 식으로 해서 여기에다가 끼워놓으면은 결국에는 이 러스 펑션이 어떻게 되냐면 현재 우리가 포워드 프로세스에서 주었던 그 노이징 오퍼레이션을 그냥 바로 따라 하도록 그냥 학습하는 형태로 러스가 심플리 파이 됩니다. 그래서 결국에는 이 뉴얼렛이 입실론 세타라는 그 뉴얼렛이 뭘 하냐면은 현재 스텝의 노이즈를 예측해서 이제 빼주는 형태로 사용되도록 노이즈 예측 모델이 되게 됩니다. 근데 물론 이렇게 각 스텝마다 노이즈를 예측하는 모델을 우리가 구현을 해서 사용을 했을 때 어 여러 가지 좀 한계가 있습니다. 이게 아무래도 아까 설명했던 대로 그 노이즈 레이턴트 스페이스가 픽셀 스페이스하고 대응하다 보니까 굉장히 큰 스페이스입니다. 굉장히 고차원의 스페이스고 그렇기 때문에 이거를 학습하는 데 있어서 GPU가 굉장히 많이 필요하고요. 이제 학습도 오래 걸립니다. 그리고 이제 인퍼런스 할 때 이제 티스텝만큼 계속 t에서부터 0까지 가도록 스텝을 이렇게 계속 밟아야 되기 때문에 이런 시퀀셜 이밸류에이션으로 인해서 한 장을 샘플링하는 데 시간이 굉장히 오래 걸리는 그런 단점들이 존재를 하게 되는 거죠. 그래서 이걸 개선하기 위해서 그다음에 이제 레이턴트 디퓨전 모델이라는 개념이 등장을 하게 됩니다. 이 레이턴트 디퓨전 모델은 다른 용어로 이제 스테이블 디퓨전으로 훨씬 더 유명한 그런 모델입니다. 레이턴트 디퓨전 다른 말로 이제 스테이블 디퓨전은 이런 식으로 모델링 되어 있습니다. 어떻게 돼 있냐면 먼저 이제 레이턴트 스페이스를 정의할 수 있게끔 엔코더 디코더를 사용을 합니다. 그래서 이런 오토 엔코더를 가지고 레이턴트 스페이스로 매핑하는 모듈을 사용을 해서 이 이미지를 먼저 이렇게 작은 레이턴트 스페이스로 매핑을 합니다. 그래서 보면은 이제 이미지 대비해서 이 레이턴트 스페이스는 굉장히 작다라고 볼 수가 있죠. 채널도 많이 늘어나지 않았고 이렇게 조금 작은 그런 레이턴트 스페이스에서 어 디퓨전을 우리가 학습을 해서 사용을 하는 형태로 굉장히 경량화 됐지만 굉장히 퀄리티가 좋은 그런 형태의 생성 모델을 도출할 수가 있게 됩니다. 그래서 그 구조를 조금 더 자세하게 살펴보면요. 어이 레이턴트 디션 모델은 먼저 엔코더하고 디코더가 이렇게 존재를 하고 이제 엔코더를 통과를 시켜서 이제 레이턴트 스페이스의 지를 이렇게 만들게 됩니다. 근데 당연하게도 이제 포워드 프로세스를 밟으면 이거는 거의 가우시안 노이즈에 가까운 그런 형태가 되겠죠. 그래서 이렇게 가우시안 노이즈 형태까지 가는 게 이제 포워드 프로세스고 이제 리버스 프로세스 같은 경우는 이런 가우시안 분포에서부터 점점 디노이징을 해서 이 레이턴트를 디노이징 합니다. 그렇게 디노이징 된 레이턴트를 이제 디코더에다가 넣어서 이미지를 샘플링해서 복원을 하는 형태가 되는 거죠. 그때 이 부분은 이제 엔코더하고 디코더 즉 픽셀 스페이스하고 레이턴트 스페이스를 연결해 주는 이 부분은 미리 프리트레인드를 해놓고 픽스를 해 놓습니다. 그다음에 최종적으로 학습하는 부분은 이 디노이징을 하는 유닛 구조인데요. 유닛 구조는 여기서 각 스텝마다 이렇게 한 스텝마다 디노이징을 하는 그런 노이즈를 프리딕션 하는 그런 모델로 학습이 되게 됩니다. 그리고 여기서 이제 추가적으로 또 중요한 부분은 여기 컨디셔닝이라고 해서 시멘틱 맵 텍스트 또는 이미지와 같은 이런 어떤 컨디션 정보들을 컨디션 엔코더를 통과시켜서 여기다가 인풋 쪽 그다음에 중간에 여기 크로스 어텐션 부분에다가 옆구리에다가 이렇게 찔러주는 형태로 모델이 구성이 되게 됩니다. 그래서 여기서 또 강조되는 포인트는 뭐냐면은 여러 컨트롤 컨디션에 대해서 이제 크로스 어텐션을 통해서 우리가 컨디션을 입력을 해 주는 그런 방식을 제안을 했고요. 그걸 통해서 이제 컨디셔널 생성을 할 수 있는 그런 모델로 잘 공원을 한 게 어떤 굉장히 중요한 포인트 중의 하나입니다. 그래서 이렇게 함으로써 이제 응용이 굉장히 풍부해지게 되는 거죠. 학습은 이제 기존 디퓨전 모델은 이제 픽셀 노이즈 에스티메이션 형태의 러스로 이제 학습을 진행을 하게 되는데요. 여기 레이턴트 디퓨전에서는 보시면은 이제 결국에는 이 노이즈가 레이턴트 레벨의 레이턴트가 인풋 그다음에 레이턴트 노이즈가 아웃풋인 형태의 레이턴트 리프랜테이션의 노이즈 프리딕션으로 이제 문제가 바뀌게 됩니다. 네 그래서 중요한 거는 여기서 g 하고 여기 x의 차이만큼 즉 여기서는 픽셀 스페이스 여기는 레이턴트 스페이스에서 이 생성 모델이 학습이 된다라는 사실이 중요하고요. 여기서 보면 여기 타임 컨디션이 이렇게 들어갑니다. 그래서 이제 원래 디노이징 디퓨전에서도 이렇게 타임 컨디션이 중간에 드러나게 되는데 이거의 구조가 이제 타임 컨디셔널 유닛 구조를 사용하게 됩니다. 이게 이제 요 피규에도 사실은 표기가 안 되어 있는데요. 어 이 부분은 좀 주의를 해야 됩니다. 타임 컨디션이 계속 들어가서 매 스텝마다 서로 다른 형태의 동작을 하도록 이 디노이징 유닛이 학습이 되게 되는데요. 이 부분에 대해서는 뒤쪽에서 다시 설명하도록 하겠습니다. 그리고 추가적으로 이제 중간에 이제 컨디셔널 인풋이 이렇게 들어오게 되면은 이 컨디셔널 인풋을 고려를 해서 아웃풋을 출력할 수 있는 그런 크로스 어텐션 메커니즘이 여기에 도입이 되어 있고요. 그래서 이 크로스 어텐션 메커니즘을 통해서 컨디셔널한 제너레이션을 할 수 있도록 여기에 입력으로 이렇게 하나를 더 넣어줘서 학습하는 그런 방법도 도입을 하고 있습니다. 그래서 이렇게 크로스 어텐션을 통해서 이제 컨디셔닝 인풋을 옆구리에 찔러 넣는 것이 어떻게 보면 굉장히 이 구조의 유용성을 높였다라고 볼 수가 있겠습니다. 네 이 결과는 텍스트 엔 코더로 텍스트 컨디션을 주고 생성한 그런 텍스트도 이미지 애플리케이션인데요. 어 이게 사실 스테이블 디퓨션에서 제일 유명하고 또 이제 코드도 잘 공개가 되어 있죠 그래서 이제 이 코드에 공개된 사실이 이제 스테이블 디퓨전의 중요성을 굉장히 부각하는 그 중요한 요소인데요. 이것으로 인해서 생성 모델의 실용화와 발전에 굉장히 큰 역할을 했다라고도 볼 수가 있겠습니다. 예 정말 라지 스케일로 잘 학습된 그런 스테이블 디퓨전이 어 이런 텍스트 저런 텍스트를 다 넣어줘도 굉장히 잘 작동을 하고 엄청 좋은 퀄리티들을 많이 보여줬습니다. 그래서 이렇게 잘 학습된 스테이블 디퓨전 모델을 이용을 해서 본인 입맛대로 수정해서 사용하기 위한 노력들이 시작이 되게 되는데요. 어떻게 보면 이 스테이블 디퓨전을 좀 파운데이션 모델 레벨로 생각을 해서 이거를 각자의 테스크에 맞게 파인 튜닝해서 사용하는 그런 전략들이 많이 활용이 되는 거죠. 그중에서 좀 성공적인 사례가 이제 컨트롤렛입니다. 컨트롤렛은 이제 사용자 편의를 위한 이미지 형태의 컨트롤 컨디션의 모달리티를 빠르게 적용할 수 있도록 모델을 간단하게 바꿔서 그리고 잘 작동하게끔 하는 건데요. 이제 컨트롤넷의 어떤 인풋으로는 캐니엣지라든지 여기서 보는 것처럼 휴먼 포즈와 같은 이런 이미지 형태의 컨디션을 주면은 그거에 맞춰서 결과들이 이런 식으로 잘 따른 결과들이 나오는 것을 볼 수가 있습니다. 그리고 퀄리티도 나쁘지 않죠. 그래서 스테이블 디퓨전의 원래의 퍼포먼스와 그 생성 능력을 그대로 계승을 하면서도 조건부 입력에 굉장히 잘 따라서 우리가 사람이 어 에디팅이라든지 컨트롤을 잘하는 형태로 생성할 수 있는 게 핵심 포인트입니다. 이 아키텍처적인 특성은 이제 뉴얼 네트워크 블록이 이렇게 있을 때 여기에 인포피처가 들어오고 이거를 이제 출력이라고 하면요. 이게 일반적인 어떤 뉴럴 네트워크의 블록일 겁니다. 내 컨트롤넷에서 제안한 거는 뭐냐면 이런 식으로 컨디션이 들어왔을 때 제로 콤블루션 레이어를 통과를 해서 0이 나오게끔 만들고 그다음에 인풋을 여기다 더해줘서 여기 트레이너블한 카피라고 써 있는 이 블록으로 넘겨줍니다. 그다음에 이제 제로 컨볼루션을 통과를 해서 다시 출력에다가 더해주는 그런 구조인데요. 여기서 중요한 포인트는 일단은 이 뉴얼 네트워크 블록 원래의 패스에 대한 블록을 학습된 것을 이 프리즈를 시켜 놓습니다. 그다음에 이제 이 네트워크의 그 파라미터를 카피를 해서 여기다 복사를 해 놓습니다. 그 이유는 이 컨디셔널한 요 인풋도 이미지의 형태이기 때문에 이 이미지 형태의 어떤 그 구조에 대한 이해를 이 원래의 네트워크의 지식을 이용을 해서 빠르게 어댑테이션 하기 위해서 이렇게 카피를 해서 사용을 하는 거라고 이해를 하면 될 것 같습니다. 그러고 나서 이제 우리가 이렇게 컨디셔닝 된 그 벡터를 입력으로 이렇게 넣어줘서 트레이너블 카피에다가 넣어주게 되는데요. 근데 여기에 제로 컨볼루션이 결국엔 0밖에 출력을 안 하는데 이게 무슨 의미일까라고 생각을 해볼 수 있는데 이게 학습을 할 때 이 부분하고 이 부분이 전부 다 다 학습이 됩니다. 이 부분만 빼고 그러면 처음에 제로 콤볼루션이 들어가면은 기존 모델의 행동에 대해서는 그냥 그대로 진행이 되고 이 컨트롤렛이 마치 없는 것처럼 작동하겠죠 그래서 초기에는 이렇게 확 망가지지 않고 학습이 되면서 점차적으로 이 컨디션이 스며드는 그런 구조를 유도를 한 거라고 이해를 할 수가 있을 것 같습니다. 네 그래서 이게 전체적인 구조인데요. 이제 컨디션이 들어오면은 처음에 제로 컨디션으로 이렇게 넘겨줘서 어 이 전체적인 그런 출력이 크게 망가지지 않도록 이렇게 유도를 해줍니다. 왜냐하면 이게 처음에 카피를 했을 때 이 인풋에 대해서 호환성 있게끔 작동을 하겠죠. 그리고 이 컨디션에 대해서는 호환성이 없는 형태로 처음에 초기화가 돼 있을 겁니다. 그래서 이제 학습을 진행하면서 점점 빠르게 어댑테이션을 하면서도 이제 자연스럽게 서로 피해를 입히지 않도록 최대한 이쪽에 대미지를 주지 않도록 그렇게 학습을 진행을 하게 되는 거고요. 그다음에 여기서의 컨디션의 최종적인 인풋은 이 바깥에 출력으로 따로 나오는 게 아니라 이 디코더 부분에 옆구리에 이렇게 찔러 들어가면서 디코더에 삽입이 들어가게 됩니다. 네 여기서 이제 좀 특징적으로 여기 타이밍 코더 부분이 이렇게 있는데요. 이게 아까 설명을 다 스킵을 해가지고 여기서 이제 설명을 하려고 합니다. 어 이 유닛 구조가 이제 타임 컨디셔널 유닛 구조인데요. 이때 이제 시간 정보 현재 스텝 정보를 이렇게 인풋으로 넣어줘야 되는데 이 시간 정보는 사실 뭐 소수점으로 된 그런 스케일러 값입니다. 그래서 디멘전이 하나짜리예요. 그런데 이 하나짜리 디맨션을 이렇게 하이 디맨전을 인풋 이미지라든지 이런 데다 껴 넣거나 아니면 중간에 뭐 그냥 하나의 원디맨전 값으로 이렇게 껴놓으면은 이제 매트릭스 멀티플리케이션이나 컨볼루션이 일어날 때에 거의 무시되게 됩니다. 그리고 결국에는 이 타임도 굉장히 시간 차이가 작죠. 값 차이가 변화가 작기 때문에 엔코딩을 정말 잘해줘서 넣어줘야 됩니다. 그래서 보통 이제 이런 타임 컨디셔널한 유닛이라든지 디퓨전에 나오는 이런 타임 컨디셔널한 구조가 언급이 되면은 별다른 내용이 안 쓰여 있고 없어도 기본적으로 이제 트랜스포머의 어떤 포지션 엔코딩처럼 사인 코사인 함수로 엔코딩 된 그런 포지션 인베이딩이 또는 타임 인베이딩이 이렇게 중간에 컨디션으로 사용되었다라고 이해해도 크게 틀리지 않습니다. 그래서 그런 식으로 좀 이해를 하면 좋을 것 같고요. 네 그렇게 학습된 이제 컨트롤넷을 가지고서는 여러 가지 멀티 컨디션 인풋도 넣는 형태로도 응용을 할 수가 있습니다. 그래서 사용자가 이런 이미지를 생성할 때 본인의 입맛에 맞는 결과를 생성할 수 있도록 유도를 할 수가 있는 거죠. 네 그리고 추가적으로 이제 스테이블 리퓨전이 보통 텍스트 이미지에 굉장히 잘 학습이 된 그런 모델로서 많이 활용이 되는데요. 그때 텍스트가 주어졌을 때 그거에 맞는 이미지들을 생성을 했었죠. 근데 만약에 우리가 이렇게 스케치나 어떤 서피스 노멀이라든지 데스와 같은 어 굉장히 잘 컨디션 된 컨디션 컨트롤 시그널들을 줄 경우에는 텍스트가 오히려 방해가 될 수도 있어요. 그래서 이제 텍스트 프로포트를 주지 않고도 이 정도의 컨시스턴트한 그런 생성 결과들을 만들 수도 있다라는 것을 보여주고 있습니다. 네 좀 다른 컨텍스트지만 이 컨트롤넷의 구조하고 좀 유사한 구조라서 로라도 같이 설명을 하려고 가져왔는데요. 이 로라 같은 경우는 로랭크 어댑테이션이라고 해서 기존에 프리트레인 된 웨이트가 있을 때 이제 추가적인 학습을 할 때 사용하는 모듈입니다. 어 이 로라 모듈의 기본적인 어떤 모티베이션은 뭐였냐면 우리가 만약에 오버 파라미터라이즈 된 그런 딥 뉴럴 네트워크를 학습을 할 때 실제로 학습된 리프엔테이션이 생각보다 굉장히 로우디맨저널한 그런 공간 속에 서 스팸을 하고 작동을 한다라는 그런 옵토베이션들이 있었는데요. 근데 이제 이걸 모티베이션을 삼아서 여기서 가정을 한 건 뭐냐면은 어 이것과 마찬가지로 모델이 어댑테이션이 일어날 때 그때 웨이트의 변화도 전부 다 굉장히 로우 디멘저널한 그런 공간에서 일어날 거다라는 가정입니다. 그래서 이제 이런 어댑테이션을 하는 모듈을 어 로우 디멘전으로 매핑하는 구조의 이런 디컴포지션 된 그런 매트릭스 팩토라이제이션 구조로 이렇게 설계를 해서 이거를 이제 학습을 해서 어댑테이션을 하는 파인트이닝을 하는 그런 모듈로 사용을 합니다. 그래서 이 웨이트를 직접 건드려서 파인 튜링 하는 게 아니라 여기에 추가적인 패스를 둬서 이제 추가적인 부분만 더하는 식으로 학습이 되는 그런 모듈이 되게 되고요. 여기서 또 특징은 이 출력 디코더 부분을 제로로 이니셜라이제이션을 해서 초기에는 이 출력이 굉장히 크게 들어가지 않아서 이 다음 부분을 망치지 않게끔 만들고 어 서서히 스며들 수 있게끔 그렇게 유도를 한 구조는 동일하고요. 그다음에 요 중간에 어 로우 디멘전으로 매핑을 한 다음에 다시 하이 디맨전으로 디코딩을 하는 이 부분에 대해서 중간에 론리니어 액티베이션 펑션이 사용되지 않습니다. 그래서 이렇게 리니어한 구조로서 이제 한번 로우디맨저널 인트린직 스페이스로 매핑을 했다가 다시 디코딩을 하는 그런 형태로 구현이 되어 있다라고 이해를 하면 될 것 같습니다. 그래서 이걸 가지고서는 이제 gpt3와 같은 그런 라지랭귀지 모델에 대해서 어 파인 튜닝을 진행한 케이스에 대해서 굉장히 성공적인 어 사례들을 많이 보여줬는데요. 이제 로나는 이제 트레이너블 파라미터도 굉장히 적게 사용을 하면서도 우리가 파인튜닝을 굉장히 이팩티브하게 해서 굉장히 높은 성능을 달성한 것을 볼 수가 있습니다. 네 이런 성공 사례를 이용을 해서 이런 로라를 가지고서는 디퓨전 모델이나 이런 생성 모델에 이제 퍼설라이제이션에 적용을 할 수도 있습니다. 그래서 이렇게 퓨샷 이그젬플들이 주어져 있을 때 어떤 모델을 이제 파인튜닝을 함으로써 이제 퍼서라이제이션 할 때 이런 로라도 사용을 할 수가 있을 거고요. 그다음에 이 오로라의 또 다른 특징으로는 이제 기존에 프리트레인 된 부분을 건드리지 않고 새로 어댑테이션 되는 부분만 학습을 하기 때문에 기본적으로 포게팅 이펙트라든지 그런 것에 굉장히 강인하다고 알려져 있습니다."
}