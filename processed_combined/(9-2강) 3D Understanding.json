{
  "lecture_name": "(9-2강) 3D Understanding",
  "source_file": "(9-2강) 3D Understanding_54.mp4_2025-12-04-10375021.json",
  "text": "네 이제 기본적인 3디의 표현 방법을 알아봤으니까요. 어 이제는 이제 3D 테스크들이 어떤 것들이 있는지 몇 가지 대표적인 예제들을 살펴보도록 하겠습니다. 네 먼저 가장 간단한 테스크로 3 레코리션이 있겠죠 어 이미지 레코리션과 마찬가지로 이렇게 3D 데이터가 주어져 있으면 3D CNN이나 그래프 뉴얼렛 같은 그런 백봉 구조를 활용해서 레코이션을 할 수도 있고요. 또 영상처럼 디텍션을 할 수도 있겠죠 그래서 3D 공간에서 이런 3D 바운딩 박스를 통해서 3디 로컬라이제이션을 수행하는 그런 디텍션 테스크도 정의를 할 수가 있을 겁니다. 그 외에도 다른 다양한 테스크들을 정의를 할 수가 있는데요. 거의 뭐 2디하고 거의 같은 구조를 가지고 있다라고 이해할 수 있을 것 같아요. 그래서 3D 오브젝트 레코이션의 경우에는 이제 3D 입력 데이터를 잘 처리할 수 있는 그런 뉴얼렛 구조를 사용한다는 것 외에는 출력으로 인식된 라벨을 반환한다는 것은 다 동일합니다. 그래서 이미지 레코니션은 결국에는 3D 모델 구조만 좀 다르고 태스크의 데피니션은 거의 동일하다라고 이해하면 될 것 같고요. 2D 하고 마찬가지로 3D 오브젝트 디텍션도 정의를 할 수가 있는데 3D 공간에서 어 3디 데이터를 가지고 3D 오브젝트를 3디 바운딩 박스로 로컬라이제이션을 할 수도 있죠. 좀 말이 복잡했는데 결국에는 3D 공간에서 3디 바운딩 박스로 디텍션을 할 수가 있다는 얘기예요. 근데 여기서 이미지 상에서 여기는 이미지죠 이미지상에서도 우리가 이런 3D 바운딩 박스를 정의해서 그릴 수도 있겠죠 디텍션을 할 수도 있겠죠. 그래서 이렇게 이미지 상에서 이제 3D 오브젝트 디텍션을 하는 경우도 있습니다. 그래서 이런 경우는 이제 무인차 어플리케이션에서 굉장히 유용하게 사용할 수가 있겠죠. 주행 보조 장치라든지 그 다음으로는 이제 우리가 이미지와 비디오 상에서도 시멘틱 세그멘테이션에 대해서 많이 언급을 했었는데요. 그에 대응하는 이제 3디 시멘틱 세그멘테이션이라는 테스크도 있습니다. 그래서 여기서는 이런 3D 메시를 각 기능마다 세그멘테이션을 한다든지 물체의 각 파트별로 세그멘테이션을 하는 그런 테스크도 우리가 정의를 할 수가 있고요. 이제 본격적으로 살펴보려고 하는 내용은 사실 이 3D 리컨석션입니다. 기존의 스트럭처 프로모션과 같이 포인트 클라우드 방식의 3D 복원 테스크를 어 기반으로 한 그런 복원들이 굉장히 많았었는데요. 최근에는 뉴럴 렌더링이라는 신기술의 발달로 새로운 뷰를 합성할 수 있는 그런 모델을 도입을 해서 3디를 복원하는 형태로 이제 새로운 접근법이 제시되고 있습니다. 그래서 이 접근법으로 인해서 이제 3D 복원의 퀄리티가 급격하게 발전하고 있는 그런 큰 도약이 있었던 시점입니다. 그중에서 그 선봉장이었던 널프에 대해서 살펴보도록 하겠습니다. 지금 여기에서 보는 이 결과들이 널프로 3디 컨석션 된 그 결과들입니다. 보면은 이제 인풋 이미지는 몇 개의 멀티플 뷰 이미지들이 주어진 상태에서 이런 식으로 3D 복원이 이루어졌는데 이 3D 복원이 이루어졌을 때에 어 그 어떤 각각의 새로운 각각의 뷰 포인트가 새로운 뷰로 대응하기 때문에 노블 뷰 신시서라고도 부릅니다. 널프는 이제 멀티뷰 이미지와 그리고 그 이미지들 간의 어떤 내러티브한 카메라 포즈들을 입력을 해서 이렇게 이 카메라 포즈들이 주어진 거 말고 새로운 뷰 포인트에서 보더라도 그 이미지를 렌더링해서 출력할 수 있는 그런 레디언스 필드라고 하는 색상을 표현하는 뉴얼 네트워크를 학습하는 방식으로 구성이 됩니다. 말이 좀 복잡했는데요. 다시 한번 차근차근 보면요. 레디언스 필드를 학습하는 이 뉴얼 네트워크는 다음과 같이 구성이 되어 있습니다. 먼저 물체상의 어떤 포인트 xyh 포인트하고 그 포인트를 바라보고 있는 뷰잉 디렉션 방향을 입력으로 주면은 그러면 이렇게 그 포인트에 대한 색깔과 그다음에 그 포인트가 실제로 3D 공간을 얼마큼의 투명도로 차지하고 있는지 그 아웃풋 덴시티를 이렇게 출력하는 구조로 이루어져 있습니다. 근데 또 반대로 생각해서 이제 엄한 빈 공간을 여기서 XYZ로 딱 찍으면 그때 아웃풋 덴시티는 0이 나와서 아 얘는 그냥 빈 공간이다 없는 투명한 그런 컬러로 취급을 해라 라고 출력을 내보내게끔 해주는 그런 모델입니다. 이런 입력과 이제 출력 관계를 학습하는 모델을 어 우리가 뉴얼 네트워크를 사용해서 모델링을 하게 되는데요. 여기서 사용하는 뉴얼 네트워크는 굉장히 간단합니다. 플리커리이티드 뉴얼 네트워크를 쌓아서 이렇게 만드는 그런 구조를 사용을 하고 각 씬마다 오버피팅 되게끔 이렇게 학습을 진행을 하게 됩니다. 네 이 모델의 입력과 출력 구조는 단순해서 이제 크게 부담은 없는데 우리가 가진 데이터는 사실 일부 이미지 샘플들이에요. 이 공간들을 전부 다 댄스하게 가지고 있는 게 아니라 좀 더 스파스한 그런 이미지 세들인데 이 모델의 출력을 보면 색깔이에요. 색깔인데 이 모델의 출력과 이미지의 표현 형태가 호환되지가 않습니다. 왜냐하면 이미지도 RGB 컬러를 가지고 있긴 한데 이 네트워크의 출력은 어떤 색깔이냐면은 요 3 포인트에 대한 색깔이에요. 그래서 이제 2디하고 3디만큼의 갭이 있는 거죠. 그래서 이런 이미지를 가지고서는 이 출력에다가 바로 슈퍼비전을 줄 수가 없습니다. 네 그래서 이 괴리를 좀 브릿징하기 위해서 이제 볼륨 매트릭 렌더링이라는 그런 테크닉을 통해서 이제 2디하고 쓰디 관계를 연결시켜 줘서 바로 이미지로 슈퍼비전을 걸어줄 수 있도록 그렇게 유도를 하게 됩니다. 기본적인 아이디어는 넓프 모델이 3D 공간에서 어떤 3D 포인트든지 쿼링을 할 수가 있기 때문에 이 점을 이용을 해서 그래픽스에서 흔히 사용하는 렌더링 방정식으로 이제 특정 뷰 포인트에서 여기에 특정 뷰 포인트에서 이런 식으로 이미지를 렌더링하도록 계산을 하는 겁니다. 그래서 이 3D를 표현하고 있는 뉴얼 네트워크를 이렇게 렌더링을 잘 해서 이미지 도메인으로 옮겨서 지금 주어진 인풋 이미지하고 비교를 하는 식으로 슈퍼비전을 걸어주게끔 할 수가 있겠죠 이게 기본적인 아이디어입니다. 근데 여기서 이제 이렇게 3 공간에서 2D의 어떤 픽셀 값하고 이렇게 매핑하는 그 관계가 렌더링 이퀘이션인데요. 렌더링 방정식 렌더링 방정식을 보면 이런 수식으로 써 있습니다. 이 방정식이 좀 복잡해 보이는데요. 이제 콘셉트는 사실 좀 간단합니다. 이 렌더링 이퀘이션은 어 하나의 픽셀 컬러 값은 이제 해당 픽셀을 거쳐서 카메라 센터로 들어오는 직선으로 들어오는 직선상의 모든 빛의 어떤 누적으로 컬러가 결정된다는 그런 카메라 센서의 작동 방식을 모델링을 한 건데요. 이전에 첫 강의에서 이제 광자의 여행 경로에 대해서 한번 봤었는데 정확하게 그 내용입니다. 그래서 빛이 광원으로부터 물체를 맞고 튕겨 나왔을 때 그때 이제 카메라 센터로 이 직선으로 들어오는 그 경로상에 있는 그 광자들의 누적으로 이렇게 컬러 값이 결정이 된다는 그런 표현을 이렇게 하고 있는 거예요. 그래서 다시 어 여기서 cr이 우리가 관찰하고자 하는 이 픽셀의 컬러인데요. 이 컬러가 어떻게 결정되냐면 이제 시작부터 이렇게 끝까지 직선상에 있는 모든 컬러 정보를 적분을 누적을 해서 이제 컬러를 결정을 하게 됩니다. 그런데 여기서 이제 허공에 아무것도 이제 없는 그런 곳에서도 이제 뉴얼 네트워크가 랜덤한 칼라 값을 반환할 수도 있기 때문에 이 앞에 오큐펀시를 이렇게 곱해서 이게 0이면은 그런 칼날은 고려하지 마라 투명하게 취급을 해라 이런 식으로 빼게 되고 그다음에 이제 1이면 완벽하게 불투명한 입자가 거기에 있으니까 그 컬러를 고려를 해서 접근을 해라라는 식으로 이렇게 수식이 되어 있는 겁니다. 이렇게 해서 이제 빈 공간은 신경 쓰지 말고 불투명한 컬러가 있는 입자들만 신경을 써서 이 선상에 있는 그런 포인트들을 다 내적을 하라라고 하는 거죠. 그때 이 각각의 포인트들은 이 레이 상에서 하나의 점을 딱 골랐을 때 뉴얼 네트워크에다가 그 레이의 점과 디렉션 d를 이렇게 넣어서 그렇게 해서 이제 어 덴시티하고 그다음에 컬러를 이렇게 출력을 뽑아내게 됩니다. 그 값들이 뉴얼 네트워크 값들이 여기에 이렇게 곱해져서 들어가는 형태가 된다라고 볼 수가 있을 것 같습니다. 네 하나의 픽셀 컬러 값은 해당 픽셀을 거쳐서 카메라 센터로 들어오는 그 직전 직선상에 있는 모든 빛의 누적으로 이제 컬러가 결정된다라는 그런 카메라 센서의 작동 방식을 이제 모델링한 게 이 렌더링 이큐에이션입니다. 그래서 이전에 첫 강의에서 광자의 여행 경로에 대해서 한번 살펴봤었는데 정확하게 그 내용을 모델링을 한 겁니다. 그래서 어떤 광자가 표면을 부딪혀서 이렇게 들어올 때 어떤 카메라 센터로 직선으로 들어오는 것에 대해서 광자들의 어큐뮬레이션으로 이 컬러 값이 결정된다는 거죠. 여기서 요 어 시그마하고 시의 어떤 표현들을 조금 살펴보고 넘어가야 되는데요. 여기서 이 알은 이제 레이입니다. 카메라 센터에서부터 이쪽 방향으로 이렇게 나가는 그런 레이이고 그다음에 이 씨알이 어떤 렌더링 된 이미지 플레임 상에서의 한 픽셀에 해당하게 됩니다. 그래서 이 픽셀을 이렇게 지나가는 그런 형태의 레일을 지금 관심을 가지고 저희가 보려고 하는 거죠. 거기서 이제 어떤 임의의 3D 포인트 이 레이상의 어떤 임의의 3D 포인트 하나를 딱 잡고 나서 거기에 컬러 값하고 이제 어큐펀시를 우리가 뉴얼 네트워크에서부터 추론을 해낼 수가 있습니다. 물론 이 값이 뭐 정확할지 안 정확할지는 아직은 모르지만 일단 어떤 3디 포인트가 딱 주어지면 그 3디 포인트에서 이 어큐펀시하고 컬러 값은 추출을 할 수가 있다라고 이해를 하면 될 것 같아요. 그래서 이 렌더링 인큐에이션을 보면 지금 잠깐 이 티를 생략하고 생각을 해보면 이 어큐펀시 곱하기 칼라 형태로 돼 있어서 이 컬러 값의 어큐뮬레이션으로 최종적인 렌더링 된 컬러가 결정이 되게 되는데 그때 이 시그마가 마치 마스크 또는 뭔가 게이팅 같은 그런 역할을 한다라고 볼 수가 있을 것 같습니다. 만약에 어떤 물체의 표면이 여기에 있고 그다음에 여기 뒤쪽에 있는 공간이나 앞쪽에 있는 공간이 전부 다 비어 있다라고 하면은 이 어큐펀시 기준으로는 빈 공간에서는 다 어큐펀시가 0이고 그 막힌 어떤 설피스 그 물체의 표면이 표면에서만 이 어큐펀시가 1이 되게 되겠죠 그랬을 때 우리가 인테그라를 취하면은 그러면은 이제 나머지는 전부 다 이 시그마가 0이니까 빈 공간에서는 0이니까 그게 어떤 컬러 값을 가지더라도 다 무시를 하게 되고 그다음에 물체 표면에 해당하는 그 t가 딱 됐을 때만 이게 1이 돼서 이 컬러 값이 그대로 욜로 넘어가는 그런 형태로 렌더링 이퀘이션을 이해할 수가 있습니다. 근데 여기서 이제 이 cr이 우리가 관찰하고자 하는 픽셀 컬러이고 이거를 다 어큐뮬레이션을 해서 어 구하는 그런 픽셀 칼라인데 어 여기서 허공에 아무것도 없는 곳에서도 이제 뉴얼 네트워크가 랜덤한 컬러 값들을 내보낼 수가 있겠죠. 그때 이 시그마가 잘 모델링 돼 있어야지 이게 빈 공간이다라고 생각을 하게끔 만들어서 얘네들을 다 캔슬해서 전혀 상관없는 그런 곳에서는 이제 어 칼라를 다 무시하고 투명하게 생각을 하고 그다음에 어큐펀시가 있는 곳에서만 이 컬러를 고려를 해서 누적을 해라라는 의미로 해석을 할 수가 있습니다. 근데 이렇게 누적을 하면은 이렇게 물체 표면이 이렇게 있을 때 그때 그 뒤에 만약에 시그마가 빈 공간이 아니라 여기에 물체 표면이 있는데도 불구하고 이 뒤쪽에도 뭔가 물체들이 있어요. 그리고 컬러들이 있어요. 그랬을 때 우리가 그냥 인테그라를 취하면은 이 시그마하고 c는 각 요 레이 상에서의 모든 3D 포인트들에 대해서 서로 관계는 상관하지 않고 그냥 각 위치에 대해서 컨튜뷰션을 바로 적용을 하기 때문에 이 뒤쪽에 어떤 물체가 있고 시그마가 0이 아니면은 그러면 전부 다 어큐뮬레이션이 돼서 오히려 물체로 가려져 있는데 이 가려진 뒤쪽에 있는 그런 광자들의 컬러까지도 다 어큐뮬레이션 되는 데 사용이 되게 되겠죠. 네 이거는 우리가 물리적으로 기대하고 있는 그 행동과는 굉장히 다른 형태가 됩니다. 그래서 이 물체의 뒤쪽 칼러는 이 픽셀에 영향을 주지 말아야 되는데 t를 사용하지 않은 경우에는 이 뒤쪽까지 다 고려하는 게 문제였고 그다음에 이렇게 물체를 뚫고서는 이 칼라에 칼라를 바꿔주는 그런 기현상이 일어나는 게 이제 문제였습니다. 그래서 그런 문제를 방지하기 위해서 여기에 티가 도입이 되는 겁니다. 그래서 이 티유는 약간 메모리하고 비슷해요. 이게 어큐뮬레이션 된 트랜스미턴스라고 해서 앞쪽에서부터 이렇게 적분을 해 나가면서 지금까지 가려진 정도가 얼마인지를 고려해서 지금 현재의 이 칼라 입자를 누적할지 말지를 결정을 하는 거죠. 그래서 방금 전에 이 예시에서 여기에 뭔가가 가려져 있다라고 하면은 그 앞까지 티는 계속 큐뮬레이션을 해도 계속 1의 값을 가져요. 그래서 트랜스피턴스가 1의 값을 갖다가 그러다가 가려진 구간을 딱 만나는 순간부터 t 값이 급격하게 줄어들기 시작합니다. 그래서 그 뒤쪽의 컬러는 이제 하나도 고려하지 않게끔 한 번 가려져서 이 안쪽의 값이 충분히 커지면 티가 0이 딱 돼버리면서 그 뒤쪽은 싹 고려를 하지 않아요. 그래서 앞에부터 어큐펀시를 이렇게 인테그라를 하면서 다 따져가지고 어 어느 순간부터가 이건 너무 가려졌는데 싶으면은 그 이웃 단은 차단하고 더 이상 사용하지 않는다 라는 수식이 여기 티로 반영이 되는 겁니다. 네 그래서 이 렌더링 수식은 사실 굉장히 잘 디자인된 그런 수식이고 심지어 여기가 빈 공간 같이 그런 단순한 구조가 아니라 이제 안개가 낀 케이스들에 대해서도 고려가 될 수가 있어서 굉장히 일반화된 경우에도 적용할 수 있는 제너럴한 그런 랜더링 인케이션입니다. 네 근데 아무래도 이제 적분 구간에 대해서 모두 계산을 하기 위해서는 거의 무한개의 샘플을 샘플링을 해야 되기 때문에 컴퓨터로 계산이 어렵습니다. 그래서 대신에 이제 샘플링 기반의 그런 어프록시메이션 방법을 사용을 하는데요. 어 그래서 이제 적분을 이렇게 시그마 형태로 서메이션 형태로 바꿔서 표현을 하게 됩니다. 그때 샘플링 된 그런 포인트 사이의 구간 길이를 고려를 해서 이제 구분 구적법처럼 이렇게 어 어프록시메이션을 사용하게 됩니다. 이렇게 렌더링을 활용해서 이미지에서 이제 한 픽셀을 선택을 하고 그다음에 그 픽셀의 레일을 그린 다음에 그 레이 상에서 샘플 포인트들을 이렇게 만들고 그다음에 샘플링된 이 포인트들을 뉴얼 네트워크에게 쿼링을 합니다. 물어보는 거죠. 그래서 나 색깔하고 그다음에 어큐펀시가 어떻게 돼라고 하면서 이런 식으로 하나씩 물어보는 겁니다. 그렇게 해서 어큐펀시하고 컬러를 구하게 되면은 그 값들로 렌더링 이큐에이션으로 이 해당 픽셀의 색상을 이렇게 어큐뮬레이션을 해서 딱 구하게 되는 거죠. 그렇게 해서 컬러 값이 나오면 그러면 인풋으로 주어졌던 그 이미지를 이제 그라운트 로스로 해서 원본 이미지의 색상과 비교하는 식으로 러스를 측정을 하게 됩니다. 그래서 이렇게 그라운트루스 로스와 이 컬러 값의 차이를 빼면서 학습이 진행되는 거죠. 당연히 렌더링 이퀘이션은 각 텀이 어 선형으로 결합이 되어 있었죠. 시그마의 어 웨이티드 섬 형태로 구성이 돼 있었고 그다음에 어큐펀시 관련된 텀들도 사실 론니뉴 펑션 하나를 통과한 정도의 간단한 형태로 구현이 되어 있어서 모두 미분이 가능합니다. 그래서 이제 FL 디퍼런셔블하게 우리가 학습을 진행을 할 수가 있게 되고요. 추가적으로 뉴얼렛의 입력으로 이제 저차원 좌표를 그대로 사용하게 되면은 작은 차이를 캐치하지 못하고 그러니까 좌표의 어떤 실수 값이 조금 변하는 경우에 대해서 그 작은 차이를 캐치하지 못하고 나서 이렇게 어 저주파 성분만 학습이 되는 등의 이슈가 좀 생깁니다. 예를 들어서 여기에 있는 좌표 포인트하고 여기 옆에 있는 좌표 포인트하고 값의 차이가 사실 그렇게 크게 나지는 않잖아요 그렇죠 그러면은 값의 차이가 그렇게 크게 안 나면은 충분히 차이가 안 난다라고 생각해서 네트워크가 비슷한 값을 출력을 해 줘요. 이게 이제 저주파 성분을 유도하는 그런 형태가 되게 되고요. 그래서 이런 게 좀 이슈가 되는데 이게 이제 트랜스포머나 디퓨전 모델에서 이제 타임 스텝이나 포지션 같은 것들을 포지션 엔코딩을 해서 사용하는 이유하고 같은 이유입니다. 그래서 포지션 이 스와 좌표를 포지션 엔코딩을 해서 사용을 하게 되면은 이렇게 빠르게 수렴이 되는 것을 볼 수가 있습니다. 그래서 여기서도 이제 좌표를 고차원 좌표로 올려서 고차원 공간으로 올려서 구분성을 잘 주기 위해서 이제 사인하고 코사인 함수를 사용을 해서 포지션 엔코딩을 만들어서 사용을 하게 됩니다. 그리고 널프의 장점은 이제 입력의 뷰 디렉션을 받아준다는 건데요. 그렇게 함으로써 이제 뷰 디렉션 디펜던트한 컬러를 표현할 수가 있게 됩니다. 그래서 만약에 이렇게 반짝이는 경우에 우리가 앞에서 보는 경우하고 뒤쪽에서 보는 경우하고 같은 3D 포인트에 대해서도 색깔이 다르게 발현이 되게 되는 거죠. 이렇게 되면은 단순히 석고상과 같은 그런 메탄 재질뿐만 아니라 굉장히 반짝이는 물체라든지 반사성이 있는 그런 기존의 컴퓨터 비전에서는 표현이 매우 어렵다고 생각했던 물체의 표현들도 매우 좋은 퀄리티로 표현을 할 수가 있게 됩니다. 그래서 결과이고요. 지금 이렇게 돌아가면서 이제 이미지를 촬영을 한 것으로 다시 이제 렌더링을 한 영상입니다. 그래서 샘플 된 그런 데이터들로 어이 널프를 학습시킨 다음에 다시 360도 렌더링을 한 결과죠. 거의 실제 동영상을 튼 것과 거의 다름이 없죠. 굉장히 좋은 퀄리티입니다. 그리고 또 이제 학습된 그 널프의 어 이런 칼라 렌더링 값뿐만 아니라 우리가 뎁스도 에스티메이션을 해볼 수가 있는데 이 뎁스도 보면은 굉장히 하이프리퀀시의 지오메틱 디테일이 나오는 것을 볼 수가 있습니다. 그래서 어떤 센서도 이 정도 퀄리티의 뎁스를 얻는 경우는 흔치 않습니다. 굉장히 좋은 퀄리티의 그런 뎁스이고 어 또 다른 거는 아까 설명했던 것처럼 우리가 똑같은 3D 포인트에 대해서도 뷰 디렉션이 달라지면은 컬러 값이 바뀌는 겁니다. 그걸 통해서 지금 이 부분처럼 반사되는 그 형태를 표현할 수가 있게 되는 거죠. 정말 리얼리스틱한 그런 형태의 표현이라고 볼 수가 있을 것 같습니다. 그래서 이렇게 뷰 디펜던트한 그런 어피런스를 표현할 수가 있습니다. 여기서 한 가지 주의사항은 어 넓프 방법이 각 장면의 데이터마다 학습을 시켜야 하는 약간 오버피팅 영역에서 작동하는 그런 모델이라는 겁니다. 그래서 각 씬마다 장면마다 개별적으로 학습을 해서 nf 모델 하나마다 이제 한 장면만 표현할 수 있는 그런 형태로 운영이 되게 됩니다. 네 물론 인풋 데이터가 이제 스팟하게 주어졌기 때문에 그 사이사이를 보관할 수 있는 영역에 대해서 그 부분은 이제 뭐 일반화 영역이라고 볼 수도 있지만 이제 장면별로 이제 개별적인 모델이 필요하다라는 정도로 이해하면 될 것 같습니다. 네 널프 다음에 볼 내용은 이제 가우시안 스플레팅인데요. 기존의 널프는 학습이 매우 느립니다. 어 학습이 매우 느리고 그 다음에 렌더링 속도도 어마어마하게 느립니다. 근데 이제 그걸 개선하려는 여러 가지 노력들이 좀 있었어요. 그래서 이제 준 리얼타임의 렌더링 성능도 나오기도 하고 그다음에 학습 시간도 굉장히 빠르게 만들기도 하고 그랬었는데 어 근데 이제 지금은 이제 3D 가우션스 플레팅이 거의 10배 가까운 도약을 보여주면서 지금 가장 활발하게 사용되는 뉴럴 렌더링 방법이 되었습니다. 그래서 결과를 보면요. 어 이 3D 가우시안 스플레팅 3디 지스라고 표현되는 이런 장면 리프레젠테이션 방법이 어 일단은 리얼 타임의 디퍼런셔블 렌더링을 사용을 하게 됩니다. 그래서 FPS를 보면은 노란색하고 자주색이 2개가 이 3D GS에 대응하는 그 값들인데 보면 100프레임이 넘게 나옵니다. 렌더링이 그래서 기존에 넓은 방법이나 이 n프의 베리언트들 굉장히 준 리얼 타임에도 이제 못 미치는 그런 형태의 속도를 보였었는데 거의 게임 엔진과 비슷한 정도의 속도를 지금 보이고 있죠. 그러면서도 이제 퀄리티를 보면은 이제 퀄리티를 설정하기에 따라 나름인데 널프하고 그렇게 많이 차이가 나지 않는다 정도로 이해를 하면 될 것 같습니다. 그래서 세팅을 잘 찾으면 널프하고 거의 차이가 안 나고 더 좋은 경우들도 있다 라고 이해를 할 수 있을 것 같고요. 그다음에 이제 트레이닝도 이제 아무래도 렌더링이 빠르다 보니까 트레이닝도 굉장히 빠른 것을 확인할 수가 있습니다. 그래서 기존 n프보다 더 빠르게 학습이 되고요. 네 n프에서는 전체 장면을 하나의 뉴얼 네트워크로 표현을 했었다면 어 3디 가우시안 스프레이팅에서는 3D 공간 중에 좀 국부적인 그런 공간을 하나의 3디 가우시안으로 표현하는 게 핵심 아이디어입니다. 그래서 포인트 클라우드보다는 훨씬 더 적은 개수로 넓은 영역을 커버하는 형태로 구성이 되어 있고 이제 각 3D 가우시아는 이렇게 민 베리언스 그다음에 오펙스티 그다음에 칼라 파라미터로 이렇게 구성이 되어 있습니다. 그래서 이 민하고 코베리언스는 3D 가우시 자체를 표현하고 있고 이 하나의 3D 가우시안에 대해서 그게 그거에 대한 투명도 그다음에 컬러 값이 이렇게 어사인이 돼 있습니다. 그중에서 이제 컬러 값을 RGB로 사용을 하는 경우에는 이제 뷰 디펜던트한 컬러를 모델링 하지 않고 어떤 뷰에서 보든지 간에 같은 컬러가 나오는 경우에 이렇게 RGB를 바로 사용을 하고요. 그다음에 만약에 뷰 디펜던트한 그런 뷰 디렉셔널 디펜던트 효과를 모델링 하고 싶을 때는 스피커 하모닉스를 사용을 해서 그 코이피션트를 각각 가우시안에다가 이제 어사인을 해주게 됩니다. 어 스피커 하모닉스는 이제 컬러마다 이렇게 하나하나씩 이제 스피커 하모닉스 베이시스를 둬서 3개의 서로 다른 스피커 하모닉스를 사용을 하고요. 베이 이거는 이제 스피리컬 하모닉스의 베이시스를 지금 표현을 하고 있습니다. 그래서 스피커 하모닉스는 자세하게 다루지는 않겠지만 스피어 상에서의 어떤 피리의 베이시스와 같은 어떤 베이시스 역할을 합니다. 그래서 이 베이시스 성분들을 합성을 해서 코입션 2를 이용을 해서 웨이티드 sum으로 합성을 해서 어 표현을 하게 되면 스피어상이 굉장히 다양한 패턴들을 몇 개의 저차원의 코이피션트로 표현을 할 수가 있게 됩니다. 어 그러면은 이 스피어를 가지고 어떤 패턴을 이제 우리가 표현을 하게 되면은 그때 이 스피어 상에서의 어떤 디렉션을 딱 지정을 했을 때 그 디렉션에 해당하는 값을 우리가 가지고 올 수가 있게 되죠. 그런 식으로 이제 뷰 디펜던트한 컬러를 표현할 수가 있게 됩니다. 그래서 어 스피커 하모니코스 코이시언트가 우리가 예를 들어서 뭐 한 채널당 9개를 사용했다라고 하면은 이제 9개 곱하기 3 알지비 따로따로 해서 이제 27개의 파라미터를 사용한다든지 그런 식으로 컬러를 표현을 하게 됩니다. 그리고 또 특히 이제 코베리언스를 표현을 할 때 여기서 주의점이 있는데요. 이게 아무래도 민하고 코베리언스 부분이 트레이닝 되는 부분이다 보니까 어 디퍼런셔블 한 어떤 오퍼레이션으로 학습이 잘 돼야 됩니다. 근데 이제 코베리언스를 표현을 할 때 파라미터레이션 테크닉을 따로 사용하지 않으면은 이 코베리언스는 positive 세미 데피닛이라는 그런 특성을 가지고 있기 때문에 이 특성을 유지하면서 트레이닝 하는 게 쉽지가 않습니다. 그래서 이제 학습을 좀 용이하게 하기 위해서 로테이션 매트릭스하고 다이어그널한 스케일 매트릭스를 이렇게 여러 개로 시멘트릭하게 결합을 해서 코베리언스를 대신 표현을 하게 됩니다. 즉 파라미터라이제션을 한 거죠. 그러면은 이게 이제 스케일 매트릭스고 다이어는 스케일 매트릭스고 그다음에 r이 로테이션 매트릭스면은 이것들을 곱하면은 항상 positive 세미드 핏이 나오게 됩니다. 그래서 추가적으로 이제 로테이션도 학습이 이제 좀 어려운 구조이기 때문에 이게 3 3이면서 로테이션이라는 그런 조건을 만족해야 되기 때문에 이거를 좀 더 학습이 용이하다고 알려진 최적화가 용이하다고 알려진 그 포디맨전의 쿼터니온을 사용을 해서 3D 로테이션을 표현하게 됩니다. 그래서 이제 학습을 할 때 어 이 포 디멘전의 쿼터니온을 이제 디퍼런셔블하게 학습을 하게 되고 이 쿼터니온에서부터 로테이션을 복원을 하고 그다음에 로테이션과 스케일을 곱하고 이런 식으로 해서 코밸런스를 표현을 한 다음에 이 코밸런스를 가지고서는 신을 표현하는 식으로 사용을 합니다. 그래서 전체적인 3D GS의 학습 파이프라인은 이렇게 생겼습니다. 네 먼저 이제 입력으로는 스트럭처 프로모션을 돌리고 나서 나온 그 3D 포인트 클라우드를 이니셜로 활용을 하게 되고요. 그다음에 이제 스트럭처 프로모션의 결과물인 카메라 포즈도 사용을 하게 됩니다. 어 이렇게 입력이 주어지게 되면은 이제 이니셜라이제이션 위에다가 이제 3디 가우시안을 대강 이렇게 올려놓고 그다음에 이제 카메라 매트릭스를 이용해서 얘네들을 프로젝션에서 이미지 렌더링을 합니다. 레스터라이제이션을 하는데요. 그때 이제 nf는 레이를 딱 그리고 레이 위에 있는 이런 값들을 포인트를 샘플링을 했었는데 여기서는 이제 3D GS는 이제 이 영역을 아예 가우시안 하나하나가 표현하고 있기 때문에 어떤 레이가 딱 있으면 그 레이에 해당하는 그 가우시안 스플레팅들을 전부 다 그냥 바로 프로젝션 해버려서 사용을 하게 되는 거죠. 그래서 이제 널프하고는 다르게 각 레이상의 점들을 샘플링하지 않고 가우시안을 그대로 프로젝션에서 한 장의 이미지를 한 번에 렌더링해서 그래서 이제 빠른 결과를 가지고 올 수가 있습니다. 레스터라이제이션 같은 경우는 이렇게 어떤 객체가 있을 때 그 객체를 바로 프로젝션을 해 가지고 이 픽셀로 이런 형태로 매핑을 하는 그런 구조이고요. 당연히 이제 레이트레이싱 같은 경우는 복잡하게 빛이 어떤 식으로 반사되는지까지 고려를 할 수가 있기 때문에 훨씬 더 고퀄리티의 렌더링이 되는데 레스터라이제이션 같은 경우는 바로 프로젝션하고 끝이기 때문에 상대적으로 이제 복잡한 씬의 어떤 관계성을 포함하지는 못합니다. 그렇지만 이 정도의 어떤 그 결과를 표현하기에는 굉장히 빠르면서도 효과적인 그런 방법이라서 3디 지스에서는 매스터라이제이션을 사용을 하게 됩니다. 네 그렇게 이제 이미지를 비교를 해서 학습을 진행을 하는데요. 그때 이제 백프로파게이션을 통해서 이쪽으로 이렇게 학습을 진행하면서도 어 이 옆쪽으로 이제 덴시티 컨트롤이라는 모듈이 따로 있어서 어 이 3디 가우시안의 개수를 어댑티브하게 조금 조금씩 바꿔줍니다. 왜 조금 조금씩 바꿔 주냐면 어떤 가우시안의 경우에는 이 부분의 영역을 전부 다 다 표현을 해야 되는데 이 가우시안 하나로 표현하기가 좀 벅찬 경우 그때는 이걸 클로닝을 해줘서 2개로 나눠서 이 영역을 커버할 수 있도록 해주고요. 또 가끔씩은 이 전체 영역을 커버를 억지로 하려고 가우시안이 그냥 뚱뚱해지고 의미 없이 이렇게 표현을 하는 경우들도 있습니다. 그런데 이 내에서 뭐 색깔이 확 바뀐다라고 하면은 이런 단일 가우시안으로 표현하기가 굉장히 어렵겠죠. 그래서 이 가우시안을 스플릿에서 이렇게 나눠서 사용을 하는 그런 경우도 있습니다. 그래서 결국에는 이 3D 볼륨 공간을 굉장히 효율적으로 잘 채우기 위해서 어댑티브한 그런 휴리스틱으로 이제 3D 공간을 채워놓고 있다라고 이해를 하면 될 것 같습니다. 네 이렇게 학습된 3D 가우시안 스플레팅을 이용을 해서 렌더링 하면은 이 정도로 굉장히 고퀄리티의 렌더링이 가능하고 심지어 엄청나게 고속 스피드로 렌더링이 가능합니다. 그래서 이렇게 어 널프하고 3디 지에스가 뉴럴 렌더링 기반의 방법으로써 3디 리컨석션하는 새로운 3디 표현법으로 많이 활용이 되고 있습니다. 네 그 다음 테스크로는 이제 생성 모델까지는 아니지만 생성과 비슷하게 이제 컨디셔널하게 3D를 리그레션하는 테스크도 있습니다. 어 구조는 이제 마스크 씨엔엔을 확장한 그런 구조인데요. 거기에 이제 메시 리그레션 헤드를 붙여서 추가함으로써 이제 입력 이미지에 대한 3D 메시가 아웃풋으로 나오는 그런 구조입니다. 네 물론 이제 마스크 시에 구조를 이제 물려받았기 때문에 디텍션과 세그멘테이션도 한 번에 이루어지게 됩니다. 어 마스크 시엔의 브랜치를 다시 한 번 리마인드를 해보면은 바운딩 박스하고 클래스가 나오는 그 클래스 헤드하고 그다음에 마스크 헤드하고 이렇게 3개의 브랜치로 이루어져 있습니다. 그리고 하나의 ROI에 대해서 이제 어떤 피처맵이 주어지면은 그 피처맵에 대해서 이런 출력들을 모두 하는 그런 구조를 이루고 있는데 여기에 메시아 시엔에는 3디 브랜치를 하나 3디 메시 브랜치를 하나 더 추가를 한 그런 형태가 되게 됩니다. 네 방금 전에 살펴본 메시 아시는 같은 경우에는 어 이미지가 주어지면은 한정된 클래스에 대해서 어 메시 아웃풋이 나오는 그런 구조로 학습이 되기 때문에 이제 이미지하고 그 이미지에 대응하는 3디가 잘 얼라인된 그런 형태의 그라운트로스 데이터셋이 있어야 됩니다. 그것도 굉장히 라지 스케일로 있어야 되는데요. 최근에 이제 3D 제너레이션 쪽에서 어 어떤 텍스트와 그거에 대응하는 3디 데이터 페어 없이도 어 좋은 퀄리티의 3디를 생성해 낼 수 있는 그런 제로샵 방법들이 많이 고안이 되고 있습니다. 그래서 어 이번에 이제 드림 퓨전에 대해서 좀 소개를 드리려고 하는데요. 어 드림 퓨전은 텍스트가 주어지면은 그거에 대응하는 3디를 생성해 주는 그런 생성 모델인데요. 어 근데 이게 뭐 사실 디퓨전 모델 같은 그런 생성 모델은 아니고 제로 샷으로 이제 트레이닝 없이 최적화 형태로 3D를 구해내는 그런 방법입니다. 그런데 여기서 이제 키포인트는 기존의 어떤 3D 데이터들을 라지 스케일로 활용하거나 그런 데이터들을 이용하지 않고 미리 프리트레인된 어 2디의 텍스트 투 이미지 디퓨전 모델을 사용을 하는 게 이제 핵심 특징입니다. 네 보면은 이 텍스트를 잘 따라가는 그런 3D가 그럴듯한 퀄리티로 잘 나온 것을 확인할 수가 있습니다. 그래서 이 드림 퓨전이라는 방법은 어 이렇게 텍스트를 주면은 그러면은 3디 널프를 출력하는 구조입니다. 근데 여기서 이제 키 포인트는 아까 설명했듯이 이제 투디 이미지에서 작동하는 텍스트 투 이미지 디퓨전 모델을 사용을 한다는 건데요. 그래서 3D 데이터가 없이 3D를 생성하는 그런 제로 샷 어프로치입니다. 네 이 방법을 소개하는 가장 큰 이유는 파운데이션 모델 레벨로 학습된 2D 이미지 디션 모델의 어마어마한 가능성에 대해서 이제 언급하고 싶어서인데요. 어 이 2D 이미지 디퓨전 모델을 클립 모델처럼 텍스트와 이미지의 매칭 정도를 측정하는 그런 리워드 모델로서 이제 그라디언트 생성기로 사용할 수 있는 매우 유용한 방법을 이 드림 퓨전에서 제시하고 있습니다. 그럼 한번 따라가 보도록 하죠. 방금 전에 설명한 그 방법을 이제 스코어 디슬레이션 샘플링 러스라고 부릅니다. 짧게 에디스 러스라고 부르는데요. 어 디퓨전 모델의 전체 프로세스는 이렇게 다음과 같이 이렇게 구성이 되어 있습니다. 이 전체 프로세스를 한번 보면서 에디스 러스에 대해서 한번 이해를 해보도록 하죠. 어 이제 학습 없이 각 샘플별로 이제 최적화를 하는 방식입니다. 그래서 이제 크게 3D를 표현하는 그 넓프 표현 모델 쪽과 그다음에 중간에 디퍼런셔블 렌더링 파트 그다음에 어 텍스트가 주어지면은 현재 상태에 맞는 그레디언트를 발생시키는 에디스 러스 부분 이렇게 3개로 구성이 됩니다. 먼저 3디 표현으로는 널프를 사용합니다. 이제 디테일은 좀 생략을 하고요. 이 3디 표현으로 이제 마치 아직 성형되지 않은 그런 찰흙 같은 느낌으로 이 널프를 사용을 하는 건데요. 여기서는 그럴듯한 오브젝트가 처음부터 있지만 사실은 이 어 널프를 기본적인 어떤 이니셜 구조로 굉장히 러프한 구조로 그냥 아무런 모양도 아닌 그런 랜덤한 3디가 주어진 상태에서 시작을 합니다. 그다음에 이제 위쪽에서부터 인포메이티브한 그런 그레디언트가 흘러와서 백퍼퍼게이션 되어 와서 어 이 그레디언트의 칼로 이렇게 잘라 가지고 성형을 하는 그런 트레이너블 파라미터로 사용을 하는 겁니다. 네 그 다음은 중간에서 이제 3D 표현으로 표현된 그 널프의 표현을 2루 투디 이미지로 렌더링을 해주는 그런 미분 가능한 렌더링 모듈입니다. 디퍼런셔블 렌더링 모듈인데요. 어 여기서 이 디퍼런셔블 렌더링 모델이 3D와 2D 사이의 어떤 스페이스를 연결을 해 주는 그런 역할을 하게 됩니다. 그리고 반대로 이제 디퍼런셔블 하기 때문에 요 2디에서 나온 그레디언트가 3D 쪽으로 흘러갈 수 있도록 도와주는 그런 역할도 하게 되는 거죠. 그래서 이게 되게 중요한 브릿징 역할을 하게 되고요. 네 그다음에 가장 중요한 핵심인 에디스 로스를 한번 보도록 하겠습니다. 어 에스러스의 입력으로는 렌더링된 이미지에다가 노이즈를 첨가해서 프리트레인 된 디퓨저 모델의 입력으로 이렇게 넣어줍니다. 그다음에 어 이 입력 이미지가 좀 따라갔으면 하는 그런 텍스트 인풋도 여기다 이렇게 넣어주게 되는 거죠. 컨디션으로 그래서 여기서 만약에 3D가 아직 굉장히 불완전한 형상인 경우에 렌더링된 이미지도 이제 엉망으로 나오겠죠 그럼 거기다가 노이즈를 이렇게 입혀 가지고서는 가려줍니다. 잘 안 보이게 좀 가려주면은 얼핏 보면은 실루엣 정도만 살짝 보이는 정도예요. 어 이거를 이제 디노이징을 하도록 디퓨전에 넣으면은 이렇게 텍스트를 잘 따르는 형태로 텍스트 입력을 잘 반영하기 위한 그런 형태로 디노이징이 좀 이루어지게 됩니다. 즉 현재 상태에서 어떻게 바뀌어야지 어 요 텍스트를 잘 따르는 형태의 이미지가 되는지 그런 방향을 제시하는 거라고 볼 수가 있겠죠. 그래서 어 이렇게 나온 그런 디노이징 된 그 결과를 이용을 해서 이제 그레디언트를 발생시켜서 백프로파게이션을 진행을 하게 됩니다. 이 백프로카비이션 그레디언트로 이 넓프를 이제 업데이트를 하게 되는 거죠. 조금 더 자세하게 보면은 어 노이즈 프리딕션 된 디퓨전 모델을 따라서 이제 백프로파게이션을 하게 되면은 시간도 사실 오래 걸리고 그다음에 계산이 굉장히 늘기 때문에 이 유닛 구조에 대해서는 이제 백프로파게이션을 진행하지 않는 게 이제 핵심 포인트입니다. 그래서 사실은 우리가 원하는 그 노이즈가 들어왔을 때 그리고 조건부 y라는 이제 텍스트 컨디션이 들어왔을 때 그거에 잘 맞는 형태의 그레디언트는 풀 그레디언트는 유닛을 통과하는 그 자코비안이 필요한데 이거를 이제 생략하는 게 키포인트라는 겁니다. 그래서 좀 효율적으로 이 그레이디언트를 계산할 수 있도록 이걸 빼버립니다. 그래서 바로 이제 노이즈 프리딕션의 그 오차를 측정하는 방식으로 이제 효율적인 그레디언트 어프록시메이션을 해서 이제 밑에 단에다가 흘려주게 되는 겁니다. 그래서 이거를 이제 계속 반복하는 겁니다. 그레디언트를 백퍼로퍼게이션에서 널프를 업데이트하고 그 널프에서부터 렌더링된 3D를 어 3D를 가지고서는 다시 디퓨전 모델에다가 넣어서 그레디언트를 만들어 주고 그걸 계속 반복을 해서 이 넓프가 현재 텍스트에 잘 맞는 형태로 학습이 될 때까지 놔두게 됩니다. 그렇게 최적화를 반복하는 거죠. 그래서 이거를 반복함으로써 이제 어떤 텍스트와 3D 데이터 에셋 페어가 라지 스케일로 없더라도 심지어 하나도 없더라도 이런 학습 데이터 없이 제로 샷으로 3D 생성하는 것을 이제 수행을 이런 식으로 구현을 할 수가 있습니다. 그래서 텍스트 설명만으로 이제 3D 에셋을 생성할 수 있는 그런 획기적인 방법이고 뎁스 렌더링 퀄리티도 보면은 꽤 잘 나오는 것을 볼 수가 있죠. 또 다른 이제 ss 러스의 활용 사례를 좀 소개를 드리려고 합니다. 이번에는 이 ss 러스를 텍스트로부터 3D가 아닌 3D의 텍스처 맵을 생성하는 그런 응용입니다. 그래서 이렇게 인풋으로 텍스트가 주어지고 그거에 대한 3D가 주어진 상태에서 그 위에 텍스처만 생성을 해서 입히는 이런 구조라고 이해하면 될 것 같습니다. 그래서 SDS 로스가 유용하다는 사실은 잘 알려져 있는데요. 사실 SDS 로스의 그레디언트가 노이즈에서 어 좋은 퀄리티의 3D 생성에 좀 방해가 된다는 사실도 같이 알려져 있습니다. 그래서 이 SDS 러스를 개선하기 위해서 여러 가지 이제 변형된 SDS 러스를 제안하기도 했었는데요. 이 연구에서는 조금 다른 접근을 취합니다. 네 텍스트에서부터 이제 텍스처를 최적화로 생성하는 프레임웍도 드림퓨전하고 유사한 구조를 갖게끔 이렇게 구성이 되어 있는데요. 차이는 이제 최적화하는 대상이 러러블 파라미터가 좀 다르다는 겁니다. 여기서는 이제 3D는 주어져 있고 그다음에 그 위에 이 텍스처 맵이 에디스 러스를 통해서 최적화하는 그런 대상으로 이제 백프로파게이션으로 업데이트를 할 예정인데요. 이 텍스처 맵은 2디 유브이 맵 구조 2D 이미지 형태의 어떤 텍스처 맵 구조로 이제 이미지 형태를 취하고 있습니다. 그래서 각 픽셀마다 이제 독립 변수로 이렇게 구성이 되어서 각 픽셀의 3D 상의 어떤 특정 영역을 담당하게끔 이렇게 연결성을 가지고서는 매핑이 되어 있는 그런 상황인 거죠. 근데 아까 설명했던 것처럼 여기에 ss 로스의 노이즈 한 특성으로 인해서 이 텍스처 맵을 바로 최적화하는 경우에 여기서는 이제 조금 일러스트레이트 이시긴 하지만 최악의 경우에는 이렇게 이제 텍스처 퀄리티가 저 퀄리티의 아티팩트가 좀 묻어 나올 수 있습니다. 그래서 많은 사람들이 이 에스러스를 개선을 하려고 어 새로운 수학적인 프레임웍을 제시를 한다든지 아니면 휴리스틱한 그런 방법들을 만들어 내는데 결국에는 아티팩트를 여전히 많이 포함하는 경우들을 많이 볼 수 있습니다. 네 이 연구에서는 이제 에스러스를 사용을 그대로 하면서도 안정적인 최적화를 위해서 이제 텍스처 맵을 컨볼루션 뉴럴 네트워크로 파라멘터라이제이션 하는 게 이제 키 아이디어인데요. 여기서 파라미터라이제이션이 무슨 의미냐고 하냐면은 입력은 이렇게 랜덤 노이즈를 샘플링을 해서 픽스를 해 놓습니다. 그래서 그냥 랜덤이에요. 아무 의미 없는 그런 랜덤을 사용을 해서 인풋으로 사용을 하고요. 그다음에 이 컨볼루션 뉴럴 네트워크도 아키텍처를 이렇게 만들어 놓고 그다음에 랜덤 이니셜라이제이션을 합니다. 그래서 이것도 정보가 없어요. 사전에 학습되거나 그런 애도 아니고 그냥 랜덤한 앱입니다. 근데 이제 구조만 있는 거죠. 대신에 이 씨엔엔의 아웃풋이 좀 텍스처 맵이 될 수 있도록 그 레졸루션을 맞춰 놓습니다. 그래서 처음에는 그냥 랜덤한 값이 출력이 되겠죠. 인풋 노이즈를 넣으면 랜덤한 텍스처 맵이 나올 겁니다. 그래서 이렇게 구성을 해 놓으면 최종적으로 최적화하는 대상이 이 텍스처 맵의 각 픽셀 밸류어블들이 아니라 이 픽셀들을 표현하는 CNN의 웨이트가 어 최적화하는 그런 타겟 밸류어블이 됩니다. 이게 이제 파라미터라이제이션이라고 부르는 거고요. 그래서 이렇게 하면은 이제 CNN에 어떤 컨볼루션 커널이 여러 번 반복 사용되는 그런 효과로 인해서 어떤 스트럭처의 리던던시도 있을 수 있고 그다음에 컬러 사이즈가 있으니까 이제 프리퀀시의 어떤 제약도 들어가게 되고 그래서 이런 스트럭처드 프라이어가 어 텍스처 맵에 적용이 되게 됩니다. 자연스럽게 그래서 이게 어떻게 보면 레듀라이션 효과를 이제 유도를 하게 되는 거죠. 또 여기서 소개를 하지 않지만 이제 이 해당 논문에서 여러 가지 부가적인 효과로 인해서 이 에디스로스로부터 온 그레디언트의 그런 노이즈가 요 요 시 구조에 의해서 필터링이 되고 정말 중요한 시그널들만으로 이제 학습에 빠르게 적용되는 형태로 안정적인 학습이 이루어진다라는 것을 이제 보였습니다. 네 이렇게 옵티미제이션이 대상이 되는 어 파라미터레이션만을 변경을 해서 기존 방법보다 훨씬 안정적이고 거의 상용 레벨의 텍스처 품질을 생성할 수 있다는 사실을 보였습니다. 그래서 에디스 러스를 그대로 사용했음에도 불구하고 그 옵티미제이션 되는 밸류어블을 파라미터레이션을 한 것이 굉장히 큰 영향을 미쳤다라고 볼 수가 있겠습니다. 그래서 이전에 소개했던 그런 클립 액터와 함께 사용하기 위한 텍스처도 이제 고퀄리티 텍스처를 만들어서 이제 활용을 할 수가 있고요. 그래서 지금 에디스 로스가 이런 식으로도 활용이 될 수 있다라는 걸 보여주고 있는데요. 여기서 중요한 메시지는 에스디에스 로스와 같이 이런 노이지한 특성을 가지고 있는 그레디언트를 사용을 할 때 이 그래디언트의 퀄리티를 높이는 것은 수학적으로도 이제 사실 간단한 일이 아닙니다. 그리고 실제로 인프로브를 했다고 하더라도 좀 휴리스틱한 경우들이 굉장히 많고요. 그래서 에이스 로스의 개선 버전이 나왔을 때도 퀄리티가 급격하게 좋아지지는 않았었고 뭐 아티팩트가 남는 경우도 굉장히 많았었는데요. 어 이 연구에서는 스탠다드 에디스 러스도 이제 최적화 대상의 파라미터레이션이 그레디언트의 노이즈를 이제 충분히 필터링할 수 있을 만큼 좋은 특성으로 잘 설계가 된다면은 어 스탠다드한 에디스로서도 충분히 좋은 퀄리티의 생성에 사용될 수 있다는 것이 이제 핵심적인 결론이라고 볼 수가 있을 것 같습니다. 네 이렇게 이번 시간에는 다양한 3D에 대한 기본적인 배경 지식과 그다음에 여러 태스크들에 대해서 좀 살펴봤습니다. 어 3D를 이해하는 것은 이제 무인차나 로봇 AR VR과 같은 어 매우 흥미로운 테스크들에 대해서 이제 필수적으로 적용되는 스킬이기 때문에 또 중요하다라고 할 수가 있고요. 특히 이제 실제 세계에 운영되는 에이전트의 도입이 됐을 때는 안전과 가장 밀접한 연관이 있는 그런 기술이 이제 3D입니다. 그래서 나중에 궁극적으로 실제 세상과 인터랙션을 할 수 있는 그런 AI를 만들기 위해서 3D에 대한 스킬셋을 갖추는 것은 굉장히 중요하다라고도 생각할 수가 있을 것 같아요. 그래서 이렇게 3D 스킬 셋에 대해서 열심히 공부를 해서 키워놓는 것도 어 차별화된 그런 컴퓨터 비전 전문가가 되는 지름길이 아닐까 생각을 합니다. 네 이렇게 이번 시간 마무리하도록 하겠습니다. 다음 시간에 뵙도록 하겠습니다. 감사합니다."
}