{
  "lecture_name": "[MRC] (5강)Passage Retrieval-Dense Embedding",
  "source_file": "[MRC] (5강)Passage Retrieval-Dense Embedding_107.mp4_2025-12-04-104718281.json",
  "text": "네 안녕하세요. 5강 시작하도록 하겠습니다. 오늘 5강에서는 지난 시간에 다뤘던 스파스 인베딩의 단점을 극복하는 댄스 인베딩에 대해서 다뤄보도록 하겠습니다. 오늘 강의는 크게 세 파트로 나눠지는데요. 첫 파트는 댄스 인베딩에 대해서 간략한 소개를 하고요. 두 번째로는 댄스 인베딩을 만드는 댄스 인코더를 어떻게 학습할 수 있을지에 대해 논의해 보도록 하겠습니다. 다음으로 세 번째로는 이런 댄스 인코더와 댄스 인코더를 통해 만들어진 패세지 인베딩을 통해서 어떻게 패시지 리트리버를 할 수 있을지를 알아보도록 하겠습니다. 먼저 댄스 인베딩에 대한 개론입니다. 저희가 지난 강의에서 알아봤듯이 패시지 인베딩이라 함은 각 컨텍스트 각 구절을 벡터로 변환하는 것을 의미하는데요. 왼쪽처럼 주어진 어떤 문서의 한 부분이 있을 때 이 문서에 대응되는 뜻을 담고 있는 패시지 임베딩을 오른쪽의 형태로 매핑을 하는 것이 목표입니다. 그리고 지난 렉처에서는 특히나 이런 패시지 임베딩 방법론 중에서 특히나 스파스 인베딩 쪽을 많이 들여다봤는데요. 스파스 인베딩 같은 경우는 tfidf와 같은 스파스 인베딩 같은 경우는 벡터의 크기는 아주 크지만 그 벡터 크기 내에서 실제로 0이 아닌 숫자는 상당히 적게 있습니다. 특히 tfidf 같은 경우는 백오브 버즈 방법론을 택하고 있기 때문에 특정 단어가 있는 경우에만 해당 보캡의 디멘션이 벡터의 디멘션이 넌 지로가 됨으로써 사실상 90% 이상의 디멘션들이 보통은 0이 되는 경우가 발생을 합니다. 물론 차원의 수가 매우 큰 부분은 저희가 컴프레스 포맷으로 극복이 가능합니다. 이게 여러 가지 방법이 있는데 그중 하나는 예를 들면은 저희가 넌 지로에 있는 부분을 위치와 넌 지로의 값만 저장하는 방식을 통해서 벡터 전체를 저장하지 않는다고 하더라도 상당히 이피션트하게 저장하는 것은 가능합니다. 하지만 스파스 인베딩의 가장 큰 문제점은 유사성을 쉽게 고려하지 못한다는 것입니다. 어떤 두 단어가 있었을 때 두 단어가 아주 비슷한 의미를 가진 단어라고 하더라도 서퍼스 폼 즉 텍스트 형태로 다른 단어일 때 두 단어는 벡터 스페이스에서 완전히 다른 디멘션을 차지하는 그리고 그 벡터 스페이스 상에서는 저희가 전혀 두 개의 유사성을 고려할 수가 없는 형태가 됩니다. 바로 이 점이 스파스 인베딩의 가장 큰 단점이 되겠고요. 이런 단점을 극복하기 위해서 최근에는 댄스 인베이딩이 더욱 많이 쓰이고 있습니다. 일반적으로 스파스 레퍼젠테이션 스파스 인베딩의 단점을 거의 많은 부분을 보완한다고 보시면 될 텐데요. 일단 첫 번째로는 스파스 같은 경우는 보캡 사이즈와 똑같은 또는 엔그램을 고려했었을 때는 보켓 사이즈 이상의 훨씬 더 큰 벡터 사이즈로 매핑이 되는 반면에 댄스 같은 경우는 훨씬 더 작은 차원의 고밀도 벡터로 매핑이 되게 됩니다. 보통의 크기는 50에서 천까지 다양하지만 천 이상으로 아주 높게 올라가는 경우는 드뭅니다. 또한 여기서는 이젠 더 이상 백업 월즈처럼 각 차원이 특정 텀에 대응되는 것이 아니고요. 차원이 모두 합쳐져서 벡터 스페이스 상에서의 위치가 의미를 나타내도록 복합적인 그리고 부분적인 의미를 갖게 됩니다. 또한 고밀도 벡터이기 때문에 대부분의 요소가 0이 아닌 의미가 있는 값을 지니게 됩니다. 아래 테이블에서 보시다시피 원래 스파스 인베딩 같은 경우는 각 디멘션마다 하나의 단어에 대응되고 또한 상당히 많은 숫자들이 0인 걸 알 수가 있는데요. 반면에 오른쪽에 있는 댄스 인베딩 같은 경우는 각 디맨션이 특정 텀을 지칭하는 것은 아니고요. 앱스트랙트한 의미를 가지고 있지만 모든 숫자가 0이 아니고 또 상당히 컴팩트하게 개수가 적은 것을 알 수가 있습니다. 그래서 스파스 같은 경우는 사실 어떤 단어의 존재 유무 이런 것들을 알아맞히기는 상당히 리트리버 할 때 상당히 유용합니다만 실제로 의미적으로 해석하기는 쉽지가 않고 따라서 댄스처럼 의미가 같다 하더라도 다른 단어로 표현된 경우를 딕텍트 할 수 있는 방법론을 쓰곤 합니다. 그리고 또 스파스 같은 경우는 항상 디멘션이 댄스에 비해 크기 때문에 결국에는 활용할 수 있는 어떤 알고리즘의 한계가 있는 반면에 댄스 같은 경우는 디멘션이 작기 때문에 훨씬 더 많은 종류의 알고리즘을 활용하실 수 있습니다. 계속해서 비교점인데요. 스파스 인베딩이 댄스 인베딩에 비해서 장점이 있는 것도 사실입니다. 중요한 텀들에 정확하게 일치해야 되는 경우 사실 스파스만큼 확실하게 할 수 있는 경우가 드문데요. 그래서 현업에서 사실 스파스 인베딩도 많이 쓰입니다만 다만 스파스 혼자만으로 많은 걸 하기 쉽지가 않습니다. 그래서 일반적으로는 스파스 인베딩을 쓰면서 동시에 댄스 인베딩을 쓰거나 또는 댄스 인베딩만으로 위트이버를 구축하는 것을 일반적으로 추천을 드립니다. 특히나 최근에 사전 학습 모델의 등장으로 인해서 댄스 인베딩을 배우는 게 훨씬 더 용이해졌고 훨씬 더 하이 퀄리티 댄스 인베딩을 배울 수 있게 됐습니다. 스파스 인베딩은 대부분의 경우는 학습을 뉴럴넷을 학습하듯이 하는 식이 아니라 배어버즈나 텀프리퀀시 등을 고려해서 상당히 엔지니어링적인 측면이 강하기 때문에 이러한 혜택을 받을 수 없었던 반면에 결국 최근 사전 학습 모델의 등장으로 댄스 인베딩 쪽은 많은 혜택을 받고 실제로 리트리블 액큐리시도 많이 올라간 것을 저희가 알 수가 있습니다. 실제로 저희가 댄스 인베딩을 위한 인코더 모델을 만든다고 하면은 이런 식으로 저희가 진행을 하게 될 텐데요. 왼쪽에는 퀘스천에 대응되는 인코더가 있습니다. WTS SI EN sic stanf라는 퀘스천이 들어왔었을 때 볼트 퀘스천에 해당하는 인코더가 이 센텐스를 인코딩을 해서 실스 토큰에 해당되는 벡터를 보고 그 인베딩을 치큐라는 벡터로 지칭할게요. 그 HQ라는 벡터를 내보내게 되고요. 마찬가지로 패시지 쪽도 동일한 방법으로 다만 다른 형태의 다른 파라미터를 활용한 버튼을 활용을 해서 패셋이 똑같이 실스 토큰을 활용을 해서 치b라는 벡터를 내보내게 됩니다. 여기서 중요한 것 중 하나는 이 두 개의 벡터가 같은 같은 사이즈여야 한다는 건데요. 같은 사이즈일 경우 2개의 유사도를 저희가 잴 수가 있는데 가장 일반적으로 많이 쓰이는 유사도 재는 방법은 두 개를 다 프로덕트를 하는 것입니다. 그래서 밑에 보시다시피 HQ 쪽을 트랜스포즈 한 다음에 치b를 멀티플라이 해 줌으로써 스케일러 밸류를 구할 수 있도록 합니다. 물론 이 숫자는 현재 퀘스천과 특정 패시지의 유사도를 잰 거고요. 저희가 모든 패시지에 대해서 유사도를 재고 싶다면 패시지를 하나씩 하나씩 넣어서 점수를 다 구한 다음에 가장 높은 점수를 가지는 패시지를 엠알씨 모델에 활용하면 되겠습니다. 실제로 여기서 훈련을 해야 되는 대상은 이 버트 부분이고요. 보통 퀘스천이랑 패시지를 다른 인코더를 쓰는데 사실 같은 인코더를 쓰는 경우도 있고 다만 아키텍처 라리는 두 개가 동일하고요. 그리고 결국 이 두 개의 아웃풋을 스코어를 내서 두 개의 아웃풋을 비교를 해서 스코어를 내는 방법으로 가장 유사한 문서를 찾는 방법을 저희가 하려고 합니다. 그래서 이제 이런 것들을 저희가 고업을 했고요. 이런 걸 통해서 저희가 어떻게 하면 댄스 인코더를 학습할 수 있을지를 한번 보도록 하겠습니다. 섹션 2로 댄스 인코더 학습 방법론입니다. 제가 지금까지 예제로 보여드렸던 건 사실은 버트라는 모델을 계속 활용을 했는데요. 사실 버트만이 옵션은 아니고 다양한 프리트윈 앵그리시 모델 흔히 약자로 PLM이라 불리는 모델을 활용해서 파인튜닝을 해 가지고 활용을 할 수도 있습니다. 여기서 저희가 버트를 사용하는 방법은 사실 MRC랑 상당히 유사한데요. 다만 조금 다른 점은 MRC 같은 경우는 저희가 패시지랑 퀘스천을 둘 다 인풋으로 넣어줬던 반면에 이번의 경우는 저희가 각각 패세지랑 퀘스천을 넣어주고 각각의 임베딩을 구하고 싶기 때문에 독립적으로 넣어주게 되고요. 또한 다른 점은 기존에는 저희가 패시지 내에 답변이 어디에 있을지 예측하기 위해서 일종의 각 토큰별로 스코어를 내는 것이 목적이었다면 이번에는 인베딩을 아웃풋 하는 것이 목적이기 때문에 CS 토큰 쪽을 보면서 CLS 토큰 쪽에 최종 인베딩이 무엇인지를 아웃풋 함으로써 패시지를 인코딩하게 됩니다. 패시지뿐만 아니라 퀘스천도 똑같은 방식으로 인코딩을 하고요. 다만 같은 파라미터를 쓸지 또는 별개의 파라미터를 쓸지는 조금 더 디자인 초이스로 보시면 되고 경우에 따라서 하나가 더 다른 것보다 잘될 수도 있습니다. 그래서 퀘스천이랑 패시지를 버터를 활용해서 벡터를 내보내게 되고 이 벡터 두 개를 유사도를 측정을 함으로써 최종 유사 점수를 낼 수 있도록 됩니다. 학습 시에는 여기서는 버트를 파인 t 해가지고 실제 정답인 패시지 같은 경우는 저 유사도 점수가 더 높도록 학습하고 정답이 아닌 패시지일 경우는 유사도 점수가 최대한 마이너스 쪽으로 갈 수 있도록 학습해서 최종적으로 모델을 완성하게 됩니다. 따라서 이제 저희가 학습 목표를 좀 구체적으로 정리를 하려고 한다면은 실제로는 연관된 퀘스천과 패스에서 댄스 인베딩 간의 거리를 좁히는 것이라 볼 수 있겠고요. 또는 이너 프로덕트를 높인다고 볼 수 있겠습니다. 리얼스 네이버를 저희가 l2 스페이스에서 거리를 좁히는 쪽으로 간다면 리얼스 네이버라고 볼 수가 있고 다만 저희가 이번 강의에서는 주로 이너 프로덕트를 활용할 것이기 때문에 실제로는 두 개의 이너 프로덕트 스코어를 높이는 쪽으로 간다고 생각해 주시면 되겠습니다. 하지만 여기서 하나의 챌린지가 있는데 결국에는 이 학습 데이터를 활용할 퀘스천과 패시지의 페어를 어떻게 찾을 것인가가 중요한 문제가 되겠습니다. 그래서 여러 가지 방법론이 있습니다마는 저희가 이제 접근하는 방법은 기존 MRC 데이터셋을 활용을 하려고 해요. 그래서 기존 MRC 데이터셋을 활용을 하게 되면 어쨌든 그 MRC 데이터셋에 있는 퀘스천과 패세지 페어는 정답 셋이라 볼 수 있고 즉 이 패시지는 해당 질문에 해당되는 패시지라 볼 수 있을 것 같고요. 그 외의 패시지들은 관련이 없는 패시지라 보실 수 있겠습니다. 따라서 어 저희가 관련이 없는 패시지를 샘플 하기 위해서는 기본적으로 랜덤하게 샘플을 해오고 관련이 있는 패시지 같은 경우는 그 퀘스천이 속해 있던 패시지를 사용을 해서 한쪽은 거리를 좁히고 한쪽은 거리를 멀리하는 방식으로 학습을 진행하도록 합니다. 그럼 어떻게 저희가 이 negative 이 샘플들을 뽑아야 될까요? 랜덤하게 뽑는 방법이 있겠고요. 그리고 좀 더 헷갈리는 negative 샘플을 뽑는 방법이 있을 텐데 이런 경우는 예를 들면 tfidf 스코어는 높지만 실제로 답을 포함하지 않는 샘플 같은 경우는 비교적 모델 입장에서 구분하기 어려운 샘플들이겠죠 이런 샘플들을 선택적으로 뽑아주는 게 더 도움이 될 수도 있습니다. 실제로 최근 워크들 중에서 이번 방법론을 택해서 더 정확성을 올린 케이스들이 꽤 많이 있습니다. 구체적으로 저희가 학습을 할 오브젝트 펑션에 대해서 알아볼게요. 저희는 결국에는 파스티 패셋에 대한 네게 팁 로그 라이크리드 후드 로스를 사용을 하려고 하는데요. 이 경우 결국 파스틱 패시지의 스코어를 확률화를 하기 위해서 파스티 패시지와 퀘스천 간의 시뮬라리티 스코어 이 스코어 같은 경우는 리얼 넘버겠죠 마이너스일 수도 있고 positive일 수도 있는데 높을수록 더 유사도가 높은 이 점수랑 negative 샘플에 대한 점수를 가져와서 소프트맥스를 하여 그 소프트맥스 한 값의 확률 값을 네기티브 로그 라이클 후드에 적용해서 학습하는 방법을 택합니다. 보시다시피 오른쪽에 이제 저희가 학습 코퍼스를 퀘스천과 positive 패시지 그리고 negative 패시지로 이렇게 나눈다고 한다면은 실제 로스를 컴퓨터 한 방법은 negative 로그 그리고 소프트맥스를 하여 소프트맥스 같은 경우 실제로 positive에 해당되는 스코어가 분자에 있고요. negative에 해당하는 스코어들이 분모에 있는 것을 확인하실 수 있습니다. 네게티브뿐만 아니라 positive도 포함을 해서요. 전부 다 포함해서 분자 분모에 있고 positive만 분자에 있는 것을 확인하실 수 있습니다. 실제로 저희가 이런 리트리버 엔진을 만들었을 때 성능을 측정하는 방법은 여러 가지가 있을 텐데요. 가장 심플한 측정 방법은 실제 저희가 골든 그라운트스 패시지를 알고 있기 때문에 리튜브 된 패시지 중에서 그라운트 투 스패시지가 있는지 없는지를 보는 방법이 있을 거고요. 또는 조금 더 나아가서는 사실 MRC에 관련된 이밸류에이션 매트릭으로는 리튜브 된 패시지 중에서 답을 포함하는 패시지의 비율을 볼 수 있겠습니다. 여기서 답이라 함은 최종 MRC 답변인 거죠. 다른 말로는 결국 MRC 모델이 우리가 익스트랙티브 한 형태를 택하게 된다면은 패시지 내에 답이 없다면 절대 답을 낼 수가 없겠죠. 그래서 어 어퍼 바운드라고 보시면 될 것 같습니다. 이제 마지막 섹션으로 패시지 리트리버 위 댄스 인코더를 다루도록 하겠습니다. 실제로 저희가 인코딩을 하고 난 다음에 리튜벌 하는 과정은 상당히 심플한데요. 저희가 패세지 여러 개가 있고 각각의 패시지에 임베딩을 먼저 컴퓨터 한 다음에 이거는 한 번 오프라인으로 해두는 거겠죠. 저희가 퀘스천 들어올 때마다 다시 하는 것이 아니라 콜퍼스가 정해지면 콜퍼스를 한 번 돌려서 오프라인으로 저장을 해 놓고요. GPU 상에 저장을 한다고 하면은 퀘스천이 들어올 때마다 GPU 상에서 기존 저장된 폐쇄지 벡터와 쿼리 벡터를 거리를 재고 또는 이너 프로덕트 를 잰 다음에 가장 유사도가 높은 패시지를 돌려주는 방식으로 가게 됩니다. 이렇게 저희가 찾은 패시지를 활용을 해서 최종적으로 MRC 모델에 넣어줌으로써 저희가 렉처 1 2 3에서 다뤘던 모델을 같이 연결을 할 수가 있습니다. 이렇게 되면은 저희가 만약에 올바른 패시지를 찾았고 저희가 좋은 MRC 모델을 만들었다면 최종적으로 질문만 던진다 하더라도 아주 큰 위키피디아 같은 스페이스에서 답을 찾아서 올바른 답을 내줄 수 있겠죠. 댄스 인코딩을 더 개선하는 방법 여러 가지가 있을 텐데요. 여기서 일단 학습 방법을 개선하는 방법이 있을 테고요. 이런 경우는 저희가 레퍼런스에 달아둘 페이퍼를 참조해 주시면 좋겠습니다. 또는 인코더 모델을 버트보다 더 최근에 만들어진 더 큰 모델 또는 더 해당 테스크에 적합한 모델을 활용하는 방법도 있을 거고요. 그리고 더 많은 데이터나 더 좋은 전처리 방법을 통해서 데이터를 개선하는 방법도 있겠습니다. 이 수업에서 결국 마지막에 여러분은 챌린지를 하시게 될 텐데 챌린지를 하실 때 MRC 모델의 성능을 향상시키는 것도 중요하지만 그만큼이나 어떻게 하면 더 올바른 문서를 찾아올 수 있을까도 중요할 거고 이 문서를 잘 찾아오는 방법을 계산을 하는 것이 상당히 중요한 프로젝트의 세부 목표가 되겠습니다. 네 본강 마치도록 하겠습니다. 감사합니다. 네 5강 실습 시작하겠습니다. 자 이제는 많이 익숙해지셨을 텐데요. 콜랩으로 다시 들어오셔가지고요. 먼저 가장 먼저 하는 게 있죠 저희가 런타임을 가셔서 GPU로 바꿔주도록 하겠습니다. 오늘은 지난번 렉처와 달리 GPU를 활용을 할 거니까요. GPU로 바꾸는 거를 꼭 기억해 주시고 네 커넥트를 하도록 하겠습니다. 네 연결됐네요. 자 이제 먼저 그리고 제가 또 항상 하는 게 있죠 자 패키지부터 인스톨을 할게요. 2개 인스톨 하고요. 데이터 셋이랑 트랜스포머 설치가 됐고요. 다음으로는 콜 코드 다운 받을게요. 마찬가지로 똑같은 루튼이고 여기까지는 그리고 다시 좀 초기에 사용했던 버트 멀티링구어를 사용하도록 하겠습니다. 그래서 마찬가지로 저희가 트랜스포머에서 오토 토크나이저를 가져오고 넌 파이도 가져오고요. 이제 모델 이름은 볼트 베이스인데 멀티 링구얼이고 그리고 케이스입니다. 토크나이저는 모터 토크나이저의 모델 체크 포인트를 입력하셔서 이 모델에 해당되는 토크나이저를 불러오시면 되겠습니다. 그래서 저희가 토크나이저를 한번 보시면은 네 잘 불러온 것을 확인할 수가 있고요. 그래서 한번 저희가 한번 그 샘플로 한번 해볼게요. 토크나이저를 사용해서 인풋을 한번 토크나이즈 해보도록 하겠습니다. 데이터 셋에서 트레인 쪽 스플릿 쪽을 들어가서 첫 번째 이그젬플을 보고 여기에 컨텍스트 즉 지문 패시지를 보는 거죠. 그리고 저희가 토크 아이즈를 하면서 패딩을 해줄 겁니다. 이거는 편의상 나중에 학습할 때 필요하기 때문에 그리고 트렁케이션은 트루로 할게요. 너무 길면 자른다는 얘기죠. 그리고 토크나이저에서 이 인풋 다시 디코드를 하는 방식으로 해볼게요. 이렇게 하게 되면은 실제로 원래 텍스트가 토크 아웃이 됐다가 다시 디코드 돼서 원래 텍스트로 돌아온 걸 볼 수가 있고 다만 스페셜 토큰대로 남아 있는 거를 볼 수가 있습니다. 제가 댄스 인코더를 학습할 때는 기본적으로 벌트를 활용을 해서 할 텐데 일단 몇 개의 중요한 패키지들을 제가 인포트 해오도록 할게요. 보시면 카페 페이스트를 할 텐데요. 하나씩 설명을 해 드릴게요. 이 티큐디 같은 경우는 간단하게는 그 저희가 프로그레스를 볼 수 있는 그런 유틸리티고요. 이따가 보시게 될 거예요. RLG 펄스랑 윈덤 같은 경우는 파이썬에서 활용할 수 있는 그런 유틸리티 펑션들이고 토치는 파이토치죠. 다음으로 토치의 엔엔의 펑셔널을 가져오게 되고 트랜스포머에서 버트 모델이랑 이제 프리트레인 모델 쪽 아담 더블 트레이닝 어그먼트 겟 리니얼 스케줄 업 학습에 용이한 이런 펑션을 가져오게 됩니다. 그리고 저희가 리폴더 시플리티를 위해서 시드를 정의해 주도록 할게요. 저희가 어쨌든 시드를 모든 레벨에서 다 정의를 해줬는데요. 토치랑 넌 파이랑 그리고 일반 파이썬 랜덤까지 다 시드를 정해 주도록 하겠습니다. 다음으로 저희가 학습 데이터를 간단하게 준비를 할 텐데 모든 데이터를 쓰지는 않을 거고요. 오늘 실습에서는 그래서 샘플을 할 건데요. 샘플을 대략 한 128개 정도 샘플을 하도록 할게요. 그래서 이 경우는 트레인 스플릿에서 128개를 샘플하는 방식으로 하고 그 총 트레인 데이터의 길이에서 128개의 숫자를 샘플 하셨다고 생각하면 돼요. 그 숫자들이 인덱스인 거죠. 다음으로는 실제로 트레이닝 데이터 데이터셋을 이 샘플 아이디스 것만 가져와서 저희의 새로운 트레이닝 데이터셋을 만듭니다. 더 작은 데이터겠죠 훨씬 원래 거보다 그래서 보시면 이렇게 한 다음에 저희가 한번 프린트를 해볼게요. 원래 트레이닝 데이터의 사이즈랑 새로운 트레이닝 데이터의 사이즈요. 보시면 원래는 원래는 6만 4천 6만 407개였는데 이제 보시면 저희가 이 길이를 많이 줄인 것을 알 수가 있습니다. 네 다음으로 저희가 간단하게 이 토크나이제이션을 할 텐데요. 토크나이제이션은 저희가 예전에 예전 렉처에서도 많이 했었죠 그래서 이제 이번에는 저희가 먼저 터치 유티스 데이터에서 필요한 좀 유틸리티 클래스를 가져오고요. 퀘스천 토큰 같은 경우는 토크나이저를 활용을 해서 트레이닝 데이터 셋에 퀘스천을 보게 되는데 여기서 마찬가지로 패딩을 해주고요. 트렁케이션도 해주고 파이 터치를 활용할 거기 때문에 리턴 텐서를 피티로 설정을 해주도록 하겠습니다. 마찬가지로 패시지 쪽도 할 텐데요. 달라지는 거는 퀘스천이 아니라 컨텍스트를 본다는 거 다른 것들은 똑같겠죠 네 토크나이제이션을 완료했고요. 이제 그다음에 저희가 데이터셋을 학습하기 위해서 텐서 데이터셋으로 좀 변경을 해 줄게요. 그래서 이 두 개를 만든 다음에 저희가 트레인 데이터 셋 같은 경우는 이 두 개를 합쳐주는 건데요. 간단하게는 이거는 학습할 때 더 용이하도록 좀 형태를 바꾸는 정도로만 생각하시면 될 것 같아요. 피 시퀀스의 인풋 아이디즈를 가져오고요. 패세지 쪽이죠. 그리고 마찬가지로 어텐션 마스크도 가져오게 되고 그리고 마지막으로는 토큰 타입 아이디스를 가져오게 됩니다. 퀘스션 쪽도 마찬가지로 진행을 해 주는데요. 이렇게 해주면은 이게 전부 다 저희가 학습할 때 좀 편하게 액세스 할 수 있는 거고 사실상 그냥 붙인다 생각하시면 될 것 같아요. 텐설 데이터 셋이 해주는 역할은 이 6개의 벡터들 6개의 인풋 값들을 좀 학습할 때 편리하게 액세스 할 수 있도록 해준다 생각하시면 되고 네 자 이제 학습을 해볼까요? 자 이제는 저희가 모델을 한번 디파인 해 볼게요. 버트 인코더를 만들 건데 벌트 트리 트레인드 모델을 가져오고요. 저희가 직접 버트 인코더를 만들어야 되는데요. 각각 패시지랑 퀘스천을 위한 사실 엄청 간단합니다. 사실상 실스 토큰에 해당되는 임베딩만 가져오면 되거든요. 컴퓨게이션이 이렇게 있고 항상 이렇게 해주면 되고요. 자 여기서 버트 같은 경우는 버트 모델을 새로 시작을 해 주고 이제 웨이트를 이니셜라이즈 해줍니다. 다음으로 포워드를 정리를 해주는데요. 보시면 인풋 마스크 인풋 아이디는 항상 필요하고 어텐션 마스크랑 사실 토큰 타입 아이디는 없어도 일단은 진행할 수 있는 방식으로 돼 있습니다. 잠깐만 제가 엔터 눌러버렸네요. 죄송요. 여기서 아웃풋 계산은 상당히 간단합니다. 일단 먼저 버튼을 한번 적용을 시켜주고요. 이거는 그냥 완전 바넬라 버트를 적용을 시켜주는 거고 다음으로는 여기서 실제로 저희가 필요한 거는 전체 아웃풋이 아니라 시레스 토큰에 해당되는 임베딩이기 때문에 이렇게 가져오고요. 그다음에 실제로는 저희는 프로드 아웃풋만 내보내주도록 됩니다. 자 이제 그럼 저희 모델은 끝났어요. 자 이제는 실제로 저희가 이 모델을 인스텐세이트를 해주고요. p 인코더 같은 경우는 버트 코더를 활용을 해서 프롬 프리 트레인드를 해가지고 아까 저희가 봤던 모델 체크 포인트 즉 버트 베이스 멀티링구어를 가져오고요. 시작점은 여기인 거죠. 둘 다 파인튜닝을 해줄 거기 때문에 시작점을 정의를 해 주는 거고요. 네 똑같이 해주고요. 이제 저희가 GPU를 쓸 거기 때문에 쿠다가 어벨립을 한 경우는 둘 다 지표에 넣어주도록 합니다. 그래서 실제로 지피 이네이블 됐다고 표시가 뜨겠죠 일단 먼저 다운을 받아 주긴 해야 돼요. 모델을 네 지피 이네이블드라는 표시가 뜬 걸 확인하셔야 됩니다. 이게 돼 있지 않으면 GPU를 사용하고 있지 않다는 뜻이고요. 자 이제 학습 루틴을 정리를 해줄 텐데 학습 루틴은 좀 길어서 제가 카피엔 페이스트를 하고 간단하게 좀 설명을 드리도록 하겠습니다. 자 학습 루틴인데요. 자 먼저 저희가 데이터 로더를 통해서 이제 그 학습 시에 어떻게 학습 데이터를 피딩할지를 결정을 하고 다음으로 여기는 옵티마이제이션 관련된 파라미터들을 설정을 해 주고요. 그다음에 옵티마이저를 정의를 하고 아담 w를 쓰도록 하고요. 그다음에 저희가 얼마 동안 학습을 할 건지 진행할 것에 대한 파라미터를 설정을 해주고요. 이제 학습을 이제 시작하는 건데 글로벌 스텝은 0에서 시작을 하고 항상 처음에 시작할 때 그라디언트를 지로로 해주시는 거를 잊지 마시고요. 그다음에 이제 캐시를 엠티 해 준 다음에 실제로 이제 이트레이션을 시작을 합니다. 시작을 하면은 각 이트에이션마다 저희가 어쨌든 중요한 거는 이제 트레인 모드로 항상 해주면서 쿠다가 어벨롭을 할 경우에는 쿠다로 바꿔주는 거 잊지 마시고 인풋을 이제 배치해서 가져오게 되는데 이 배치가 아까 텐셜 데이터셋을 이용한 각 배치로 나눠진 그 안에 있는 값들이고요. 그 순서대로 이제 들어가 있기 때문에 실제로 첫 번째 거는 패시지 쪽의 인풋 아이디 그리고 네 번째 거는 퀘스천 쪽의 인풋 아이디 이렇게 저희가 좀 컨비넌트하게 액셋을 할 수가 있습니다. 그다음에 실제로 저희가 이거를 모델에 넣어 줌으로써 그 패시지 인베딩과 퀘스천 인베딩을 가져오게 되는데요. 여기서 중요한 건 사실 각 배치마다 퀘스천의 개수가 여러 개 있기 때문에 배치 사이즈 개수만큼 있기 때문에 실제로 그 벡터의 개수도 배치 사이즈 개만큼 있습니다. 그러면은 이렇게 보시면 될 텐데요. 각 퀘스천에 대응되는 패시지가 있는 것이고 근데 다른 패시지들은 사실 지금 현재 쿠션에 대응되지는 않겠죠 그래서 저희가 여기서는 인벤치 네게르티브라고 하는 방법을 쓸 건데 학습할 때 즉 현재 퀘스천과 현재 배치 안에 있는 현재 배치라기보다는 현재 이젠플 안에 있는 폐쇄지의 시뮬널티 스코어는 최대화시키면서 현재 퀘스천과 다른 다른 이그젬플에 있는 패시지의 인베딩의 시미널티 스코어는 최소화시키는 방식을 택하려고 합니다. 이제 이렇게 하게 되면은 좀 더 효율적으로 학습을 할 수가 있고 이걸 인벤치 negative라고 부릅니다. 그래서 저희가 이제 먼저 시뮬리이티 스코어를 구할 텐데 보시면은 저희가 실제로 구해야 되는 그 서로 콤비네이션은 단순하게 각각 안에서 퀘스천과 패시지 사이에 스멀티 스코어를 구할 뿐만 아니라 모든 퀘스천과 모든 패시지 서로의 가짓수를 전부 다 구할 필요가 있어요. 그래서 이렇게 매 뭐를 해 가지고 구하도록 하게 돼 있고요. 그다음에 이 심 스코어를 결국은 실제로 저희가 학습할 때 필요한 부분만 가져와서 실제로 다이아그널한 부분만 학습할 때 필요하겠죠. 왜냐하면 그게 저희가 옵티마이즈 하고 싶어 하는 positive 샘플들이니까 그래서 여기서 다이아그널하게 가져오는 그 코드가 있고요. 그다음에 쿠다로 변경해주는 게 있고 그다음에 실제로 저희가 소프 맥스를 활용을 해서 실제로 확률 값을 바꿔준 다음에 이거에 대한 로스를 아래에 구하게 됩니다. 그리고 로스를 구한 다음에 로스를 100월드 함으로써 저희가 positive한 페어들은 좀 더 높은 스코어를 받는 쪽으로 가도록 하고 네게티한 페어들은 더 더 낮은 점수를 받는 쪽으로 학습하도록 합니다. 스케줄러도 같이 업데이트해 주고요. 그리고 그라디언트를 다시 d로 해줌으로써 이제 원래 그라디언트를 다시 저장할 수 있도록 새로운 그라디언트를 저장할 수 있도록 공간을 마련해 주고 그다음에 글로벌 스텝을 하나 더 함으로써 플러스 캐시a를 MTM이 함으로써 이제 한 스텝을 끝내도록 됩니다. 맨 마지막에는 당연히 이게 끝나고 난 다음에는 저희가 두 개의 모델을 리턴을 해야 되겠죠. 이제 이 트레인 루틴이 사실 저희가 렉처 1에서부터 쓰리에서 봤던 트레이너와 역할이 비슷합니다. 그러니까 저희가 원에서 3에서는 기존 존재하는 트레이너를 썼고 여기서는 직접 트레이너와 유사한 펑션을 직접 만들어 보는 방식으로 실습을 진행을 하고 있습니다. 그다음에는 마찬가지로 예전에 많이 보셨던 것처럼 트레이닝 아규먼트를 정의를 해 주는데 이거는 카피 앤 페이스트에서 또 보여드리도록 하고요. 보시다시피 특별할 건 없고 전반적인 학습에 쓰이는 그런 하이퍼 파라미터들 배치 사이즈 등과 같은 것들을 정리를 해줍니다. 자 이제 학습을 시작하도록 하겠습니다. 학습은 모델이 아웃풋이고요. 학습에 학습을 하는데 아규멘트를 넣어주고 트레인 데이터 셋을 넣어주고 피인 코더와 큐 인코더를 넣어주는 방식으로 진행을 합니다. 자 시작하게 되면은 네 저희가 GPU를 쓰고 있기 때문에 상당히 빨리 진행이 되죠. 그래서 학습이 금방 끝나는 거를 확인하실 수 있습니다. 저희가 총 두 에 포크이기 때문에 저 프로그래스 바만 채워지면 끝나게 되고요. 한 1분 정도 걸렸죠 네 학습을 1분 만에 끝냈습니다. 저희 GPU를 활용을 해서 자 이제 그러면은 학습된 모델을 활용해서 실제 리트리버를 한번 해보겠습니다. 그럼 먼저 저희가 모델을 학습했으니 이제는 어떤 문서들을 대상으로 리트입을 할지를 정의를 해야 되겠죠. 그래서 발리드 콜퍼스 같은 경우는 익숙하시죠 지난 렉처에서 했던 거와 똑같은 모든 콘텍스트를 데이터셋 내에 있는 모든 콘텍스트를 가져오는 방식을 사용하는데요. 제가 이번에는 학습을 했기 때문에 밸리데이션 셋을 쓰도록 하겠습니다. 트레이는 학습에 활용을 했기 때문에 그리고 일단 10개만 볼게요. 그리고 여기서 저희가 쿠션 하나를 고르도록 할게요. 그래서 하나를 고르도록 하고 실제로 idx를 먼저 랜덤리 고른 다음에 이 아디스를 이용을 해서 해당 데이터 셋을 접근하는 방법이죠. 네 마찬가지로 그라운트 루스도 이런 방식으로 접근을 해서 가져오도록 하겠습니다. 네 그럼 한번 저희가 한번 일단 프린트를 해볼게요. 자 그럼 이렇게 하면은 저희가 이 질문과 질문에 대응되는 그라운트 루스를 볼 수가 있는데요. 보시면은 질문은 유아인에게 타고난 배우라고 말한 드라마 밀회의 감독은 이고 이 질문에 대한 답을 갖고 있는 컨텍스트는 화보 촬영을 위해 미국에 있을 때 이렇게 이어지는 지문입니다. 그리고 저희가 한번 확인해 보고 싶은 거는 그러면 저희가 이게 실제로 콜퍼스 내에 있는지 없는지를 한번 확인해 봐야겠죠. 그래서 만약에 없다고 한다면 콜퍼스에 더하도록 할게요. 네 자 이제 그러면은 저희가 앞서 만들었던 인코더를 활용해서 인베딩을 진행해 보도록 하겠습니다. to 코더라는 간단한 펑션을 만들어서 GPU 상에 올릴 수 있도록 해 주고요. 자 이제 각각의 패스에 대한 인베딩을 한번 확보해 보도록 할게요. 이밸류에이션 할 때는 노그래드를 해주시는 걸 추천을 드리고요. 그 계산할 일이 없을 테니까 이벨레이션 할 땐 그리고 QA 코더 전부 다 이별 모드로 바꿔주시고 이제 각각의 토큰들을 정의하게 됩니다. 이제 쿼리에 해당하는 토큰들은 쿼리를 넣어주게 되고 토크 와이저 안에 아까처럼 패딩 같은 경우는 맥스 트렁케이션은 트루 리턴 텐서는 PT겠죠 그리고 쿠다에 올려주도록 할게요. 쿠션 인배딩 같은 경우는 여기서 인코더 인코더에 이 값들을 넣어준 다음에 이 토큰들을 넣어주고 아웃풋을 가져오면 되겠죠. 근데 다만 저희가 다시 CPU로 보내도록 하겠습니다. GPU 상에 있었던 거를 마찬가지로 똑같은 거를 패세지 쪽에 해주면 되는데요. 각 패시지를 보면서 이제 토크나이저를 진행을 해주고 트렁케이션 똑같이 해줍니다. 그리고 마찬가지로 마지막에 쿠다로 올려주고요. 각 폐쇄제 인베딩은 똑같은 방법으로 구해줍니다. 그리고 넌 파이로 바꿔주도록 할게요. 그리고 이 인베딩들을 전부 다 저장 저장을 해서 맨 마지막에는 하나의 매트릭스로 변형을 시켜주도록 하겠습니다. 스퀴즈를 하도록 하고요. 개수가 디멘션이 하나인 경우는 없애주는 펑션이죠. 그다음에 저희가 한번 만든 거에 사이즈를 한번 볼게요. 잠깐만요. 하나 에러가 있었네요. 죄송해요. 치겠습니다. 네 그럼 사이즈가 101 768은 폐쇄지 인베딩 매트릭스의 크기고 1768은 쿼리 쪽의 크기인데 여기서 의미하는 바는 저 11이 의미하는 거는 패세지 개수고요. 저희가 원래 처음에 10개를 했다가 정답으로 쓸 거가 그 10개 없으니까 하나를 더 해줘서 11개가 된 거겠죠. 그리고 768 같은 경우는 임베딩의 사이즈고요. 마찬가지로 퀘스션 쪽도 인베딩 사이즈는 768이고 퀘스천이 하나만 있으니까 앞에 사이즈는 1입니다. 네 이제 저희가 인베딩들을 구했으면 패시지 쪽과 퀘스천 쪽 양쪽의 인베딩들을 구했으면 이제는 시너리티 스코어를 재봐야겠죠. 그래서 다 프로덕트 스코어를 재기 위해서 mt m를 해줍니다. 간단하게 이 두 개 같은 경우는 크기가 그렇게 크지가 않다 보니 상당히 쉽게 수행할 수 있겠죠. 그래서 트랜스포즈를 해주는 이유는 저희가 멤버를 하기 위해서 피 인베딩 쪽을 768 바이 11로 바꿔준 다음에 두 개를 곱하게 됩니다. 매트릭스 멀티플리케이션으로요. 그래서 저희가 이거 한번 사이즈를 확인해 보면요. 예상한 대로 1에 11이 나오죠. 그래서 11개 문서에 대한 저희 해당 쿼리의 유사도라고 보시면 될 것 같습니다. 유사도 점수를 각각 디멘션이 담고 있다고 보시면 될 것 같아요. 자 이제는 랭킹을 해야 되겠습니다. 가장 높은 걸 찾아야겠죠 그래서 랭크는 알그 솔트를 이용을 해서 순서대로 정렬해 주도록 하고요. 그다음에 스콜스를 한번 프린트 해 보도록 할게요. 네 보시다시피 스코어는 23 22 22 이렇게 돼 있는 걸 볼 수가 있고 각각의 스코어들의 랭크는 5위 4위 7위 해가지고 맨 마지막 게 1위인 걸 볼 수가 있어요. 그럼 맨 마지막 저 문서가 정답이라는 얘기겠죠 아마 네 저희가 한번 결괏값을 한번 보도록 할 텐데요. 프린트를 해주는 건데 보시면은 저희가 그 쿼리를 프린트를 하고요. 여기서 그리고 그라운트 로스를 프린트를 하고 그리고 랭크대로 프린트를 하는 거라고 보시면 될 것 같습니다. 그래서 한번 보시면은 일단은 쿼리는 이거였고 그라운트 루스는 화보 촬영을 위해 미국에 있을 때라는 질문인데 다만 저희가 학습을 오랫동안 하지 않아서 정답이 탑 쪽에 나오지 않았고 좀 아래쪽에 to 7에 있긴 해요. 하지만 이걸 학습을 많이 하게 되면은 이 top 7으로 나왔던 랭킹이 좀 더 올라가서 나중에 뭐 1이나 2 이렇게 올라가는 거를 보실 수 있을 겁니다. 네 그럼 오늘 5강 실습은 여기까지 하도록 하겠습니다. 네 감사합니다."
}