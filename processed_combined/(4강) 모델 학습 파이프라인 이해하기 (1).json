{
  "lecture_name": "(4강) 모델 학습 파이프라인 이해하기 (1)",
  "source_file": "(4강) 모델 학습 파이프라인 이해하기 (1)_30.mp4_2025-12-04-103247240.json",
  "text": "안녕하세요. 도메인 공통 프로젝트 4강 모델 학습 파이프라인 이야기 1번 시작하겠습니다. 이번 강의에서는 모델 성능 평가, 모델 학습 파이프라인 이 두 가지에 대해서 다뤄보겠습니다. 먼저 모델 성능 평가입니다. 온라인 오프라인 평가에 대해서 먼저 이야기를 해보겠습니다. AI 조직에서 모델 성능을 이야기할 때 온라인 성능, 오프라인 성능이라는 말을 사용합니다. 여기에서 온라인 성능이란 모델 배포 단위에서 실제 입력 데이터로 평가하는 모델의 성능입니다. 모델을 학습하는 단계에서 알 수 없는 지표이고요. AI 모델의 배포 상황에서의 성능을 나타냅니다. 정확하게는 AI 모델의 직접적인 매트릭이 아닐 수 있습니다. 다음은 오프라인 성능입니다. 모델 학습 단계에서 검증 데이터 혹은 테스트 데이터로 평가하는 모델의 성능을 이야기합니다. 모델을 학습하는 단계에서 알 수 있는 지표이고요. AI 모델의 학습 단계에서의 성능을 나타냅니다. 이때는 AI 모델의 성능 매트릭을 이야기합니다. 오프라인 평가를 하는 이유에 대해서 먼저 이야기해 보겠습니다. 일반화 성능을 사전에 측정하기 위해서입니다. 실제 서비스에 배포하기 전에 리스크를 최소화하기 위함인데요. 여기서의 리스크는 우리 모델의 성능이 떨어져서 서비스 품질 저하로 인해 비즈니스 손실, 사용자 경험 악화를 의미합니다. 학습 파이프라인을 점검하기 위한 목적도 있습니다. 모델이 학습 데이터의 패턴을 제대로 이해하지 못하진 않았는지 이 부분을 우리가 언더피팅 혹은 과소적합이라고 이야기를 하고요. 학습 데이터의 노이즈까지 학습하여 일관성이 떨어지지 않는지를 평가합니다. 이것을 우리가 과적합 혹은 과대 적합 오버피팅이라고 이야기를 합니다. 그리고 모델 선택의 기준을 제공하기도 합니다. 여러 모델 중 가장 성능이 좋은 모델을 선택하거나 하이퍼 파라미터를 선택할 때의 기준을 제공합니다. 다음은 온라인 평가를 하는 이유입니다. 첫 번째로는 비즈니스 성과를 확인합니다. 모델의 성능이 실제 비즈니스 목표를 얼마나 잘 충족하였는지를 평가합니다. 예를 들어 고객 이탈 예측의 경우 높은 정확도뿐만 아니라 실제로 이탈을 줄이는 데 얼마나 기여할 수 있는지를 평가합니다. 다음은 의사 결정의 용이성입니다. 다양한 관점이 공존하는 조직에서 합리적인 의사 결정을 내리는 데 근거를 제공합니다. 오프라인 평가 지표에 대해서 이야기해 보겠습니다. 분류 모델의 평가 지표입니다. 첫 번째는 정확도입니다. 전체 예측에서 올바르게 예측되는 비율을 이야기합니다. 다음은 정밀도입니다. 예측된 클래스에 대한 실제 클래스의 비율입니다. 다음은 재현율입니다. 실제 클래스에 대해 올바르게 예측된 클래스의 비율입니다. 다음은 에프1 스코어입니다. 정밀도와 재현율의 조화 평균입니다. 마지막으로 ROC 에유씨라고 이야기를 하고 일반적으로 우리가 에유씨라고 합니다. 다양한 임계값에서의 트루 퍼시티브 레이트, 퍼스 퍼시티브 레이트 관계를 곡선으로 나타내었을 때 그 아래의 면적을 이야기합니다. 좀 더 자세히 설명하기에 앞서 정밀도와 재현율에 대해서 조금 더 설명을 하겠습니다. 사실 정밀도와 재현율은 약간 어찌 보면 말을 뒤집으면 되게 비슷해 보이는 평가 지표인데요. 저도 사실 이 두 개의 지표를 외우는 데 조금 오랜 시간이 걸렸습니다. 여러분들이 이 정밀도와 재현율을 쉽게 이해하고 외우는 데 한 가지 팁을 좀 드리고 싶어서 말씀을 드립니다. 재현율이 조금 더 직관적이기 때문에 재현율을 이해를 하시면 그 말을 뒤집어서 우리가 정밀도를 이해할 수 있습니다. 재현율 말 그대로 재현율입니다. 우리가 어떤 질병을 예시로 한번 해보겠습니다. 병원에서 우리가 어떤 질병을 예측을 한다 혹은 검사를 받았다라고 해 보겠습니다. 검사를 받는 행위를 우리가 모델로 예측을 했다로 바꿔서 한번 생각을 해볼게요. 실제로 제가 질병이 있습니다. 그래서 이상해서 검사를 받으러 가봤어요. 근데 이 모델이 어 이 사람은 질병이 있습니다 라고 이야기를 하는 거예요. 그러니까 내가 질병이 있는 것을 모델 예측에서 재현이 되었다라고 이해하시면 됩니다. 그래서 실제 클래스에 대해서 올바르게 예측된 클래스의 비율을 우리가 재현율이라고 하고요. 여러분들이 이 말을 뒤집어서 예측된 클래스에 대해서 실제 클래스 비율이 얼마나 되지를 정밀도로 이해하시면 됩니다. 정확도를 조금 더 자세히 보겠습니다. 전체 예측에서 올바르게 예측되는 비율입니다. 가장 직관적이고 이해하기 쉽지만 클래스 분포가 불균형일 때는 사용에 주의가 필요합니다. 이제 다음과 같이 트루 positive, 트루 negative 퍼스트 positive 퍼스트 negative를 분모로 두고요. 투루 positive 트루 negative를 분자로 둡니다. 다음으로 정밀도입니다. 예측된 클래스에 대한 실제 클래스의 비율입니다. 퍼스 퍼시티브가 치명적인 경우에 사용을 하고요. 예를 들어서 정상 메일을 스팸 메일로 판단하는 경우가 퍼스 퍼시티브입니다. 그래서 분모를 보시면 트루 positive 퍼스 positive가 들어가는데요. 여기에서 우리가 집중해야 되는 부분은 positive라고 하는 겁니다. positive는 모델이 positive로 예측한 것 중에 t인 경우라면 실제로 t인 거 f라면 실제는 negative인 거를 이야기를 하는 거예요. 그러니까 모델이 퍼시티블 한 것 중에 실제로 positive인 거 그렇기 때문에 수식이 이런 형태로 구성이 된다라고 이해하시면 됩니다. 다음은 재현율입니다. 실제 클래스에 대해 올바르게 예측된 클래스의 비율입니다. 퍼스 negative가 치명적인 경우에 사용을 하고요. 암 진단에서 양성 실제로 질병이 있는 것을 음성으로 판단하는 것이 매우 치명적이기 때문에 이럴 때는 재현율이 중요합니다. 실제 클래스에 대해서 올바르게 예측해야 되기 때문에 실제 클래스가 퍼시티브인 거를 이야기를 해야 됩니다. 그렇기 때문에 트루 퍼스티브 모델이 퍼시티브를 예측했는데 실제로 퍼스티브인 거 그리고 퍼스 negative 모델이 negative라고 했는데 틀린 거 그러니까 실제로는 양성인 거죠. 그게 분모로 들어가고요. 분자에는 트루 퍼스티브가 들어가게 됩니다. 다음으로는 1 스코어입니다. 1 스코어는 정밀도와 재현율의 조합 평균입니다. 정밀도와 재현율을 모두 만족시켜야 할 때 사용을 하고요. 수식은 다음과 같이 사용할 수 있습니다. 다음으로는 많은 분들이 좀 이해하기 어려운 ROC AUC 커브에 대해서 이야기를 한번 해 보겠습니다. 다양한 임계 값에서의 트루 퍼시티브 레이트, 퍼스트 퍼시티브 레이트 관계를 곡선으로 나타내었을 때 곡선 아래의 면적입니다. 여기에서 임계 값이란 우리가 분류를 할 때 어떤 쓰레시홀드 어떤 임계 값을 사용할 것이냐에 따라 달라집니다. 우리가 분류 모델을 사용을 할 때 분류 모델이 이제 반환하는 결과는 우리가 기대하기에는 어떤 클래스 어떤 레이블을 기대를 하는데요. 실제로 모델이 반환하는 결과값은 어떤 클래스 레이블이 아니라 이전에 확률 값을 반환을 하게 됩니다. 우리가 투루 or 펄스라고 하는 이진 분류를 한다고 해 보겠습니다. 일반적으로 이진 분류를 하는 모델은 하나의 확률 값을 반환을 합니다. 우리가 그 확률 값을 받아서 50%가 넘어가면 트룩 넘어가지 않으면 펄스라고 일반적으로 사용을 하는데요. 여기에서 우리가 사용하는 그 0.5 50% 이거를 스레시홀드 임계값이라고 이야기를 합니다. 그렇기 때문에 우리가 이런 다양한 임계 값들을 사용을 해보면서 TR 포시티브 레이트와 퍼스 포시티브 레이트가 어떤 식으로 변화하는지를 그린다라고 생각하시면 될 것 같아요. 이를 예시를 통해서 한번 알아보겠습니다. 다음과 같이 각 샘플에 정답과 모델 예측 값이 있다고 가정해 보겠습니다. 그래서 모델이 예측한 값은 확률처럼 나오는 걸 보실 수가 있고요. 뭐 예를 들어서 샘플 a는 실제 정답은 1이지만 예측 값이 0.9라고 합니다. 여기서 만약에 우리가 스레시 월드 값을 0.5로 잡는다면 a는 1이 되겠죠. 하지만 우리가 이 스레시홀드 값을 0.9가 아니라 0.91로 한다면 에는 레이블 값이 0이 되게 됩니다. 이런 식으로 우리가 쓰레시홀드 값을 바꿔가면서 어떤 식으로 바뀌는지 확인해 보겠습니다. 이런 스레시홀드 값을 계산을 할 때는 우리가 가지고 있는 이 샘플들의 예측 확률 값들에 맞게 이 스레시홀드를 설정을 하면서 계산을 합니다. 다음 페이지에서 자세히 보겠습니다. 모든 인계 값에 대한 트루 퍼시티브 레이트와 퍼스 퍼시티브 레이트를 계산을 하면 다음과 같습니다. 약간 한 번에 큰 어떤 표가 생겨나니 좀 어지러울 수 있는데요. 하나하나 살펴보도록 하겠습니다. 만약에 우리가 가장 왼쪽에 있는 스레시홀드 값이 어떤 확률값을 1로 분류할지 0으로 분류할지 설정하는 값입니다. 첫 번째 스레시 홀드는 무한대로 되어 있습니다. 그래서 확인을 해보시면 프레드 1이라고 하는 곳에는 이제 아무것도 포함되지 않은 것을 보실 수가 있죠. 왜냐하면 무한대 스레시홀드보다 높은 확률 값은 존재하지 않으니까요. 무한대로 표현했지만 정확하게는 1이라고 이해하시면 되겠습니다. 그래서 스레시홀드가 무한대인 케이스에서는 모든 샘플에 대해서 예측 값이 0으로 나오는 걸 보실 수가 있고요. 이 예측 값들 예측값 1 예측값 0에 따라 트루 퍼스티브, 퍼스 퍼스티브 트루 negative, 퍼스트 negative가 달라지고 이 4개의 값이 달라짐에 따라 펄스 positive 레이트, 트루 positive 레이트가 산정되는 것을 보실 수가 있습니다. 다음 스래시홀드 0.9로 가보겠습니다. 0.9로 가는 경우에는 에 샘플에 대해서만 예측 값이 1이 나왔고요. 나머지에 대해서 0이 나왔습니다. 여기서 예측 값이 1이 나왔기 때문에 트루 positive가 에 1개가 생겼고요. 그다음에 펄스 negative에서 a가 사라진 것을 확인하실 수가 있습니다. 여기에서 퍼스 포시티브 레이트는 그대로이고 2루 포스티브 레이트가 증가된 것을 보실 수가 있습니다. 다음 스레시홀드 0.85로 가보겠습니다. 다음은 a와 b 두 샘플에 대해 예측 값이 1이 되었고 cdef에 대해서만 예측 값이 0이 되었습니다. 여기에서 투루 positive는 그대로이고요. 퍼스 positive가 새롭게 한 개 생겼습니다. 투루 negative에 있었던 비가 제거되면서 디와 프만 남고 퍼스 negative c와 e는 그대로 있습니다. 여기에서 변경된 건 f스 퍼시티브 레이트가 0.333으로 증가된 걸 보실 수가 있습니다. 이런 방식으로 0.6, 0.4, 0.3 0.2로 스레시 홀드를 내려감에 따라 퍼스 퍼시티브 레이트와 트루 퍼시티브 레이트가 변화되는 것을 확인하실 수가 있습니다. 이전 단계에서 계산한 트루 퍼시티브 레이트, 퍼스 퍼시티브 레이트를 x축과 y축으로 만들어서 점을 하나하나 찍어 보겠습니다. 그러면 오른쪽에 있는 그림과 같이 이제 어떤 곡선은 아니고 약간 직각으로 움직이는 어떤 영역이 생기죠? 사실 이게 지금 샘플이 몇 개 없기 때문에 이런 형태로 보이지만 만약에 샘플이 만 개, 10만 개, 100만 개가 된다면 우리가 보기에는 우리 눈으로 보기에는 어떤 하나의 곡선처럼 보여지게 될 겁니다. 그래서 우리가 이렇게 그린 걸 ROC 커브라고 이야기를 합니다. 여기에서 우리가 계산하고 싶은 건 에이유씨 에어리어 언더 더 ROC 커브이기 때문에 이 그린 커브 밑에 면적을 계산을 합니다. 그 면적을 우리는 에유씨라고 이야기를 합니다. 에유씨는 모델의 전반적인 성능을 평가하는 지표로 사용이 됩니다. 다음으로는 회귀 모델 평가 지표입니다. 평균 제곱 오차는 실제 값과 예측값의 차이를 제곱한 뒤에 평균을 취하고요. 평균 제곱근 오차는 평균 제곱 오차의 루트를 제곱근을 씌운 결과입니다. 평균 절대 오차는 실제 값과 예측값 차이의 절대값 평균을 나타냅니다. 다음으로는 평균 절대 백분율 오차 엠에피라고 하고요. 오차의 비율을 평균을 취합니다. 상대적 오차를 평가합니다. 다음으로는 결정 계수 알스퀘어라고 하고요. 데이터셋이 가진 전체 변동을 예측 모델이 얼마나 잘 설명하는가 예측 모델의 변동이 얼마나 비효율적으로 이루어지는가를 판단합니다. 하지만 결정 개수에 있는 문제점이 있어서 그 문제를 해결한 게 어드저스티드 결정 개수, 어저스티드 아이스퀘어를 사용합니다. 여기에서는 피처 개수를 고려해서 조정된 결정 개수라고 이해하시면 됩니다. 평균 제곱 오차를 조금 더 자세히 보겠습니다. 수식에서 보여지는 와 아가 실제 값이고요. 와아 해이 모델이 예측한 예측 값입니다. 그 두 개의 값을 뺀 뒤에 제곱하여서 평균을 냅니다. 제곱의 형태를 가지고 있기 때문에 이상치에 민감한 평가 지표 중 하나입니다. 다음은 RMS 루트 민 스퀘드 에러입니다. rms2의 제곱근이고요. 실제 데이터와 동일한 단위를 가지고 있지만 여전히 미상치에 민감합니다. 여기에서 실제 데이터와 동일한 단위라고 함은 우리가 차이 값을 제곱한 뒤에 평균을 했기 때문에 실제 데이터의 제곱의 스케일을 가지고 있습니다. 이를 루트를 씌워서 동일한 스케일로 가져왔다라고 이해하시면 되겠습니다. 다음은 평균 절대 오차 민 앱솔루트 에러입니다. 실제 값과 예측값의 차이에 절대값 평균을 취하고요. 실제 데이터와 동일한 스케일 단위를 가지고 있으면서 평균을 취하지 않기 때문에 이상치에 덜 민감합니다. 다음은 엠에피 미 앱솔루트 퍼센티지 에러입니다. 오차의 비율을 평균을 냅니다. 상대적인 오차를 표현하기 때문에 서로 다른 데이터의 성능을 직접적으로 비교할 수 있는 평가 지표 중 하나입니다. 다음은 결정 계수입니다. 모델이 전체 변동성 중 얼마나 설명했는지를 나타내는 지표입니다. 결정 계수가 가지고 있는 문제점 중 하나는 모델의 피처를 추가하면 알스퀘어의 값이 같거나 높아지는 문제가 있습니다. 그렇기 때문에 피처의 수가 많은 경우 알스퀘어의 값은 높게 나올 수 있습니다. 이 문제를 해결하기 위해 피처 개수를 고려해서 조정된 결정 개수인 어드저스티드 알스퀘어라고 하는 평가 지표가 있습니다. 피처의 개수를 나타내는 피인자를 추가하여 기존 결정 개수의 문제점을 해결한 평가 지표입니다. 다음으로는 온라인 평가 지표입니다. 도메인마다 평가하는 방법이 크게 다릅니다. 우리 강의에서는 대표적으로 광고 추천과 서비스 플랫폼에서 사용하는 온라인 지표를 알아보겠습니다. 광고 추천에서 사용하는 온라인 평가 지표입니다. 첫 번째는 클릭률입니다. 씨티알이라고 우리가 이야기를 하고요. 광고가 노출된 횟수 대비 실제 클릭된 비율입니다. 다음은 전환율입니다. CVR이라고 이야기를 합니다. 클릭 후 실제 전환까지 이루어진 비율입니다. 여기에서 전환이란 실제 유저가 그 광고 상품을 구매한 경우라고 보시면 됩니다. 쉬운 예시로 여러분들이 웹사이트를 돌아다니다가 보여지는 광고에 들어가서 그 제품을 그 물건을 실제로 구매하는 것을 우리가 컨버전이라고 이야기를 합니다. 다음은 클릭당 비용이라고 합니다. CPC라고 이야기를 하고요. 총 광고비 대비 총 클릭수를 기반으로 해서 이 광고주 입장에서 봤을 때 아 내가 하나의 클릭을 발생시키기 위해 얼마의 돈을 써야 되지 이거를 파악할 수 있도록 도와주는 평가 지표입니다. 낮을수록 좋겠죠. 다음은 전환당 비용입니다. CPA라고 이야기를 하고요. 여기에서는 분모가 클릭 수에서 전환수로 변경이 됩니다. 그래서 나의 물건을 하나 팔기 위해 얼마의 광고비를 써야 되지라는 것을 표현해 줍니다. 다음은 광고비 대비 수익입니다. 로아스라고 이야기를 합니다. 총 매출 대비 총 광고비입니다. 쉽게 설명하면 내가 광고비를 얼마 쓰면 얼마를 매출을 올릴 수 있지를 평가할 수 있습니다. 다음으로는 서비스 플랫폼에서 사용하는 온라인 평가 지표입니다. 첫 번째로는 dau 일일 활성 사용자 수라고 이야기를 합니다. 다음은 MAU 월간 활성 사용자 수라고 합니다. 다음은 이탈률입니다. 전체 사용자 수 분의 이탈 사용자 수입니다. 다음은 사용자 참여입니다. 전체 사용자 수 분의 총 액션 수입니다. 다음은 모델 학습 파이파인에 대해서 이야기해 보겠습니다. 모델 학습 파이프라인도 우리 전처리 단계에서 사용했었던 그런 프로세스와 동일하게 프로세스가 존재합니다. 첫 번째로는 데이터 준비, 그다음 데이터 전처리 모델 학습 모델 평가 모델 배포가 있습니다. 일반적으로 경진대회에서는 데이터 전처리 모델 학습 모델 평가 이 세 가지를 반복적으로 수행하게 됩니다. 첫 번째는 데이터 준비입니다. 다양한 출처에서 목적에 맞는 데이터를 확보합니다. 여기에서 데이터의 품질, 신뢰성, 최신성, 데이터의 라이선스 등을 고려해야 됩니다. 예시로는 로그 데이터 혹은 트랜잭션 기록 혹은 설문 결과 등이 있습니다. 현업에서는 일반적으로 데이터 수집되는 통로가 이미 존재합니다. 그래서 데이터가 어떤 데이터 파이프라인에 수집이 되면 데이터 엔지니어링 팀이 그 데이터 파이프라인을 통해 데이터를 가공을 해주고 그 가공된 데이터들을 AI 팀 혹은 ML 팀 AI 조직들이 사용하는 형태로 준비가 됩니다. 준비된 데이터를 우리가 쿼리 엔진 혹은 데이터를 탐색할 수 있는 어떤 툴을 이용을 해서 eda를 진행을 합니다. 데이터의 분포, 결측치, 이상치, 주요 통계량 등을 파악할 수 있고요. 시각화 및 통계로 데이터의 특성을 이해할 수 있고 문제와 가설 설정의 인사이트를 제공합니다. 예를 들어 문장을 구성하고 있는 문자 수를 확인해 본다 이런 것들도 eda에 포함될 수 있겠습니다. 다음으로 피처 엔지니링입니다. 모델 성능 개선 목적으로 혹은 변수 표현을 좋게 만드는 목적으로 진행을 하게 됩니다. 도메인에 따라 접근 방법이 다를 수 있습니다. 정형 데이터의 경우 새로운 변수 파생 변수를 생성한다 혹은 변환 로그 정규화, 범주화, 인코딩 등을 시도할 수 있습니다. 이미지는 리사이즈 크로핑, 노이드 제거 등 여러 가지 방법이 존재할 수 있고요. 자연어는 토크나 불필요한 단어 제거, 표준화 등 여러 가지 피처 엔지니어링 방법이 있을 수 있습니다. 다음은 토큰화의 예시입니다. 다음은 피처 셀렉션에 대해서 이야기를 한번 해볼 건데요. 일반적으로는 정형 데이터에서만 사용이 됩니다. 모델 성능에 불필요하거나 상관관계가 높은 변수를 제거하게 됩니다. 통계적 기법으로 정보 이득, 상관, 계수 라소와 같은 방법들을 활용을 해서 피처를 셀렉션을 하고요. 과적합 방지 및 계산 효율성을 확보하는 데 큰 도움이 됩니다. 다음은 모델 학습입니다. 주어진 데이터를 기반으로 다양한 모델 선형 트리, 신경망 등을 학습합니다. 학습 과정에서 손실 최소화를 위해서 옵티마이저, 로스 펑션 스케줄러 등을 선언해서 사용하게 됩니다. 여러분들이 피처 엔지니어링 다음으로 많은 시간을 쓰게 되는 부분이라고 생각하시면 됩니다. 모델 학습 단계를 추상화시켜 보면 다음과 같습니다. 순전파 단계에서는 예측 값을 계산을 하고요. 그다음 예측 값을 기반으로 손실 계산을 해서 얼마만큼의 로스 손실이 발생했는지를 계산을 합니다. 발생한 손실을 기반으로 해서 이제 모델을 학습시키기 위해서 역전파 기울기를 계산한 뒤에 경사 하강법을 통해서 그 모델이 가지고 있는 가중치를 업데이트를 합니다. 이 과정을 여러 번 반복을 하면서 모델의 성능이 수렴할 때까지 진행을 하게 됩니다. 다음은 하이퍼 파라미터 튜닝입니다. 모델 성능에 큰 영향을 미치는 파라미터들을 조정합니다. 하이퍼 파라미터 튜닝에는 그레이드 서치, 랜덤 설치, 베이징 옵티마이제이션 등 여러 가지 방법을 통해서 하이퍼 파라미터를 선택하고 튜닝을 할 수 있습니다. 반복 실험을 통한 최적 조합을 탐색하게 됩니다. 하지만 하이퍼 파라미터 튜닝이 모든 도메인 그리고 모든 모델에 적용될 수 있는 것은 아닙니다. 왜냐하면 우리 강의 8강에서 좀 더 자세히 다루겠지만 하이퍼 파라미터 튜닝을 한다는 것은 모델 학습을 반복적으로 여러 번 한다는 것을 의미합니다. 이는 많은 GPU 리소스와 많은 휴먼 리소스를 사용하게 되기 때문에 모든 모델 모든 도메인에 대해서 하이퍼 파라미터 튜닝을 항상 고려할 수 있는 것은 아닙니다. 다음은 모델 선택입니다. 여러 후보 모델을 비교해서 최적의 모델을 선택합니다. 비교 기준은 성능, 해석력 그리고 학습 시간 등을 고려합니다. 예시를 기반으로 좀 더 쉽게 이해해 보겠습니다. 이진 분류 문제에서 긍정 부정을 정확하게 예측하는 문제라고 가정해 보겠습니다. 평가 지표는 a씨를 사용할 거고 제약 조건으로는 인퍼런스 시간은 30밀리세크 이하, 메모리 사용량은 100메가바이트 이하라고 해보겠습니다. 우리가 고려하는 모델은 네 종류가 있었습니다. 에유시 측면에서 봤을 때 로지스틱 리그레션은 0.8 이하이기 때문에 고려하지 않도록 하겠습니다. 다음은 인퍼런스 시간입니다. 인퍼런스에서는 엠엘비 모델이 45밀리세크 인퍼런스 시간을 보여주고 있기 때문에 우리가 고려할 수 있는 모델은 스지 부스트와 라이트 비엠 두 종류가 되겠습니다. 다음으로 메모리 사용량을 보겠습니다. 메모리 사용량에서 시지 부스트 라치비엠은 모두 100메가바이트 이하를 사용하고 있기 때문에 이 두 모델 중에서 고려할 수 있는데요. 저의 선택은 xg 부스트를 선택하도록 하겠습니다. 왜냐하면 인퍼런스 시간이 약간 느리고 메모리가 약간 사용량이 높다 하더라도 에유시스코어에서 성능이 더 좋기 때문에 이 두 개는 감안할 수 있습니다. 이런 식으로 우리가 모델을 선택할 수 있습니다. 다음은 평가 지표입니다. 문제 유형 이진 다중 혹은 회귀에 맞는 지표를 선정하는 것이 중요합니다. 분류 문제 예시의 경우 에큐러시 프리시전 리콜 에프1 스코어 a유c 등이 있을 거고요. 회귀 문제 같은 경우는 ms RMS mae 등이 있습니다. 각 지표에 따라 모델의 강점과 약점을 파악할 수 있는 지표를 선정을 해야 하고요. 우리가 단일 매트릭을 가지고 지표를 선정할 수도 있기는 하지만 단일 매트릭이 아닌 여러 매트릭을 융합해서 만드는 새로운 지표를 만들 수도 있습니다. 다음은 모델 배포입니다. 물론 경진대회에서 여러분들이 실제 환경의 모델을 배포하지는 않지만 가볍게 다뤄보도록 하겠습니다. 여러분들이 학습한 모델을 온프레미스 혹은 클라우드 등 인프라에 적용하는 단계이고요. 이 단계에서 우리가 중요하게 생각해야 하는 것은 모델의 버전 관리 그리고 모델 서빙을 위한 코드 버전 관리가 중요해지고요. 그리고 AI 모델을 서빙한다라고 하는 것은 일반적인 백핸드 서비스와 다르게 컴퓨팅 자원을 많이 사용을 하게 됩니다. 그렇기 때문에 이 스케일링 서버를 몇 대를 배포를 할 거고 서버가 자동으로 늘어났다가 줄어드는 이런 것들도 모두 고려를 하셔야 하고요. 그리고 모델을 서빙한다라고 하면 일반적으로 백엔드 서버를 배포하는 것과 동일합니다. 거기에 플러스로 AI 모델 추론 서비스를 제공한다라고 하는 것이 추가가 되는데요. 그렇기 때문에 기본적인 백엔드 서버 모니터링 체계 그리고 모델의 성능을 추적할 수 있는 이제 모니터링 체계 이런 것들을 같이 고려를 하셔야 합니다. 이후 모델이 배포됐다면 이제 운영을 하셔야겠죠. 배포된 모델들의 이제 추론 예측 결과 이런 것들을 모니터링을 하면서 이상을 탐지합니다. 예를 들어서 모델이 예측하던 값이 모델이 예측하던 확률 값이 0.1 언저리에 있었는데 갑자기 0 3으로 튀었다거나 혹은 0.01로 내려갔다거나 이런 문제가 발생했을 때 우리가 빠르게 대응할 수 있어야 됩니다. 그렇기 때문에 이상 탐지 모니터링이 매우 중요하고요. 그리고 모델은 일반적으로 주기적으로 재학습을 해 주어야 합니다. 왜냐하면 입력 데이터의 트렌드가 바뀌는 경우 모델 성능이 떨어질 수 있기 때문이에요. 그래서 이 재학습 주기의 경우는 여러분들이 실험적으로 한번 확인을 해보셔야 됩니다. 예를 들어서 일주일 전에 학습한 모델을 가지고 이제 하루 지난 거 이틀 지난 거 3일, 4일 5일 6일 7일 이런 식으로 시간이 지난 입력 데이터를 모델의 통과시키고 그 성능을 평가를 해 본 뒤에 아 한 3일쯤 되니까 모델 성능이 한 80%까지 떨어지더라 그러면은 3일에 한 번씩 재학습을 할까 이런 식으로 여러분들이 성능을 점검해 보시는 거를 추천을 드립니다. 요약을 해 보겠습니다. 이번 강의에서는 모델 성능 평가 부분에서 목적에 따라 적합한 평가 지표를 선정하여 모델의 성능을 평가했습니다. 분류 문제의 모델 오프라인 성능 평가 지표는 정확도, 정밀도, 재현율, F1 스코어, 온라인 성능 평가는 도메인과 비즈니스에 따라 크게 다르다라는 것도 말씀을 드렸었고요. 모델 학습 파이프라인 데이터 수집 데이터 전처리 모델 학습 모델 평가 모델 배포 각각의 단계에 대해서도 이야기해 보았습니다. 이번 강의는 여기까지입니다. 고생 많으셨습니다."
}