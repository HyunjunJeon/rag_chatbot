{
  "lecture_name": "[MLforRecSys] (8강) 데이터의 가치측정 및 해석 II",
  "source_file": "[MLforRecSys] (8강) 데이터의 가치측정 및 해석 II_100.mp4_2025-12-04-104606926.json",
  "text": "네 안녕하세요 여러분 이번에는 데이터의 가치 측정 및 해석의 심화 버전을 저희가 한번 살펴보도록 하겠습니다. 여기서 데이터 가치의 측정 및 해석의 심화라고 해서 기존에 배웠던 것보다 더 어려운 걸 배운다기보다는 기존에 저희가 데이터 가치 측정 방법론을 보다 더 다양한 방법에 대해서 한번 살펴보는 것을 목표로 합니다. 그래서 데이터 가치 측정 방법과 관련된 대표적인 알고리즘 데이터 쉐플릭 그다음에 강화학습 기반의 방법 그다음에 오비 기반의 방법 이 세 가지 방법론의 알고리즘들을 저희가 한번 살펴보고 각각의 활용처와 장단점을 살펴보도록 하겠습니다. 저희가 데이터 어트리뷰션이라 함은 트레이닝 데이터 인스턴스마다 가치를 측정하는 방식이라고 확인했습니다. 그렇죠 그래서 자 이러한 트레이닝 데이터가 만약에 100개가 있으면 그 100개에 대해서 우리가 각각의 가치를 하나씩 다 매겨주는 걸로 생각해 주시면 됩니다. 자 이러한 가치는 좀 다양한 방식으로 측정이 될 수 있습니다. 사실 그 유저가 정의하기 나름이에요. 가장 많이 활용되는 방식 중에 하나가 결국 우리가 머신러닝 모델을 통해서 잘하고 싶은 게 테스트 로스를 감소시키는 거기 때문에 또는 테스트의 성능을 올리는 것이기 때문에 우리가 해당 데이터를 학습했을 때 테스트 데이터 로스가 얼마나 감소될 것인가를 우리의 가치 평가의 기준으로 삼는 경우가 많습니다. 또는 해당 데이터를 퍼처베이션 했을 때 테스트 로스가 얼마나 감소되고 증가되는지도 우리가 확인을 할 수가 있고요. 그러면 테스트 로스가 크게 증가될 것으로 예상되는 트레이닝 데이터 퍼처벳을 우리가 찾게 되면 그때는 어드버서리얼 데이터라고 부르고 우리가 인공지능 모델을 공격할 수 있는 악의적인 데이터를 만드는 것 또한 가능하게 됩니다. 즉 이와 같이 데이터 밸류에이션은 또는 데이터 어트리뷰션은 다양한 밸류로 우리가 활용이 될 수 있고요. 이러한 데이터 어트리뷰션 또는 데이터 밸류에이션이 중요한 것은 결국 우리 모델이 테스트 데이터에 대해서 왜 이런 아웃풋을 내보내는지 결국 판단할 수 있는 설명할 수 있는 근거가 되기 때문입니다. 왜 우리의 모델이라 함은 결국 트레이닝 데이터에서 얻은 널리지를 기반으로 테스트 데이터에 대한 예측을 진행하기 때문입니다. 그렇죠 그 까닭에 우리는 결국 이 테스트 데이터에 대해서 우리 모델이 왜 이런 아웃풋을 내보냈는지 알려면 우리 모델을 이해해야 되고 우리 모델을 이해하기 위해서는 트레이닝 데이터에 대한 이해가 필요한 상황인 겁니다. 그 까닭에 우리가 이러한 트레이닝 데이터에 대한 가치 평가 중요도 평가를 계속해서 진행하고 있게 됩니다. 자 그러면 우리가 지금부터는 데이터 가치 평가를 하기 위한 인플루언서 펑션 기반의 방법론 외에 또 다른 어떠한 방법론들이 있는지 한번 살펴보고 넘어가도록 하겠습니다. 저희가 데이터 쉐플링 기반의 방법론을 학습을 진행하겠습니다. 저희가 과거에 인플루언서 펑션 기반의 방법론을 배운 적이 있습니다. 인플루언서 펑션 기반의 방법론은 우리가 리브 원 아웃 기반의 방법론이라고 부르기도 합니다. 그 이유는 무엇이냐면 결국 우리가 데이터를 하나 제거하고 그 외에 남아있는 트레이닝 데이터를 학습시키고 테스트했을 때 성능이 어떻게 바뀌는지를 우리가 보는 방법론이기 때문입니다. 그 까닭에 우리가 얘를 live 1 아웃 기반의 방법론이라고 부르고 있습니다. 그리고 다음과 같은 우리가 이제부터 살펴볼 데이터 쉐플리 디비아l 데이터 오비도 사실은 우리가 뭐 큰 관점에서는 어떻게 생각하면 리브 1 아웃 기반의 방법이라고 볼 수는 있지만 디테일하게 약간씩 다릅니다. 먼저 첫 번째로 데이터 쉐플리 같은 경우는 쉐플링 이론 게임 이론에서 많이 쓰이는 쉐플링 이론에 근거한 방법론이 되겠고요. 디브아엘은 여기 아래이라고 적혀 있는 것처럼 강화학습 기반의 방법론이라고 볼 수가 있습니다. 그다음에 데이터 오비는 ro 베그 기반의 방법론이라고 우리가 볼 수 있는 것이고 여기서는 우리가 베깅 알고리즘을 활용해서 또 진행을 하게 됩니다. 이 각각에 대해서 저희가 하나씩 자세하게 좀 살펴보도록 하겠습니다. 먼저 첫 번째로는 데이터 채플린 기반의 방법론입니다. 여기서 우리가 문제 상황을 아래와 같이 정리를 한번 하고 넘어가도록 하겠습니다. 우리가 슈퍼바이스 러닝에서는 보통 아래에 세 가지의 구성 요소가 있습니다. 첫 번째로 트레이닝 데이터인데 얘가 레이블이 달려 있는 데이터라고 볼 수가 있겠죠 그다음에 알고리즘이 하나 존재합니다. 에이라는 알고리즘이 하나 존재할 거고 그다음에 퍼포먼스 스코어 브라는 게 존재할 겁니다. 자 그때 결국 우리가 하고 싶은 건 어떤 거냐면 이러한 알고리즘을 기반으로 해서 결국 이러한 퍼포먼스 즉 퍼포먼스 즉 우리 모델의 정확도라든지 노스라든지 그런 것들을 우리가 측정하고 싶은 게 우리의 목표가 되겠습니다. 자 여기서 데이터 밸류라는 것은 우리가 다음과 같이 즉 특정한 데이터에 대한 우리의 밸류에이션을 나타냅니다. 우리한테 데이터가 이렇게 있고 알고리즘이 있고 퍼포먼스 스코어도 있다고 하겠습니다. 얘는 우리가 정하기 나름이겠죠 오큐레시라고 할 수도 있고 로스라고 할 수도 있고 그때 결국 우리가 다음과 같은 아이 번째 데이터에 대한 데이터 밸류를 이렇게 한번 정리하겠습니다. 즉 이러한 데이터 밸류에이션을 위한 한 가지 방안은 다음과 같은 리뷰 1 아웃 기반의 방법입니다. 자 인플루언서 펑션을 우리가 다룰 때도 한번 봤던 내용인데요. 즉 하나의 데이터를 우리가 제거하고 학습시켰을 때 과연 어떻게 변화되는지를 보면은 그 데이터에 우리가 가치를 알 수 있다라는 뜻입니다. 즉 아래를 보면은 이러한 데이터에 대해서 우리가 밸류에이션을 하고 그다음에 그 데이터에서 아이 번체 데이터가 빠진 상황에서 우리가 또 밸류에이션을 합니다. 자 그러면 그때 두 가치들의 차이를 우리가 다음과 같은 아이번체 데이터에 대한 밸류에이션이라고 볼 수가 있습니다. 자 그때 우리가 인플루언서 펑션을 볼 때 이거를 보긴 했었는데요. 그러면 인플루언서 펑션을 그대로 쓰면 되지 왜 데이터 쉐플이라는 방법을 또 가져와서 우리가 새로 배워야 되는가 라고 하면은 자 인플루언서 펑션은 좀 여러 가지 만족하지 않는 성질들이 존재합니다. 자 이게 어떤 건지 저희가 뒤에서부터 한번 보도록 할게요. 즉 이제부터는 어떤 걸 볼 거냐면 데이터 가치 평가가 만족해야만 하는 조건들을 우리가 하나씩 나열할 겁니다. 물론 얘를 반드시 만족해야 된다는 건 아니고요. 데이터 쉐플리 방법에서 주장하는 데이터의 가치 평가는 이런 거는 만족해야 돼라고 제시하는 겁니다. 자 하나씩 보도록 하겠습니다. 첫 번째 상황입니다. 첫 번째 조건 만약에 스아 콤마 와아라는 아이 번째 데이터가 트레이닝 데이터에 포함되어도 만약에 모델의 퍼포먼스에 영향을 주지 않는다고 하겠습니다. 그러면 그때는 데이터 밸류에이션은 이 아이 번체 데이터에 대한 가치 평가는 0이 되어야 한다는 말입니다. 어쩌면 너무 당연한 거죠. 얘를 우리가 수식으로 나타낸다면 만약에 우리가 그 아이 번체 데이터가 빠져 있는 데이터를 생각하겠습니다. 즉 우리가 실제로는 d라는 데이터가 뭐 n개가 있겠죠 데이터 n개가 있는데 거기서 아이 번체 데이터가 빠진 엔 마이너스 1개의 데이터에 대한 부분 집합인 겁니다. 스는 그렇죠 그중에서 임의의 데이터를 하나 뽑아도 그때 그 데이터만 가지고 우리가 트레이닝을 시키고 밸리데이션 로스나 어큐러시를 보는 거나 아니면 그 데이터에서 아이 번체 데이터를 추가한 상황에서 가치 평가를 한 거나 두 개가 만약에 동일하다면 그때 아이 번체 데이터에 대한 가치는 우리가 0이라고 하겠다라는 뜻이 됩니다. 그렇죠 어쩌면 되게 합리적인 컨디션이라고 볼 수가 있습니다. 자 그다음에 두 번째 컨디션입니다. 만약에 XI 콤마 y아가 트레이닝 데이터에 포함되거나 아니면 여기서 x 제 콤마 와 제가 와 제가 트레인 데이터에 포함되었을 때의 퍼포먼스가 동일하다면 두 데이터의 밸류에이션은 동일해야 한다라는 게 두 번째 조건입니다. 즉 만약에 자 여기서 기가 아까처럼 엔게이 데이터를 갖고 있는 트레인 데이터 셋입니다. 거기서 데이터 2개를 빼요. 엠 마이너스 2개의 데이터가 있는 겁니다. 그러면 그 엔 마이너스 2개의 데이터에 대한 부분 집합이 여기 스예요. 자 그러면 이 스라는 데이터에다가 아이라는 데이터를 추가했을 때의 가치랑 그다음에 제라는 데이터를 추가했을 때의 가치가 만약에 동일하다면 즉 에스라는 트레잉 데이터에다가 아이라는 데이터를 추가시키고 나서 밸리데이션 어큐러시를 본 거나 에스라는 트레잉 데이터에다가 제 번째 데이터를 추가시키고 학습한 다음에 밸리데이션 어큐러시를 본 거나 2개가 동일하다면 그때는 아이 번츠 데이터나 제번츠 데이터나 가치가 동일하다라는 뜻을 나타내고 있는 겁니다. 자 그다음에 마지막 세 번째 만약 퍼포먼스 측정 시 개별적인 퍼포먼스 스코어들의 합으로 만약에 설정한다고 가정하겠습니다. 자 그러면 데이터의 전체적인 밸류는 각 퍼포먼스 스코어에 대한 데이터 밸류들의 합으로 우리가 표현하겠다는 뜻입니다. 자 무슨 말이냐면 결국 이거예요. 자 우리가 실제로 여러분 많은 머신러닝 모델 학습시킬 때 우리가 퍼포먼스 뭐 또는 밸리데이션 로스를 어떻게 평가하나요? 밸리데이션 데이터에 대한 로스는 우리한테 주어진 밸리데이션 데이터 각각에 대한 로스들의 평균으로 나타냅니다. 테스트도 마찬가지죠. 즉 테스트 데이터가 만약에 여러 개 있다고 치면 첫 번째 테스트 데이터 로스 두 번째 테스트 데이터 로스 이렇게 쭉쭉쭉 그러한 테스트 데이터에 대한 로스들의 평균을 기준으로 우리가 가치 평가를 하게 된다는 겁니다. 아시겠죠? 자 그러면 그때 결국 데이터가 여러 개가 되는 거고 테스트 데이터가 여러 개 되는 거죠. 그러면 그때 우리가 평가 기준이 여러 개 되는 겁니다. 그렇죠 그러면은 그때 우리가 어떻게 한다는 말입니까? 그때 우리가 하는 거는 다음과 같이 더해서 나타내겠다. 개별적인 퍼포먼스 스코어들의 합으로 우리가 설정하게 되면은 결국 각 퍼포먼스 스코어들의 밸류들의 합으로 표현하겠다는 겁니다. 즉 우리가 테스트 데이터에 대한 퍼포먼스를 퍼포먼스 코드를 텍스트 데이터 각각에 대한 퍼포먼스들의 합으로 로스들의 합으로 나타내겠다 또는 평균으로 나타내겠다라고 하면은 데이터 가치도 이 첫 번째 데이터 첫 번째 테스트 데이터에 미치는 영향, 두 번째 테스트 데이터에 미치는 영향 세 번째 테스트 데이터에 미치는 영향 그 영향들의 싸움으로 우리가 가치 평가를 정리하겠다라는 뜻입니다. 아시겠죠? 네 실제로 현실적인 머신 러닝에서는 또 많이 쓰이는 환경이 되겠죠. 여기서 그러면 우리가 지금까지 조건을 세 가지를 한번 같이 봤습니다. 첫 번째 조건은 XI랑 와i가 그렇죠 우리가 트레이닝 데이터에 포함되어도 모델 퍼포먼스가 하나도 안 달라진다. 그러면은 그때는 데이터 밸류에이션이 0이 돼야 된다. 두 번째로 만약에 이 x y가 포함되거나 xjy 제가 포함되거나 2개가 동일하다면 가치 평가도 동일해야 된다. 그다음에 퍼포먼스 측정 시에 퍼포먼스 스코어들의 우리가 합으로 나타낼 경우 데이터 밸류에이션도 우리가 합으로 표현한다라는 거를 봤습니다. 자 여기서 여러분 이 세 가지 조건을 모두 만족하는 밸류에이션 방법은 딱 하나만 존재합니다. 유일하게 그게 여기 나와 있는 데이터 밸류에이션이라는 방법입니다. 즉 이 세 가지를 다 만족하는 거는 이거밖에 없다는 거예요. 그러면 굉장히 강력한 방법으로 생각이 되죠 여러분 왜 여기 나와 있는 세 가지가 물론 굉장히 좀 강한 가정들도 사실 존재하긴 합니다. 하지만 그럼에도 불구하고 각각의 컨디션이 그래도 어느 정도 좀 말이 되는 가정질이에요. 그쵸 말이 되는 과정들이기 때문에 이 가정들을 하는 게 합리적으로 보이는데 이 가정질을 하는 순간 우리한테 주어지는 데이터 가치 평가 방법은 이게 유일하다. 즉 얘가 어떻게 생각하면 이 조건 이 세 가지 조건을 만족하는 가치 평가 중에서는 가장 좋은 유일한 가치 평가 기준이다라는 뜻이 됩니다. 그렇죠 유일성 때문에 굉장히 강력한 방법이 되고 이 유일성에 대한 증명은 우리가 여기서 다루지 않을 겁니다. 이거는 궁금하신 분들은 이 아래 소스를 한번 확인하시길 바라겠습니다. 즉 정리하면은 여기 c는 임의의 상수라고 생각해 주시면 되고요. 여기 파i가 i번째 데이터에 대한 가치가 되는 것이죠. 결국 그거를 우리가 알기 위해서는 d라는 데이터에 대해서 아라는 아이 번째 데이터를 뺍니다. 그렇죠 만약에 d가 n개의 데이터가 있다고 치면 이제 엔 마이너스 1개의 데이터가 있는 것이고 거기에서 우리가 부분 집합을 고르게 되는 것이죠. 그때 부분 집합을 고르고 거기에 우리가 아이를 추가했을 때랑 그다음에 그냥 vs를 봤을 때랑 두 개의 우리가 차이를 성능의 차이를 보게 되면은 그때는 뭐가 된다는 겁니까 그때는 우리가 데이터의 가치를 볼 수 있게 된다 라는 뜻이 됩니다. 그래서 다시 한 번 정리하면은 우리가 아이 번체 데이터에 대한 가치 평가를 하기 위해서는 결국 앞에서 우리가 봤던 루우 기반의 방법론과 유사합니다. 아이번지 데이터를 넣고 아이번지 데이터를 빼고 두 개가 아닌 퍼포먼스를 측정한다. 그거를 모든 부분 집합에 대해서 여기서 제가 말씀드린 거는 모든 부분 집합에 대해서입니다. 즉 디가 n개의 데이터가 있다 그러면은 아이라는 데이터 1개를 뺀 겁니다. 그러면 엔 마이너스 1개의 데이터가 있는 거고 그러면은 그거의 부분 집합은 2의 n 마이너스 1승 개수만큼 있는 겁니다. 무진장 많은 거죠. 그렇죠 그러면은 실제로는 우리가 얘를 정확하게 계산을 사실 하는 게 불가능하다는 겁니다. 그렇죠 왜냐하면 데이터가 100개만 돼도 2에 99승 개를 계산을 해야 되는데 그거 뭐 사실 말이 쉽지 굉장히 어려운 거죠. 그 까닭에 우리는 좀 다르게 근사를 하는 알고리즘이 필요한 거예요. 이 데이터 쉐플이라는 거는 뭐 컨셉은 좋은 거 알겠는데 근데 애초에 이걸 계산하는 게 프레티컬하게 계산하기에는 너무 연산량이 많다는 겁니다. 자 그래서 우리는 얘를 다르게 좀 문제를 한번 풀어보고 싶다는 겁니다. 자 어떻게 풀 거냐면 이렇게 한번 생각해 볼게요. 이렇게 자 이렇게 한번 봅니다. 자 여기 나와 있는 이 파이 프로덕트로 우리가 많이 쓰는 이 라지 파일을 우리가 뭐라고 할 거냐면 유니폼 분포로 설정할 거예요. 앤 팩토리얼 개수에 대해서 즉 무슨 말이냐면 자 우리가 데이터가 만약에 1부터 n개가 트레이닝 데이터가 엔개가 있다고 하겠습니다. 즉 이 디가 이 뒤에 지금 포함된 게 뭐 엔개라고 여러분들 뭐 생각하셔도 되겠습니다. 자 그랬을 때 우리가 얘를 랜덤하게 퍼뮤테이션 시킬 거예요. 즉 랜덤하게 줄 세우는 겁니다. 1 2 3 4로 줄 세울 수도 있고 아니면 엔 엔 마이너스를 이렇게 줄 세울 수도 있고 완전히 무작위로 줄을 세울 수도 있습니다. 그러면 모든 가지 수는 몇 가지입니까? 줄 세우는 거니까 엠팩토리얼 개수만큼 나옵니다. 그러면 그 엠팩토리얼 개수만큼 줄의 조합이 나오는 거죠. 그렇죠 1부터 n까지 순차적으로 세우는 거 엔부터 1까지 반대로 세우는 거 또는 뭐 홀수끼리 세우고 그다음 짝수끼리 세우는 거 쭉쭉쭉 가서 이걸 다 하면 엠 팩토리얼 개수만큼 된다는 거예요. 거기서 랜덤하게 하나 뽑는 거를 이 프로덕트라고 하겠다는 겁니다. 그리고 거기에서 우리가 하나를 딱 고르는 것을 파이라고 하겠다는 겁니다. 그럼 파이는 1부터 n까지 랜덤하게 줄 세워져 있는 시퀀스입니다. 예를 들어서 파이는 예를 들어서 엔 엔 마이너스는 엔 마이너스 마이너스 3 마이너스 4 쭉쭉쭉 1까지인 거 그걸 우리가 파이라고 나타낼 수가 있겠죠. 그렇죠 자 그러면은 한번 보시면 결국 우리가 이렇게 계산을 하면은 그때는 또 우리가 모든 조합에 대해서 다 보는 걸로 해석할 수가 있습니다. 모든 조합에 대해서 그렇죠 왜냐하면 우리가 이렇게 줄을 세워 놓고 자 줄 세워 놓고 우리가 아이 번째 데이터를 우리가 아이 번째 데이터를 포함시키고 그렇죠 우리가 아이 번째 데이터를 포함시키고 그다음에 나머지 데이터들로 포함시킨 거랑 포함시키지 않은 원래 이 데이터들이랑 우리가 성능을 한번 평가해 보겠다라는 뜻이 되는 거니까요. 그쵸 그래서 이거랑 얘는 우리가 결국 이 씨가 만약에 모든 조합에 대해서 우리가 이렇게 설정하게 될 경우에는 얘랑 얘가 같다라고 우리가 볼 수가 있게 되는 겁니다. 아시겠죠? 자 그런 상황에서 자 이걸 다시 한 번 보면은 우리가 줄을 세웠습니다. 그렇죠 줄을 뭔가 하나 한 번 세웠어요. 1부터 n까지 세울 수도 있고 n부터 1까지 세울 수도 있고 그렇죠 자 그때 이 아이번체 인덱스까지 우리가 원하는 이 아이번체 인덱스까지 즉 데이터 아이가 위치한 그 위치 전까지만 우리가 학습한 거랑 그다음에 거기서 아이 번째 데이터까지 학습한 거랑 그거의 차이를 보는데 우리가 줄을 뭐 어떤 방법으로든 다 세울 거잖아요. 엠팩트럴 개수만큼 이걸 다 한다는 겁니다. 그렇죠 그러면은 우리가 정확하게 데이터 쉐플리를 계산할 수 있는 조건이 만족되는 겁니다. 다시 한 번 보면은 얘를 계산하는 방법은 요거랑 사실상 유사한데 그러니까 좀 더 계산하기 쉽게 우리가 표현하기 쉽게 바꾼 것뿐입니다. 그렇죠 우리가 1부터 n까지의 데이터가 있으면 얘를 랜덤하게 무작위로 줄을 세웁니다. 그렇죠 무작위로 줄을 세워가지고 우리가 딱 아이 번째 데이터 우리가 원하는 데이터 밸류에이션을 원하는 그 데이터가 나오기 전까지를 우리가 스파아라고 하고 그다음에 그럼 이걸로만 우리가 학습하고 테스트한 거랑 우리가 원하는 이 아이번지 데이터가 포함되고 트레이닝 데이터로 포함되고 학습을 한 다음에 성능 평가한 거랑 두 개 간의 차이를 보겠다 인 거니까요. 그리고 그거를 모든 엠팩토리의 조합에 대해서 다 보겠다인 거니까 그렇죠 모든 부분 집합을 다 본 거랑 우리가 동일한 효과를 낼 수가 있습니다. 이렇게 하면 표현은 간단해졌는데 무거운 거는 마찬가지가 되는 거예요. 왜 그 이유는 우리가 엠팩토리얼 개수만큼 다 우리가 고려해야 되기 때문입니다. 엠팩토리얼 굉장히 개수가 많겠죠 그래서 우리가 이거를 몬디칼로 오포시메이션을 통해서 문제를 해결합니다. 무슨 말이냐면 결국 앞서 말씀드린 것처럼 엠팩토리얼 개수에 대해서 우리가 얘를 다 계산해야 돼요. 그렇죠 이렇게 줄 세웠을 때 아이 번째 우리가 원하는 아이 번째 데이터가 위치한 곳까지 가서 트레이닝하고 이것까지 포함하고 트레이닝하고 성능 평가 또 우리가 랜덤하게 줄 세우고 우리가 원하는 아이 번체 데이터가 여기 있다고 하면 여기까지 그렇죠 또 우리가 줄을 세우고 아이 번째 데이터가 만약에 마지막에 있다면은 마지막 직전까지 트레이닝하고 마지막 것까지 포함시키고 트레이닝하고 두 개의 비교 그런 식으로 우리가 엠팩트럴 개수만큼 해야 되는데 그게 너무 많으니까 이 중에서 우리가 몇 개만 랜덤하게 골라서 하겠다라는 게 몬테칼로 어펙시메이션입니다. 그렇죠 얘를 우리가 무수히 많이 하게 되면은 그때 엠팩트럴 개수만큼 하게 되면 정확하게 얘가 추정이 되는 거겠죠. 근데 얘가 무지 많다 보니까 보통 이거보다 훨씬 더 적은 개수로 우리가 진행을 하게 됩니다. 자 이게 데이터 채플린 기반의 방법이고요. 이거를 통해서 사실 뭐 인플런스 펑션하고 유사하게 여러 가지 활용처에 쓰일 수가 있습니다. 즉 우리가 데이터 밸류에이션을 통해서 믹스 레이블들 즉 레이블이 잘못된 데이터들도 우리가 자동으로 탐지할 수 있게 돼요. 즉 얘를 보시면 얘는 이제 데이지 꽃인데 실제로는 레이블이 트레인 데이터에서 트레인 데이터에서 얘가 썸플라워로 되어 있던 겁니다. 그러니까 얘를 학습하면 오히려 테스트에서 성능이 안 좋아질 수 있는 거죠. 얘는 장미대 댓이라고 되어 있고 그렇죠 지금 이런 식으로 아 이런 트레이닝 데이터는 애초에 레이블이 잘못된 트레이닝 데이터는 학습을 하면은 성능에 방해가 될 수 있으니까 우리가 제거하는 툴로 또 이런 데이터 밸류에이션을 쓸 수가 있게 되는 겁니다. 자 그리고 이미지 같은 경우도 우리가 이렇게 원본 이미지가 있고 점점 노이즈를 가하게 되면은 사실상 좀 이미지의 가치가 떨어지는 걸로 또 생각을 할 수가 있겠죠. 그러면 한번 보시면 데이터 가치가 약간씩 내려가는 것을 볼 수가 있습니다. 우리가 좀 클린한 좋은 데이터로만 구성된 데이터베이스를 만들고 싶다라고 하면은 이러한 데이터 밸류에이션을 통해서 우리가 문제를 자동으로 해결을 할 수가 있게 되는 것이겠죠. 네 여기까지 해서 우리가 데이터 밸류에이션 기반의 쉐플리 방법을 한번 살펴봤고요. 이번에는 강 학습 기반의 방법론으로 한번 넘어가도록 하겠습니다. 데이터의 가치 측정을 위한 강학습 기반의 방법 자 먼저 우리가 인플런스 펑션을 배웠고 그거 참 좋지만 한 가지 문제는 데이터 쉐플링에서 만족해야 했던 약간 이런 그 컨디션들을 만족을 하지 않는다. 인플런스 펑션은 그래서 좀 이러한 컨디션을 만족하는 가치 평가 방법을 만들어 보자라고 해서 데이터 쉐플리가 그 후에 나오게 되었고요. 그다음에 강 학습 기반의 이 디브알엘이라는 거는 애초에 우리가 모델을 트레이닝하는 과정에서부터 어떠한 트레이닝 데이터를 학습해야지 좋은지 자동으로 한번 학습해 보자는 겁니다. 즉 기존에는 우리가 앞에서 배웠던 인플루언서 펑션과 데이터 채플린은 이미 학습은 다 끝난 거예요. 학습은 전체 데이터로 학습은 다 했고 그다음에 우리가 밸리데이션 셋이나 테스트 데이터에 대해서 성능을 올리기 위해서 도움이 되었을 트레이닝 데이터를 우리가 좀 설명하는 용도로 많이 썼습니다. 그다음에 너무 이제 믹스 레벨리가 심하면 그때 데이터를 제거하고 다시 모델을 학습하는 방법이 필요하겠죠. 근데 기존과 다르게 애초에 학습 시작 시점부터 우리가 밸리데이션 데이터에 대한 성능을 올리기 위한 트레이닝 데이터 밸류에이션을 한번 봐보자라는 얘기가 되는 겁니다. 여기서 더 나아가서 좀 기존하고 다르게 대량의 데이터와 대형 모델에서도 좀 적용 가능한 스케일러블 알고리즘 즉 스케일러블이라고 하면 우리가 확장 가능함이라는 뜻이지 않습니까? 즉 데이터가 많아져도 또는 모델이 복잡해져도 우리가 손쉽게 쓸 수 있는 방법론을 스캐러블 알고리즘이라고 부릅니다. 앞에서 인플런트 펑션 같은 경우는 해시안 연산 즉 그라디언트 미분을 두 번 해야 되는 연산이 들어갔습니다. 그래서 굉장히 무거운 연산이 되는 것이고요. 그다음에 데이터 밸류에이션 또한 근사한 방법들이 존재하긴 하지만 여전히 무거운 방법들이 존재했습니다. 데이터 채플릿 또한 자 그 까닭에 좀 스케일러블 하면서 애초에 트레이닝 데이터부터 우리가 좋은 데이터를 한번 찾아보자 학습 과정에서부터 라는 컨셉입니다. 즉 우리가 가학습 기반으로 한번 생각해 보면 밸리데이션 데이터 셋 성능을 리워드로 두는 거예요. 그렇죠 마치 우리가 뭐 바둑 게임을 한다고 하면 바둑에서 이기는 걸 우리가 리워드로 두는 것처럼 그래서 강화 학습을 학습시키는 것처럼 여기서는 밸리데이션 데이터 셋을 성능을 리워드로 두고 해당 리워드를 맥시마이즈 시켜주는 액션을 우리가 찾을 겁니다. 근데 여기서 액션이라고 하면 우리한테 트레이닝 데이터가 있을 때 어떠한 트레이 데이터를 선택하고 어떠한 트레이닝 데이터를 제외할 건지 정하는 것을 액션으로 정의하겠습니다. 그래서 이거를 우리가 그림으로 나타내면 이런 방식으로 그림으로 나타낼 수가 있습니다. 자 이거를 한번 짚고 넘어갈게요. 자 우리한테 이렇게 현재 배치에서 이렇게 비에스개만큼 데이터가 들어왔습니다. 즉 한 배치 안에 데이터가 이만큼 있다라고만 생각하시면 됩니다. 자 그때 여기 데이터밸류 에스티메이터가 하는 역할이 뭐냐면요. 이 데이터가 얼마나 가치 있는지 또는 이 데이터가 트레이닝 데이터에 실제로 포함되어야 할 확률 값을 내뱉는 애가 됩니다. 데이터 밸류에스트입니다. 즉 이 데이터가 트레이닝 데이터에 포함되어야 할 확률이니까 그 확률이 크다면 트레이닝 데이터에 무조건 포함이 되는 거고 그만큼 이 데이터는 중요하다라고 볼 수가 있겠죠. 그 확률 값을 내뱉게 됩니다. 0.9 0.6 이런 식으로 그 내뱉게 되면 거기에서 우리가 멀티노미얼 분포에서 값을 샘플링합니다. 그러면은 그래서 얘를 쓸지 말지 얘를 쓸지 말지 얘를 쓸지 말지 정하게 됩니다. 그러면은 안 쓰는 데이터도 생기게 되겠죠. 그렇죠 그러면 데이터가 약간 줄어든 몇 개는 이제 빠진 형태가 되겠습니다. 그러면 그 데이터로 우리가 트레인 시킨다는 겁니다. 즉 트레잉 데이터가 이만큼 있어도 우리가 여기서 몇 개는 1 몇 개는 0으로 되니까 1로 켜져 있는 즉 포함될 확률이 높은 애들만 트레잉 데이터로 해서 우리가 학습을 시키겠다는 겁니다. 그러면 그걸로 우리 모델을 학습을 시키고 그러면 그걸로 모델을 학습시켰을 때 결국에는 그 트레이닝 로스가 나오고 우리 모델을 열심히 학습시키는 거예요. 그러고 나서 밸리데이션 데이터에 대해서 우리가 성능을 봐서 그 성능을 리워드로 정하겠다는 겁니다. 그러면 그 리워드를 맥시마이즈 시키도록 밸리데이션 성능 데이터에 대한 리워드를 맥시마이즈 하도록 하기 위해서는 우리가 데이터 가치 평가가 각 데이터에 대해서 몇 점의 점수를 내보내야 될지 얘가 다시 학습이 되는 겁니다. 즉 여기서 학습되는 게 2개입니다. 하나는 트레잉 데이터가 주어지면 해당 트레잉 데이터를 우리가 포함시켜야 할 확률 값을 내뱉는 데이터밸류 에스티메이터가 하나 있는 것이고 두 번째로는 결국 트레잉 데이터가 정해지면 여기에서 우리가 이 트레잉 데이터로 모델을 결국 클래식 파이어를 우리가 흔히 알고 있는 그런 클래식 파이어를 학습시키는 과정이 들어갑니다. 그러면 트레이닝 데이터를 학습시키고 성능 평가는 밸리데이션 데이터에 대해서 진행하는 겁니다. 그리고 그러한 리워드가 높아지도록 다시 밸류 에스티메이터를 학습시킵니다. 이제부터는 그럼 이런 DVR의 강화학습 기반의 데이터 밸류에이션 방법론을 우리가 학습하기 위한 로테이션을 한번 정리하고 넘어가겠습니다. 자 트레이 데이터가 이렇게 엔게에 존재하고 테스트 데이터가 엠개 밸리데이션 데이터가 1개 있다고 하겠습니다. 그리고 트레이 데이터는 디 테스트 데이터는 디티 밸리데이션은 디브라고 하겠습니다. 자 여기서 한 가지 가정 사항이 있는데요. 테스트 데이터랑 밸리데이션 데이터가 동일한 분포에서 샘플링 됐다라고 가정하는 겁니다. 즉 밸리데이션 데이터랑 테스트 데이터가 유사하다라는 가정과 같은 말인데요. 실제로 이거는 뭐 현실에서는 적용이 안 되는 경우도 상당히 많습니다. 예를 들어서 우리가 주식 시장을 가정한다면 트레이닝 데이터는 한 달 전 까지의 주식 데이터 테스트 데이터는 그 앞으로 미래에 나타날 데이터 밸리데이션 데이터는 한 달 전부터 오늘까지 데이터라고 가정한다면 오늘까지의 주식 시장 데이터랑 내일부터 나올 미래의 시점에 주식 시장의 데이터는 완전히 다르지 않습니까 그 까닭에 실제로는 이게 작동하지 않는 경우도 많지만 제가 여기서는 밸리데이션 데이터와 테스트 데이터가 동일한 분포에서 샘플링 되는데 그냥 개수만 다르다라고 가정하고 넘어가겠습니다. 자 우리가 일반적인 상황에서는 트레이닝 데이터 트레이닝 목적식이 이렇습니다. 즉 우리가 데이터 n개 트레잉 데이터 NG에 대해서 결국 로스를 낮추는 게 목표예요. 우리 모델의 예측치랑 그다음에 실제 데이터랑 두개 간의 로스 차이를 우리가 낮추는 게 목표입니다. 그렇죠 만약에 이 치파가 1이라고 한다면 얘가 항상 1이라고 하겠습니다. 그러면은 우리가 흔히 보는 트레이닝 데이터에 대한 목적지 이알엠 인프레커 리스크 미니마이제이션과 동일한 상황이 됩니다. 왜 치파가 1이라는 말은 모든 데이터에 대해서 얘가 어떤 거든 1인 거니까 모든 데이터에 대해서 다 동일한 데이터 가중치 중요도를 준다는 겁니다. 그래서 여기에 n분의 1이 딱 있게 되는 것이죠. 자 근데 우리가 하고 싶은 건 뭐냐면 데이터마다 가치가 다르다는 겁니다. 그렇죠 그래서 중요한 데이터도 있고 아닌 데이터도 있다 그거를 우리가 학습하고 싶은 거예요. 그 까닭에 우리가 그러면 이 데이터를 h파라는 걸 학습시켜야 되는 겁니다. 파이가 결국 파라미터라고 생각하시면 됩니다. 보통 머신러닝 쪽에서 이렇게 쓰면은 치는 이제 뉴럴 네트워크 자체고 파이는 그 뉴럴 네트워크의 파라미터 w나 비 웨이트나 바이러스를 의미하게 됩니다. 즉 우리는 치를 학습시켜야 되는 거예요. 그래서 우리의 목적식은 이렇게 쓸 수가 있습니다. 우리가 하고 싶은 거는 밸리데이션 데이터에 대한 로스를 낮추고 싶은 거예요. 근데 어떻게 우리가 h파일을 정해야지 가장 밸리데이션 로스가 낮을까라는 뜻입니다. 즉 무슨 말이냐면 우리가 다음과 같이 트레이닝 데이터에 대해서 결국 우리 모델을 학습시킬 거잖아요. 결국 우리 모델은 학습시키는 대상은 트레인 데이터입니다. 우리 모델 여기 클래식 파이어 일반적인 프레젝터 모델 즉 이 프로젝터 모델을 이 프레이터 모델을 우리가 트레이닝 데이터에 대해서 학습시킬 건데 어떤 데이터의 가중치를 높게 주고 어떤 데이터의 가중치를 작게 주고 아예 아니면 빼버리거나 그렇게 해야지 어떻게 학습한 모델이 이 밸리데이션에서 가장 성능이 좋을까 또는 로스가 낮을까라는 의미를 갖고 있는 겁니다. 즉 한번 보시면 프레딕터라는 모델은 클래식 파이어라고 생각하시면 됩니다. 그거는 트레인 데이터 로스를 낮추기 위해서 학습이 되는 거고요. 그다음에 데이터 밸류 에스티메이터 치파는 결국 밸리데이션 로스를 낮추기 위해서 학습이 됩니다. 그래서 우리가 아까 앞에서 그림에서 밸리데이션 로스를 낮추기 위해서 또는 밸리데이션 데이터에 대한 어큐러시를 높이기 위해서 이 데이터 밸류 에스티메이터가 학습이 되는 거예요. 바뀌는 겁니다. 자 그러면은 여기서 어떻게 또 문제를 풀 수 있을까 한번 보면은 몇 가지 로테이션을 조금만 더 정리하고 넘어가겠습니다. 자 여기서 치파가 내뱉는 거 그렇죠 얘가 내뱉는 거를 우리가 블라고 하겠습니다. 더블유는 결국 트레이닝 데이터로 이 데이터가 이 데이터가 트레이닝 데이터로 활용될 확률 값을 의미합니다. 자 우리가 앞에서 그림에서 본 것처럼 데이터 밸류 에스티메이터는 데이터가 들어오면 w를 아웃풋으로 내보낸다고 했잖아요. 얘가 이 데이터가 트레이닝 데이터에 포함될 확률 값입니다. 자 그다음에 h파의 d라는 거는 결국 트레이닝 데이터 전체에 대해서 우리가 얘를 포함시킬지 말지 엔게에 대해서 우리가 확률을 나타내는 걸로 생각할 수가 있을 거고요. 그다음에 s라는 거는 결국 바이너리 엔개의 데이터에 대해서 얘를 추가할 것인지 말 것인지 바이너리로 나타내는 것을 의미합니다. 즉 우리는 우리가 베르누이 분포를 활용하면 다음과 같이 우리가 작성을 할 수가 있게 됩니다. 즉 베르누이 분포를 활용하면은 자 그 데이터가 우리가 데이터가 인기가 있는데 그 데이터가 결국 포함될 확률인 거고 그 데이터가 포함되지 않을 확률 근데 여기서 우리가 그 데이터가 만약에 포함됐을 때 포함이 안 됐을 때 즉 우리가 동전을 엔게에 던졌을 때 우리가 앞면이 나올 확률 뒷면이 나올 확률을 모델링하는 것과 사실상 동일한 분포로 설정할 수가 있습니다. 자 이런 식으로 우리가 모델링을 하면 결국 이제 어떤 걸 하게 될 거냐면 자 프레딕터 같은 경우는 여기 나와 있는 프레딕터 프 같은 경우는 결국 우리한테 주어진 트레이닝 데이터에 대한 로스를 낮추기 위해서 미니마이즈 하기 위해서 학습되는 겁니다. 일반적인 그라이언트 디센트로 학습을 우리가 하면 되는 거예요. 그런데 여기서 데이터 에스티메이터 같은 경우는 우리가 샘플링 과정이 들어갑니다. 왜 우리가 그림에서 보면 데이트 이스트미트에서 이 데이터가 트레이닝 데이터로 포함될 확률 값이 각각 나오게 됩니다. 그러면 그랬을 때 이 확률 값이 나오면 이 확률 값에서 우리가 얘를 그래서 포함시킬지 말지 얘를 포함시킬지 말지 01로 샘플링을 합니다. 즉 얘가 0.7의 확률이 나왔다고 하더라도 어 얘를 무조건 포함시키는 게 아니라 랜덤하게 샘플링을 해서 물론 1이 나올 확률이 높겠죠. 그때는 1 0 해서 얘를 포함시킬지 말지 결정해서 우리가 선별된 데이터만 트레이닝 데이터로 모델을 학습하기 때문입니다. 즉 샘플링 과정이 들어가는 것이죠. 그러면 그라인 디센트로 우리가 학습이 어렵습니다. 그래서 여기서는 리인포스 알고리즘을 활용해서 치에 존재하는 이 데이터밸류 에스트메이터에 존재하는 파이라는 파라미터를 학습시킬 겁니다. 자 그래서 우리가 한번 살펴보면 결국 우리의 목적식은 이렇게 볼 수가 있습니다. 다음 보는 것과 같이 파이에 대해서만 우리가 집중을 한번 해보도록 하겠습니다. 왜냐하면 앞서 말씀드린 것처럼 프는 일반적인 그라진 디센트로 그냥 학습하면 되니까 근데 이 치파 얘를 어떻게 학습할 거냐 왜 한번 보시면 샘플링이 여기 들어갑니다. 자 샘플링이 여기 들어가고 로스가 여기 쪽에 있어요. 그렇죠 그럼 샘플링의 그 이후에 있는 샘플링과 로스 사이에 있는 이 프로젝터는 모델을 학습하는 데 문제가 전혀 없습니다. 다만 이 샘플링에 이전 단계에 있는 왜 로스가 이 샘플링을 타고 흐르지가 않기 때문에 그라디언트가 그래서 얘를 학습하기 위한 방법만 저희가 살펴보게 되는 것입니다. 자 그랬을 때 우리가 결국 목적식은 뭐냐면 우리가 어떻게 어떤 데이터를 포함시키고 어떤 트레인 데이터를 빼야지 밸리데이션 로스가 가장 작을까를 목표로 합니다. 그래서 목적식을 이렇게 쓸 수가 있겠죠 어떠한 데이터를 우리가 포함시키고 또는 포함시키지 않아야지 로스가 가장 작을까에 대한 얘기니까요. 어떤 트레이닝 데이터를 그쵸 엔게이 트레이닝 데이터가 있다고 할 때 이 중에서 뭐를 포함시키고 뭐를 포함시키지 말아야 될까를 우리가 학습하고 싶은 겁니다. 이 로스가 가장 작아지려면 여기에서 그러면 이 로스에 대해서 우리가 결국 그라디언트를 취해서 학습하게 되지 않습니까 그러면은 여기에서 한 번 그라디언트를 한번 취해 본다고 하겠습니다. 자 여기서 그라이던트를 한번 취해보면은 결국 우리가 학습하고 싶은 게 파이니까 파이에 대해서 그라이언트를 한번 취해보겠습니다. 그러면 이렇게 우리가 그라이언트가 계산이 되게 되겠죠 그렇죠 그런데 여기에서 한 가지 트랙이 존재합니다. 이런 트랙이 존재해요. 로그 함수에 대한 미분값이지 않습니까 그러면 얘는 로그 함수에 대한 미분값이니까 얘가 분모로 가고 그다음에 얘를 이 파이에 대해서 그라디언트 한번 취한 이 형태로 바뀌게 되는 거는 그렇죠 로그 함수에 대한 그라디언트 공식입니다. 그렇죠 자 그러면 우리가 이 분자에 대해서 정리하면 분자는 이거 곱하기 요걸로 볼 수가 있게 되는 것이죠. 그래서 한번 보시면 이거 대신에 얘가 이렇게 들어가 있는 걸 볼 수가 있습니다. 로그에 대한 그라디언트 그다음에 파이 즉 이 자리에 얘가 들어가 있는 거를 볼 수가 있게 되는 겁니다. 그쵸 자 그러면은 이제 우리가 얘를 또 어떻게 표현할 수 있냐면 이거에 대한 익스펙테이션으로 표현할 수 있는 거예요. 즉 우리가 얘는 우리가 하나 샘플링해서 가져오고 그다음에 이거에 대한 그라디언트를 우리가 구하는 거다로 해석을 할 수가 있게 되는 겁니다. 그렇죠 자 그 까닭에 우리는 이 식이 요렇게 결국 적히게 되고 그러고 나면은 우리는 이제 여기 나와 있는 그라디언트 식만 어떻게 계산할지 모르는 건데 이 식은 앞에서 이 파이파이라는 거를 우리가 베르누이 분포로 정의를 하지 않았습니까 그러면 베르누이 분포로 정의했기 때문에 이렇게 써지게 되고 결국은 프로덕트 형태로 쓰였겠지만 우리가 로그가 들어가게 되면서 서메이션 로그로 바뀌게 되는 것이죠. 그래서 우리가 파일을 베르뉴 분포로 정의했고 거기에 그라디언트 로그를 씌우고 그라이언트를 하면 이렇게 바뀌게 되고 그러면 이 그라이언트가 서메이션 안으로 들어가게 되면 이렇게 되는 것을 볼 수가 있습니다. 그러면 이제 우리는 모든 걸 다 계산할 수가 있게 된 거예요. 그렇죠 왜 이거에 대한 그라디언트 즉 우리는 그라디언트 디센트로 파일을 업데이트할 건데 파일에 대한 그라디언트가 이거라는 겁니다. 그럼 여기서 지금 우리가 계산을 못 할 거는 없어요. 왜 자 파일에서 그러면 파일을 통해서 각 데이터가 포함된 확률 값이 나오면 거기서 값을 우리가 샘플링합니다. 0 또는 1이라는 s 값을 샘플링합니다. 그렇죠 그다음에 그 0 또는 1이라는 샘플링 되는 s 값을 이용해서 여기 에스에 넣어 가지고 얘를 계산할 수가 있겠죠. 그다음에 얘는 밸리데이션에 대한 로스니까 밸리데이션에 대한 로스가 이제 들어가게 됩니다. 그럼 한번 보시면 밸리데이션에 대한 로스가 만약에 크면 이 그라디언트도 이제 우리가 크다고 볼 수 있겠죠 많이 변하겠죠 왜 밸리데이션에 대한 로스가 크면은 우리가 지금 뭔가 잘못 선택하고 있는 거니까 얘를 우리가 많이 그라이던트를 크게 키워서 우리가 파일을 많이 변화시키게 됩니다. 그래서 이런 과정으로 우리가 림포스먼트 러닝을 통해서 강화학습을 통해서도 이런 데이터 밸류에이션이 가능하다. 결국 이런 방식으로 우리가 활용하게 되면 전체의 트레인 데이터가 우리가 많이 주어지더라도 그걸 다 쓰지 않고 일부 데이터만 썼을 때도 여전히 좋은 성능 오히려 일부 데이터만 썼을 때 전체 데이터를 쓰는 것보다도 더 좋은 경우도 많이 볼 수가 있습니다. 왜냐하면 애초에 데이터 수집 과정에서 노이즈와 편향성 또는 이제 레이블의 잘못된 레이블의 에러는 사실상 사람이 하는 한 피할 수가 없는 거기 때문이에요. 그래서 다음과 같이 우리가 중요한 데이터를 파악해서 그 데이터만 학습할 경우에는 오히려 전체 데이터를 학습할 때보다 더 좋은 성능을 내기도 합니다. 네 그러면 이제는 저희가 세 번째 방법 데이터 오비로 한번 넘어가도록 하겠습니다. 아마 지금까지 데이터 가치 측정이 좀 많이 어려웠던 분들 같은 경우는 자 이 방법만 기억을 하셔도 괜찮습니다. 가장 단순하면서도 강력한 방법 중에 하나입니다. DVRL은 방금 봤던 DVRL 강화 학습 기반의 방법론은 사실 좀 스케일러블 알고리즘이긴 해요. 그러니까 우리가 앞에서 봤던 인플런스 펑션은 좋긴 한데 좀 만족하지 않는 컨디션이 있었고 그래서 데이터 쉐플린은 그러한 컨디션을 만족시키는 새로운 가치 평가 방법을 만든 거였습니다. 하지만 앞에서 봤던 인플루언서 펑션 그다음에 데이터 채플린은 모두 다 스케일러블 하지 않았어요. 그렇죠 데이터가 많아지거나 모델이 복잡해지면 좀 어려웠습니다. 그래서 디브알을 같은 경우는 강화 학습을 통해서 애초에 뭘 마스킹하고 뭘 마스킹 하지 않을지 이 데이터에 대한 확률값이 뭔지를 우리 모델로 학습시킨 겁니다. 그래서 굉장히 스케러블 즉 데이터가 많거나 모듈이 복잡해도 쓸 수 있는 알고리즘이었습니다. 하지만 디비아래을 현실에서는 적용하기 어려운 요소가 있어요. 어떤 요소일까요? 자 디브알을 힌트를 드리면 트레이 데이터로 우리가 학습을 했을 때 어떤 데이터들로 우리가 학습해야지 밸리데이션 데이터에 대해서 성능이 가장 높을지 정할 수 있는 방법이었습니다. 그렇죠 자 그거 만약에 DVRL 같은 방법을 현실에서 적용하기 어려운 이유는 뭘까요? 자 디브알엘은 밸리데이션 데이터가 필요합니다. 그렇죠 그래야지 DBRL은 결국 데이터밸류 에스티메이터가 학습하는 거는 목적식이 뭐였어요? 데이터밸류 에스티메이터가 학습하는 거는 밸리데이션 성능이 높아지도록 이걸 리워드로 해서 얘가 학습하는 겁니다. 즉 밸리데이션 데이터가 없다 또는 밸리데이션 데이터가 있는데 데이터가 굉장히 적거나 아니면은 노이지한 데이터가 많다라고 하면은 부정확한 가치 평가 기준이 되는 겁니다. 그래서 이거를 해결할 수 있는 방법은 없을까 즉 밸리데이션 데이터를 필요하지 않으면서 스케일러블한 데이터 어트리뷰션 또는 데이터 밸류에이션 방법은 없을까 입니다. 자 이거를 우리가 다음과 같은 배인 기반의 방법론으로 생각해 보겠습니다. 자 배깅이라는 것은 보트 스랩과 어그리게이션을 이제 합친 용어인데요. 예시로 트레인 데이터가 만약에 엔 게 있다고 하겠습니다. 그러면 특정 데이터 우리가 일단은 뭐 1개를 예를 들어서 제외하고 나머지 데이터로 학습을 하는 거예요. 그렇죠 그랬을 때 특정 데이터 1개에 대한 로스를 측정했을 때 로스가 크면 해당 데이터는 좀 중요한 데이터라고 볼 수 있다는 겁니다. 얘도 마찬가지로 r 기반의 방법이긴 하지만 더 스케일러블 합니다. 그전에 우리가 이 배경이 뭔지 한번 보도록 하겠습니다. 자 배깅이라는 거는 여러 개의 모델을 앙상블하는 방법이에요. 그래서 어떻게 구성이 되냐면 우리가 트레이닝 데이터에서 만약에 엔게이 트레이닝 데이터가 있다고 하겠습니다. 그럼 엔게이 트레이닝 데이터에서 중복을 허락해서 엔게를 샘플링합니다. w 리플레이스먼트로 그러면은 동일한 데이터가 여러 번 나올 수도 있는 거예요. 그렇죠 그러면 이 과정을 비번 반복합니다. 그러면 데이터 셋이 총 2개가 나옵니다. 즉 엔개의 데이터로 이루어진 데이터 셋이 총 2개가 나옵니다. 그렇죠 그러면은 각 모델에 대해서 각 데이터에 대해서 우리 모델을 각각 독립적으로 학습시키는 거예요. 그러면 비계의 모델이 나오게 되겠죠 그리고 그러한 모델들의 아웃풋을 앙상블하는 겁니다. 그게 베깅 알고리즘이에요. 그리고 가장 유명한 건 랜덤 포레스트가 대표적인 베깅 알고리즘의 예시입니다. 즉 우리가 데이터가 엔게에 있다고 하면 이 데이터 n개로 이루어진 한 개의 데이터 셋이 있는 거죠. 1개의 데이터 셋을 비개의 데이터셋으로 늘리는 겁니다. 그리고 각각 모델을 학습시키고 우리가 비개의 모델이 나오면 비개의 모델의 아웃풋을 안상불한다입니다. 그 컨셉을 이용할 거예요. 자 그러면은 여기서 한번 보면 이런 오리지널 데이터가 있습니다. 여기서 우리가 마찬가지로 우리가 앞서 봤던 것처럼 우리가 다음과 같이 부트스랩을 할 겁니다. 즉 말대로 4개의 데이터가 있는데 4개의 데이터로 이루어진 또 다른 데이터를 우리가 만드는 거예요. 여기서 우리가 중복을 허락해서 샘플링하면 이런 데이터가 만들어질 수도 있겠죠. 동일한 데이터가 한 번 더 있는 그러면 여기서 이 별표라는 데이터는 안 들어가 있습니다. 이런 거를 우리가 오비라고 할게요. 아로 베그라는 뜻에서 또 우리가 또 다른 부트스랩을 하면 이런 데이터도 만들어질 수가 있습니다. 그때 오비 데이터는 요거 근데 오비 데이터가 여러 개일 수도 있어요. 부트스랩을 해서 이렇게 만들면 오비 데이터는 이렇게 2개가 됩니다. 그렇죠 자 그러면 이 부트셋 된 데이터만 가지고 학습을 시킨 다음에 얘를 이거에 대한 성능을 측정하는 겁니다. 자 이거에 대해서 우리가 또 학습하고 이거에 대한 테스트 이거에 대해서 학습하고 이거에 대한 테스트를 하는 겁니다. 자 그러면 여기서 만약에 별표 데이터의 가치가 궁금하다 라고 하면은 별표 데이터가 오비에 들어가 있는 부트 셀만 고릅니다. 여기서 만약에 부트 셉이 이렇게 3개 있다라고 치면은 첫 번째랑 마지막 것만 우리가 고려할 겁니다. 별표가 OB로 들어가 있을 때만 별표를 만약에 같이 평가하고 싶으면 별표가 오호b에 있는 환경만 고려합니다. 자 그러면 그때 이것만 가지고 별표의 성능을 예측했습니다. 또 이것만 가지고 별표의 성능을 예측했습니다. 만약에 별표의 성능이 높다 즉 별표가 충분히 잘 예측된다라고 하면 어떨까요? 여러분 그때는 그때는 별표가 만약에 잘 예측이 된다라고 하면은 이 데이터는 어쩌면 중요한 데이터가 아닌 겁니다. 그렇죠 이 즉 여기서는 이거에 대한 로스가 커야지 이 로스가 커야지 별표가 중요한 겁니다. 왜 이 로스가 크다라는 말은 이 동그라미 세모 네모만 가지고는 이 별표의 패턴을 우리가 설명할 수 없다는 겁니다. 그럼 이 별표라는 데이터는 동그라미 세모 네모라는 데이터와는 다른 거니까 이들과는 다른 중요한 데이터라고 판단할 수 있는 거죠. 로스가 크면 자 그러면 그때 별표가 포함된 이 두 개를 우리가 종합해서 이렇게 즉 별표가 포함된 별표가 포함된 지금 부트 스랩의 개수가 분모로 오는 것이고요. 그럼 분모는 만약에 이렇게 3개의 부트스랩이 있다고 하시면 분모는 두 개가 되겠죠. 오비의 별표가 포함된 케이스는 두 가지입니다. 그리고 로스트를 측정해서 우리가 평균을 매길 건데 그때 이 별표가 오비에 있을 때만 그렇다는 겁니다. 즉 오 별표가 오오비에 있을 때만 이 별표에 대한 로스트를 측정해서 그 로스들을 우리가 평균 낸 거를 우리의 데이터 가치 평가라고 하겠다는 겁니다. 아시겠죠? 자 그러면 여기서 한번 보게 되면 얘가 얘는 밸리데이션 데이터는 필요 없다라는 걸 볼 수가 있겠죠. 왜 트레이닝 데이터를 가지고 우리가 부트스랩을 통해서 여러 데이터를 만들어서 문제를 해결한 겁니다. 그래서 밸리데이션 데이터가 필요 없기 때문에 DVR을 대비한 장점이 있죠. 자 그러면 두 번째 얘는 왜 스케일러블 하냐 생긴 것만 봤을 때는 얘도 루 방식 인플루언서 펑션이나 아니면은 데이터 쉐플이랑 동일하게 모델을 여러 번 학습해야 되는 것 같은데 왜 얘는 더 스킬러블하다고 하냐 자 여기서 한번 보면 얘는 이 데이터를 가지고 모델을 한번 학습하고 나면 뭐가 가능해집니까? 별표에 대한 데이터 가치 평가도 가능하고 빨간색 동그라미에 대한 데이터 가치 평가도 가능해지는 거예요. 한 번의 모델 학습으로 2개에 대한 데이터 가치 평가가 가능해지는 겁니다. 루 방식은 데이터를 하나만 빼고 넣는 거예요. 그래서 모델을 한 번 학습하면 그 데이터 하나에 대한 가치 평가만 가능한 겁니다. 그런 게 복잡하니까 인플루언서 펑션은 근사치를 계산한 건데 여전히 해시한 계산은 필요한 거죠. 근데 데이터 오비는 그런 거 없이 애초에 오비로 여러 개의 데이터가 들어갈 수도 있는 거니까 모델 하나만 학습해도 다음과 같은 데이터의 가치 평가를 여러 개에 대해서 잘 할 수 있다입니다. 그래서 실제로 뭐 데이터 개수가 많아진다고 하더라도 여전히 이제 속도가 거의 그대로 유지가 되는 굉장히 스케일러블한 알고리즘으로 볼 수가 있습니다. 그래서 결국에는 뭐 이런 데이터 오비를 뭐 우리가 앞에서 봤던 거를 좀 더 공식적으로 만약에 쓰게 되면은 이런 부트스랩 데이터를 만들고 이런 부트스랩 데이터에 대해서 가장 성능이 좋은 모델을 만든 다음에 그 모델을 이용해서 우리가 오오비 데이터에 대해서 성능 로스를 측정합니다. 그렇죠 그래서 그 로스가 크면 우리는 그 이런 오오비 데이터가 중요하다라고 말할 수가 있는 겁니다. 자 여기까지 해서 이번에는 다양한 데이터 밸류에이션 방법들을 봤습니다. 저희가 과거에 인플루언서 펑션을 봤었고 그다음에 오늘은 데이터 쉐플링 그리고 데이터 쉐플링의 그러한 스켈러블한 문제를 해결하기 위한 또 다른 데이터 밸류에이션 방법이죠. 디vrl 강화학습 기반의 방법론을 봤고 하지만 디브알엘은 또 밸리데이션 데이터가 반드시 필요하다라는 그리고 그러한 밸리데이션 데이터가 굉장히 깨끗하고 잘 큐레이션 되어 있는 데이터여야만 한다는 가정을 해야 하는 한계가 있습니다. 그런 한계를 깨뜨리면서도 스켈러블한 알고리즘인 데이터 오비까지 저희가 같이 한번 살펴봤습니다. 이러한 데이터 가치 측정 방법은 앞서 말씀드린 것처럼 모델의 설명 가능성을 향상시키는 것뿐만 아니라 우리 모델이 성능이 좋지 않을 때 결국 모델을 진단하고 트레인 데이터를 다시 구성하는 방법론으로 활용될 수 있습니다. 추천 시스템에 굉장히 활용 범위가 많은 방법론이다 보니까 여러분들께서 반드시 우리가 배운 네 가지 데이터 밸류에이션 방법 중에서 한 가지 정도는 깊게 이해하고 가시면 좋겠습니다. 네 여러분 고생 많으셨습니다."
}