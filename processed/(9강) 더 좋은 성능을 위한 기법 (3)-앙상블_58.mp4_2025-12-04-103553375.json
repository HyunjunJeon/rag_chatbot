{"result":"SUCCEEDED","message":"Succeeded","token":"5711e4ebbef648d1a93f91a50022dd59","version":"ncp_v2_v2.4.6-c00dd1b-20250528__v4.2.20.1_ko_firedepartment_20250923_","params":{"service":"ncp","domain":"general","lang":"ko","completion":"sync","callback":"","diarization":{"enable":false,"speakerCountMin":-1,"speakerCountMax":-1},"sed":{"enable":false},"boostings":[],"forbiddens":"","wordAlignment":true,"fullText":true,"noiseFiltering":true,"priority":0,"userdata":{"_ncp_DomainCode":"tpc-boostcamp","_ncp_DomainId":13807,"_ncp_TaskId":42975715,"_ncp_TraceId":"93f316d45e854989927f798e058d72e2"}},"progress":100,"keywords":{},"segments":[{"start":0,"end":12900,"text":"안녕하세요. 도메인 공통 프로젝트 9강 더 좋은 성능을 위한 기법 세 번째 앙상블 시작하겠습니다. 이번 강의에서는","confidence":0.9887,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[5770,6200,"안녕하세요."],[6510,6820,"도메인"],[6820,7060,"공통"],[7060,7420,"프로젝트"],[7550,7820,"9강"],[8170,8320,"더"],[8430,8600,"좋은"],[8710,8947,"성능을"],[8947,9120,"위한"],[9170,9440,"기법"],[9490,9640,"세"],[9640,9880,"번째"],[10170,10540,"앙상블"],[10810,11420,"시작하겠습니다."],[12070,12280,"이번"],[12350,12760,"강의에서는"]],"textEdited":"안녕하세요. 도메인 공통 프로젝트 9강 더 좋은 성능을 위한 기법 세 번째 앙상블 시작하겠습니다. 이번 강의에서는"},{"start":12900,"end":27700,"text":"여러 모델의 결과를 섞어서 더 좋은 성능을 내는 모델 앙상블에 대해서 이야기해 보겠습니다. 다음으로는 여러분들이 사용할 수 있는 몇 가지 앙상블 기법에 대해서 소개해 드리겠습니다. 첫 번째 모델 앙상블입니다.","confidence":0.9592,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[13150,13420,"여러"],[13430,13760,"모델의"],[13810,14260,"결과를"],[14630,15000,"섞어서"],[15210,15360,"더"],[15430,15600,"좋은"],[15750,15994,"성능을"],[15994,16200,"내는"],[16590,16840,"모델"],[16950,17447,"앙상블에"],[17447,17780,"대해서"],[18130,18507,"이야기해"],[18507,18940,"보겠습니다."],[19510,20040,"다음으로는"],[20390,20880,"여러분들이"],[20880,21160,"사용할"],[21160,21267,"수"],[21267,21460,"있는"],[21970,22120,"몇"],[22170,22440,"가지"],[22690,23080,"앙상블"],[23130,23460,"기법에"],[23460,23760,"대해서"],[24270,24567,"소개해"],[24567,25080,"드리겠습니다."],[26130,26280,"첫"],[26280,26520,"번째"],[26650,26900,"모델"],[26910,27480,"앙상블입니다."]],"textEdited":"여러 모델의 결과를 섞어서 더 좋은 성능을 내는 모델 앙상블에 대해서 이야기해 보겠습니다. 다음으로는 여러분들이 사용할 수 있는 몇 가지 앙상블 기법에 대해서 소개해 드리겠습니다. 첫 번째 모델 앙상블입니다."},{"start":27700,"end":39800,"text":"앙상블의 개념은 간단합니다. 단일 모델을 사용하는 것보다 여러 모델의 결과를 같이 사용하는 것이 더 좋은 예측 성능을 보여줄 수 있다라는 의미입니다. 예시에서 볼 수 있듯이","confidence":0.9849,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[28490,29020,"앙상블의"],[29020,29320,"개념은"],[29770,30220,"간단합니다."],[30750,31000,"단일"],[31070,31420,"모델을"],[31420,31674,"사용하는"],[31674,32000,"것보다"],[32350,32620,"여러"],[32620,32940,"모델의"],[33110,33500,"결과를"],[33550,33840,"같이"],[33840,34200,"사용하는"],[34200,34460,"것이"],[35050,35200,"더"],[35310,35480,"좋은"],[35570,35800,"예측"],[35830,36100,"성능을"],[36100,36340,"보여줄"],[36340,36447,"수"],[36447,37300,"있다라는"],[37570,38040,"의미입니다."],[38650,39040,"예시에서"],[39050,39200,"볼"],[39230,39334,"수"],[39334,39640,"있듯이"]],"textEdited":"앙상블의 개념은 간단합니다. 단일 모델을 사용하는 것보다 여러 모델의 결과를 같이 사용하는 것이 더 좋은 예측 성능을 보여줄 수 있다라는 의미입니다. 예시에서 볼 수 있듯이"},{"start":39800,"end":49000,"text":"테스트 샘플을 마이 모델 이외에도 다른 종류의 여러 모델들의 결과를 출력한 뒤에 이를 합산해서 결과를 만들어내는","confidence":0.9769,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[40270,40600,"테스트"],[40610,40980,"샘플을"],[41450,41700,"마이"],[41750,42000,"모델"],[42050,42520,"이외에도"],[43070,43320,"다른"],[43470,43780,"종류의"],[43790,44040,"여러"],[44110,44580,"모델들의"],[44810,45320,"결과를"],[45830,46200,"출력한"],[46200,46440,"뒤에"],[46910,47120,"이를"],[47190,47640,"합산해서"],[47910,48360,"결과를"],[48370,48840,"만들어내는"]],"textEdited":"테스트 샘플을 마이 모델 이외에도 다른 종류의 여러 모델들의 결과를 출력한 뒤에 이를 합산해서 결과를 만들어내는"},{"start":49000,"end":63300,"text":"앙상블이 더 좋은 성능을 보여줄 수 있다라는 것입니다. 조금 더 직관적으로 이해해 보겠습니다. 우리가 전교 1, 2, 3, 4등의 4명의 학생이 있다고 가정해 보겠습니다. 전교 2 3, 4등의 학생은","confidence":0.9688,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[49310,49840,"앙상블이"],[50230,50380,"더"],[50470,50640,"좋은"],[50730,51020,"성능을"],[51030,51320,"보여줄"],[51320,51414,"수"],[51414,51800,"있다라는"],[51800,52180,"것입니다."],[52890,53120,"조금"],[53120,53240,"더"],[53310,53860,"직관적으로"],[54410,54667,"이해해"],[54667,55140,"보겠습니다."],[55910,56180,"우리가"],[56490,56860,"전교"],[57070,57220,"1,"],[57230,57380,"2,"],[57390,57540,"3,"],[57630,58040,"4등의"],[58650,59020,"4명의"],[59030,59307,"학생이"],[59307,59640,"있다고"],[60110,60387,"가정해"],[60387,60840,"보겠습니다."],[61510,61800,"전교"],[61890,62040,"2"],[62070,62220,"3,"],[62350,62760,"4등의"],[62770,63080,"학생은"]],"textEdited":"앙상블이 더 좋은 성능을 보여줄 수 있다라는 것입니다. 조금 더 직관적으로 이해해 보겠습니다. 우리가 전교 1, 2, 3, 4등의 4명의 학생이 있다고 가정해 보겠습니다. 전교 2 3, 4등의 학생은"},{"start":63300,"end":76100,"text":"전교 1등과 개개인의 성적을 비교했을 때 이길 수 없다고 가정을 해 보겠습니다. 하지만 전교 2등, 3등, 4등 학생이 잘하는 과목이 다르다면","confidence":0.9639,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[64110,64480,"전교"],[64670,65160,"1등과"],[65430,65920,"개개인의"],[66450,66800,"성적을"],[66830,67280,"비교했을"],[67310,67460,"때"],[67710,67960,"이길"],[68050,68200,"수"],[68330,68760,"없다고"],[69150,69427,"가정을"],[69427,69500,"해"],[69500,69960,"보겠습니다."],[70510,70840,"하지만"],[71370,71680,"전교"],[71790,72060,"2등,"],[72450,72740,"3등,"],[73230,73540,"4등"],[73610,74000,"학생이"],[74510,74900,"잘하는"],[74950,75320,"과목이"],[75390,75860,"다르다면"]],"textEdited":"전교 1등과 개개인의 성적을 비교했을 때 이길 수 없다고 가정을 해 보겠습니다. 하지만 전교 2등, 3등, 4등 학생이 잘하는 과목이 다르다면"},{"start":76100,"end":90500,"text":"그리고 이 3명의 점수 혹은 이 3명의 풀이를 혹은 정답을 합쳐서 성적을 낸다면 모두 준수하게 잘하는 전교 1등을 이길 수 있다 이런 식으로 이해하시면 좋겠습니다.","confidence":0.9824,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[76690,77000,"그리고"],[77310,77460,"이"],[77550,77940,"3명의"],[78490,78840,"점수"],[79210,79420,"혹은"],[79510,79660,"이"],[79710,80120,"3명의"],[80770,81160,"풀이를"],[81630,81840,"혹은"],[81930,82340,"정답을"],[82870,83260,"합쳐서"],[83470,83840,"성적을"],[83870,84300,"낸다면"],[84990,85260,"모두"],[85310,85700,"준수하게"],[85700,86020,"잘하는"],[86430,86740,"전교"],[86770,87140,"1등을"],[87510,87740,"이길"],[87770,87920,"수"],[87930,88180,"있다"],[88790,88980,"이런"],[89010,89280,"식으로"],[89280,89740,"이해하시면"],[89930,90500,"좋겠습니다."]],"textEdited":"그리고 이 3명의 점수 혹은 이 3명의 풀이를 혹은 정답을 합쳐서 성적을 낸다면 모두 준수하게 잘하는 전교 1등을 이길 수 있다 이런 식으로 이해하시면 좋겠습니다."},{"start":90500,"end":102600,"text":"하지만 성적이 고만고만한 학생들끼리 뭉치는 경우에는 어떻게 해도 전교 1등보다 높은 성적을 받기는 어렵습니다. 이는 여러분들이 모델을 앙상블을 할 때","confidence":0.9567,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[91310,91620,"하지만"],[91970,92320,"성적이"],[92350,92880,"고만고만한"],[92890,93440,"학생들끼리"],[93810,94220,"뭉치는"],[94270,94740,"경우에는"],[95510,95900,"어떻게"],[95910,96160,"해도"],[96710,97040,"전교"],[97130,97640,"1등보다"],[97870,98100,"높은"],[98230,98560,"성적을"],[98650,99040,"받기는"],[99250,99740,"어렵습니다."],[100350,100600,"이는"],[100630,101120,"여러분들이"],[101170,101560,"모델을"],[101710,102200,"앙상블을"],[102200,102320,"할"],[102320,102460,"때"]],"textEdited":"하지만 성적이 고만고만한 학생들끼리 뭉치는 경우에는 어떻게 해도 전교 1등보다 높은 성적을 받기는 어렵습니다. 이는 여러분들이 모델을 앙상블을 할 때"},{"start":102600,"end":113800,"text":"모든 모델을 기반으로 결과를 내는 것이 아니라 어느 정도 성능이 좋은 성능이 비슷한 모델들의 결과들을 섞어야 더 좋은 성능을 얻을 수 있다는 것을 의미합니다.","confidence":0.9945,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[103210,103460,"모든"],[103510,103860,"모델을"],[103890,104300,"기반으로"],[104630,104987,"결과를"],[104987,105187,"내는"],[105187,105427,"것이"],[105427,105680,"아니라"],[106350,106527,"어느"],[106527,106820,"정도"],[107270,107660,"성능이"],[107830,108000,"좋은"],[108530,108900,"성능이"],[109030,109420,"비슷한"],[109570,110120,"모델들의"],[110270,110740,"결과들을"],[110750,111100,"섞어야"],[111670,111820,"더"],[111930,112100,"좋은"],[112190,112500,"성능을"],[112570,112780,"얻을"],[112780,112874,"수"],[112874,113114,"있다는"],[113114,113340,"것을"],[113340,113780,"의미합니다."]],"textEdited":"모든 모델을 기반으로 결과를 내는 것이 아니라 어느 정도 성능이 좋은 성능이 비슷한 모델들의 결과들을 섞어야 더 좋은 성능을 얻을 수 있다는 것을 의미합니다."},{"start":113800,"end":125100,"text":"앙상블의 대표적인 방식인 베깅에 대해서 개념적으로 이해해 보겠습니다. 베깅은 bing로 이해하시면 됩니다. 가지고 있는 데이터셋을","confidence":0.9405,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[114270,114760,"앙상블의"],[114810,115200,"대표적인"],[115270,115620,"방식인"],[115910,116300,"베깅에"],[116300,116580,"대해서"],[117090,117680,"개념적으로"],[117790,118080,"이해해"],[118080,118540,"보겠습니다."],[119310,119720,"베깅은"],[120150,121940,"bing로"],[122050,122414,"이해하시면"],[122414,122660,"됩니다."],[123570,123920,"가지고"],[123920,124100,"있는"],[124250,125000,"데이터셋을"]],"textEdited":"앙상블의 대표적인 방식인 베깅에 대해서 개념적으로 이해해 보겠습니다. 베깅은 bing로 이해하시면 됩니다. 가지고 있는 데이터셋을"},{"start":125100,"end":139900,"text":"여러 분할로 쪼개어서 가방에 담는다고 상상해 보겠습니다. 각각의 모델들은 각 가방에 담긴 여러 서로 다른 데이터셋을 기반으로 모델을 학습하게 됩니다. 이 학습한 결과를 기반으로","confidence":0.976,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[125430,125740,"여러"],[125770,126260,"분할로"],[126570,127040,"쪼개어서"],[127450,127820,"가방에"],[128050,128560,"담는다고"],[128590,128887,"상상해"],[128887,129320,"보겠습니다."],[129850,130260,"각각의"],[130270,130720,"모델들은"],[131310,131460,"각"],[131590,131940,"가방에"],[131970,132240,"담긴"],[133010,133300,"여러"],[134130,134400,"서로"],[134410,134660,"다른"],[134890,135520,"데이터셋을"],[135520,135920,"기반으로"],[136330,136700,"모델을"],[136870,137214,"학습하게"],[137214,137460,"됩니다."],[138170,138320,"이"],[138370,138680,"학습한"],[138770,139200,"결과를"],[139250,139680,"기반으로"]],"textEdited":"여러 분할로 쪼개어서 가방에 담는다고 상상해 보겠습니다. 각각의 모델들은 각 가방에 담긴 여러 서로 다른 데이터셋을 기반으로 모델을 학습하게 됩니다. 이 학습한 결과를 기반으로"},{"start":139900,"end":154800,"text":"예측 값을 만들어 내는 것이 베깅입니다. 여기에서 각 모델들의 결과를 섞는 방식이 섞는 방식을 우리가 보팅이라고 하는데요. 그래서 베깅은 보팅 앙상블의 어떤 예시로 이해할 수도 있습니다.","confidence":0.9623,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[140170,140480,"예측"],[140480,140720,"값을"],[140720,140914,"만들어"],[140914,141067,"내는"],[141067,141300,"것이"],[141470,141980,"베깅입니다."],[142570,143000,"여기에서"],[143590,143740,"각"],[143810,144220,"모델들의"],[144270,144700,"결과를"],[144850,145140,"섞는"],[145230,145620,"방식이"],[146270,146520,"섞는"],[146610,147000,"방식을"],[147330,147580,"우리가"],[147650,148260,"보팅이라고"],[148550,148940,"하는데요."],[149530,149780,"그래서"],[150070,150480,"베깅은"],[150870,151160,"보팅"],[151210,151680,"앙상블의"],[152390,152640,"어떤"],[152890,153300,"예시로"],[153550,153880,"이해할"],[153880,154100,"수도"],[154310,154720,"있습니다."]],"textEdited":"예측 값을 만들어 내는 것이 베깅입니다. 여기에서 각 모델들의 결과를 섞는 방식이 섞는 방식을 우리가 보팅이라고 하는데요. 그래서 베깅은 보팅 앙상블의 어떤 예시로 이해할 수도 있습니다."},{"start":154800,"end":168400,"text":"다음은 보팅이 어떤 식으로 이루어지는지 조금 더 자세히 다뤄보겠습니다. 현재 우리가 풀고자 하는 문제는 주어진 입력에 대해 이 입력이 어떤 음식을 뜻하는지 분류하는 문제입니다. 먼저 하드 보팅입니다.","confidence":0.9484,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[155130,155440,"다음은"],[155710,156200,"보팅이"],[156390,156660,"어떤"],[156730,157020,"식으로"],[157070,157680,"이루어지는지"],[157930,158160,"조금"],[158160,158280,"더"],[158310,158640,"자세히"],[158830,159480,"다뤄보겠습니다."],[160170,160387,"현재"],[160387,160620,"우리가"],[160670,161020,"풀고자"],[161020,161180,"하는"],[161290,161660,"문제는"],[162070,162400,"주어진"],[162450,162754,"입력에"],[162754,162960,"대해"],[163370,163520,"이"],[163550,163920,"입력이"],[164170,164400,"어떤"],[164410,164687,"음식을"],[164687,165240,"뜻하는지"],[165550,166000,"분류하는"],[166230,166680,"문제입니다."],[167270,167520,"먼저"],[167520,167740,"하드"],[167740,168180,"보팅입니다."]],"textEdited":"다음은 보팅이 어떤 식으로 이루어지는지 조금 더 자세히 다뤄보겠습니다. 현재 우리가 풀고자 하는 문제는 주어진 입력에 대해 이 입력이 어떤 음식을 뜻하는지 분류하는 문제입니다. 먼저 하드 보팅입니다."},{"start":168400,"end":181300,"text":"하드 보팅은 말 그대로 레이블 그 자체로 보팅을 수행합니다. 첫 번째 모델은 애플, 두 번째 세 번째 모델 모두 애플이라고 답했습니다. 하지만 네 번째 모델은 핫도그라고 답변을 했는데요.","confidence":0.9544,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[168710,168960,"하드"],[168960,169260,"보팅은"],[169450,169600,"말"],[169730,170060,"그대로"],[170470,170780,"레이블"],[170950,171100,"그"],[171150,171600,"자체로"],[171710,172120,"보팅을"],[172290,172720,"수행합니다."],[173430,173580,"첫"],[173590,173820,"번째"],[173820,174120,"모델은"],[174190,174400,"애플,"],[174870,175020,"두"],[175020,175280,"번째"],[175530,175680,"세"],[175680,175900,"번째"],[175900,176120,"모델"],[176170,176440,"모두"],[176790,177320,"애플이라고"],[177510,178020,"답했습니다."],[178470,178720,"하지만"],[178730,178880,"네"],[178880,179120,"번째"],[179120,179420,"모델은"],[179490,180060,"핫도그라고"],[180430,180727,"답변을"],[180727,181080,"했는데요."]],"textEdited":"하드 보팅은 말 그대로 레이블 그 자체로 보팅을 수행합니다. 첫 번째 모델은 애플, 두 번째 세 번째 모델 모두 애플이라고 답했습니다. 하지만 네 번째 모델은 핫도그라고 답변을 했는데요."},{"start":181300,"end":194800,"text":"여기에서 4개의 모델의 앙상블 결과는 3개의 사과 1개의 핫도그가 됩니다. 이를 통해 결과가 사과가 되는 것을 확인하실 수가 있습니다. 다음은 소프트 보팅입니다. 제가 우리 강의에서","confidence":0.951,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[181750,182220,"여기에서"],[182370,182740,"4개의"],[182750,183100,"모델의"],[183170,183540,"앙상블"],[183570,183980,"결과는"],[184410,184800,"3개의"],[185010,185260,"사과"],[185830,186180,"1개의"],[186310,186687,"핫도그가"],[186687,186940,"됩니다."],[187530,187720,"이를"],[187720,187920,"통해"],[187930,188340,"결과가"],[188770,189100,"사과가"],[189100,189227,"되는"],[189227,189480,"것을"],[189650,190020,"확인하실"],[190020,190200,"수가"],[190200,190500,"있습니다."],[191270,191600,"다음은"],[191630,191927,"소프트"],[191927,192360,"보팅입니다."],[193090,193320,"제가"],[193590,193800,"우리"],[193890,194320,"강의에서"]],"textEdited":"여기에서 4개의 모델의 앙상블 결과는 3개의 사과 1개의 핫도그가 됩니다. 이를 통해 결과가 사과가 되는 것을 확인하실 수가 있습니다. 다음은 소프트 보팅입니다. 제가 우리 강의에서"},{"start":194800,"end":207000,"text":"사실 분류 모델이 반환하는 것은 어떤 분류 클래스가 아니라 그 직전에 확률 값을 반환한다고 언급한 적이 있습니다. 예시에서 볼 수 있듯이 모델 1 2 3","confidence":0.9779,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[195110,195380,"사실"],[195490,195760,"분류"],[195790,196120,"모델이"],[196170,196527,"반환하는"],[196527,196800,"것은"],[197210,197400,"어떤"],[197470,197700,"분류"],[197890,198274,"클래스가"],[198274,198520,"아니라"],[199030,199180,"그"],[199270,199720,"직전에"],[200210,200440,"확률"],[200450,200740,"값을"],[200870,201460,"반환한다고"],[201690,202060,"언급한"],[202060,202300,"적이"],[202430,202800,"있습니다."],[203270,203700,"예시에서"],[203710,203860,"볼"],[203890,203994,"수"],[203994,204300,"있듯이"],[204770,205020,"모델"],[205070,205220,"1"],[205790,205940,"2"],[206510,206660,"3"]],"textEdited":"사실 분류 모델이 반환하는 것은 어떤 분류 클래스가 아니라 그 직전에 확률 값을 반환한다고 언급한 적이 있습니다. 예시에서 볼 수 있듯이 모델 1 2 3"},{"start":207000,"end":220200,"text":"사과 출력하는 각 클래스에 대한 확률을 볼 수가 있습니다. 이 과정에서 모델 1 2 3이 사과라고 답변을 했지만 실제로는 각 모델이 보여주는","confidence":0.979,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[207330,207640,"사과"],[207970,208440,"출력하는"],[209070,209220,"각"],[209310,209667,"클래스에"],[209667,209860,"대한"],[210030,210400,"확률을"],[210650,210800,"볼"],[210850,211060,"수가"],[211170,211540,"있습니다."],[212370,212520,"이"],[212530,212920,"과정에서"],[213650,213900,"모델"],[214130,214280,"1"],[214280,214420,"2"],[214420,214700,"3이"],[215570,216120,"사과라고"],[216290,216607,"답변을"],[216607,216920,"했지만"],[218030,218440,"실제로는"],[218790,218940,"각"],[219110,219460,"모델이"],[219610,220080,"보여주는"]],"textEdited":"사과 출력하는 각 클래스에 대한 확률을 볼 수가 있습니다. 이 과정에서 모델 1 2 3이 사과라고 답변을 했지만 실제로는 각 모델이 보여주는"},{"start":220200,"end":233300,"text":"컨피던스는 약간 다를 수 있습니다. 1번 모델은 0.5의 확률로 사과하라고 답했고요. 2번 모델은 0.8의 확률로 사과하라고 답했습니다. 모델 3은 0.7의 확률로 사과하라고 답했습니다.","confidence":0.9608,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[220530,221140,"컨피던스는"],[221350,221620,"약간"],[221670,221867,"다를"],[221867,221940,"수"],[221940,222240,"있습니다."],[222670,222940,"1번"],[222950,223280,"모델은"],[223550,224300,"0.5의"],[224510,224920,"확률로"],[225530,225907,"사과하라고"],[225907,226320,"답했고요."],[226750,226980,"2번"],[226990,227320,"모델은"],[227510,228060,"0.8의"],[228060,228380,"확률로"],[228650,229080,"사과하라고"],[229080,229520,"답했습니다."],[230170,230440,"모델"],[230440,230700,"3은"],[230990,231540,"0.7의"],[231540,231840,"확률로"],[232150,232580,"사과하라고"],[232710,233220,"답했습니다."]],"textEdited":"컨피던스는 약간 다를 수 있습니다. 1번 모델은 0.5의 확률로 사과하라고 답했고요. 2번 모델은 0.8의 확률로 사과하라고 답했습니다. 모델 3은 0.7의 확률로 사과하라고 답했습니다."},{"start":233300,"end":247900,"text":"이런 식으로 각각 레이블의 확률을 출력으로 삼아서 이 확률을 모두 평균을 낸 뒤에 가장 평균 확률이 높은 클래스를 선택하는 방식이 소프트 보팅입니다. 우리가 가능하다면","confidence":0.9662,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[233950,234160,"이런"],[234210,234540,"식으로"],[235170,235580,"각각"],[235950,236360,"레이블의"],[236610,237020,"확률을"],[237610,238080,"출력으로"],[238130,238520,"삼아서"],[238890,239040,"이"],[239090,239420,"확률을"],[239610,239860,"모두"],[240050,240440,"평균을"],[240510,240660,"낸"],[240690,240960,"뒤에"],[241450,241700,"가장"],[241990,242240,"평균"],[242240,242480,"확률이"],[242480,242700,"높은"],[243230,243640,"클래스를"],[243640,244000,"선택하는"],[244070,244440,"방식이"],[244770,245087,"소프트"],[245087,245560,"보팅입니다."],[246310,246620,"우리가"],[247010,247680,"가능하다면"]],"textEdited":"이런 식으로 각각 레이블의 확률을 출력으로 삼아서 이 확률을 모두 평균을 낸 뒤에 가장 평균 확률이 높은 클래스를 선택하는 방식이 소프트 보팅입니다. 우리가 가능하다면"},{"start":247900,"end":259700,"text":"일반적으로는 하드 보팅보다는 소프트 보팅을 사용하는 것을 추천드리고 조금 더 일반적인 방법입니다. 다음은 앙상블의 대표적인 다른 형태인 부스팅에 대해서 설명하도록 하겠습니다.","confidence":0.9298,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[248370,249140,"일반적으로는"],[249550,249800,"하드"],[249800,250320,"보팅보다는"],[250610,250980,"소프트"],[250980,251340,"보팅을"],[251370,251747,"사용하는"],[251747,252020,"것을"],[252370,252920,"추천드리고"],[253150,253380,"조금"],[253380,253520,"더"],[253650,254120,"일반적인"],[254150,254640,"방법입니다."],[255310,255680,"다음은"],[256010,256540,"앙상블의"],[256710,257120,"대표적인"],[257130,257340,"다른"],[257350,257620,"형태인"],[257650,258027,"부스팅에"],[258027,258320,"대해서"],[258510,258947,"설명하도록"],[258947,259340,"하겠습니다."]],"textEdited":"일반적으로는 하드 보팅보다는 소프트 보팅을 사용하는 것을 추천드리고 조금 더 일반적인 방법입니다. 다음은 앙상블의 대표적인 다른 형태인 부스팅에 대해서 설명하도록 하겠습니다."},{"start":259700,"end":270700,"text":"부스팅은 내부적으로 여러 개의 모델을 생성을 합니다. 각각의 모델은 순차적으로 학습되고 평가됩니다. 각 모델에서 틀린 샘플,","confidence":0.9878,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[260050,260560,"부스팅은"],[261150,261720,"내부적으로"],[261850,262140,"여러"],[262140,262400,"개의"],[262430,262820,"모델을"],[263030,263340,"생성을"],[263350,263620,"합니다."],[264430,264800,"각각의"],[264800,265140,"모델은"],[265530,266120,"순차적으로"],[266150,266640,"학습되고"],[266990,267520,"평가됩니다."],[268050,268200,"각"],[268430,268920,"모델에서"],[269430,269700,"틀린"],[270230,270500,"샘플,"]],"textEdited":"부스팅은 내부적으로 여러 개의 모델을 생성을 합니다. 각각의 모델은 순차적으로 학습되고 평가됩니다. 각 모델에서 틀린 샘플,"},{"start":270700,"end":284500,"text":"잘못 맞춘 샘플에 대해 다음 모델이 더 잘 맞출 수 있도록 가중치를 주거나 혹은 그레디언트를 통해 더 높은 로스를 발생시켜 많은 업데이트를 할 수 있도록 만드는 것이 부스팅입니다.","confidence":0.9903,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[271050,271340,"잘못"],[271390,271680,"맞춘"],[271750,272087,"샘플에"],[272087,272300,"대해"],[272610,272900,"다음"],[273010,273360,"모델이"],[273670,273820,"더"],[274010,274160,"잘"],[274210,274480,"맞출"],[274490,274607,"수"],[274607,274940,"있도록"],[275410,276020,"가중치를"],[276050,276420,"주거나"],[276750,276980,"혹은"],[277330,278040,"그레디언트를"],[278070,278320,"통해"],[278570,278720,"더"],[278870,279140,"높은"],[279350,279780,"로스를"],[279890,280420,"발생시켜"],[280870,281100,"많은"],[281430,282000,"업데이트를"],[282050,282200,"할"],[282200,282294,"수"],[282294,282640,"있도록"],[283050,283400,"만드는"],[283400,283640,"것이"],[283830,284460,"부스팅입니다."]],"textEdited":"잘못 맞춘 샘플에 대해 다음 모델이 더 잘 맞출 수 있도록 가중치를 주거나 혹은 그레디언트를 통해 더 높은 로스를 발생시켜 많은 업데이트를 할 수 있도록 만드는 것이 부스팅입니다."},{"start":284500,"end":299400,"text":"조금 쉽게 말하면 1번 모델이 틀린 문제를 2번 모델이 집중적으로 학습하고, 2번 모델이 틀린 문제를, 3번 모델이, 3번 모델이 틀린 문제를, 4번 모델이 이런 식으로 점진적으로 취약점을 해결해 나가는 방안으로 모델이 업데이트됩니다.","confidence":0.9882,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[284830,285060,"조금"],[285130,285420,"쉽게"],[285420,285760,"말하면"],[286190,286460,"1번"],[286490,286820,"모델이"],[286830,287040,"틀린"],[287050,287380,"문제를"],[287670,287900,"2번"],[287910,288260,"모델이"],[288410,288840,"집중적으로"],[288840,289260,"학습하고,"],[289530,289780,"2번"],[289790,290100,"모델이"],[290100,290320,"틀린"],[290370,290700,"문제를,"],[291070,291340,"3번"],[291340,291660,"모델이,"],[291930,292147,"3번"],[292147,292347,"모델이"],[292347,292520,"틀린"],[292520,292820,"문제를,"],[293130,293380,"4번"],[293380,293700,"모델이"],[294170,294360,"이런"],[294450,294760,"식으로"],[295190,295900,"점진적으로"],[296170,296640,"취약점을"],[296640,296907,"해결해"],[296907,297220,"나가는"],[297330,297740,"방안으로"],[298110,298460,"모델이"],[298690,299280,"업데이트됩니다."]],"textEdited":"조금 쉽게 말하면 1번 모델이 틀린 문제를 2번 모델이 집중적으로 학습하고, 2번 모델이 틀린 문제를, 3번 모델이, 3번 모델이 틀린 문제를, 4번 모델이 이런 식으로 점진적으로 취약점을 해결해 나가는 방안으로 모델이 업데이트됩니다."},{"start":299400,"end":309700,"text":"결과적으로는 부스팅 과정을 통해 생성된 모든 모델의 결과를 보팅 연산을 통해 만들어내게 됩니다. 다음은 부스팅 학습 과정을 보여줍니다. 첫 번째 예시를 보겠습니다.","confidence":0.9877,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[299830,300500,"결과적으로는"],[300590,300960,"부스팅"],[300970,301280,"과정을"],[301290,301520,"통해"],[301590,301960,"생성된"],[302250,302480,"모든"],[302570,302900,"모델의"],[302910,303300,"결과를"],[303870,304180,"보팅"],[304210,304560,"연산을"],[304560,304780,"통해"],[305230,305634,"만들어내게"],[305634,305900,"됩니다."],[306290,306600,"다음은"],[306710,307080,"부스팅"],[307110,307340,"학습"],[307340,307640,"과정을"],[307650,308060,"보여줍니다."],[308630,308780,"첫"],[308790,308987,"번째"],[308987,309194,"예시를"],[309194,309600,"보겠습니다."]],"textEdited":"결과적으로는 부스팅 과정을 통해 생성된 모든 모델의 결과를 보팅 연산을 통해 만들어내게 됩니다. 다음은 부스팅 학습 과정을 보여줍니다. 첫 번째 예시를 보겠습니다."},{"start":309700,"end":323300,"text":"백인과 동일하게 학습 셋은 랜덤하게 샘플링을 합니다. 여기서 랜덤하게 샘플링한다라는 것은 랜덤하게 행을 선택하는 것도 포함하며, 랜덤하게 피처 컬럼을 열을 선택하는 것도 포함을 합니다.","confidence":0.9415,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[309990,310440,"백인과"],[310490,310940,"동일하게"],[311490,311780,"학습"],[311780,312060,"셋은"],[312350,312900,"랜덤하게"],[313070,313580,"샘플링을"],[313790,314080,"합니다."],[314370,314700,"여기서"],[314730,315120,"랜덤하게"],[315120,315674,"샘플링한다라는"],[315674,315900,"것은"],[316310,316760,"랜덤하게"],[316870,317140,"행을"],[317530,317947,"선택하는"],[317947,318260,"것도"],[318490,318920,"포함하며,"],[319350,319880,"랜덤하게"],[320230,320540,"피처"],[320830,321200,"컬럼을"],[321370,321740,"열을"],[321970,322407,"선택하는"],[322407,322680,"것도"],[322750,322967,"포함을"],[322967,323220,"합니다."]],"textEdited":"백인과 동일하게 학습 셋은 랜덤하게 샘플링을 합니다. 여기서 랜덤하게 샘플링한다라는 것은 랜덤하게 행을 선택하는 것도 포함하며, 랜덤하게 피처 컬럼을 열을 선택하는 것도 포함을 합니다."},{"start":323300,"end":337800,"text":"그래서 첫 번째 학습 셋에 대해서 첫 번째 모델을 학습하고 밸리데이션을 진행합니다. 예측을 진행한다는 것이죠. 예측된 밸리데이션 레이블과 실제 밸리데이션 레이블의 결과를 비교하여 잘못 예측된 에러를 계산합니다.","confidence":0.9816,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[323530,323740,"그래서"],[323750,323900,"첫"],[323930,324180,"번째"],[324270,324500,"학습"],[324500,324780,"셋에"],[324830,325160,"대해서"],[325530,325680,"첫"],[325690,325940,"번째"],[325950,326260,"모델을"],[326260,326660,"학습하고"],[326990,327520,"밸리데이션을"],[327520,327900,"진행합니다."],[328310,328680,"예측을"],[328690,329087,"진행한다는"],[329087,329400,"것이죠."],[329930,330420,"예측된"],[330950,331380,"밸리데이션"],[331510,331920,"레이블과"],[332430,332740,"실제"],[332750,333100,"밸리데이션"],[333130,333540,"레이블의"],[333770,334240,"결과를"],[334870,335340,"비교하여"],[335770,336040,"잘못"],[336070,336440,"예측된"],[336530,336900,"에러를"],[337210,337780,"계산합니다."]],"textEdited":"그래서 첫 번째 학습 셋에 대해서 첫 번째 모델을 학습하고 밸리데이션을 진행합니다. 예측을 진행한다는 것이죠. 예측된 밸리데이션 레이블과 실제 밸리데이션 레이블의 결과를 비교하여 잘못 예측된 에러를 계산합니다."},{"start":337800,"end":351300,"text":"그리고 이 잘못 예측된 에러를 다음 모델 학습에 포함하게 하여 더 잘 맞출 수 있도록 합니다. 이런 식으로 이터레이션을 반복해 나가면서 이전 단계에서 틀렸던 샘플에 대해 좋은 모델을 학습할 수 있도록 모델을 개선합니다.","confidence":0.9865,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[338010,338320,"그리고"],[338350,338500,"이"],[338550,338800,"잘못"],[338950,339300,"예측된"],[339470,339820,"에러를"],[340270,340500,"다음"],[340570,340840,"모델"],[340870,341220,"학습에"],[341470,341960,"포함하게"],[341970,342200,"하여"],[342470,342620,"더"],[342770,342920,"잘"],[342970,343240,"맞출"],[343240,343334,"수"],[343334,343600,"있도록"],[343600,343860,"합니다."],[344370,344560,"이런"],[344610,344860,"식으로"],[344860,345380,"이터레이션을"],[345590,345960,"반복해"],[345960,346420,"나가면서"],[346750,347000,"이전"],[347130,347520,"단계에서"],[347590,347860,"틀렸던"],[347910,348214,"샘플에"],[348214,348420,"대해"],[348770,348980,"좋은"],[349010,349340,"모델을"],[349510,349807,"학습할"],[349807,349894,"수"],[349894,350220,"있도록"],[350410,350760,"모델을"],[350770,351200,"개선합니다."]],"textEdited":"그리고 이 잘못 예측된 에러를 다음 모델 학습에 포함하게 하여 더 잘 맞출 수 있도록 합니다. 이런 식으로 이터레이션을 반복해 나가면서 이전 단계에서 틀렸던 샘플에 대해 좋은 모델을 학습할 수 있도록 모델을 개선합니다."},{"start":351300,"end":365400,"text":"좀 쉽게 말하면 이런 작은 위클 러너들이 서로 예측하기 어려운 부분들을 반복적으로 개선해 나가면서 결과적으로 마지막에 앙상블 된 모델에서는 강한 모델 스트롱 러너가 되는 과정을","confidence":0.9435,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[351530,351680,"좀"],[351730,352000,"쉽게"],[352000,352320,"말하면"],[352690,352860,"이런"],[353030,353260,"작은"],[353530,353840,"위클"],[353850,354260,"러너들이"],[354630,354920,"서로"],[354970,355600,"예측하기"],[355750,356060,"어려운"],[356110,356580,"부분들을"],[357070,357780,"반복적으로"],[358190,358540,"개선해"],[358540,359040,"나가면서"],[359630,360260,"결과적으로"],[360690,361180,"마지막에"],[361290,361720,"앙상블"],[361720,361860,"된"],[361970,362640,"모델에서는"],[363090,363320,"강한"],[363430,363660,"모델"],[364010,364300,"스트롱"],[364310,364640,"러너가"],[364640,364820,"되는"],[364910,365260,"과정을"]],"textEdited":"좀 쉽게 말하면 이런 작은 위클 러너들이 서로 예측하기 어려운 부분들을 반복적으로 개선해 나가면서 결과적으로 마지막에 앙상블 된 모델에서는 강한 모델 스트롱 러너가 되는 과정을"},{"start":365400,"end":377300,"text":"표현한 앙상블 기법이라고 생각하시면 되겠습니다. 다음은 모델의 분산과 편향에 대해서 이야기를 해 보겠습니다. 먼저 편향은 얼마나 예측 값이 실제 값보다 다른지 이야기합니다.","confidence":0.9158,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[365710,366060,"표현한"],[366430,366780,"앙상블"],[366790,367300,"기법이라고"],[367430,367880,"생각하시면"],[367950,368400,"되겠습니다."],[368810,369140,"다음은"],[369190,369540,"모델의"],[369590,370060,"분산과"],[370110,370420,"편향에"],[370420,370720,"대해서"],[370930,371320,"이야기를"],[371350,371467,"해"],[371467,371940,"보겠습니다."],[372350,372620,"먼저"],[372670,373040,"편향은"],[373490,373860,"얼마나"],[373890,374160,"예측"],[374160,374480,"값이"],[375050,375440,"실제"],[375450,375900,"값보다"],[376070,376480,"다른지"],[376670,377180,"이야기합니다."]],"textEdited":"표현한 앙상블 기법이라고 생각하시면 되겠습니다. 다음은 모델의 분산과 편향에 대해서 이야기를 해 보겠습니다. 먼저 편향은 얼마나 예측 값이 실제 값보다 다른지 이야기합니다."},{"start":377300,"end":389700,"text":"예측값의 평균과 실제 값을 뺀 값을 이야기합니다. 다음은 분산입니다. 분산은 모델이 출력하는 예측값이 같은 샘플들에 대해 얼마나 달라질 수 있는지를 뜻합니다.","confidence":0.9674,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[377850,378460,"예측값의"],[378530,378960,"평균과"],[379410,379760,"실제"],[379830,380180,"값을"],[380510,380660,"뺀"],[381110,381460,"값을"],[381470,381940,"이야기합니다."],[382350,382680,"다음은"],[382750,383320,"분산입니다."],[383590,383960,"분산은"],[384150,384520,"모델이"],[384570,385040,"출력하는"],[385210,385920,"예측값이"],[386430,386740,"같은"],[386810,387234,"샘플들에"],[387234,387440,"대해"],[387890,388240,"얼마나"],[388240,388520,"달라질"],[388520,388594,"수"],[388594,389040,"있는지를"],[389170,389700,"뜻합니다."]],"textEdited":"예측값의 평균과 실제 값을 뺀 값을 이야기합니다. 다음은 분산입니다. 분산은 모델이 출력하는 예측값이 같은 샘플들에 대해 얼마나 달라질 수 있는지를 뜻합니다."},{"start":389700,"end":401500,"text":"예측값과 예측값의 평균을 뺀 뒤 제곱한 것의 평균을 취합니다. 이는 우리가 정의한 로스 펑션을 분해하면 편향과 분산으로 표현되는 것을 알 수 있습니다.","confidence":0.9655,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[390030,390620,"예측값과"],[391170,391640,"예측값의"],[391670,392020,"평균을"],[392250,392400,"뺀"],[392470,392620,"뒤"],[393310,393700,"제곱한"],[393710,393960,"것의"],[394030,394360,"평균을"],[394360,394700,"취합니다."],[395710,395980,"이는"],[396170,396500,"우리가"],[396570,396860,"정의한"],[396890,397160,"로스"],[397170,397520,"펑션을"],[397730,398180,"분해하면"],[398930,399340,"편향과"],[399670,400100,"분산으로"],[400100,400407,"표현되는"],[400407,400640,"것을"],[400810,400960,"알"],[400960,401020,"수"],[401020,401420,"있습니다."]],"textEdited":"예측값과 예측값의 평균을 뺀 뒤 제곱한 것의 평균을 취합니다. 이는 우리가 정의한 로스 펑션을 분해하면 편향과 분산으로 표현되는 것을 알 수 있습니다."},{"start":401500,"end":416400,"text":"다음은 모델의 분산과 편향에 따라 우리가 언더피팅 혹은 오버피팅이라고 말하는 양상을 보여줍니다. 먼저 왼쪽부터 보겠습니다. 높은 편향과 낮은 분산이 있는 경우 우리는 이를 과소 적합이라고 이야기를 합니다.","confidence":0.9666,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[401930,402260,"다음은"],[402390,402760,"모델의"],[402790,403260,"분산과"],[403510,403880,"편향에"],[403890,404180,"따라"],[404510,404780,"우리가"],[404850,405400,"언더피팅"],[405810,406020,"혹은"],[406130,406800,"오버피팅이라고"],[406800,407140,"말하는"],[407750,408120,"양상을"],[408270,408720,"보여줍니다."],[409270,409480,"먼저"],[409510,410000,"왼쪽부터"],[410000,410460,"보겠습니다."],[410870,411140,"높은"],[411250,411600,"편향과"],[412030,412280,"낮은"],[412430,412774,"분산이"],[412774,412940,"있는"],[412950,413180,"경우"],[413670,413960,"우리는"],[413990,414200,"이를"],[414690,415020,"과소"],[415030,415580,"적합이라고"],[415810,416094,"이야기를"],[416094,416340,"합니다."]],"textEdited":"다음은 모델의 분산과 편향에 따라 우리가 언더피팅 혹은 오버피팅이라고 말하는 양상을 보여줍니다. 먼저 왼쪽부터 보겠습니다. 높은 편향과 낮은 분산이 있는 경우 우리는 이를 과소 적합이라고 이야기를 합니다."},{"start":416400,"end":428600,"text":"예시에서 볼 수 있듯이 결정 경계 혹은 회귀선이 데이터셋을 전혀 표현하지 못하는 것을 보실 수가 있습니다. 다음으로는 로우 바이어스 로우 베리언스로 보겠습니다.","confidence":0.9352,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[416690,417100,"예시에서"],[417110,417260,"볼"],[417270,417374,"수"],[417374,417680,"있듯이"],[418290,418660,"결정"],[418710,419000,"경계"],[419310,419540,"혹은"],[419650,420140,"회귀선이"],[420610,421220,"데이터셋을"],[421510,421820,"전혀"],[421890,422260,"표현하지"],[422260,422527,"못하는"],[422527,422800,"것을"],[422990,423260,"보실"],[423270,423480,"수가"],[423590,423940,"있습니다."],[424550,425080,"다음으로는"],[425870,426100,"로우"],[426110,426540,"바이어스"],[427130,427340,"로우"],[427350,427900,"베리언스로"],[428010,428480,"보겠습니다."]],"textEdited":"예시에서 볼 수 있듯이 결정 경계 혹은 회귀선이 데이터셋을 전혀 표현하지 못하는 것을 보실 수가 있습니다. 다음으로는 로우 바이어스 로우 베리언스로 보겠습니다."},{"start":428600,"end":441000,"text":"편향이 낮고 모델이 표현하는 분산이 낮은 경우 다음과 같이 적절하게 어느 정도 오차를 허용하면서 결정 경계 혹은 회귀선을 만들어 내는 것을 보실 수가 있습니다.","confidence":0.9825,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[429290,429660,"편향이"],[429670,430000,"낮고"],[430310,430680,"모델이"],[430750,431180,"표현하는"],[431490,431940,"분산이"],[432170,432460,"낮은"],[432510,432740,"경우"],[433170,433560,"다음과"],[433570,433840,"같이"],[434270,434900,"적절하게"],[435210,435400,"어느"],[435400,435680,"정도"],[435680,436080,"오차를"],[436510,437100,"허용하면서"],[437450,437820,"결정"],[437820,438080,"경계"],[438330,438580,"혹은"],[438990,439460,"회귀선을"],[439460,439634,"만들어"],[439634,439774,"내는"],[439774,440020,"것을"],[440090,440340,"보실"],[440340,440520,"수가"],[440570,440980,"있습니다."]],"textEdited":"편향이 낮고 모델이 표현하는 분산이 낮은 경우 다음과 같이 적절하게 어느 정도 오차를 허용하면서 결정 경계 혹은 회귀선을 만들어 내는 것을 보실 수가 있습니다."},{"start":441000,"end":453900,"text":"마지막 오른쪽의 경우는 로우 바이어스 하이 베리언스를 갖습니다. 이는 우리가 이야기하는 과적합 형태입니다. 주어진 데이터에 대해서는 매우 잘 표현하는 어떤 결정 경계나 회귀선을 보여주지만","confidence":0.9236,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[441290,441620,"마지막"],[441770,442280,"오른쪽의"],[442280,442620,"경우는"],[442990,443220,"로우"],[443220,443640,"바이어스"],[443950,444180,"하이"],[444180,444640,"베리언스를"],[444790,445140,"갖습니다."],[445490,445720,"이는"],[445750,446020,"우리가"],[446050,446440,"이야기하는"],[446650,447140,"과적합"],[447430,447960,"형태입니다."],[448510,448880,"주어진"],[448930,449347,"데이터에"],[449347,449760,"대해서는"],[449970,450260,"매우"],[450430,450580,"잘"],[450710,451120,"표현하는"],[451610,451840,"어떤"],[451950,452280,"결정"],[452290,452640,"경계나"],[452930,453307,"회귀선을"],[453307,453720,"보여주지만"]],"textEdited":"마지막 오른쪽의 경우는 로우 바이어스 하이 베리언스를 갖습니다. 이는 우리가 이야기하는 과적합 형태입니다. 주어진 데이터에 대해서는 매우 잘 표현하는 어떤 결정 경계나 회귀선을 보여주지만"},{"start":453900,"end":466900,"text":"실제로 관측하지 않은 데이터에 대해서는 잘 맞추지 못하는 문제가 발생할 수 있습니다. 정리를 해보면 하이 바이러스를 갖는 경우는 과소적합, 지나치게 단순한 모델로 인해 예측력이 감소된 상태입니다.","confidence":0.9732,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[454290,454680,"실제로"],[455110,455640,"관측하지"],[455640,455820,"않은"],[455930,456400,"데이터에"],[456400,456820,"대해서는"],[457170,457320,"잘"],[457430,457780,"맞추지"],[457780,458120,"못하는"],[458230,458560,"문제가"],[458650,458947,"발생할"],[458947,459034,"수"],[459034,459360,"있습니다."],[460010,460307,"정리를"],[460307,460640,"해보면"],[461050,461320,"하이"],[461320,461880,"바이러스를"],[461930,462160,"갖는"],[462170,462480,"경우는"],[462850,463400,"과소적합,"],[463770,464280,"지나치게"],[464310,464600,"단순한"],[464600,464960,"모델로"],[464970,465180,"인해"],[465450,465860,"예측력이"],[465870,466240,"감소된"],[466290,466860,"상태입니다."]],"textEdited":"실제로 관측하지 않은 데이터에 대해서는 잘 맞추지 못하는 문제가 발생할 수 있습니다. 정리를 해보면 하이 바이러스를 갖는 경우는 과소적합, 지나치게 단순한 모델로 인해 예측력이 감소된 상태입니다."},{"start":466900,"end":474000,"text":"하이베리언스는 과대적합 오버피팅으로 지나치게 복잡한 모델로 인해 일반화가 되기 어려운 상태를 이야기합니다.","confidence":0.9472,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[467170,467920,"하이베리언스는"],[468110,468700,"과대적합"],[468910,469540,"오버피팅으로"],[469910,470440,"지나치게"],[470510,470860,"복잡한"],[470890,471187,"모델로"],[471187,471380,"인해"],[471610,472100,"일반화가"],[472100,472340,"되기"],[472550,472820,"어려운"],[472910,473260,"상태를"],[473410,473940,"이야기합니다."]],"textEdited":"하이베리언스는 과대적합 오버피팅으로 지나치게 복잡한 모델로 인해 일반화가 되기 어려운 상태를 이야기합니다."},{"start":474000,"end":488600,"text":"앙상블을 통해 편향과 분산이 낮아지게 되는데요. 이 이유에 대해서 살펴보겠습니다. 왼쪽에 있는 것은 단일 모델로 분류한 결정 경계입니다. 오른쪽에 있는 그림은 베깅 앙상블을 통해 구성된 결정 경계입니다.","confidence":0.9113,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[474370,474920,"앙상블을"],[474920,475140,"통해"],[475470,475920,"편향과"],[476110,476540,"분산이"],[476690,477107,"낮아지게"],[477107,477500,"되는데요."],[477830,477980,"이"],[478070,478400,"이유에"],[478400,478700,"대해서"],[479090,479720,"살펴보겠습니다."],[480010,480400,"왼쪽에"],[480400,480580,"있는"],[480580,480840,"것은"],[481030,481260,"단일"],[481330,481780,"모델로"],[482030,482380,"분류한"],[482670,483020,"결정"],[483070,483600,"경계입니다."],[483950,484400,"오른쪽에"],[484400,484580,"있는"],[485050,485360,"그림은"],[485810,486080,"베깅"],[486090,486520,"앙상블을"],[486520,486740,"통해"],[487090,487440,"구성된"],[487670,488020,"결정"],[488030,488480,"경계입니다."]],"textEdited":"앙상블을 통해 편향과 분산이 낮아지게 되는데요. 이 이유에 대해서 살펴보겠습니다. 왼쪽에 있는 것은 단일 모델로 분류한 결정 경계입니다. 오른쪽에 있는 그림은 베깅 앙상블을 통해 구성된 결정 경계입니다."},{"start":488600,"end":501700,"text":"단일 모델을 사용하면 과대적합이 되어 분산이 높아지지만 배깅 앙상블을 통해 분산을 줄일 수가 있습니다. 이를 조금 더 직관적인 그림으로 이해해 보겠습니다. 위에서 오른쪽에 있는 그림은","confidence":0.9685,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[488930,489200,"단일"],[489270,489600,"모델을"],[489600,489960,"사용하면"],[490310,490920,"과대적합이"],[490920,491100,"되어"],[491370,491707,"분산이"],[491707,492240,"높아지지만"],[492570,492840,"배깅"],[492930,493460,"앙상블을"],[493470,493700,"통해"],[493990,494360,"분산을"],[494360,494560,"줄일"],[494570,494780,"수가"],[494970,495340,"있습니다."],[495690,495940,"이를"],[496390,496660,"조금"],[496690,496840,"더"],[497390,497900,"직관적인"],[497970,498360,"그림으로"],[498510,498800,"이해해"],[498800,499280,"보겠습니다."],[499770,500140,"위에서"],[500390,500860,"오른쪽에"],[500860,501020,"있는"],[501150,501440,"그림은"]],"textEdited":"단일 모델을 사용하면 과대적합이 되어 분산이 높아지지만 배깅 앙상블을 통해 분산을 줄일 수가 있습니다. 이를 조금 더 직관적인 그림으로 이해해 보겠습니다. 위에서 오른쪽에 있는 그림은"},{"start":501700,"end":515400,"text":"낮은 베리언스를 갖지만 높은 바이러스를 갖는 언더피팅 된 데이터입니다. 이는 부스팅 과정을 통해 잘 맞추지 못한 샘플을 더 잘 맞추도록 하여 높은 바이러스를 낮은 바이러스 쪽으로 가져올 수 있게 됩니다.","confidence":0.9489,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[502010,502300,"낮은"],[502390,502920,"베리언스를"],[502930,503260,"갖지만"],[503670,503980,"높은"],[504410,504920,"바이러스를"],[504970,505220,"갖는"],[505630,506220,"언더피팅"],[506220,506360,"된"],[506690,507220,"데이터입니다."],[507690,507920,"이는"],[508010,508340,"부스팅"],[508340,508567,"과정을"],[508567,508760,"통해"],[509030,509180,"잘"],[509290,509660,"맞추지"],[509660,509900,"못한"],[509950,510340,"샘플을"],[510570,510720,"더"],[510810,510960,"잘"],[510990,511440,"맞추도록"],[511490,511740,"하여"],[512230,512500,"높은"],[512570,513120,"바이러스를"],[513390,513640,"낮은"],[513710,514040,"바이러스"],[514040,514320,"쪽으로"],[514430,514760,"가져올"],[514760,514840,"수"],[514840,514974,"있게"],[514974,515320,"됩니다."]],"textEdited":"낮은 베리언스를 갖지만 높은 바이러스를 갖는 언더피팅 된 데이터입니다. 이는 부스팅 과정을 통해 잘 맞추지 못한 샘플을 더 잘 맞추도록 하여 높은 바이러스를 낮은 바이러스 쪽으로 가져올 수 있게 됩니다."},{"start":515400,"end":528400,"text":"아래의 왼쪽에 있는 그림을 보겠습니다. 이는 낮은 바이어스를 갖지만 높은 베리언스를 갖습니다. 이는 배깅 앙상블을 통해 높은 베리언스를 낮은 베리언스 쪽으로 가져와서 더 좋은 모델로 만들 수가 있습니다.","confidence":0.891,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[515770,516080,"아래의"],[516150,516520,"왼쪽에"],[516520,516680,"있는"],[516750,516987,"그림을"],[516987,517420,"보겠습니다."],[517850,518100,"이는"],[518510,518800,"낮은"],[518830,519340,"바이어스를"],[519390,519740,"갖지만"],[519950,520200,"높은"],[520270,520760,"베리언스를"],[520930,521320,"갖습니다."],[521590,521820,"이는"],[522090,522360,"배깅"],[522430,522940,"앙상블을"],[522970,523220,"통해"],[523530,523860,"높은"],[524170,524740,"베리언스를"],[524910,525160,"낮은"],[525250,525554,"베리언스"],[525554,525760,"쪽으로"],[525760,526180,"가져와서"],[526450,526600,"더"],[526630,526820,"좋은"],[526910,527320,"모델로"],[527530,527760,"만들"],[527760,527960,"수가"],[527960,528260,"있습니다."]],"textEdited":"아래의 왼쪽에 있는 그림을 보겠습니다. 이는 낮은 바이어스를 갖지만 높은 베리언스를 갖습니다. 이는 배깅 앙상블을 통해 높은 베리언스를 낮은 베리언스 쪽으로 가져와서 더 좋은 모델로 만들 수가 있습니다."},{"start":528400,"end":540700,"text":"다음은 앙상블 기법입니다. 먼저 우리가 이전에 배웠던 교차 검증 프로세스를 통해 진행하는 앙상블에 대해서 배워보겠습니다. 우리가 이전 교차 검증에서는 주어진 데이터셋을 케익의 폴드로","confidence":0.9682,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[528790,529100,"다음은"],[529170,529540,"앙상블"],[529590,530100,"기법입니다."],[530410,530680,"먼저"],[530910,531180,"우리가"],[531230,531520,"이전에"],[531520,531820,"배웠던"],[532110,532440,"교차"],[532450,532680,"검증"],[532750,533240,"프로세스를"],[533250,533480,"통해"],[533710,534140,"진행하는"],[534270,534734,"앙상블에"],[534734,535020,"대해서"],[535190,535800,"배워보겠습니다."],[536310,536600,"우리가"],[536610,536820,"이전"],[536950,537260,"교차"],[537290,537940,"검증에서는"],[538330,538720,"주어진"],[538810,539360,"데이터셋을"],[539690,540060,"케익의"],[540210,540600,"폴드로"]],"textEdited":"다음은 앙상블 기법입니다. 먼저 우리가 이전에 배웠던 교차 검증 프로세스를 통해 진행하는 앙상블에 대해서 배워보겠습니다. 우리가 이전 교차 검증에서는 주어진 데이터셋을 케익의 폴드로"},{"start":540700,"end":552800,"text":"분할하여 모든 폴드를 돌아가며 검증 데이터로 사용하는 교차 검증 방식이라고 배웠습니다. 여기에서 교차 검증의 단점이었던 여러 번 학습을 해야 된다라는 단점을","confidence":0.983,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[540950,541420,"분할하여"],[541650,541900,"모든"],[542050,542440,"폴드를"],[542770,543240,"돌아가며"],[543570,543880,"검증"],[543890,544280,"데이터로"],[544290,544680,"사용하는"],[545070,545400,"교차"],[545450,545700,"검증"],[546050,546600,"방식이라고"],[546790,547280,"배웠습니다."],[547630,548020,"여기에서"],[548090,548420,"교차"],[548450,548820,"검증의"],[549030,549720,"단점이었던"],[550290,550580,"여러"],[550580,550700,"번"],[551150,551480,"학습을"],[551480,551607,"해야"],[551607,552040,"된다라는"],[552330,552780,"단점을"]],"textEdited":"분할하여 모든 폴드를 돌아가며 검증 데이터로 사용하는 교차 검증 방식이라고 배웠습니다. 여기에서 교차 검증의 단점이었던 여러 번 학습을 해야 된다라는 단점을"},{"start":552800,"end":563600,"text":"조금 완화하기 위해 앙상블을 사용해 보려고 합니다. 교차 검증에서는 각 폴드에 대해서 학습을 진행하고 검증 스코어를 확인하는 것으로 프로세스를 마무리했었는데요.","confidence":0.9561,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[553030,553260,"조금"],[553610,554120,"완화하기"],[554120,554300,"위해"],[554590,555140,"앙상블을"],[555190,555480,"사용해"],[555480,555780,"보려고"],[555780,556020,"합니다."],[556370,556680,"교차"],[556690,557300,"검증에서는"],[557630,557780,"각"],[557910,558247,"폴드에"],[558247,558540,"대해서"],[558830,559200,"학습을"],[559250,559700,"진행하고"],[560150,560420,"검증"],[560450,560940,"스코어를"],[561150,561540,"확인하는"],[561570,561920,"것으로"],[562350,562800,"프로세스를"],[562830,563500,"마무리했었는데요."]],"textEdited":"조금 완화하기 위해 앙상블을 사용해 보려고 합니다. 교차 검증에서는 각 폴드에 대해서 학습을 진행하고 검증 스코어를 확인하는 것으로 프로세스를 마무리했었는데요."},{"start":563600,"end":574800,"text":"그게 아니라 여기에서 학습된 각 폴드의 모델을 앙상블하는 기법을 교차검증 앙상블이라고 이야기를 합니다. 단순히 검증 스코어를 확인하기 위해 모델을 학습하고","confidence":0.9558,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[563890,564120,"그게"],[564120,564360,"아니라"],[564710,565140,"여기에서"],[565330,565680,"학습된"],[565870,566020,"각"],[566150,566540,"폴드의"],[566650,567040,"모델을"],[567530,568120,"앙상블하는"],[568250,568660,"기법을"],[568950,569480,"교차검증"],[569550,570120,"앙상블이라고"],[570130,570354,"이야기를"],[570354,570600,"합니다."],[571250,571600,"단순히"],[571750,572040,"검증"],[572090,572520,"스코어를"],[572550,573020,"확인하기"],[573020,573240,"위해"],[573670,574040,"모델을"],[574110,574640,"학습하고"]],"textEdited":"그게 아니라 여기에서 학습된 각 폴드의 모델을 앙상블하는 기법을 교차검증 앙상블이라고 이야기를 합니다. 단순히 검증 스코어를 확인하기 위해 모델을 학습하고"},{"start":574800,"end":586700,"text":"그 모델을 사용하지 않았었는데 이를 다시 재활용하면서 컴퓨팅 리소스의 효율성을 높일 수 있는 방법입니다. 다음과 같이 각 모델이 출력하는 확률 값을 소프트 보팅하여","confidence":0.9685,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[575070,575220,"그"],[575250,575640,"모델을"],[575710,576120,"사용하지"],[576120,576600,"않았었는데"],[576970,577240,"이를"],[577550,577800,"다시"],[577830,578540,"재활용하면서"],[579010,579360,"컴퓨팅"],[579390,579920,"리소스의"],[580350,580860,"효율성을"],[580910,581180,"높일"],[581190,581294,"수"],[581294,581460,"있는"],[581750,582220,"방법입니다."],[582630,583000,"다음과"],[583000,583260,"같이"],[583430,583580,"각"],[583690,584060,"모델이"],[584170,584620,"출력하는"],[584790,585040,"확률"],[585090,585420,"값을"],[585790,586087,"소프트"],[586087,586580,"보팅하여"]],"textEdited":"그 모델을 사용하지 않았었는데 이를 다시 재활용하면서 컴퓨팅 리소스의 효율성을 높일 수 있는 방법입니다. 다음과 같이 각 모델이 출력하는 확률 값을 소프트 보팅하여"},{"start":586700,"end":596300,"text":"최종 레이블을 만들어 낼 수 있습니다. 교차 검증 앙상부를 구현하는 예시를 보겠습니다. 이전에 만들었던 예시와 동일하게 k 폴드 객체를 정의하고요.","confidence":0.943,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[587050,587320,"최종"],[587590,588040,"레이블을"],[588290,588534,"만들어"],[588534,588660,"낼"],[588670,588820,"수"],[588830,589180,"있습니다."],[589530,589807,"교차"],[589807,590020,"검증"],[590020,590440,"앙상부를"],[590440,590740,"구현하는"],[590770,591160,"예시를"],[591160,591600,"보겠습니다."],[592130,592460,"이전에"],[592470,592840,"만들었던"],[592870,593200,"예시와"],[593310,593760,"동일하게"],[594150,594300,"k"],[594390,594680,"폴드"],[595070,595460,"객체를"],[595670,596240,"정의하고요."]],"textEdited":"최종 레이블을 만들어 낼 수 있습니다. 교차 검증 앙상부를 구현하는 예시를 보겠습니다. 이전에 만들었던 예시와 동일하게 k 폴드 객체를 정의하고요."},{"start":596300,"end":607000,"text":"그리고 k 폴드 스플릿이라고 하는 함수를 통해 인덱스를 생성합니다. 생성된 인덱스를 기반으로 데이터셋을 먼저 만들고요. 만든 데이터셋을","confidence":0.9471,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[596610,596920,"그리고"],[597290,597440,"k"],[597510,597800,"폴드"],[597990,598860,"스플릿이라고"],[598860,599060,"하는"],[599410,599800,"함수를"],[599850,600080,"통해"],[600490,601020,"인덱스를"],[601270,601720,"생성합니다."],[602390,602720,"생성된"],[602790,603240,"인덱스를"],[603240,603680,"기반으로"],[604010,604560,"데이터셋을"],[604560,604800,"먼저"],[604990,605420,"만들고요."],[605810,606080,"만든"],[606190,606820,"데이터셋을"]],"textEdited":"그리고 k 폴드 스플릿이라고 하는 함수를 통해 인덱스를 생성합니다. 생성된 인덱스를 기반으로 데이터셋을 먼저 만들고요. 만든 데이터셋을"},{"start":607000,"end":621500,"text":"데이터 로더로 만듭니다. 해당 데이터 로더는 각 폴드마다 생성이 되게 되고 트레인 밸리데이션 스텝에서 사용되게 됩니다. 이전에 봤었던 예시와 동일하게 케 폴드마다 모델을 따로 지정하게 됩니다.","confidence":0.9091,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[607230,607520,"데이터"],[607530,607880,"로더로"],[608110,608540,"만듭니다."],[608910,609180,"해당"],[609230,609500,"데이터"],[609500,609860,"로더는"],[610170,610320,"각"],[610450,610920,"폴드마다"],[611350,611647,"생성이"],[611647,611847,"되게"],[611847,612140,"되고"],[612570,612880,"트레인"],[613490,614040,"밸리데이션"],[614450,614900,"스텝에서"],[615290,615647,"사용되게"],[615647,615920,"됩니다."],[616330,616660,"이전에"],[616660,616960,"봤었던"],[617010,617360,"예시와"],[617590,618060,"동일하게"],[618570,618720,"케"],[618870,619340,"폴드마다"],[619710,620100,"모델을"],[620170,620420,"따로"],[620690,621140,"지정하게"],[621140,621400,"됩니다."]],"textEdited":"데이터 로더로 만듭니다. 해당 데이터 로더는 각 폴드마다 생성이 되게 되고 트레인 밸리데이션 스텝에서 사용되게 됩니다. 이전에 봤었던 예시와 동일하게 케 폴드마다 모델을 따로 지정하게 됩니다."},{"start":621500,"end":635700,"text":"즉 케이개의 모델을 학습시킨다라는 의미입니다. 각 모델 개별적으로 테스트 셋에 대해 추론을 통해 생성된 프레딕션 값을 평균을 취하면서 오프 프레딕션즈라고 하는 변수에다가 저장합니다.","confidence":0.9104,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[621870,622020,"즉"],[622350,622780,"케이개의"],[622790,623120,"모델을"],[623190,623820,"학습시킨다라는"],[623830,624260,"의미입니다."],[624910,625060,"각"],[625090,625340,"모델"],[625410,626000,"개별적으로"],[626550,626900,"테스트"],[626900,627107,"셋에"],[627107,627320,"대해"],[627650,628020,"추론을"],[628030,628260,"통해"],[628830,629200,"생성된"],[629350,629740,"프레딕션"],[629830,630180,"값을"],[630750,631140,"평균을"],[631210,631700,"취하면서"],[632050,632580,"오프"],[632610,633540,"프레딕션즈라고"],[633550,633780,"하는"],[634270,634780,"변수에다가"],[635030,635580,"저장합니다."]],"textEdited":"즉 케이개의 모델을 학습시킨다라는 의미입니다. 각 모델 개별적으로 테스트 셋에 대해 추론을 통해 생성된 프레딕션 값을 평균을 취하면서 오프 프레딕션즈라고 하는 변수에다가 저장합니다."},{"start":635700,"end":646600,"text":"이런 식으로 모든 폴드에 대해 학습을 진행을 하고 마지막으로 검증 스코어를 확인을 하면서 테스트 셋에 대한 소프트 보팅 앙상블 결과를","confidence":0.9659,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[636250,636440,"이런"],[636470,636780,"식으로"],[636910,637160,"모든"],[637290,637680,"폴드에"],[637680,637920,"대해"],[638450,638800,"학습을"],[638850,639160,"진행을"],[639160,639380,"하고"],[639830,640380,"마지막으로"],[641030,641320,"검증"],[641430,641940,"스코어를"],[642170,642540,"확인을"],[642670,643040,"하면서"],[643510,643880,"테스트"],[643880,644094,"셋에"],[644094,644280,"대한"],[644850,645220,"소프트"],[645220,645480,"보팅"],[645690,646060,"앙상블"],[646130,646540,"결과를"]],"textEdited":"이런 식으로 모든 폴드에 대해 학습을 진행을 하고 마지막으로 검증 스코어를 확인을 하면서 테스트 셋에 대한 소프트 보팅 앙상블 결과를"},{"start":646600,"end":659200,"text":"확인합니다. 결과는 다음과 같습니다. 각 폴드의 테스트 알피알씨는 0.741 0.6117, 0.6113, 0.7261이 나왔고요.","confidence":0.8285,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[646890,647340,"확인합니다."],[647870,648260,"결과는"],[648260,648560,"다음과"],[648560,648880,"같습니다."],[649310,649460,"각"],[649570,649940,"폴드의"],[650170,650560,"테스트"],[650870,651900,"알피알씨는"],[652330,653180,"0.741"],[653510,654800,"0.6117,"],[655230,656520,"0.6113,"],[656910,658660,"0.7261이"],[658670,659120,"나왔고요."]],"textEdited":"확인합니다. 결과는 다음과 같습니다. 각 폴드의 테스트 알피알씨는 0.741 0.6117, 0.6113, 0.7261이 나왔고요."},{"start":659200,"end":673400,"text":"최종적으로 합친 테스트 ruprc의 결과는 0.8915가 나왔습니다. 이를 통해 개별보다 더 좋은 테스트 성능을 얻을 수 있었습니다. 우리가 교차검증 앙상블을 다른 말로","confidence":0.9651,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[659590,660140,"최종적으로"],[660190,660500,"합친"],[660890,661280,"테스트"],[661590,662440,"ruprc의"],[662850,663320,"결과는"],[663790,664940,"0.8915가"],[665170,665740,"나왔습니다."],[666190,666460,"이를"],[666490,666720,"통해"],[667030,667580,"개별보다"],[667790,667940,"더"],[668030,668220,"좋은"],[668770,669120,"테스트"],[669130,669400,"성능을"],[669450,669660,"얻을"],[669670,669820,"수"],[669820,670220,"있었습니다."],[670690,670960,"우리가"],[671050,671660,"교차검증"],[671770,672320,"앙상블을"],[672590,672860,"다른"],[672890,673200,"말로"]],"textEdited":"최종적으로 합친 테스트 ruprc의 결과는 0.8915가 나왔습니다. 이를 통해 개별보다 더 좋은 테스트 성능을 얻을 수 있었습니다. 우리가 교차검증 앙상블을 다른 말로"},{"start":673400,"end":688200,"text":"ro 폴드 앙상블이라고도 이야기를 합니다. 교차 검증 앙상블의 장단점에 대해서 이야기를 해 보겠습니다. 먼저 장점입니다. 모델의 일반화 성능을 평가하면서 앙상블을 진행할 수 있습니다. 데이터를 여러 부분으로 나누어 반복적으로 모델을 학습하고 평가함으로써","confidence":0.9429,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[673810,674100,"ro"],[674150,674480,"폴드"],[674550,675660,"앙상블이라고도"],[675770,676107,"이야기를"],[676107,676340,"합니다."],[676710,677040,"교차"],[677050,677300,"검증"],[677410,677780,"앙상블의"],[677780,678214,"장단점에"],[678214,678460,"대해서"],[678510,678740,"이야기를"],[678740,678814,"해"],[678814,679260,"보겠습니다."],[679850,680060,"먼저"],[680110,680620,"장점입니다."],[681190,681540,"모델의"],[681610,681920,"일반화"],[681920,682160,"성능을"],[682210,682780,"평가하면서"],[682950,683440,"앙상블을"],[683440,683687,"진행할"],[683687,683774,"수"],[683774,684060,"있습니다."],[684550,684980,"데이터를"],[684980,685160,"여러"],[685160,685520,"부분으로"],[685520,685820,"나누어"],[685970,686520,"반복적으로"],[686520,686820,"모델을"],[686820,687220,"학습하고"],[687450,688060,"평가함으로써"]],"textEdited":"ro 폴드 앙상블이라고도 이야기를 합니다. 교차 검증 앙상블의 장단점에 대해서 이야기를 해 보겠습니다. 먼저 장점입니다. 모델의 일반화 성능을 평가하면서 앙상블을 진행할 수 있습니다. 데이터를 여러 부분으로 나누어 반복적으로 모델을 학습하고 평가함으로써"},{"start":688200,"end":702700,"text":"모델이 새로운 데이터에 대해 얼마나 잘 일반화할 수 있는지를 더 정확하게 측정할 수 있습니다. 다음은 과적합 방지입니다. 모델이 특정 데이터 분할에 과적합되는 것을 방지할 수 있습니다. 다양한 데이터 분할에 대해 모델을 평가하므로 특정 분할에만 최적화되지 않도록 합니다.","confidence":0.9629,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[688450,688800,"모델이"],[688830,689140,"새로운"],[689150,689494,"데이터에"],[689494,689680,"대해"],[689730,690040,"얼마나"],[690050,690200,"잘"],[690730,691127,"일반화할"],[691127,691200,"수"],[691200,691540,"있는지를"],[691540,691680,"더"],[691790,692220,"정확하게"],[692250,692540,"측정할"],[692540,692614,"수"],[692614,692940,"있습니다."],[693310,693620,"다음은"],[693670,694040,"과적합"],[694130,694600,"방지입니다."],[695010,695340,"모델이"],[695390,695660,"특정"],[695670,695927,"데이터"],[695927,696240,"분할에"],[696650,697214,"과적합되는"],[697214,697460,"것을"],[697490,697827,"방지할"],[697827,697914,"수"],[697914,698240,"있습니다."],[698530,698900,"다양한"],[698930,699180,"데이터"],[699180,699414,"분할에"],[699414,699600,"대해"],[699710,700020,"모델을"],[700050,700500,"평가하므로"],[700950,701240,"특정"],[701240,701560,"분할에만"],[701570,702000,"최적화되지"],[702000,702340,"않도록"],[702340,702600,"합니다."]],"textEdited":"모델이 새로운 데이터에 대해 얼마나 잘 일반화할 수 있는지를 더 정확하게 측정할 수 있습니다. 다음은 과적합 방지입니다. 모델이 특정 데이터 분할에 과적합되는 것을 방지할 수 있습니다. 다양한 데이터 분할에 대해 모델을 평가하므로 특정 분할에만 최적화되지 않도록 합니다."},{"start":702700,"end":714800,"text":"마지막으로는 안정된 성능 평가입니다. 단일 학습 검증 분할에서 발생할 수 있는 편차를 줄여줍니다. 여러 번의 평가를 통해 평균적인 성능을 구함으로써 보다 안정적인 모델 성능 평가가 가능합니다.","confidence":0.9555,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[703130,703740,"마지막으로는"],[703930,704420,"안정된"],[704590,704840,"성능"],[704870,705300,"평가입니다."],[705890,706140,"단일"],[706370,706640,"학습"],[706770,707040,"검증"],[707070,707440,"분할에서"],[707450,707780,"발생할"],[707780,707840,"수"],[707840,707980,"있는"],[708010,708400,"편차를"],[708400,708780,"줄여줍니다."],[709330,709534,"여러"],[709534,709760,"번의"],[709770,710120,"평가를"],[710120,710320,"통해"],[710850,711240,"평균적인"],[711250,711520,"성능을"],[711520,712020,"구함으로써"],[712670,712940,"보다"],[712990,713420,"안정적인"],[713530,713780,"모델"],[713790,713980,"성능"],[713980,714280,"평가가"],[714280,714680,"가능합니다."]],"textEdited":"마지막으로는 안정된 성능 평가입니다. 단일 학습 검증 분할에서 발생할 수 있는 편차를 줄여줍니다. 여러 번의 평가를 통해 평균적인 성능을 구함으로써 보다 안정적인 모델 성능 평가가 가능합니다."},{"start":714800,"end":726000,"text":"다음은 단점입니다. 아무리 교차 검증의 결과를 앙상블을 했다 하더라도 시간과 계산 비용은 여전히 단점입니다. 교차검증 앙상블은 여러 번의 모델 학습과 평가를 필요로 하므로","confidence":0.9462,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[715190,715520,"다음은"],[715550,716100,"단점입니다."],[716630,716920,"아무리"],[716930,717240,"교차"],[717290,717680,"검증의"],[717770,718220,"결과를"],[718630,719067,"앙상블을"],[719067,719247,"했다"],[719247,719620,"하더라도"],[719970,720460,"시간과"],[720610,720900,"계산"],[720900,721200,"비용은"],[721470,721820,"여전히"],[721850,722340,"단점입니다."],[722850,723320,"교차검증"],[723330,723720,"앙상블은"],[723890,724107,"여러"],[724107,724360,"번의"],[724360,724560,"모델"],[724560,724880,"학습과"],[724990,725360,"평가를"],[725370,725607,"필요로"],[725607,725880,"하므로"]],"textEdited":"다음은 단점입니다. 아무리 교차 검증의 결과를 앙상블을 했다 하더라도 시간과 계산 비용은 여전히 단점입니다. 교차검증 앙상블은 여러 번의 모델 학습과 평가를 필요로 하므로"},{"start":726000,"end":735400,"text":"시간과 계산 비용이 증가할 수 있습니다. 다음은 복잡성의 증가입니다. 여러 번의 모델 학습과 평가를 관리해야 하므로 구현과 유지 보수가 복잡해질 수 있습니다.","confidence":0.9434,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[726390,726800,"시간과"],[726830,727047,"계산"],[727047,727320,"비용이"],[727350,727680,"증가할"],[727680,727740,"수"],[727740,728060,"있습니다."],[728330,728640,"다음은"],[728790,729340,"복잡성의"],[729470,729920,"증가입니다."],[730330,730534,"여러"],[730534,730780,"번의"],[730780,731000,"모델"],[731000,731320,"학습과"],[731410,731800,"평가를"],[731870,732247,"관리해야"],[732247,732520,"하므로"],[732870,733320,"구현과"],[733550,733820,"유지"],[733820,734120,"보수가"],[734290,734740,"복잡해질"],[734740,734834,"수"],[734834,735140,"있습니다."]],"textEdited":"시간과 계산 비용이 증가할 수 있습니다. 다음은 복잡성의 증가입니다. 여러 번의 모델 학습과 평가를 관리해야 하므로 구현과 유지 보수가 복잡해질 수 있습니다."},{"start":735400,"end":745000,"text":"다음은 데이터 요구 사항입니다. 충분한 데이터가 없는 경우 데이터의 분할이 모델 성능에 부정적인 영향을 미칠 수 있습니다. 교차 검증을 위해서는 데이터가 충분히 많아야 합니다.","confidence":0.9514,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[735870,736180,"다음은"],[736190,736480,"데이터"],[736480,736660,"요구"],[736660,737060,"사항입니다."],[737610,737900,"충분한"],[737900,738240,"데이터가"],[738250,738440,"없는"],[738470,738680,"경우"],[738870,739280,"데이터의"],[739280,739580,"분할이"],[739930,740180,"모델"],[740210,740480,"성능에"],[740530,741020,"부정적인"],[741050,741340,"영향을"],[741370,741620,"미칠"],[741620,741714,"수"],[741714,742020,"있습니다."],[742570,742860,"교차"],[742860,743120,"검증을"],[743120,743440,"위해서는"],[743670,744040,"데이터가"],[744090,744380,"충분히"],[744380,744647,"많아야"],[744647,744880,"합니다."]],"textEdited":"다음은 데이터 요구 사항입니다. 충분한 데이터가 없는 경우 데이터의 분할이 모델 성능에 부정적인 영향을 미칠 수 있습니다. 교차 검증을 위해서는 데이터가 충분히 많아야 합니다."},{"start":745000,"end":759700,"text":"다음은 스태킹 앙상블입니다. 스태킹 앙상블은 모델마다 가중치를 주어서 양상블 모델을 만드는 것이다라고 생각하시면 되겠습니다. 이때 가중치를 어떻게 주는지에 따라 최종 예측이 달라질 수 있는데요. 이때 추가적인 모델을 사용하게 됩니다.","confidence":0.9452,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[745270,745560,"다음은"],[745590,745900,"스태킹"],[745930,746440,"앙상블입니다."],[747090,747400,"스태킹"],[747410,747820,"앙상블은"],[748130,748660,"모델마다"],[748790,749340,"가중치를"],[749340,749660,"주어서"],[749990,750420,"양상블"],[750470,750840,"모델을"],[750950,751300,"만드는"],[751300,752200,"것이다라고"],[752230,752667,"생각하시면"],[752667,753100,"되겠습니다."],[753810,754040,"이때"],[754070,754520,"가중치를"],[754550,754880,"어떻게"],[754910,755407,"주는지에"],[755407,755660,"따라"],[756170,756400,"최종"],[756400,756700,"예측이"],[756700,756980,"달라질"],[756980,757054,"수"],[757054,757380,"있는데요."],[757770,758000,"이때"],[758070,758460,"추가적인"],[758460,758780,"모델을"],[758890,759214,"사용하게"],[759214,759480,"됩니다."]],"textEdited":"다음은 스태킹 앙상블입니다. 스태킹 앙상블은 모델마다 가중치를 주어서 양상블 모델을 만드는 것이다라고 생각하시면 되겠습니다. 이때 가중치를 어떻게 주는지에 따라 최종 예측이 달라질 수 있는데요. 이때 추가적인 모델을 사용하게 됩니다."},{"start":759700,"end":772700,"text":"가중치들을 어떻게 셋업할 것인지 학습하는 모델이 메타 모델이고 이러한 메타 모델을 활용한 앙상블을 스태킹 앙상블이라고 부릅니다. 그림에서 볼 수 있듯이 샘플링을 통해 형성된 여러 학습 셋을","confidence":0.9649,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[760610,761160,"가중치들을"],[761170,761500,"어떻게"],[761510,761880,"셋업할"],[761910,762240,"것인지"],[762250,762680,"학습하는"],[762730,763060,"모델이"],[763250,763520,"메타"],[763590,764040,"모델이고"],[764370,764640,"이러한"],[764690,764940,"메타"],[764970,765300,"모델을"],[765300,765540,"활용한"],[765650,766160,"앙상블을"],[766430,766780,"스태킹"],[766810,767340,"앙상블이라고"],[767340,767680,"부릅니다."],[768050,768400,"그림에서"],[768410,768560,"볼"],[768570,768674,"수"],[768674,768940,"있듯이"],[769610,770080,"샘플링을"],[770080,770300,"통해"],[770750,771140,"형성된"],[771450,771720,"여러"],[771910,772180,"학습"],[772190,772480,"셋을"]],"textEdited":"가중치들을 어떻게 셋업할 것인지 학습하는 모델이 메타 모델이고 이러한 메타 모델을 활용한 앙상블을 스태킹 앙상블이라고 부릅니다. 그림에서 볼 수 있듯이 샘플링을 통해 형성된 여러 학습 셋을"},{"start":772700,"end":785700,"text":"각각의 모델들이 학습을 합니다. 그리고 각각의 모델의 결과에 대해 가중치를 부여해서 예측을 생성하는 메타 모델을 추가로 정의합니다. 다음과 같이 각 모델의 예측값을 피처로 만듭니다.","confidence":0.9822,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[772970,773420,"각각의"],[773430,773880,"모델들이"],[773950,774280,"학습을"],[774290,774580,"합니다."],[775050,775360,"그리고"],[775650,776020,"각각의"],[776020,776360,"모델의"],[776530,776940,"결과에"],[776940,777120,"대해"],[777450,778000,"가중치를"],[778000,778420,"부여해서"],[778770,779200,"예측을"],[779250,779660,"생성하는"],[779970,780220,"메타"],[780230,780560,"모델을"],[780610,780960,"추가로"],[781090,781560,"정의합니다."],[782030,782400,"다음과"],[782400,782640,"같이"],[782950,783100,"각"],[783270,783640,"모델의"],[783670,784320,"예측값을"],[784570,785000,"피처로"],[785170,785580,"만듭니다."]],"textEdited":"각각의 모델들이 학습을 합니다. 그리고 각각의 모델의 결과에 대해 가중치를 부여해서 예측을 생성하는 메타 모델을 추가로 정의합니다. 다음과 같이 각 모델의 예측값을 피처로 만듭니다."},{"start":785700,"end":797800,"text":"다음 샘플의 클래스를 기반으로 레이블 와를 설정합니다. 이스와 이와를 기반으로 메타 모델을 학습합니다. 다음은 티티에라고 하는 테스트 타임 어그멘테이션입니다.","confidence":0.7772,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[785970,786220,"다음"],[786570,786980,"샘플의"],[787050,787540,"클래스를"],[787630,788060,"기반으로"],[788290,788580,"레이블"],[788810,789200,"와를"],[789590,790060,"설정합니다."],[790450,791060,"이스와"],[791150,791760,"이와를"],[791850,792300,"기반으로"],[792690,792960,"메타"],[792960,793280,"모델을"],[793350,793820,"학습합니다."],[794290,794640,"다음은"],[794970,795820,"티티에라고"],[795820,796000,"하는"],[796370,796654,"테스트"],[796654,796840,"타임"],[796890,797800,"어그멘테이션입니다."]],"textEdited":"다음 샘플의 클래스를 기반으로 레이블 와를 설정합니다. 이스와 이와를 기반으로 메타 모델을 학습합니다. 다음은 티티에라고 하는 테스트 타임 어그멘테이션입니다."},{"start":797800,"end":812400,"text":"학습이 끝난 모델에 대해 테스트 샘플을 어그멘테이션을 통해 한 샘플에 대해 여러 번 추론한 후 평균을 내어 추정 결과를 냅니다. 좀 쉽게 직관적으로 이해해 보겠습니다. 우리가 만약 강아지 혹은 고양이를 분류한 사진이 있다고 해 보겠습니다.","confidence":0.9389,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[798150,798440,"학습이"],[798470,798740,"끝난"],[798750,799067,"모델에"],[799067,799260,"대해"],[799570,799880,"테스트"],[799880,800220,"샘플을"],[800390,801060,"어그멘테이션을"],[801060,801260,"통해"],[801570,801720,"한"],[801850,802154,"샘플에"],[802154,802340,"대해"],[802410,802627,"여러"],[802627,802760,"번"],[802810,803067,"추론한"],[803067,803200,"후"],[803490,803847,"평균을"],[803847,804040,"내어"],[804390,804640,"추정"],[804640,804960,"결과를"],[804960,805240,"냅니다."],[805690,805840,"좀"],[805950,806260,"쉽게"],[806530,807000,"직관적으로"],[807000,807187,"이해해"],[807187,807620,"보겠습니다."],[808010,808260,"우리가"],[808350,808580,"만약"],[809110,809440,"강아지"],[809910,810100,"혹은"],[810190,810660,"고양이를"],[810750,811080,"분류한"],[811110,811354,"사진이"],[811354,811660,"있다고"],[811690,811807,"해"],[811807,812260,"보겠습니다."]],"textEdited":"학습이 끝난 모델에 대해 테스트 샘플을 어그멘테이션을 통해 한 샘플에 대해 여러 번 추론한 후 평균을 내어 추정 결과를 냅니다. 좀 쉽게 직관적으로 이해해 보겠습니다. 우리가 만약 강아지 혹은 고양이를 분류한 사진이 있다고 해 보겠습니다."},{"start":812400,"end":825900,"text":"강아지와 고양이는 똑바로 보아도 강아지와 고양이일 거고요. 사진을 90도를 돌려도 강아지와 고양이처럼 보일 것입니다. 혹은 플립을 해서 뒤집는다 하더라도 똑같이 강아지와 고양이처럼 보일 거예요.","confidence":0.938,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[812890,813360,"강아지와"],[813470,813900,"고양이는"],[814370,814760,"똑바로"],[814760,815060,"보아도"],[815270,815700,"강아지와"],[815770,816260,"고양이일"],[816260,816540,"거고요."],[817350,817700,"사진을"],[817890,818247,"90도를"],[818247,818600,"돌려도"],[818850,819260,"강아지와"],[819310,819740,"고양이처럼"],[819770,819980,"보일"],[819980,820340,"것입니다."],[820930,821140,"혹은"],[821410,821687,"플립을"],[821687,821880,"해서"],[821950,822360,"뒤집는다"],[822360,822740,"하더라도"],[823150,823560,"똑같이"],[823950,824360,"강아지와"],[824490,825000,"고양이처럼"],[825190,825420,"보일"],[825420,825680,"거예요."]],"textEdited":"강아지와 고양이는 똑바로 보아도 강아지와 고양이일 거고요. 사진을 90도를 돌려도 강아지와 고양이처럼 보일 것입니다. 혹은 플립을 해서 뒤집는다 하더라도 똑같이 강아지와 고양이처럼 보일 거예요."},{"start":825900,"end":840300,"text":"이런 식으로 이미지 혹은 비전 쪽에서는 이미지들을 추론하는 테스트 단계에서 여러 번의 어그멘테이션을 통해 동일한 이미지를 다양한 버전을 생성을 하고 이를 여러 번 추론을 합니다.","confidence":0.9817,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[826410,826620,"이런"],[826670,826980,"식으로"],[827650,828020,"이미지"],[828350,828540,"혹은"],[828770,829020,"비전"],[829190,829700,"쪽에서는"],[830170,830720,"이미지들을"],[831290,831740,"추론하는"],[832070,832460,"테스트"],[832470,832940,"단계에서"],[833450,833687,"여러"],[833687,833940,"번의"],[833970,834680,"어그멘테이션을"],[834680,834880,"통해"],[835350,835680,"동일한"],[835690,836100,"이미지를"],[836630,836960,"다양한"],[837190,837540,"버전을"],[837670,837960,"생성을"],[837960,838180,"하고"],[838610,838900,"이를"],[839090,839307,"여러"],[839307,839440,"번"],[839610,839940,"추론을"],[839940,840260,"합니다."]],"textEdited":"이런 식으로 이미지 혹은 비전 쪽에서는 이미지들을 추론하는 테스트 단계에서 여러 번의 어그멘테이션을 통해 동일한 이미지를 다양한 버전을 생성을 하고 이를 여러 번 추론을 합니다."},{"start":840300,"end":850900,"text":"이 추론한 결과의 평균을 소프트 보팅을 처리하여 예측하는 것이 tta 테스트 타임 어그멘테이션 앙상블 기법입니다. 다음은 스톡캐스틱 웨이트 에버리지입니다.","confidence":0.8373,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[840670,840820,"이"],[840870,841220,"추론한"],[841350,841760,"결과의"],[842250,842620,"평균을"],[842950,843300,"소프트"],[843300,843660,"보팅을"],[843770,844220,"처리하여"],[844670,845120,"예측하는"],[845120,845340,"것이"],[845770,846120,"tta"],[846710,846994,"테스트"],[846994,847160,"타임"],[847160,847680,"어그멘테이션"],[847890,848240,"앙상블"],[848240,848700,"기법입니다."],[849030,849320,"다음은"],[849330,849840,"스톡캐스틱"],[849870,850160,"웨이트"],[850160,850800,"에버리지입니다."]],"textEdited":"이 추론한 결과의 평균을 소프트 보팅을 처리하여 예측하는 것이 tta 테스트 타임 어그멘테이션 앙상블 기법입니다. 다음은 스톡캐스틱 웨이트 에버리지입니다."},{"start":850900,"end":865700,"text":"이 개념은 모델이 어느 정도 학습이 이루어지고 나면 더 이상 옵티멀 지점에 가까이 가기 어려울 때 그 주변부에 있는 모델들을 가지고 배기 앙상블을 하면 옵티멀의 근사한 성능을 얻을 수 있게 해주는 기법입니다.","confidence":0.9348,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[851410,851560,"이"],[851690,852040,"개념은"],[852410,852800,"모델이"],[853110,853340,"어느"],[853340,853660,"정도"],[853890,854260,"학습이"],[854290,854840,"이루어지고"],[854840,855080,"나면"],[855410,855560,"더"],[855560,855760,"이상"],[855930,856360,"옵티멀"],[856430,856720,"지점에"],[856910,857260,"가까이"],[857270,857500,"가기"],[857610,857920,"어려울"],[857950,858100,"때"],[858450,858600,"그"],[858670,859180,"주변부에"],[859180,859340,"있는"],[859430,859940,"모델들을"],[859970,860320,"가지고"],[860810,861120,"배기"],[861170,861607,"앙상블을"],[861607,861820,"하면"],[862270,862840,"옵티멀의"],[862890,863220,"근사한"],[863270,863580,"성능을"],[863710,863940,"얻을"],[863950,864054,"수"],[864054,864260,"있게"],[864610,864960,"해주는"],[865110,865640,"기법입니다."]],"textEdited":"이 개념은 모델이 어느 정도 학습이 이루어지고 나면 더 이상 옵티멀 지점에 가까이 가기 어려울 때 그 주변부에 있는 모델들을 가지고 배기 앙상블을 하면 옵티멀의 근사한 성능을 얻을 수 있게 해주는 기법입니다."},{"start":865700,"end":879900,"text":"조금 더 쉽게 말하면 하나의 모델에 대해 학습을 진행합니다. 그리고 그 모델이 어느 정도 성능이 세츄레이션 됐을 때 그때부터 각 스텝 혹은 각 에폭마다 모델의 체크 포인트를 저장을 합니다.","confidence":0.9684,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[866130,866360,"조금"],[866360,866480,"더"],[866510,866760,"쉽게"],[866760,867080,"말하면"],[867450,867740,"하나의"],[867750,868047,"모델에"],[868047,868240,"대해"],[868390,868760,"학습을"],[868850,869320,"진행합니다."],[869750,870040,"그리고"],[870310,870460,"그"],[870510,870860,"모델이"],[871170,871440,"어느"],[871530,871900,"정도"],[872170,872540,"성능이"],[872830,873240,"세츄레이션"],[873240,873480,"됐을"],[873510,873660,"때"],[874130,874680,"그때부터"],[875010,875160,"각"],[875290,875560,"스텝"],[875870,876100,"혹은"],[876510,876660,"각"],[876850,877420,"에폭마다"],[877810,878180,"모델의"],[878250,878500,"체크"],[878500,878900,"포인트를"],[879090,879380,"저장을"],[879380,879700,"합니다."]],"textEdited":"조금 더 쉽게 말하면 하나의 모델에 대해 학습을 진행합니다. 그리고 그 모델이 어느 정도 성능이 세츄레이션 됐을 때 그때부터 각 스텝 혹은 각 에폭마다 모델의 체크 포인트를 저장을 합니다."},{"start":879900,"end":893100,"text":"그다음 그 모델들의 파라미터 웨이트 값을 평균을 낸 뒤에 결과를 추론하게 만드는 것입니다. 이를 통해 더 좋은 성능을 얻을 수 있는 것이 블에의 기본적인 개념입니다.","confidence":0.8855,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[880250,880540,"그다음"],[880810,880960,"그"],[881030,881540,"모델들의"],[881890,882340,"파라미터"],[882770,883200,"웨이트"],[883290,883620,"값을"],[883930,884380,"평균을"],[884450,884600,"낸"],[884690,884960,"뒤에"],[885590,886080,"결과를"],[886210,886660,"추론하게"],[887030,887420,"만드는"],[887690,888080,"것입니다."],[888450,888660,"이를"],[888660,888860,"통해"],[888860,889000,"더"],[889070,889240,"좋은"],[889410,889680,"성능을"],[889680,889880,"얻을"],[889880,890020,"수"],[890050,890240,"있는"],[890250,890540,"것이"],[891170,891640,"블에의"],[891870,892320,"기본적인"],[892510,893100,"개념입니다."]],"textEdited":"그다음 그 모델들의 파라미터 웨이트 값을 평균을 낸 뒤에 결과를 추론하게 만드는 것입니다. 이를 통해 더 좋은 성능을 얻을 수 있는 것이 블에의 기본적인 개념입니다."},{"start":893100,"end":907000,"text":"오른쪽 예시에서 볼 수 있듯이 w1, w2, w3라고 하는 같은 모델의 3개의 웨이트 값을 앙상블을 한 모델로 추론했을 때 더 좋은 성능을 보일 수 있었습니다.","confidence":0.8882,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[893330,893720,"오른쪽"],[893750,894080,"예시에서"],[894080,894220,"볼"],[894220,894314,"수"],[894314,894600,"있듯이"],[894930,895240,"w1,"],[895590,895940,"w2,"],[896370,897460,"w3라고"],[897470,897680,"하는"],[898170,898500,"같은"],[898630,898980,"모델의"],[899450,899840,"3개의"],[900190,900560,"웨이트"],[900790,901140,"값을"],[901770,902287,"앙상블을"],[902287,902420,"한"],[902430,902860,"모델로"],[903370,903840,"추론했을"],[903850,904000,"때"],[904510,904660,"더"],[904750,904920,"좋은"],[905050,905400,"성능을"],[905930,906180,"보일"],[906190,906340,"수"],[906470,907000,"있었습니다."]],"textEdited":"오른쪽 예시에서 볼 수 있듯이 w1, w2, w3라고 하는 같은 모델의 3개의 웨이트 값을 앙상블을 한 모델로 추론했을 때 더 좋은 성능을 보일 수 있었습니다."},{"start":907000,"end":918400,"text":"다음은 믹스트 오브 엑스퍼트입니다. 이 앙상블 기법은 최근 엘엘엠에서 많이 선택되는 구조인데요. 입력에 따라 서로 다른 전문가 모델 중 일부만 선택적으로 활성화되는 구조입니다.","confidence":0.8571,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[907390,907720,"다음은"],[907790,908067,"믹스트"],[908067,908260,"오브"],[908290,908920,"엑스퍼트입니다."],[909390,909540,"이"],[909630,910000,"앙상블"],[910050,910460,"기법은"],[910990,911220,"최근"],[911470,912000,"엘엘엠에서"],[912170,912400,"많이"],[912730,913160,"선택되는"],[913210,913680,"구조인데요."],[914170,914507,"입력에"],[914507,914740,"따라"],[914830,915027,"서로"],[915027,915200,"다른"],[915230,915660,"전문가"],[915670,915900,"모델"],[915930,916080,"중"],[916270,916640,"일부만"],[916750,917180,"선택적으로"],[917190,917640,"활성화되는"],[917750,918300,"구조입니다."]],"textEdited":"다음은 믹스트 오브 엑스퍼트입니다. 이 앙상블 기법은 최근 엘엘엠에서 많이 선택되는 구조인데요. 입력에 따라 서로 다른 전문가 모델 중 일부만 선택적으로 활성화되는 구조입니다."},{"start":918400,"end":928300,"text":"각 전문가의 특화된 예측을 게이트 모델이 조합하여 전체 예측 성능을 높입니다. 이 과정에서 게이트 모델은 탑 k개의 엑스퍼트를 선택을 하고","confidence":0.9497,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[918650,918800,"각"],[918910,919380,"전문가의"],[919390,919700,"특화된"],[919700,920040,"예측을"],[920170,920500,"게이트"],[920500,920727,"모델이"],[920727,921140,"조합하여"],[921550,921880,"전체"],[921910,922140,"예측"],[922150,922420,"성능을"],[922420,922820,"높입니다."],[923270,923420,"이"],[923490,923920,"과정에서"],[924370,924780,"게이트"],[924790,925140,"모델은"],[925630,925780,"탑"],[925970,926420,"k개의"],[926630,927260,"엑스퍼트를"],[927570,927920,"선택을"],[927920,928120,"하고"]],"textEdited":"각 전문가의 특화된 예측을 게이트 모델이 조합하여 전체 예측 성능을 높입니다. 이 과정에서 게이트 모델은 탑 k개의 엑스퍼트를 선택을 하고"},{"start":928300,"end":943200,"text":"선택된 엑스퍼트들에 대한 노드만 활성화하는 방식으로 구현합니다. 앞서 여러 가지 앙상블 기법을 설명을 드렸는데요. 여러분들이 쉽게 사용할 수 있는 강력한 앙상블 기법인 스태킹 앙상블에 대해 조금 정리하고 넘어가겠습니다.","confidence":0.9275,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[928850,929300,"선택된"],[929430,930200,"엑스퍼트들에"],[930200,930420,"대한"],[930510,930920,"노드만"],[931310,931860,"활성화하는"],[931990,932480,"방식으로"],[932830,933280,"구현합니다."],[934090,934380,"앞서"],[934530,934820,"여러"],[934820,935020,"가지"],[935050,935440,"앙상블"],[935510,935900,"기법을"],[936050,936360,"설명을"],[936360,936800,"드렸는데요."],[937150,937660,"여러분들이"],[937750,938000,"쉽게"],[938000,938260,"사용할"],[938260,938354,"수"],[938354,938540,"있는"],[938970,939340,"강력한"],[939370,939700,"앙상블"],[939730,940080,"기법인"],[940170,940500,"스태킹"],[940530,940934,"앙상블에"],[940934,941140,"대해"],[941590,941780,"조금"],[941850,942260,"정리하고"],[942390,943020,"넘어가겠습니다."]],"textEdited":"선택된 엑스퍼트들에 대한 노드만 활성화하는 방식으로 구현합니다. 앞서 여러 가지 앙상블 기법을 설명을 드렸는데요. 여러분들이 쉽게 사용할 수 있는 강력한 앙상블 기법인 스태킹 앙상블에 대해 조금 정리하고 넘어가겠습니다."},{"start":943200,"end":956400,"text":"먼저 장점입니다. 첫 번째는 일반화 성능 향상 부분입니다. 스태킹 향상블은 여러 모델의 예측 결과를 종합하여 최종 예측을 수행하므로 개별 모델의 과적합을 방지하고 더 나은 일반화 성능을 제공합니다. 다음은 복잡한 패턴 학습입니다.","confidence":0.9513,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[943450,943680,"먼저"],[943730,944260,"장점입니다."],[944590,944740,"첫"],[944750,945080,"번째는"],[945150,945460,"일반화"],[945460,945660,"성능"],[945670,945940,"향상"],[946050,946520,"부분입니다."],[947070,947420,"스태킹"],[947420,947800,"향상블은"],[947890,948140,"여러"],[948140,948440,"모델의"],[948440,948640,"예측"],[948650,948980,"결과를"],[949010,949480,"종합하여"],[949770,950040,"최종"],[950040,950340,"예측을"],[950350,950820,"수행하므로"],[951110,951360,"개별"],[951410,951720,"모델의"],[951750,952160,"과적합을"],[952190,952640,"방지하고"],[952850,953000,"더"],[953030,953200,"나은"],[953310,953580,"일반화"],[953580,953840,"성능을"],[953840,954260,"제공합니다."],[954730,955020,"다음은"],[955290,955660,"복잡한"],[955690,955900,"패턴"],[955900,956300,"학습입니다."]],"textEdited":"먼저 장점입니다. 첫 번째는 일반화 성능 향상 부분입니다. 스태킹 향상블은 여러 모델의 예측 결과를 종합하여 최종 예측을 수행하므로 개별 모델의 과적합을 방지하고 더 나은 일반화 성능을 제공합니다. 다음은 복잡한 패턴 학습입니다."},{"start":956400,"end":971000,"text":"메타 모델은 예측 모델의 예측 결과를 입력으로 사용하여 복잡한 패턴을 학습할 수 있습니다. 이는 단일 모델로는 잡아내기 어려운 복잡한 데이터 구조를 더 잘 포착할 수 있습니다. 다음은 유연성입니다. 스태킹 영상물은 다양한 모델을 자유롭게 결합할 수 있어 매우 유연합니다.","confidence":0.9313,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[956710,957000,"메타"],[957000,957320,"모델은"],[957470,957780,"예측"],[957780,958080,"모델의"],[958080,958300,"예측"],[958310,958680,"결과를"],[958710,959080,"입력으로"],[959080,959440,"사용하여"],[959690,960060,"복잡한"],[960070,960314,"패턴을"],[960314,960547,"학습할"],[960547,960647,"수"],[960647,960980,"있습니다."],[961330,961580,"이는"],[961630,961860,"단일"],[961870,962320,"모델로는"],[962450,962900,"잡아내기"],[962900,963140,"어려운"],[963330,963680,"복잡한"],[963710,963980,"데이터"],[963980,964260,"구조를"],[964470,964620,"더"],[964730,964880,"잘"],[965110,965480,"포착할"],[965480,965554,"수"],[965554,965860,"있습니다."],[966250,966540,"다음은"],[966540,967100,"유연성입니다."],[967570,967900,"스태킹"],[967900,968300,"영상물은"],[968410,968720,"다양한"],[968730,969040,"모델을"],[969090,969480,"자유롭게"],[969480,969820,"결합할"],[969820,969894,"수"],[969894,970080,"있어"],[970210,970460,"매우"],[970470,970900,"유연합니다."]],"textEdited":"메타 모델은 예측 모델의 예측 결과를 입력으로 사용하여 복잡한 패턴을 학습할 수 있습니다. 이는 단일 모델로는 잡아내기 어려운 복잡한 데이터 구조를 더 잘 포착할 수 있습니다. 다음은 유연성입니다. 스태킹 영상물은 다양한 모델을 자유롭게 결합할 수 있어 매우 유연합니다."},{"start":971000,"end":982500,"text":"예를 들어 선형 모델, 결정, 트리, 신경망 등 서로 다른 유형의 모델을 함께 사용할 수 있습니다. 다음은 단점입니다. 단점에서는 시간과 계산 비용이 있는데요.","confidence":0.9317,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[971290,971547,"예를"],[971547,971740,"들어"],[971930,972180,"선형"],[972180,972380,"모델,"],[972930,973187,"결정,"],[973187,973380,"트리,"],[973910,974260,"신경망"],[974290,974440,"등"],[974910,975107,"서로"],[975107,975300,"다른"],[975490,975840,"유형의"],[975870,976200,"모델을"],[976310,976600,"함께"],[976670,976980,"사용할"],[977010,977160,"수"],[977250,977620,"있습니다."],[978030,978340,"다음은"],[978450,979020,"단점입니다."],[979610,980200,"단점에서는"],[980630,981080,"시간과"],[981230,981520,"계산"],[981520,981840,"비용이"],[981970,982360,"있는데요."]],"textEdited":"예를 들어 선형 모델, 결정, 트리, 신경망 등 서로 다른 유형의 모델을 함께 사용할 수 있습니다. 다음은 단점입니다. 단점에서는 시간과 계산 비용이 있는데요."},{"start":982500,"end":997000,"text":"스태킹 영상물은 여러 모델을 학습시키고 예측을 종합하는 과정이 필요하므로 시간과 계산 비용이 증가할 수 있습니다. 또한 복잡성이 증가될 수 있습니다. 여러 모델을 결합하고 메타 모델을 학습시켜야 하므로 구현과 유지 보수가 복잡해질 수 있습니다.","confidence":0.921,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[982990,983300,"스태킹"],[983310,983700,"영상물은"],[983700,983920,"여러"],[983920,984167,"모델을"],[984167,984660,"학습시키고"],[984870,985260,"예측을"],[985390,985820,"종합하는"],[985890,986220,"과정이"],[986230,986640,"필요하므로"],[987110,987540,"시간과"],[987590,987840,"계산"],[987840,988180,"비용이"],[988370,988740,"증가할"],[988740,988827,"수"],[988827,989140,"있습니다."],[989730,989960,"또한"],[990290,990780,"복잡성이"],[990790,991047,"증가될"],[991047,991134,"수"],[991134,991440,"있습니다."],[992290,992540,"여러"],[992550,992840,"모델을"],[992840,993280,"결합하고"],[993310,993560,"메타"],[993560,993787,"모델을"],[993787,994187,"학습시켜야"],[994187,994460,"하므로"],[994870,995300,"구현과"],[995430,995680,"유지"],[995680,995960,"보수가"],[996010,996380,"복잡해질"],[996380,996454,"수"],[996454,996760,"있습니다."]],"textEdited":"스태킹 영상물은 여러 모델을 학습시키고 예측을 종합하는 과정이 필요하므로 시간과 계산 비용이 증가할 수 있습니다. 또한 복잡성이 증가될 수 있습니다. 여러 모델을 결합하고 메타 모델을 학습시켜야 하므로 구현과 유지 보수가 복잡해질 수 있습니다."},{"start":997000,"end":1007700,"text":"마지막은 모델 선택의 어려움입니다. 적절한 기본 모델들과 메타 모델을 선택하는 과정이 어렵고 최적의 조합을 찾기 위해 많은 실험이 필요할 수 있습니다. 이번 강의에서는 앙상블","confidence":0.9822,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[997450,997920,"마지막은"],[998010,998260,"모델"],[998270,998580,"선택의"],[998580,999060,"어려움입니다."],[999710,1000100,"적절한"],[1000100,1000280,"기본"],[1000280,1000700,"모델들과"],[1000910,1001160,"메타"],[1001160,1001374,"모델을"],[1001374,1001700,"선택하는"],[1001730,1002007,"과정이"],[1002007,1002360,"어렵고"],[1002810,1003140,"최적의"],[1003140,1003400,"조합을"],[1003400,1003634,"찾기"],[1003634,1003820,"위해"],[1004130,1004340,"많은"],[1004470,1004740,"실험이"],[1004750,1005040,"필요할"],[1005070,1005220,"수"],[1005250,1005600,"있습니다."],[1006070,1006280,"이번"],[1006370,1006840,"강의에서는"],[1007110,1007540,"앙상블"]],"textEdited":"마지막은 모델 선택의 어려움입니다. 적절한 기본 모델들과 메타 모델을 선택하는 과정이 어렵고 최적의 조합을 찾기 위해 많은 실험이 필요할 수 있습니다. 이번 강의에서는 앙상블"},{"start":1007700,"end":1020900,"text":"모델의 분산과 편향, 교차 검증, 앙상블과 스태킹 앙상블 기법 등 앙상블을 활용하는 방법에 대해서 배웠습니다. 먼저 앙상블에서는 여러 모델을 결합하여 성능을 향상시키는 기법이라고 이야기했습니다.","confidence":0.9161,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1008030,1008360,"모델의"],[1008370,1008740,"분산과"],[1008740,1008960,"편향,"],[1009410,1009740,"교차"],[1009740,1009960,"검증,"],[1010010,1010540,"앙상블과"],[1010930,1011300,"스태킹"],[1011350,1011660,"앙상블"],[1011730,1012040,"기법"],[1012070,1012220,"등"],[1012870,1013420,"앙상블을"],[1013670,1014080,"활용하는"],[1014230,1014507,"방법에"],[1014507,1014780,"대해서"],[1014890,1015320,"배웠습니다."],[1015630,1015880,"먼저"],[1015930,1016520,"앙상블에서는"],[1017010,1017280,"여러"],[1017290,1017620,"모델을"],[1017620,1018060,"결합하여"],[1018450,1018760,"성능을"],[1018810,1019300,"향상시키는"],[1019310,1019880,"기법이라고"],[1020070,1020680,"이야기했습니다."]],"textEdited":"모델의 분산과 편향, 교차 검증, 앙상블과 스태킹 앙상블 기법 등 앙상블을 활용하는 방법에 대해서 배웠습니다. 먼저 앙상블에서는 여러 모델을 결합하여 성능을 향상시키는 기법이라고 이야기했습니다."},{"start":1020900,"end":1031700,"text":"그중 백인 앙상블의 경우 여러 모델의 예측 결과를 투표로 결합하여 최종 예측하는 앙상블 기법이라고 했었고요. 여기서 중요한 부분은 데이터를 샘플링해서","confidence":0.9538,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1021130,1021380,"그중"],[1021670,1021960,"백인"],[1021990,1022400,"앙상블의"],[1022400,1022600,"경우"],[1022950,1023220,"여러"],[1023220,1023520,"모델의"],[1023520,1023740,"예측"],[1023740,1024120,"결과를"],[1024350,1024740,"투표로"],[1024870,1025340,"결합하여"],[1025530,1025780,"최종"],[1025870,1026320,"예측하는"],[1026810,1027180,"앙상블"],[1027290,1027780,"기법이라고"],[1027780,1028220,"했었고요."],[1028550,1028840,"여기서"],[1028910,1029240,"중요한"],[1029250,1029600,"부분은"],[1029990,1030520,"데이터를"],[1030750,1031280,"샘플링해서"]],"textEdited":"그중 백인 앙상블의 경우 여러 모델의 예측 결과를 투표로 결합하여 최종 예측하는 앙상블 기법이라고 했었고요. 여기서 중요한 부분은 데이터를 샘플링해서"},{"start":1031700,"end":1045500,"text":"동일한 데이터를 사용하는 것이 아닌 행과 열을 랜덤하게 구성하는 서로 다른 데이터셋을 사용한다는 점입니다. 부스팅 앙상블은 백인 강상블의 아이디어에 더해 순차적으로 모델을 학습시켜 오차를 줄이는 방법이었습니다.","confidence":0.9218,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1031970,1032340,"동일한"],[1032350,1032647,"데이터를"],[1032647,1032907,"사용하는"],[1032907,1033114,"것이"],[1033114,1033280,"아닌"],[1033750,1034040,"행과"],[1034330,1034680,"열을"],[1035010,1035500,"랜덤하게"],[1035730,1036180,"구성하는"],[1036550,1036767,"서로"],[1036767,1036960,"다른"],[1036970,1037460,"데이터셋을"],[1037460,1037880,"사용한다는"],[1037930,1038340,"점입니다."],[1039010,1039380,"부스팅"],[1039410,1039860,"앙상블은"],[1040190,1040460,"백인"],[1040470,1040900,"강상블의"],[1040910,1041400,"아이디어에"],[1041410,1041700,"더해"],[1042150,1042740,"순차적으로"],[1043010,1043360,"모델을"],[1043360,1043740,"학습시켜"],[1043990,1044380,"오차를"],[1044380,1044640,"줄이는"],[1044690,1045280,"방법이었습니다."]],"textEdited":"동일한 데이터를 사용하는 것이 아닌 행과 열을 랜덤하게 구성하는 서로 다른 데이터셋을 사용한다는 점입니다. 부스팅 앙상블은 백인 강상블의 아이디어에 더해 순차적으로 모델을 학습시켜 오차를 줄이는 방법이었습니다."},{"start":1045500,"end":1053800,"text":"앙상블에서 모델의 분산과 편향이 낮아지는 이유로는 여러 모델의 예측을 결합해서 평균화하기 때문이라고 이야기했습니다.","confidence":0.9838,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1046050,1046600,"앙상블에서"],[1046970,1047320,"모델의"],[1047350,1047740,"분산과"],[1047930,1048260,"편향이"],[1048260,1048640,"낮아지는"],[1048670,1049120,"이유로는"],[1049630,1049900,"여러"],[1049900,1050220,"모델의"],[1050410,1050800,"예측을"],[1050800,1051240,"결합해서"],[1051690,1052240,"평균화하기"],[1052240,1052780,"때문이라고"],[1052890,1053620,"이야기했습니다."]],"textEdited":"앙상블에서 모델의 분산과 편향이 낮아지는 이유로는 여러 모델의 예측을 결합해서 평균화하기 때문이라고 이야기했습니다."},{"start":1053800,"end":1068100,"text":"교차 검증 앙상블은 교차 검증을 통해 모델을 평가하고 이를 보팅 기법으로 결합하는 방법이라고 설명을 드렸었고요. 스태킹 앙상블은 여러 모델의 예측 결과를 다시 학습하는 메타 모델을 사용하여 최종 예측하는 앙상블 기법이었습니다.","confidence":0.9352,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1054290,1054600,"교차"],[1054600,1054800,"검증"],[1054850,1055280,"앙상블은"],[1055550,1055840,"교차"],[1055840,1056107,"검증을"],[1056107,1056300,"통해"],[1056330,1056680,"모델을"],[1056890,1057420,"평가하고"],[1057790,1058020,"이를"],[1058270,1058560,"보팅"],[1058560,1058940,"기법으로"],[1058950,1059380,"결합하는"],[1059610,1060100,"방법이라고"],[1060150,1060387,"설명을"],[1060387,1060880,"드렸었고요."],[1061450,1061780,"스태킹"],[1061790,1062220,"앙상블은"],[1062430,1062680,"여러"],[1062680,1062980,"모델의"],[1062980,1063200,"예측"],[1063210,1063600,"결과를"],[1063710,1063960,"다시"],[1063960,1064360,"학습하는"],[1064510,1064780,"메타"],[1064780,1065054,"모델을"],[1065054,1065400,"사용하여"],[1065850,1066080,"최종"],[1066080,1066480,"예측하는"],[1066830,1067220,"앙상블"],[1067290,1067900,"기법이었습니다."]],"textEdited":"교차 검증 앙상블은 교차 검증을 통해 모델을 평가하고 이를 보팅 기법으로 결합하는 방법이라고 설명을 드렸었고요. 스태킹 앙상블은 여러 모델의 예측 결과를 다시 학습하는 메타 모델을 사용하여 최종 예측하는 앙상블 기법이었습니다."},{"start":1068100,"end":1078464,"text":"이번 강의는 여기까지입니다. 고생 많으셨습니다.","confidence":0.9856,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1068750,1068980,"이번"],[1069030,1069234,"강의는"],[1069234,1069720,"여기까지입니다."],[1070230,1070447,"고생"],[1070447,1070940,"많으셨습니다."]],"textEdited":"이번 강의는 여기까지입니다. 고생 많으셨습니다."}],"text":"안녕하세요. 도메인 공통 프로젝트 9강 더 좋은 성능을 위한 기법 세 번째 앙상블 시작하겠습니다. 이번 강의에서는 여러 모델의 결과를 섞어서 더 좋은 성능을 내는 모델 앙상블에 대해서 이야기해 보겠습니다. 다음으로는 여러분들이 사용할 수 있는 몇 가지 앙상블 기법에 대해서 소개해 드리겠습니다. 첫 번째 모델 앙상블입니다. 앙상블의 개념은 간단합니다. 단일 모델을 사용하는 것보다 여러 모델의 결과를 같이 사용하는 것이 더 좋은 예측 성능을 보여줄 수 있다라는 의미입니다. 예시에서 볼 수 있듯이 테스트 샘플을 마이 모델 이외에도 다른 종류의 여러 모델들의 결과를 출력한 뒤에 이를 합산해서 결과를 만들어내는 앙상블이 더 좋은 성능을 보여줄 수 있다라는 것입니다. 조금 더 직관적으로 이해해 보겠습니다. 우리가 전교 1, 2, 3, 4등의 4명의 학생이 있다고 가정해 보겠습니다. 전교 2 3, 4등의 학생은 전교 1등과 개개인의 성적을 비교했을 때 이길 수 없다고 가정을 해 보겠습니다. 하지만 전교 2등, 3등, 4등 학생이 잘하는 과목이 다르다면 그리고 이 3명의 점수 혹은 이 3명의 풀이를 혹은 정답을 합쳐서 성적을 낸다면 모두 준수하게 잘하는 전교 1등을 이길 수 있다 이런 식으로 이해하시면 좋겠습니다. 하지만 성적이 고만고만한 학생들끼리 뭉치는 경우에는 어떻게 해도 전교 1등보다 높은 성적을 받기는 어렵습니다. 이는 여러분들이 모델을 앙상블을 할 때 모든 모델을 기반으로 결과를 내는 것이 아니라 어느 정도 성능이 좋은 성능이 비슷한 모델들의 결과들을 섞어야 더 좋은 성능을 얻을 수 있다는 것을 의미합니다. 앙상블의 대표적인 방식인 베깅에 대해서 개념적으로 이해해 보겠습니다. 베깅은 bing로 이해하시면 됩니다. 가지고 있는 데이터셋을 여러 분할로 쪼개어서 가방에 담는다고 상상해 보겠습니다. 각각의 모델들은 각 가방에 담긴 여러 서로 다른 데이터셋을 기반으로 모델을 학습하게 됩니다. 이 학습한 결과를 기반으로 예측 값을 만들어 내는 것이 베깅입니다. 여기에서 각 모델들의 결과를 섞는 방식이 섞는 방식을 우리가 보팅이라고 하는데요. 그래서 베깅은 보팅 앙상블의 어떤 예시로 이해할 수도 있습니다. 다음은 보팅이 어떤 식으로 이루어지는지 조금 더 자세히 다뤄보겠습니다. 현재 우리가 풀고자 하는 문제는 주어진 입력에 대해 이 입력이 어떤 음식을 뜻하는지 분류하는 문제입니다. 먼저 하드 보팅입니다. 하드 보팅은 말 그대로 레이블 그 자체로 보팅을 수행합니다. 첫 번째 모델은 애플, 두 번째 세 번째 모델 모두 애플이라고 답했습니다. 하지만 네 번째 모델은 핫도그라고 답변을 했는데요. 여기에서 4개의 모델의 앙상블 결과는 3개의 사과 1개의 핫도그가 됩니다. 이를 통해 결과가 사과가 되는 것을 확인하실 수가 있습니다. 다음은 소프트 보팅입니다. 제가 우리 강의에서 사실 분류 모델이 반환하는 것은 어떤 분류 클래스가 아니라 그 직전에 확률 값을 반환한다고 언급한 적이 있습니다. 예시에서 볼 수 있듯이 모델 1 2 3 사과 출력하는 각 클래스에 대한 확률을 볼 수가 있습니다. 이 과정에서 모델 1 2 3이 사과라고 답변을 했지만 실제로는 각 모델이 보여주는 컨피던스는 약간 다를 수 있습니다. 1번 모델은 0.5의 확률로 사과하라고 답했고요. 2번 모델은 0.8의 확률로 사과하라고 답했습니다. 모델 3은 0.7의 확률로 사과하라고 답했습니다. 이런 식으로 각각 레이블의 확률을 출력으로 삼아서 이 확률을 모두 평균을 낸 뒤에 가장 평균 확률이 높은 클래스를 선택하는 방식이 소프트 보팅입니다. 우리가 가능하다면 일반적으로는 하드 보팅보다는 소프트 보팅을 사용하는 것을 추천드리고 조금 더 일반적인 방법입니다. 다음은 앙상블의 대표적인 다른 형태인 부스팅에 대해서 설명하도록 하겠습니다. 부스팅은 내부적으로 여러 개의 모델을 생성을 합니다. 각각의 모델은 순차적으로 학습되고 평가됩니다. 각 모델에서 틀린 샘플, 잘못 맞춘 샘플에 대해 다음 모델이 더 잘 맞출 수 있도록 가중치를 주거나 혹은 그레디언트를 통해 더 높은 로스를 발생시켜 많은 업데이트를 할 수 있도록 만드는 것이 부스팅입니다. 조금 쉽게 말하면 1번 모델이 틀린 문제를 2번 모델이 집중적으로 학습하고, 2번 모델이 틀린 문제를, 3번 모델이, 3번 모델이 틀린 문제를, 4번 모델이 이런 식으로 점진적으로 취약점을 해결해 나가는 방안으로 모델이 업데이트됩니다. 결과적으로는 부스팅 과정을 통해 생성된 모든 모델의 결과를 보팅 연산을 통해 만들어내게 됩니다. 다음은 부스팅 학습 과정을 보여줍니다. 첫 번째 예시를 보겠습니다. 백인과 동일하게 학습 셋은 랜덤하게 샘플링을 합니다. 여기서 랜덤하게 샘플링한다라는 것은 랜덤하게 행을 선택하는 것도 포함하며, 랜덤하게 피처 컬럼을 열을 선택하는 것도 포함을 합니다. 그래서 첫 번째 학습 셋에 대해서 첫 번째 모델을 학습하고 밸리데이션을 진행합니다. 예측을 진행한다는 것이죠. 예측된 밸리데이션 레이블과 실제 밸리데이션 레이블의 결과를 비교하여 잘못 예측된 에러를 계산합니다. 그리고 이 잘못 예측된 에러를 다음 모델 학습에 포함하게 하여 더 잘 맞출 수 있도록 합니다. 이런 식으로 이터레이션을 반복해 나가면서 이전 단계에서 틀렸던 샘플에 대해 좋은 모델을 학습할 수 있도록 모델을 개선합니다. 좀 쉽게 말하면 이런 작은 위클 러너들이 서로 예측하기 어려운 부분들을 반복적으로 개선해 나가면서 결과적으로 마지막에 앙상블 된 모델에서는 강한 모델 스트롱 러너가 되는 과정을 표현한 앙상블 기법이라고 생각하시면 되겠습니다. 다음은 모델의 분산과 편향에 대해서 이야기를 해 보겠습니다. 먼저 편향은 얼마나 예측 값이 실제 값보다 다른지 이야기합니다. 예측값의 평균과 실제 값을 뺀 값을 이야기합니다. 다음은 분산입니다. 분산은 모델이 출력하는 예측값이 같은 샘플들에 대해 얼마나 달라질 수 있는지를 뜻합니다. 예측값과 예측값의 평균을 뺀 뒤 제곱한 것의 평균을 취합니다. 이는 우리가 정의한 로스 펑션을 분해하면 편향과 분산으로 표현되는 것을 알 수 있습니다. 다음은 모델의 분산과 편향에 따라 우리가 언더피팅 혹은 오버피팅이라고 말하는 양상을 보여줍니다. 먼저 왼쪽부터 보겠습니다. 높은 편향과 낮은 분산이 있는 경우 우리는 이를 과소 적합이라고 이야기를 합니다. 예시에서 볼 수 있듯이 결정 경계 혹은 회귀선이 데이터셋을 전혀 표현하지 못하는 것을 보실 수가 있습니다. 다음으로는 로우 바이어스 로우 베리언스로 보겠습니다. 편향이 낮고 모델이 표현하는 분산이 낮은 경우 다음과 같이 적절하게 어느 정도 오차를 허용하면서 결정 경계 혹은 회귀선을 만들어 내는 것을 보실 수가 있습니다. 마지막 오른쪽의 경우는 로우 바이어스 하이 베리언스를 갖습니다. 이는 우리가 이야기하는 과적합 형태입니다. 주어진 데이터에 대해서는 매우 잘 표현하는 어떤 결정 경계나 회귀선을 보여주지만 실제로 관측하지 않은 데이터에 대해서는 잘 맞추지 못하는 문제가 발생할 수 있습니다. 정리를 해보면 하이 바이러스를 갖는 경우는 과소적합, 지나치게 단순한 모델로 인해 예측력이 감소된 상태입니다. 하이베리언스는 과대적합 오버피팅으로 지나치게 복잡한 모델로 인해 일반화가 되기 어려운 상태를 이야기합니다. 앙상블을 통해 편향과 분산이 낮아지게 되는데요. 이 이유에 대해서 살펴보겠습니다. 왼쪽에 있는 것은 단일 모델로 분류한 결정 경계입니다. 오른쪽에 있는 그림은 베깅 앙상블을 통해 구성된 결정 경계입니다. 단일 모델을 사용하면 과대적합이 되어 분산이 높아지지만 배깅 앙상블을 통해 분산을 줄일 수가 있습니다. 이를 조금 더 직관적인 그림으로 이해해 보겠습니다. 위에서 오른쪽에 있는 그림은 낮은 베리언스를 갖지만 높은 바이러스를 갖는 언더피팅 된 데이터입니다. 이는 부스팅 과정을 통해 잘 맞추지 못한 샘플을 더 잘 맞추도록 하여 높은 바이러스를 낮은 바이러스 쪽으로 가져올 수 있게 됩니다. 아래의 왼쪽에 있는 그림을 보겠습니다. 이는 낮은 바이어스를 갖지만 높은 베리언스를 갖습니다. 이는 배깅 앙상블을 통해 높은 베리언스를 낮은 베리언스 쪽으로 가져와서 더 좋은 모델로 만들 수가 있습니다. 다음은 앙상블 기법입니다. 먼저 우리가 이전에 배웠던 교차 검증 프로세스를 통해 진행하는 앙상블에 대해서 배워보겠습니다. 우리가 이전 교차 검증에서는 주어진 데이터셋을 케익의 폴드로 분할하여 모든 폴드를 돌아가며 검증 데이터로 사용하는 교차 검증 방식이라고 배웠습니다. 여기에서 교차 검증의 단점이었던 여러 번 학습을 해야 된다라는 단점을 조금 완화하기 위해 앙상블을 사용해 보려고 합니다. 교차 검증에서는 각 폴드에 대해서 학습을 진행하고 검증 스코어를 확인하는 것으로 프로세스를 마무리했었는데요. 그게 아니라 여기에서 학습된 각 폴드의 모델을 앙상블하는 기법을 교차검증 앙상블이라고 이야기를 합니다. 단순히 검증 스코어를 확인하기 위해 모델을 학습하고 그 모델을 사용하지 않았었는데 이를 다시 재활용하면서 컴퓨팅 리소스의 효율성을 높일 수 있는 방법입니다. 다음과 같이 각 모델이 출력하는 확률 값을 소프트 보팅하여 최종 레이블을 만들어 낼 수 있습니다. 교차 검증 앙상부를 구현하는 예시를 보겠습니다. 이전에 만들었던 예시와 동일하게 k 폴드 객체를 정의하고요. 그리고 k 폴드 스플릿이라고 하는 함수를 통해 인덱스를 생성합니다. 생성된 인덱스를 기반으로 데이터셋을 먼저 만들고요. 만든 데이터셋을 데이터 로더로 만듭니다. 해당 데이터 로더는 각 폴드마다 생성이 되게 되고 트레인 밸리데이션 스텝에서 사용되게 됩니다. 이전에 봤었던 예시와 동일하게 케 폴드마다 모델을 따로 지정하게 됩니다. 즉 케이개의 모델을 학습시킨다라는 의미입니다. 각 모델 개별적으로 테스트 셋에 대해 추론을 통해 생성된 프레딕션 값을 평균을 취하면서 오프 프레딕션즈라고 하는 변수에다가 저장합니다. 이런 식으로 모든 폴드에 대해 학습을 진행을 하고 마지막으로 검증 스코어를 확인을 하면서 테스트 셋에 대한 소프트 보팅 앙상블 결과를 확인합니다. 결과는 다음과 같습니다. 각 폴드의 테스트 알피알씨는 0.741 0.6117, 0.6113, 0.7261이 나왔고요. 최종적으로 합친 테스트 ruprc의 결과는 0.8915가 나왔습니다. 이를 통해 개별보다 더 좋은 테스트 성능을 얻을 수 있었습니다. 우리가 교차검증 앙상블을 다른 말로 ro 폴드 앙상블이라고도 이야기를 합니다. 교차 검증 앙상블의 장단점에 대해서 이야기를 해 보겠습니다. 먼저 장점입니다. 모델의 일반화 성능을 평가하면서 앙상블을 진행할 수 있습니다. 데이터를 여러 부분으로 나누어 반복적으로 모델을 학습하고 평가함으로써 모델이 새로운 데이터에 대해 얼마나 잘 일반화할 수 있는지를 더 정확하게 측정할 수 있습니다. 다음은 과적합 방지입니다. 모델이 특정 데이터 분할에 과적합되는 것을 방지할 수 있습니다. 다양한 데이터 분할에 대해 모델을 평가하므로 특정 분할에만 최적화되지 않도록 합니다. 마지막으로는 안정된 성능 평가입니다. 단일 학습 검증 분할에서 발생할 수 있는 편차를 줄여줍니다. 여러 번의 평가를 통해 평균적인 성능을 구함으로써 보다 안정적인 모델 성능 평가가 가능합니다. 다음은 단점입니다. 아무리 교차 검증의 결과를 앙상블을 했다 하더라도 시간과 계산 비용은 여전히 단점입니다. 교차검증 앙상블은 여러 번의 모델 학습과 평가를 필요로 하므로 시간과 계산 비용이 증가할 수 있습니다. 다음은 복잡성의 증가입니다. 여러 번의 모델 학습과 평가를 관리해야 하므로 구현과 유지 보수가 복잡해질 수 있습니다. 다음은 데이터 요구 사항입니다. 충분한 데이터가 없는 경우 데이터의 분할이 모델 성능에 부정적인 영향을 미칠 수 있습니다. 교차 검증을 위해서는 데이터가 충분히 많아야 합니다. 다음은 스태킹 앙상블입니다. 스태킹 앙상블은 모델마다 가중치를 주어서 양상블 모델을 만드는 것이다라고 생각하시면 되겠습니다. 이때 가중치를 어떻게 주는지에 따라 최종 예측이 달라질 수 있는데요. 이때 추가적인 모델을 사용하게 됩니다. 가중치들을 어떻게 셋업할 것인지 학습하는 모델이 메타 모델이고 이러한 메타 모델을 활용한 앙상블을 스태킹 앙상블이라고 부릅니다. 그림에서 볼 수 있듯이 샘플링을 통해 형성된 여러 학습 셋을 각각의 모델들이 학습을 합니다. 그리고 각각의 모델의 결과에 대해 가중치를 부여해서 예측을 생성하는 메타 모델을 추가로 정의합니다. 다음과 같이 각 모델의 예측값을 피처로 만듭니다. 다음 샘플의 클래스를 기반으로 레이블 와를 설정합니다. 이스와 이와를 기반으로 메타 모델을 학습합니다. 다음은 티티에라고 하는 테스트 타임 어그멘테이션입니다. 학습이 끝난 모델에 대해 테스트 샘플을 어그멘테이션을 통해 한 샘플에 대해 여러 번 추론한 후 평균을 내어 추정 결과를 냅니다. 좀 쉽게 직관적으로 이해해 보겠습니다. 우리가 만약 강아지 혹은 고양이를 분류한 사진이 있다고 해 보겠습니다. 강아지와 고양이는 똑바로 보아도 강아지와 고양이일 거고요. 사진을 90도를 돌려도 강아지와 고양이처럼 보일 것입니다. 혹은 플립을 해서 뒤집는다 하더라도 똑같이 강아지와 고양이처럼 보일 거예요. 이런 식으로 이미지 혹은 비전 쪽에서는 이미지들을 추론하는 테스트 단계에서 여러 번의 어그멘테이션을 통해 동일한 이미지를 다양한 버전을 생성을 하고 이를 여러 번 추론을 합니다. 이 추론한 결과의 평균을 소프트 보팅을 처리하여 예측하는 것이 tta 테스트 타임 어그멘테이션 앙상블 기법입니다. 다음은 스톡캐스틱 웨이트 에버리지입니다. 이 개념은 모델이 어느 정도 학습이 이루어지고 나면 더 이상 옵티멀 지점에 가까이 가기 어려울 때 그 주변부에 있는 모델들을 가지고 배기 앙상블을 하면 옵티멀의 근사한 성능을 얻을 수 있게 해주는 기법입니다. 조금 더 쉽게 말하면 하나의 모델에 대해 학습을 진행합니다. 그리고 그 모델이 어느 정도 성능이 세츄레이션 됐을 때 그때부터 각 스텝 혹은 각 에폭마다 모델의 체크 포인트를 저장을 합니다. 그다음 그 모델들의 파라미터 웨이트 값을 평균을 낸 뒤에 결과를 추론하게 만드는 것입니다. 이를 통해 더 좋은 성능을 얻을 수 있는 것이 블에의 기본적인 개념입니다. 오른쪽 예시에서 볼 수 있듯이 w1, w2, w3라고 하는 같은 모델의 3개의 웨이트 값을 앙상블을 한 모델로 추론했을 때 더 좋은 성능을 보일 수 있었습니다. 다음은 믹스트 오브 엑스퍼트입니다. 이 앙상블 기법은 최근 엘엘엠에서 많이 선택되는 구조인데요. 입력에 따라 서로 다른 전문가 모델 중 일부만 선택적으로 활성화되는 구조입니다. 각 전문가의 특화된 예측을 게이트 모델이 조합하여 전체 예측 성능을 높입니다. 이 과정에서 게이트 모델은 탑 k개의 엑스퍼트를 선택을 하고 선택된 엑스퍼트들에 대한 노드만 활성화하는 방식으로 구현합니다. 앞서 여러 가지 앙상블 기법을 설명을 드렸는데요. 여러분들이 쉽게 사용할 수 있는 강력한 앙상블 기법인 스태킹 앙상블에 대해 조금 정리하고 넘어가겠습니다. 먼저 장점입니다. 첫 번째는 일반화 성능 향상 부분입니다. 스태킹 향상블은 여러 모델의 예측 결과를 종합하여 최종 예측을 수행하므로 개별 모델의 과적합을 방지하고 더 나은 일반화 성능을 제공합니다. 다음은 복잡한 패턴 학습입니다. 메타 모델은 예측 모델의 예측 결과를 입력으로 사용하여 복잡한 패턴을 학습할 수 있습니다. 이는 단일 모델로는 잡아내기 어려운 복잡한 데이터 구조를 더 잘 포착할 수 있습니다. 다음은 유연성입니다. 스태킹 영상물은 다양한 모델을 자유롭게 결합할 수 있어 매우 유연합니다. 예를 들어 선형 모델, 결정, 트리, 신경망 등 서로 다른 유형의 모델을 함께 사용할 수 있습니다. 다음은 단점입니다. 단점에서는 시간과 계산 비용이 있는데요. 스태킹 영상물은 여러 모델을 학습시키고 예측을 종합하는 과정이 필요하므로 시간과 계산 비용이 증가할 수 있습니다. 또한 복잡성이 증가될 수 있습니다. 여러 모델을 결합하고 메타 모델을 학습시켜야 하므로 구현과 유지 보수가 복잡해질 수 있습니다. 마지막은 모델 선택의 어려움입니다. 적절한 기본 모델들과 메타 모델을 선택하는 과정이 어렵고 최적의 조합을 찾기 위해 많은 실험이 필요할 수 있습니다. 이번 강의에서는 앙상블 모델의 분산과 편향, 교차 검증, 앙상블과 스태킹 앙상블 기법 등 앙상블을 활용하는 방법에 대해서 배웠습니다. 먼저 앙상블에서는 여러 모델을 결합하여 성능을 향상시키는 기법이라고 이야기했습니다. 그중 백인 앙상블의 경우 여러 모델의 예측 결과를 투표로 결합하여 최종 예측하는 앙상블 기법이라고 했었고요. 여기서 중요한 부분은 데이터를 샘플링해서 동일한 데이터를 사용하는 것이 아닌 행과 열을 랜덤하게 구성하는 서로 다른 데이터셋을 사용한다는 점입니다. 부스팅 앙상블은 백인 강상블의 아이디어에 더해 순차적으로 모델을 학습시켜 오차를 줄이는 방법이었습니다. 앙상블에서 모델의 분산과 편향이 낮아지는 이유로는 여러 모델의 예측을 결합해서 평균화하기 때문이라고 이야기했습니다. 교차 검증 앙상블은 교차 검증을 통해 모델을 평가하고 이를 보팅 기법으로 결합하는 방법이라고 설명을 드렸었고요. 스태킹 앙상블은 여러 모델의 예측 결과를 다시 학습하는 메타 모델을 사용하여 최종 예측하는 앙상블 기법이었습니다. 이번 강의는 여기까지입니다. 고생 많으셨습니다.","confidence":0.9480247,"speakers":[{"label":"","name":"","edited":false}],"events":[],"eventTypes":[]}