{"result":"SUCCEEDED","message":"Succeeded","token":"199c918efc8c42b8a31f2bb3272c3d2a","version":"ncp_v2_v2.4.6-c00dd1b-20250528__v4.2.20.1_ko_firedepartment_20250923_","params":{"service":"ncp","domain":"general","lang":"ko","completion":"sync","callback":"","diarization":{"enable":false,"speakerCountMin":-1,"speakerCountMax":-1},"sed":{"enable":false},"boostings":[],"forbiddens":"","wordAlignment":true,"fullText":true,"noiseFiltering":true,"priority":0,"userdata":{"_ncp_DomainCode":"tpc-boostcamp","_ncp_DomainId":13807,"_ncp_TaskId":42975811,"_ncp_TraceId":"3bc52a042b1e486eb289d9d97643aa5b"}},"progress":100,"keywords":{},"segments":[{"start":0,"end":14000,"text":"안녕하세요. 추천 시스템 이론 강의를 맡은 강사 이준원입니다. 이제 강의가 절반 정도 진행되었는데요.","confidence":0.9537,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[5630,6100,"안녕하세요."],[7390,7660,"추천"],[7690,8040,"시스템"],[8070,8260,"이론"],[8270,8580,"강의를"],[8590,8860,"맡은"],[9150,9420,"강사"],[9550,10340,"이준원입니다."],[11610,11820,"이제"],[11870,12160,"강의가"],[12250,12540,"절반"],[12550,12780,"정도"],[12790,13520,"진행되었는데요."]],"textEdited":"안녕하세요. 추천 시스템 이론 강의를 맡은 강사 이준원입니다. 이제 강의가 절반 정도 진행되었는데요."},{"start":14000,"end":28000,"text":"생각해 보면 아직까지 저희는 딥러닝을 사용한 추천 모델을 본격적으로 배우지 않았습니다. 물론 5강에서 아이템 투 백 모델이 간단한 뉴럴넷 랭귀지 모델이긴 하지만 그렇게 복잡한 딥러닝 모델은 아니었죠.","confidence":0.9148,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[14650,14914,"생각해"],[14914,15140,"보면"],[15190,15620,"아직까지"],[15620,15940,"저희는"],[16090,16680,"딥러닝을"],[16850,17140,"사용한"],[17190,17440,"추천"],[17440,17780,"모델을"],[18130,18640,"본격적으로"],[18650,18960,"배우지"],[18960,19460,"않았습니다."],[20490,20700,"물론"],[20730,21180,"5강에서"],[21510,21820,"아이템"],[21830,21980,"투"],[21980,22100,"백"],[22210,22560,"모델이"],[23230,23580,"간단한"],[23590,23920,"뉴럴넷"],[24110,24420,"랭귀지"],[24420,24800,"모델이긴"],[24800,25080,"하지만"],[26010,26220,"그렇게"],[26290,26700,"복잡한"],[26750,27100,"딥러닝"],[27100,27400,"모델은"],[27400,27820,"아니었죠."]],"textEdited":"생각해 보면 아직까지 저희는 딥러닝을 사용한 추천 모델을 본격적으로 배우지 않았습니다. 물론 5강에서 아이템 투 백 모델이 간단한 뉴럴넷 랭귀지 모델이긴 하지만 그렇게 복잡한 딥러닝 모델은 아니었죠."},{"start":28000,"end":38100,"text":"이전에 말씀드린 대로 추천 시스템 분야는 다른 분야에 비해서는 딥러닝 모델이 기존 ML 모델에 비해 월등히 좋은 성능을 내지 못하는 부분이 있습니다.","confidence":0.9019,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[28450,28760,"이전에"],[28830,29240,"말씀드린"],[29240,29480,"대로"],[30130,30400,"추천"],[30410,30740,"시스템"],[30740,31100,"분야는"],[31250,31560,"다른"],[31610,31960,"분야에"],[31960,32420,"비해서는"],[32610,33020,"딥러닝"],[33020,33360,"모델이"],[33710,33940,"기존"],[34010,34220,"ML"],[34250,34600,"모델에"],[34600,34820,"비해"],[35350,35880,"월등히"],[35930,36100,"좋은"],[36270,36580,"성능을"],[36580,36800,"내지"],[36810,37160,"못하는"],[37160,37427,"부분이"],[37427,37900,"있습니다."]],"textEdited":"이전에 말씀드린 대로 추천 시스템 분야는 다른 분야에 비해서는 딥러닝 모델이 기존 ML 모델에 비해 월등히 좋은 성능을 내지 못하는 부분이 있습니다."},{"start":38100,"end":47500,"text":"또한 추천을 수행할 때 이 모델을 서빙하는 레이턴시가 굉장히 중요하기 때문에 또 너무 복잡한 모델을 사용하기에는 실제로는 어렵다는 챌린지도 존재합니다.","confidence":0.9937,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[38350,38580,"또한"],[38650,39060,"추천을"],[39070,39440,"수행할"],[39450,39600,"때"],[39750,39900,"이"],[39910,40260,"모델을"],[40270,40740,"서빙하는"],[40750,41300,"레이턴시가"],[41330,41620,"굉장히"],[41690,42100,"중요하기"],[42100,42440,"때문에"],[42730,42880,"또"],[42880,43060,"너무"],[43170,43560,"복잡한"],[43570,43920,"모델을"],[43970,44600,"사용하기에는"],[45230,45660,"실제로는"],[45660,46080,"어렵다는"],[46150,46660,"챌린지도"],[46850,47500,"존재합니다."]],"textEdited":"또한 추천을 수행할 때 이 모델을 서빙하는 레이턴시가 굉장히 중요하기 때문에 또 너무 복잡한 모델을 사용하기에는 실제로는 어렵다는 챌린지도 존재합니다."},{"start":47500,"end":61000,"text":"그럼에도 불구하고 딥러닝을 사용한 추천 모델은 여전히 활발하게 연구되어 있고 또 일부 구글과 핀터레스트와 같은 추천을 잘하는 회사는 딥러닝을 추천에 적극적으로 활용하고 있습니다.","confidence":0.987,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[47790,48160,"그럼에도"],[48170,48640,"불구하고"],[48990,49600,"딥러닝을"],[49610,49900,"사용한"],[49950,50200,"추천"],[50210,50560,"모델은"],[50850,51180,"여전히"],[51250,51680,"활발하게"],[51710,52140,"연구되어"],[52170,52480,"있고"],[53010,53160,"또"],[53250,53520,"일부"],[53970,55020,"구글과"],[55090,55780,"핀터레스트와"],[55790,56060,"같은"],[56710,57080,"추천을"],[57080,57360,"잘하는"],[57360,57700,"회사는"],[58230,58800,"딥러닝을"],[58910,59300,"추천에"],[59430,59980,"적극적으로"],[59990,60380,"활용하고"],[60380,60900,"있습니다."]],"textEdited":"그럼에도 불구하고 딥러닝을 사용한 추천 모델은 여전히 활발하게 연구되어 있고 또 일부 구글과 핀터레스트와 같은 추천을 잘하는 회사는 딥러닝을 추천에 적극적으로 활용하고 있습니다."},{"start":61000,"end":71100,"text":"그래서 이번 시간에는 3강부터 5강까지 배웠던 컬래버레이터의 필터링의 원리를 바탕으로 딥러닝 추천 모델들에 대해 살펴보겠습니다.","confidence":0.9498,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[61230,61480,"그래서"],[61480,61680,"이번"],[61730,62140,"시간에는"],[62630,63300,"3강부터"],[63710,64240,"5강까지"],[64240,64600,"배웠던"],[64910,65580,"컬래버레이터의"],[65950,66500,"필터링의"],[66530,67140,"원리를"],[67190,67640,"바탕으로"],[67970,68420,"딥러닝"],[68450,68720,"추천"],[68720,69180,"모델들에"],[69180,69400,"대해"],[69790,70640,"살펴보겠습니다."]],"textEdited":"그래서 이번 시간에는 3강부터 5강까지 배웠던 컬래버레이터의 필터링의 원리를 바탕으로 딥러닝 추천 모델들에 대해 살펴보겠습니다."},{"start":71100,"end":83900,"text":"네 목차는 다음과 같습니다. 딥러닝이 어떤 장점을 가지는지, 딥러닝에 사용되는 기법은 무엇인지에 대해 간단히 랩업을 하고 나서 이제 이번 시간에는 멀티 레이어 퍼셉트론 제일 기본적인","confidence":0.9085,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[71450,71600,"네"],[71810,72180,"목차는"],[72180,72520,"다음과"],[72520,72900,"같습니다."],[73250,73800,"딥러닝이"],[73830,74040,"어떤"],[74170,74520,"장점을"],[74770,75280,"가지는지,"],[75470,75940,"딥러닝에"],[75940,76340,"사용되는"],[76390,76740,"기법은"],[76770,77367,"무엇인지에"],[77367,77560,"대해"],[77670,78100,"간단히"],[78630,78980,"랩업을"],[78990,79220,"하고"],[79220,79520,"나서"],[80170,80340,"이제"],[80340,80540,"이번"],[80590,81000,"시간에는"],[81430,81760,"멀티"],[81760,82020,"레이어"],[82050,82560,"퍼셉트론"],[82770,82980,"제일"],[83050,83640,"기본적인"]],"textEdited":"네 목차는 다음과 같습니다. 딥러닝이 어떤 장점을 가지는지, 딥러닝에 사용되는 기법은 무엇인지에 대해 간단히 랩업을 하고 나서 이제 이번 시간에는 멀티 레이어 퍼셉트론 제일 기본적인"},{"start":83900,"end":96800,"text":"피드 포워드 뉴럴 네트워크 구조이죠. 그리고 오토 인코더를 기반으로 설계된 대표적인 추천 모델에 대해서 배워보도록 하겠습니다. 먼저 추천 시스템에 딥러닝을 사용하는 것이 왜 좋은가? 딥러닝을 통해","confidence":0.9363,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[84130,84380,"피드"],[84390,84647,"포워드"],[84647,84860,"뉴럴"],[84860,85260,"네트워크"],[85270,85680,"구조이죠."],[85970,86240,"그리고"],[86430,86720,"오토"],[86730,87960,"인코더를"],[87970,88420,"기반으로"],[88470,88860,"설계된"],[89370,89780,"대표적인"],[89850,90080,"추천"],[90090,90374,"모델에"],[90374,90700,"대해서"],[91230,91740,"배워보도록"],[91750,92280,"하겠습니다."],[92670,92940,"먼저"],[92990,93240,"추천"],[93250,93640,"시스템에"],[93670,94160,"딥러닝을"],[94160,94507,"사용하는"],[94507,94760,"것이"],[94760,94900,"왜"],[94970,95360,"좋은가?"],[95770,96280,"딥러닝을"],[96330,96580,"통해"]],"textEdited":"피드 포워드 뉴럴 네트워크 구조이죠. 그리고 오토 인코더를 기반으로 설계된 대표적인 추천 모델에 대해서 배워보도록 하겠습니다. 먼저 추천 시스템에 딥러닝을 사용하는 것이 왜 좋은가? 딥러닝을 통해"},{"start":96800,"end":111700,"text":"어떻게 추천 모델이 고도화될 수 있는지 살펴봅시다. 네 먼저 딥러닝 모델은 가장 잘 알려진 특징이죠. 논 리니어 트랜스포메이션이 가능합니다. 데이터가 가진 비선형의 패턴을 효과적으로 나타내고","confidence":0.9777,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[97070,97420,"어떻게"],[97450,97720,"추천"],[97730,98060,"모델이"],[98110,98680,"고도화될"],[98750,98900,"수"],[98900,99300,"있는지"],[99930,100520,"살펴봅시다."],[101490,101640,"네"],[101650,101900,"먼저"],[102510,102980,"딥러닝"],[103030,103560,"모델은"],[103910,104160,"가장"],[104190,104340,"잘"],[104350,104640,"알려진"],[104730,105120,"특징이죠."],[105570,105720,"논"],[105870,106160,"리니어"],[106160,106860,"트랜스포메이션이"],[106860,107340,"가능합니다."],[107610,108060,"데이터가"],[108060,108260,"가진"],[108550,109060,"비선형의"],[109110,109540,"패턴을"],[110110,110780,"효과적으로"],[110830,111320,"나타내고"]],"textEdited":"어떻게 추천 모델이 고도화될 수 있는지 살펴봅시다. 네 먼저 딥러닝 모델은 가장 잘 알려진 특징이죠. 논 리니어 트랜스포메이션이 가능합니다. 데이터가 가진 비선형의 패턴을 효과적으로 나타내고"},{"start":111700,"end":126400,"text":"모델링 할 수 있습니다. DNN에서 사용되는 멜루나 탄젠트 하이퍼블릭 같은 활성화 함수들이 이런 논 리니얼리티를 가능하게 하는 것을 이미 배우셨을 것입니다. 이제 이러한 DNN의 논 리니어 트랜스포메이션 성질은","confidence":0.9256,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[111990,112360,"모델링"],[112360,112480,"할"],[112530,112680,"수"],[112690,113080,"있습니다."],[113330,113860,"DNN에서"],[113870,114340,"사용되는"],[114670,115100,"멜루나"],[115250,115640,"탄젠트"],[115640,116080,"하이퍼블릭"],[116110,116340,"같은"],[116430,116760,"활성화"],[116760,117200,"함수들이"],[117790,117980,"이런"],[118210,118360,"논"],[118490,119180,"리니얼리티를"],[119750,120160,"가능하게"],[120160,120307,"하는"],[120307,120560,"것을"],[120560,120720,"이미"],[120810,121240,"배우셨을"],[121240,121640,"것입니다."],[121890,122080,"이제"],[122110,122360,"이러한"],[122450,122920,"DNN의"],[123970,124120,"논"],[124230,124580,"리니어"],[124850,125480,"트랜스포메이션"],[125770,126140,"성질은"]],"textEdited":"모델링 할 수 있습니다. DNN에서 사용되는 멜루나 탄젠트 하이퍼블릭 같은 활성화 함수들이 이런 논 리니얼리티를 가능하게 하는 것을 이미 배우셨을 것입니다. 이제 이러한 DNN의 논 리니어 트랜스포메이션 성질은"},{"start":126400,"end":141100,"text":"추천 모델 학습에 사용되는 이 유저 아이템의 복잡한 인터랙션을 모델링하는 데 큰 도움을 줍니다. 우리가 4강에서 배웠던 매트리스 팩토라이제이션의 경우 유저 아이템을 임베딩한 이후에는 닷 프로덕트","confidence":0.954,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[126690,126980,"추천"],[126980,127200,"모델"],[127250,127580,"학습에"],[127610,128100,"사용되는"],[128510,128660,"이"],[128690,129020,"유저"],[129130,129600,"아이템의"],[129790,130200,"복잡한"],[130430,131120,"인터랙션을"],[131730,132340,"모델링하는"],[132340,132480,"데"],[132830,132980,"큰"],[133210,133580,"도움을"],[133710,134040,"줍니다."],[134390,134680,"우리가"],[134710,135240,"4강에서"],[135250,135580,"배웠던"],[135670,136080,"매트리스"],[136080,136900,"팩토라이제이션의"],[136900,137140,"경우"],[137810,138100,"유저"],[138210,138680,"아이템을"],[138730,139180,"임베딩한"],[139230,139700,"이후에는"],[140270,140420,"닷"],[140490,140960,"프로덕트"]],"textEdited":"추천 모델 학습에 사용되는 이 유저 아이템의 복잡한 인터랙션을 모델링하는 데 큰 도움을 줍니다. 우리가 4강에서 배웠던 매트리스 팩토라이제이션의 경우 유저 아이템을 임베딩한 이후에는 닷 프로덕트"},{"start":141100,"end":146200,"text":"즉 선형 결합을 통해서 바로 유저의 선호도를 예측하게 됩니다.","confidence":0.9936,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[141370,141520,"즉"],[142010,142300,"선형"],[142300,142660,"결합을"],[142660,142980,"통해서"],[143350,143640,"바로"],[144370,144700,"유저의"],[144700,145360,"선호도를"],[145390,145807,"예측하게"],[145807,146200,"됩니다."]],"textEdited":"즉 선형 결합을 통해서 바로 유저의 선호도를 예측하게 됩니다."},{"start":146200,"end":160000,"text":"그리고 8강에서 배우게 될 대표적인 클래시컬 모델인 팩토라이제이션 머신이나 그 외에 사용하는 다양한 추천 모델의 경우에서도 선형 가정을 토대로 모델이 설계된 경우가 많습니다. 그래서 이러한 가정은 모델을 너무 단순하게 만들고","confidence":0.9668,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[146390,146620,"그리고"],[146650,147080,"8강에서"],[147110,147400,"배우게"],[147400,147520,"될"],[147810,148220,"대표적인"],[148270,148680,"클래시컬"],[148710,149000,"모델인"],[149150,149740,"팩토라이제이션"],[149770,150220,"머신이나"],[150450,150600,"그"],[150610,150840,"외에"],[150870,151260,"사용하는"],[151350,151660,"다양한"],[151770,152040,"추천"],[152040,152360,"모델의"],[152360,153040,"경우에서도"],[153490,153840,"선형"],[153870,154260,"가정을"],[154270,154620,"토대로"],[154850,155160,"모델이"],[155550,155880,"설계된"],[155890,156160,"경우가"],[156170,156640,"많습니다."],[156790,156980,"그래서"],[156990,157240,"이러한"],[157290,157620,"가정은"],[158290,158620,"모델을"],[158620,158760,"너무"],[158870,159340,"단순하게"],[159350,159800,"만들고"]],"textEdited":"그리고 8강에서 배우게 될 대표적인 클래시컬 모델인 팩토라이제이션 머신이나 그 외에 사용하는 다양한 추천 모델의 경우에서도 선형 가정을 토대로 모델이 설계된 경우가 많습니다. 그래서 이러한 가정은 모델을 너무 단순하게 만들고"},{"start":160000,"end":164300,"text":"모델이 가지는 표현력에 큰 한계를 두게 합니다. 따라서 딥뉴럴 네트워크","confidence":0.9655,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[160290,160660,"모델이"],[160660,160960,"가지는"],[161030,161460,"표현력에"],[161490,161640,"큰"],[161750,162100,"한계를"],[162100,162280,"두게"],[162280,162580,"합니다."],[162770,163080,"따라서"],[163330,163680,"딥뉴럴"],[163690,164160,"네트워크"]],"textEdited":"모델이 가지는 표현력에 큰 한계를 두게 합니다. 따라서 딥뉴럴 네트워크"},{"start":164300,"end":178000,"text":"DNN을 사용하여서 전통적인 추천 모델이 표현할 수 없는 복잡한 인터랙션을 딥러닝 모델이 학습하기를 기대하는 것입니다. 또한 DNN은 주어진 로우 데이터로부터 피처 레프레젠테이션을 직접 할 수 있기 때문에","confidence":0.8421,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[164510,164960,"DNN을"],[164960,165420,"사용하여서"],[165990,166620,"전통적인"],[166750,167020,"추천"],[167030,167380,"모델이"],[167410,167740,"표현할"],[167770,167874,"수"],[167874,168060,"없는"],[168350,168780,"복잡한"],[168990,169580,"인터랙션을"],[169890,170260,"딥러닝"],[170260,170560,"모델이"],[170630,171180,"학습하기를"],[171250,171640,"기대하는"],[171640,172020,"것입니다."],[172230,172440,"또한"],[172510,173000,"DNN은"],[173410,173760,"주어진"],[173790,173980,"로우"],[173990,174700,"데이터로부터"],[175510,175800,"피처"],[175810,176520,"레프레젠테이션을"],[176570,176820,"직접"],[176830,176980,"할"],[176980,177074,"수"],[177074,177227,"있기"],[177227,177580,"때문에"]],"textEdited":"DNN을 사용하여서 전통적인 추천 모델이 표현할 수 없는 복잡한 인터랙션을 딥러닝 모델이 학습하기를 기대하는 것입니다. 또한 DNN은 주어진 로우 데이터로부터 피처 레프레젠테이션을 직접 할 수 있기 때문에"},{"start":178000,"end":192700,"text":"피처 프리 프로세싱이 훨씬 적고 사람이 직접 피처를 디자인하지 않아도 됩니다. 또한 디엔엔을 사용하면 기존에 사용하기 어려웠던 텍스트나 이미지, 오디오와 같은 데이터도 추천 모델의 피처로 직접 사용할 수 있습니다.","confidence":0.9152,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[178270,178540,"피처"],[178540,178720,"프리"],[178720,179200,"프로세싱이"],[179250,179540,"훨씬"],[179610,180040,"적고"],[180670,181060,"사람이"],[181410,181700,"직접"],[181710,182040,"피처를"],[182040,182560,"디자인하지"],[182560,182880,"않아도"],[182930,183280,"됩니다."],[183530,183740,"또한"],[183810,184220,"디엔엔을"],[184220,184620,"사용하면"],[185250,185560,"기존에"],[185560,185900,"사용하기"],[185900,186240,"어려웠던"],[186450,186900,"텍스트나"],[186950,187300,"이미지,"],[187890,188740,"오디오와"],[188810,189080,"같은"],[189190,189660,"데이터도"],[190130,190420,"추천"],[190420,191040,"모델의"],[191090,191460,"피처로"],[191630,191880,"직접"],[191880,192200,"사용할"],[192200,192287,"수"],[192287,192700,"있습니다."]],"textEdited":"피처 프리 프로세싱이 훨씬 적고 사람이 직접 피처를 디자인하지 않아도 됩니다. 또한 디엔엔을 사용하면 기존에 사용하기 어려웠던 텍스트나 이미지, 오디오와 같은 데이터도 추천 모델의 피처로 직접 사용할 수 있습니다."},{"start":192700,"end":204900,"text":"그래서 이러한 레프레젠테이션은 인베딩 레이어나 컨볼루션 레이어와 같은 레이어를 사용하여서 하나의 모델로 엔드 투 엔드로 직접 학습할 수 있게 되고, 그래서 복잡한 피처를","confidence":0.9137,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[192930,193160,"그래서"],[193170,193440,"이러한"],[193710,194480,"레프레젠테이션은"],[194590,194940,"인베딩"],[194990,195840,"레이어나"],[196150,196640,"컨볼루션"],[196670,197240,"레이어와"],[197270,197580,"같은"],[198050,198420,"레이어를"],[198420,198900,"사용하여서"],[199350,199700,"하나의"],[199710,200100,"모델로"],[200250,200500,"엔드"],[200500,200640,"투"],[200640,200980,"엔드로"],[201350,201640,"직접"],[201870,202260,"학습할"],[202490,202607,"수"],[202607,202767,"있게"],[202767,203040,"되고,"],[203490,203680,"그래서"],[203770,204160,"복잡한"],[204210,204620,"피처를"]],"textEdited":"그래서 이러한 레프레젠테이션은 인베딩 레이어나 컨볼루션 레이어와 같은 레이어를 사용하여서 하나의 모델로 엔드 투 엔드로 직접 학습할 수 있게 되고, 그래서 복잡한 피처를"},{"start":204900,"end":216500,"text":"적절한 레프리젠테이션으로 표현할 수 있게 됩니다. 또한 딥러닝 모델은 시퀀스 모델링에 굉장히 뛰어난 성능을 보이고 있습니다. 대표적으로 자연어 처리 머신 트레저레이션이나 음성 인식, 챗봇","confidence":0.8698,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[205230,205640,"적절한"],[205750,206680,"레프리젠테이션으로"],[206790,207140,"표현할"],[207150,207300,"수"],[207300,207467,"있게"],[207467,207760,"됩니다."],[207930,208160,"또한"],[208270,208660,"딥러닝"],[208660,208980,"모델은"],[209230,209680,"시퀀스"],[209680,210080,"모델링에"],[210130,210420,"굉장히"],[210490,210840,"뛰어난"],[210950,211260,"성능을"],[211260,211487,"보이고"],[211487,211860,"있습니다."],[211990,212540,"대표적으로"],[212590,212940,"자연어"],[212950,213220,"처리"],[213790,214060,"머신"],[214070,214860,"트레저레이션이나"],[215230,215520,"음성"],[215530,215800,"인식,"],[215950,216240,"챗봇"]],"textEdited":"적절한 레프리젠테이션으로 표현할 수 있게 됩니다. 또한 딥러닝 모델은 시퀀스 모델링에 굉장히 뛰어난 성능을 보이고 있습니다. 대표적으로 자연어 처리 머신 트레저레이션이나 음성 인식, 챗봇"},{"start":216500,"end":221600,"text":"과 같은 테스크에서 이런 시퀀스 모델링이 아주 좋은 성능을 보이고 있는데요.","confidence":0.984,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[216790,216940,"과"],[216970,217220,"같은"],[217790,218340,"테스크에서"],[218510,218680,"이런"],[218790,219180,"시퀀스"],[219180,220000,"모델링이"],[220030,220220,"아주"],[220230,220420,"좋은"],[220570,220880,"성능을"],[220880,221160,"보이고"],[221160,221600,"있는데요."]],"textEdited":"과 같은 테스크에서 이런 시퀀스 모델링이 아주 좋은 성능을 보이고 있는데요."},{"start":221600,"end":234200,"text":"앞선 강의에서 배우셨겠지만 RNN이나 CNN 계열의 모델 그리고 요즘에는 트랜스포머 같은 모델들이 이런 시퀀스 모델링을 아주 잘 하고 있습니다. 추천 시스템에서는 현재까지 소비한 아이템 다음에","confidence":0.8782,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[221910,222200,"앞선"],[222250,222620,"강의에서"],[222620,223180,"배우셨겠지만"],[223650,224300,"RNN이나"],[224430,224840,"CNN"],[224950,225300,"계열의"],[225350,225580,"모델"],[225730,225874,"그리고"],[225874,226160,"요즘에는"],[226160,226640,"트랜스포머"],[226640,226880,"같은"],[227030,227520,"모델들이"],[227890,228060,"이런"],[228110,228520,"시퀀스"],[228520,228920,"모델링을"],[228970,229180,"아주"],[229270,229420,"잘"],[229490,229700,"하고"],[229700,230060,"있습니다."],[230370,230620,"추천"],[230630,231300,"시스템에서는"],[231970,232580,"현재까지"],[232650,233020,"소비한"],[233110,233480,"아이템"],[233570,233960,"다음에"]],"textEdited":"앞선 강의에서 배우셨겠지만 RNN이나 CNN 계열의 모델 그리고 요즘에는 트랜스포머 같은 모델들이 이런 시퀀스 모델링을 아주 잘 하고 있습니다. 추천 시스템에서는 현재까지 소비한 아이템 다음에"},{"start":234200,"end":248800,"text":"넥스트 아이템을 예측하는 넥스트 아이템, 프리딕션이나 같은 세션에서 추천을 수행하는 세션, 베이스 레코멘데이션 같은 데스크에 이런 시퀀스 모델링이 활용될 수 있습니다. 유저나 아이템에 대한 시간적 정보 즉 어떤 시퀀셜한 정보를","confidence":0.9564,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[234530,234960,"넥스트"],[234990,235440,"아이템을"],[235450,235920,"예측하는"],[236030,236307,"넥스트"],[236307,236560,"아이템,"],[236560,237380,"프리딕션이나"],[238010,238280,"같은"],[238350,238820,"세션에서"],[239390,239740,"추천을"],[239740,240060,"수행하는"],[240070,240360,"세션,"],[240360,240600,"베이스"],[240610,241200,"레코멘데이션"],[241230,241480,"같은"],[241510,241940,"데스크에"],[242290,242460,"이런"],[242530,242880,"시퀀스"],[242880,243300,"모델링이"],[243310,243640,"활용될"],[243650,243754,"수"],[243754,244100,"있습니다."],[244330,244700,"유저나"],[244710,245087,"아이템에"],[245087,245300,"대한"],[245470,245900,"시간적"],[246010,246300,"정보"],[246510,246660,"즉"],[247070,247260,"어떤"],[247430,248020,"시퀀셜한"],[248110,248540,"정보를"]],"textEdited":"넥스트 아이템을 예측하는 넥스트 아이템, 프리딕션이나 같은 세션에서 추천을 수행하는 세션, 베이스 레코멘데이션 같은 데스크에 이런 시퀀스 모델링이 활용될 수 있습니다. 유저나 아이템에 대한 시간적 정보 즉 어떤 시퀀셜한 정보를"},{"start":248800,"end":261900,"text":"그러니까 이 딥러닝 모델이 표현하고 학습할 수 있기 때문입니다. 또한 마지막으로 플렉서빌리티인데요. 이러한 딥러닝 모델을 쉽게 개발할 수 있는 다양한 프레임워크가 이미 있기 때문에 연구와 현업에서도 이런 텐서플로우나 파이터치","confidence":0.9121,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[248930,249160,"그러니까"],[249190,249340,"이"],[249370,249800,"딥러닝"],[249800,250140,"모델이"],[250450,250880,"표현하고"],[250910,251240,"학습할"],[251250,251367,"수"],[251367,251527,"있기"],[251527,252020,"때문입니다."],[252150,252380,"또한"],[252390,252920,"마지막으로"],[253330,254160,"플렉서빌리티인데요."],[254530,254760,"이러한"],[254790,255140,"딥러닝"],[255140,255400,"모델을"],[255400,255640,"쉽게"],[255640,256020,"개발할"],[256030,256120,"수"],[256120,256280,"있는"],[256330,256620,"다양한"],[256670,257240,"프레임워크가"],[257240,257380,"이미"],[257410,257600,"있기"],[257600,257940,"때문에"],[258510,258900,"연구와"],[258900,259440,"현업에서도"],[259950,260120,"이런"],[260250,260960,"텐서플로우나"],[261010,261500,"파이터치"]],"textEdited":"그러니까 이 딥러닝 모델이 표현하고 학습할 수 있기 때문입니다. 또한 마지막으로 플렉서빌리티인데요. 이러한 딥러닝 모델을 쉽게 개발할 수 있는 다양한 프레임워크가 이미 있기 때문에 연구와 현업에서도 이런 텐서플로우나 파이터치"},{"start":261900,"end":272700,"text":"같은 것을 잘 활용하여서 활발하게 연구와 개발을 동시에 하고 있습니다. 이러한 프레임웍을 사용하는 커뮤니티도 굉장히 활발하기 때문에 이 딥러닝 분야가 계속 추천 시스템에서도","confidence":0.9823,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[262130,262347,"같은"],[262347,262580,"것을"],[262580,262720,"잘"],[262750,263320,"활용하여서"],[263730,264160,"활발하게"],[264210,264600,"연구와"],[264970,265380,"개발을"],[265630,265907,"동시에"],[265907,266047,"하고"],[266047,266400,"있습니다."],[266630,266880,"이러한"],[267130,267540,"프레임웍을"],[267540,267860,"사용하는"],[267890,268420,"커뮤니티도"],[268430,268700,"굉장히"],[268730,269140,"활발하기"],[269140,269520,"때문에"],[269790,269940,"이"],[269940,270340,"딥러닝"],[270790,271140,"분야가"],[271370,271580,"계속"],[271610,271880,"추천"],[271890,272540,"시스템에서도"]],"textEdited":"같은 것을 잘 활용하여서 활발하게 연구와 개발을 동시에 하고 있습니다. 이러한 프레임웍을 사용하는 커뮤니티도 굉장히 활발하기 때문에 이 딥러닝 분야가 계속 추천 시스템에서도"},{"start":272700,"end":285600,"text":"잘 연구되고 있습니다. 그래서 이러한 이유들로 인해서 추천 시스템에서도 최근에 발생되는 최신 논문들과 기법은 거의 딥러닝 모델 혹은 그러한 접근들을 사용하고 있습니다. 네 이제 제일 기본적인 딥러닝의 레이어","confidence":0.9801,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[272990,273140,"잘"],[273350,273760,"연구되고"],[273760,274140,"있습니다."],[274430,274620,"그래서"],[274620,274840,"이러한"],[274850,275174,"이유들로"],[275174,275440,"인해서"],[275810,276080,"추천"],[276080,276600,"시스템에서도"],[276930,277260,"최근에"],[277350,277820,"발생되는"],[278050,278340,"최신"],[278340,278780,"논문들과"],[278810,279180,"기법은"],[279630,279840,"거의"],[279850,280220,"딥러닝"],[280230,280460,"모델"],[280570,280760,"혹은"],[280830,281080,"그러한"],[281150,281680,"접근들을"],[281810,282180,"사용하고"],[282180,282560,"있습니다."],[282850,283000,"네"],[283530,283700,"이제"],[283700,283880,"제일"],[283950,284400,"기본적인"],[284450,284920,"딥러닝의"],[284930,285240,"레이어"]],"textEdited":"잘 연구되고 있습니다. 그래서 이러한 이유들로 인해서 추천 시스템에서도 최근에 발생되는 최신 논문들과 기법은 거의 딥러닝 모델 혹은 그러한 접근들을 사용하고 있습니다. 네 이제 제일 기본적인 딥러닝의 레이어"},{"start":285600,"end":299600,"text":"인 멀티 레이어 퍼셉션을 사용한 대표적인 추천 모델 몇 가지를 살펴봅시다. 참고로 지금부터 일곱 번째 강의 즉 다음 강의까지 다양한 딥러닝 모델들을 배우게 될 것인데요. 제 강의에서 소개하는 모델들","confidence":0.9563,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[285790,285940,"인"],[286390,286700,"멀티"],[286710,287000,"레이어"],[287030,288280,"퍼셉션을"],[288290,288600,"사용한"],[288690,289100,"대표적인"],[289130,289380,"추천"],[289380,289580,"모델"],[289580,289720,"몇"],[289720,290040,"가지를"],[290070,290600,"살펴봅시다."],[291150,291500,"참고로"],[291750,292280,"지금부터"],[292630,292880,"일곱"],[292890,293160,"번째"],[293170,293400,"강의"],[293530,293680,"즉"],[293750,294000,"다음"],[294050,294520,"강의까지"],[295050,295380,"다양한"],[295490,295880,"딥러닝"],[295890,296300,"모델들을"],[296310,296547,"배우게"],[296547,296680,"될"],[296690,297120,"것인데요."],[297590,297740,"제"],[297810,298240,"강의에서"],[298290,298680,"소개하는"],[299070,299500,"모델들"]],"textEdited":"인 멀티 레이어 퍼셉션을 사용한 대표적인 추천 모델 몇 가지를 살펴봅시다. 참고로 지금부터 일곱 번째 강의 즉 다음 강의까지 다양한 딥러닝 모델들을 배우게 될 것인데요. 제 강의에서 소개하는 모델들"},{"start":299600,"end":312300,"text":"그 논문들은 여러 가지 딥러닝 접근법을 추천 시스템의 각 분야에 처음 활용했다는 점에서 각각의 발자취를 남긴 논문이 되겠습니다. 따라서 실제 현업에서 자주 사용되는 기준으로 모델을","confidence":0.9942,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[299850,300000,"그"],[300000,300480,"논문들은"],[300970,301220,"여러"],[301220,301420,"가지"],[301470,301900,"딥러닝"],[302210,302740,"접근법을"],[302890,303160,"추천"],[303190,303620,"시스템의"],[303630,303780,"각"],[303810,304140,"분야에"],[304250,304480,"처음"],[304570,305067,"활용했다는"],[305067,305380,"점에서"],[306050,306380,"각각의"],[306450,307000,"발자취를"],[307000,307240,"남긴"],[307290,307587,"논문이"],[307587,308080,"되겠습니다."],[308230,308580,"따라서"],[309170,309440,"실제"],[309450,309900,"현업에서"],[310010,310280,"자주"],[310310,310740,"사용되는"],[310790,311240,"기준으로"],[311610,312000,"모델을"]],"textEdited":"그 논문들은 여러 가지 딥러닝 접근법을 추천 시스템의 각 분야에 처음 활용했다는 점에서 각각의 발자취를 남긴 논문이 되겠습니다. 따라서 실제 현업에서 자주 사용되는 기준으로 모델을"},{"start":312300,"end":323800,"text":"혹은 논문을 소개한다기보다는 이론적으로 큰 의미를 가지는 기준으로 소개하는 것임을 참고하시길 바랍니다. 네 멀티 레이어 퍼셉트론 한국말로 다중 퍼셉트론이라고 표현할 수 있는데요.","confidence":0.8941,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[312530,312760,"혹은"],[312770,313200,"논문을"],[313310,314120,"소개한다기보다는"],[314710,315280,"이론적으로"],[315370,315520,"큰"],[315670,316040,"의미를"],[316070,316400,"가지는"],[316410,316780,"기준으로"],[316790,317200,"소개하는"],[317200,317540,"것임을"],[317930,318460,"참고하시길"],[318460,318820,"바랍니다."],[319430,319580,"네"],[320230,320507,"멀티"],[320507,320740,"레이어"],[320750,321180,"퍼셉트론"],[321550,321980,"한국말로"],[322030,322320,"다중"],[322350,322894,"퍼셉트론이라고"],[322894,323180,"표현할"],[323180,323267,"수"],[323267,323580,"있는데요."]],"textEdited":"혹은 논문을 소개한다기보다는 이론적으로 큰 의미를 가지는 기준으로 소개하는 것임을 참고하시길 바랍니다. 네 멀티 레이어 퍼셉트론 한국말로 다중 퍼셉트론이라고 표현할 수 있는데요."},{"start":323800,"end":333100,"text":"가장 기본적인 퍼셉션 즉 노드 여러 개의 노드로 이루어진 레이어를 순차적으로 쌓은 구조입니다. 피드 포드 유n 네트워크가 되겠죠","confidence":0.8828,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[324090,324320,"가장"],[324390,324820,"기본적인"],[324870,325300,"퍼셉션"],[325450,325600,"즉"],[325670,325980,"노드"],[326250,326427,"여러"],[326427,326640,"개의"],[326640,326960,"노드로"],[326960,327300,"이루어진"],[327350,327760,"레이어를"],[328130,328740,"순차적으로"],[329530,329760,"쌓은"],[329870,330360,"구조입니다."],[330970,331220,"피드"],[331250,331540,"포드"],[331710,331960,"유n"],[331960,332720,"네트워크가"],[332720,333060,"되겠죠"]],"textEdited":"가장 기본적인 퍼셉션 즉 노드 여러 개의 노드로 이루어진 레이어를 순차적으로 쌓은 구조입니다. 피드 포드 유n 네트워크가 되겠죠"},{"start":333100,"end":345900,"text":"딥러닝이 가지고 있는 가장 기본적인 논 리니어와 문제를 풀 수 있다는 것을 설명하는 레이어이고요. 뭐 아래의 예시는 여러분들이 잘 아시는 엑스알 문제를 통해 엠엘피 레이어로 해결할 수 있다는 것을 보여줍니다.","confidence":0.8051,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[333390,333880,"딥러닝이"],[333890,334200,"가지고"],[334200,334380,"있는"],[334610,334880,"가장"],[335030,335540,"기본적인"],[335650,335800,"논"],[335950,336420,"리니어와"],[336430,336740,"문제를"],[336750,336900,"풀"],[336910,337014,"수"],[337014,337287,"있다는"],[337287,337560,"것을"],[338030,338420,"설명하는"],[338420,338900,"레이어이고요."],[339450,339600,"뭐"],[339630,340300,"아래의"],[340410,340780,"예시는"],[341230,341620,"여러분들이"],[341630,341780,"잘"],[341870,342140,"아시는"],[342190,342560,"엑스알"],[342610,342960,"문제를"],[343090,343300,"통해"],[343750,344160,"엠엘피"],[344160,344460,"레이어로"],[344460,344707,"해결할"],[344707,344794,"수"],[344794,345027,"있다는"],[345027,345280,"것을"],[345370,345900,"보여줍니다."]],"textEdited":"딥러닝이 가지고 있는 가장 기본적인 논 리니어와 문제를 풀 수 있다는 것을 설명하는 레이어이고요. 뭐 아래의 예시는 여러분들이 잘 아시는 엑스알 문제를 통해 엠엘피 레이어로 해결할 수 있다는 것을 보여줍니다."},{"start":345900,"end":360400,"text":"그래서 RNN CNN 오토 인코더 혹은 트랜스포머 같은 다양한 복잡한 레이어들이 있지만 그 모든 레이어들 이전에 이 기본적인 MLP 레이어로부터 딥러닝 모델이 출발한 것입니다. 네 그래서 처음으로 소개하는 논문은","confidence":0.8036,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[346670,346880,"그래서"],[346910,347400,"RNN"],[347590,347980,"CNN"],[348130,348380,"오토"],[348390,348760,"인코더"],[348870,349060,"혹은"],[349090,349560,"트랜스포머"],[349560,349800,"같은"],[349870,350220,"다양한"],[350630,350980,"복잡한"],[350980,351314,"레이어들이"],[351314,351600,"있지만"],[352050,352167,"그"],[352167,352380,"모든"],[352410,352800,"레이어들"],[352910,353300,"이전에"],[353590,353740,"이"],[353740,354180,"기본적인"],[354270,354740,"MLP"],[354810,355640,"레이어로부터"],[355870,356260,"딥러닝"],[356260,356600,"모델이"],[356970,357287,"출발한"],[357287,357680,"것입니다."],[358410,358560,"네"],[358560,358780,"그래서"],[358850,359220,"처음으로"],[359230,359640,"소개하는"],[359690,360080,"논문은"]],"textEdited":"그래서 RNN CNN 오토 인코더 혹은 트랜스포머 같은 다양한 복잡한 레이어들이 있지만 그 모든 레이어들 이전에 이 기본적인 MLP 레이어로부터 딥러닝 모델이 출발한 것입니다. 네 그래서 처음으로 소개하는 논문은"},{"start":360400,"end":375300,"text":"뉴럴 컬라버레이트 필터링입니다. 추천 시스템에서 가장 많이 사용하던 엠프 매트리스 팩토라이제이션에다가 이 MLP 레이어를 적용한 기법인데요. 매트리스 팩토라이제이션이 가진 한계","confidence":0.8541,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[360630,360940,"뉴럴"],[361230,361740,"컬라버레이트"],[361790,362520,"필터링입니다."],[363750,364020,"추천"],[364030,364640,"시스템에서"],[364790,365040,"가장"],[365050,365240,"많이"],[365270,365700,"사용하던"],[366650,367000,"엠프"],[367090,367500,"매트리스"],[367500,369880,"팩토라이제이션에다가"],[370110,370260,"이"],[370270,370660,"MLP"],[370660,371080,"레이어를"],[371290,371620,"적용한"],[371650,372180,"기법인데요."],[373190,373640,"매트리스"],[373670,374400,"팩토라이제이션이"],[374430,374660,"가진"],[374750,375020,"한계"]],"textEdited":"뉴럴 컬라버레이트 필터링입니다. 추천 시스템에서 가장 많이 사용하던 엠프 매트리스 팩토라이제이션에다가 이 MLP 레이어를 적용한 기법인데요. 매트리스 팩토라이제이션이 가진 한계"},{"start":375300,"end":389800,"text":"즉 아까도 잠깐 언급했지만 이 리니어 모델에 대한 한계를 지적하면서 뉴럴넷 모델을 이 엠프에 추가하여 좀 더 일반화된 모델을 본 논문에서는 제시하고 있습니다. 네 본 논문의 아이디어부터 살펴보겠습니다.","confidence":0.9155,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[375490,375640,"즉"],[375710,376160,"아까도"],[376230,376480,"잠깐"],[376510,377020,"언급했지만"],[377290,377440,"이"],[377470,377820,"리니어"],[377850,378134,"모델에"],[378134,378320,"대한"],[378410,378700,"한계를"],[378700,379260,"지적하면서"],[379990,380460,"뉴럴넷"],[380490,380900,"모델을"],[381730,381880,"이"],[382050,382600,"엠프에"],[382670,383140,"추가하여"],[383470,383620,"좀"],[383670,383820,"더"],[383890,384340,"일반화된"],[384390,384740,"모델을"],[384890,385040,"본"],[385090,385600,"논문에서는"],[385650,386140,"제시하고"],[386150,386560,"있습니다."],[387350,387500,"네"],[387510,387660,"본"],[387690,388020,"논문의"],[388030,388720,"아이디어부터"],[388930,389660,"살펴보겠습니다."]],"textEdited":"즉 아까도 잠깐 언급했지만 이 리니어 모델에 대한 한계를 지적하면서 뉴럴넷 모델을 이 엠프에 추가하여 좀 더 일반화된 모델을 본 논문에서는 제시하고 있습니다. 네 본 논문의 아이디어부터 살펴보겠습니다."},{"start":389800,"end":401700,"text":"우리가 4강에서 대표적인 추천 모델이었던 매트리스 팩토라이제이션에 대해서 배웠던 거 기억하시죠? 간단하게 수식으로 써보면 rui는","confidence":0.8924,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[390590,390880,"우리가"],[390950,391500,"4강에서"],[392050,392540,"대표적인"],[392590,392860,"추천"],[392860,393340,"모델이었던"],[393930,394320,"매트리스"],[394320,395187,"팩토라이제이션에"],[395187,395520,"대해서"],[395590,395874,"배웠던"],[395874,396000,"거"],[396000,396440,"기억하시죠?"],[397070,397500,"간단하게"],[397930,398360,"수식으로"],[398370,398740,"써보면"],[399470,401160,"rui는"]],"textEdited":"우리가 4강에서 대표적인 추천 모델이었던 매트리스 팩토라이제이션에 대해서 배웠던 거 기억하시죠? 간단하게 수식으로 써보면 rui는"},{"start":401700,"end":412400,"text":"유저 벡터 트랜스포즈 아이템 벡터로 나타낼 수 있죠. 이 수식을 보면은 유저 아이템 사이에 임베딩을 우리가 구했지만","confidence":0.9466,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[401950,402240,"유저"],[402590,402900,"벡터"],[403570,404180,"트랜스포즈"],[404810,405200,"아이템"],[405690,406640,"벡터로"],[406890,407240,"나타낼"],[407290,407440,"수"],[407570,407820,"있죠."],[408590,408740,"이"],[408740,409040,"수식을"],[409040,409380,"보면은"],[410030,410300,"유저"],[410300,410600,"아이템"],[410600,410860,"사이에"],[410870,411320,"임베딩을"],[411320,411500,"우리가"],[411570,412020,"구했지만"]],"textEdited":"유저 벡터 트랜스포즈 아이템 벡터로 나타낼 수 있죠. 이 수식을 보면은 유저 아이템 사이에 임베딩을 우리가 구했지만"},{"start":412400,"end":426500,"text":"결국 그 둘은 닷 프로덕트 즉 선형 연산으로 곱해지게 됩니다. 그래서 유저와 아이템 사이의 복잡한 관계를 표현해야 하는데 이런 리니어한 인터랙션으로 표현되는 경우에는 표현력에 한계를 가질 수밖에 없다는 것이죠. 그래서 엠프 모델을 통해서","confidence":0.9167,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[412670,412900,"결국"],[412930,413080,"그"],[413080,413340,"둘은"],[413570,413720,"닷"],[413790,414220,"프로덕트"],[414350,414500,"즉"],[414510,414800,"선형"],[414800,415160,"연산으로"],[415160,415507,"곱해지게"],[415507,415820,"됩니다."],[415950,416140,"그래서"],[416140,416480,"유저와"],[416510,416900,"아이템"],[416930,417220,"사이의"],[417310,417700,"복잡한"],[417790,418120,"관계를"],[418150,418540,"표현해야"],[418540,418840,"하는데"],[419410,419580,"이런"],[419690,420120,"리니어한"],[420170,420820,"인터랙션으로"],[421630,422020,"표현되는"],[422030,422460,"경우에는"],[422730,423140,"표현력에"],[423190,423560,"한계를"],[423570,423780,"가질"],[423780,424120,"수밖에"],[424120,424434,"없다는"],[424434,424720,"것이죠."],[424870,425060,"그래서"],[425060,425360,"엠프"],[425360,425640,"모델을"],[425640,425920,"통해서"]],"textEdited":"결국 그 둘은 닷 프로덕트 즉 선형 연산으로 곱해지게 됩니다. 그래서 유저와 아이템 사이의 복잡한 관계를 표현해야 하는데 이런 리니어한 인터랙션으로 표현되는 경우에는 표현력에 한계를 가질 수밖에 없다는 것이죠. 그래서 엠프 모델을 통해서"},{"start":426500,"end":439500,"text":"유저 아이템 매트릭스는 각각 유저와 아이템 매트릭스로 나뉘어서 학습이 됩니다. 그래서 아래 그림에 요 왼쪽에 있는 예시를 살펴봅시다. 이 왼쪽에 있는 데이터가 유저 아이템","confidence":0.9436,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[426870,427140,"유저"],[427140,427380,"아이템"],[427410,427920,"매트릭스는"],[428250,428600,"각각"],[428890,429340,"유저와"],[429570,429900,"아이템"],[429950,430440,"매트릭스로"],[430440,430840,"나뉘어서"],[430850,431114,"학습이"],[431114,431440,"됩니다."],[431610,431767,"그래서"],[431767,431940,"아래"],[431950,432260,"그림에"],[432490,432640,"요"],[432730,433140,"왼쪽에"],[433150,433360,"있는"],[434390,434760,"예시를"],[435130,435660,"살펴봅시다."],[436710,436860,"이"],[436890,437240,"왼쪽에"],[437240,437400,"있는"],[437410,437840,"데이터가"],[438250,438580,"유저"],[438750,439120,"아이템"]],"textEdited":"유저 아이템 매트릭스는 각각 유저와 아이템 매트릭스로 나뉘어서 학습이 됩니다. 그래서 아래 그림에 요 왼쪽에 있는 예시를 살펴봅시다. 이 왼쪽에 있는 데이터가 유저 아이템"},{"start":439500,"end":454100,"text":"매트릭스 즉 매트릭스 팩터라이제이션 학습에 필요한 인풋 데이터고요. 오른쪽에 있는 이 학습된 유저 매트릭스를 인베딩 공간에 그려본 것입니다. 학습이 모두 이루어져 있기 때문에 유저 레이턴트 스페이스 즉 인베딩 스페이스에","confidence":0.9606,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[439730,440180,"매트릭스"],[440310,440460,"즉"],[441010,441380,"매트릭스"],[441380,441900,"팩터라이제이션"],[441990,442320,"학습에"],[442320,442560,"필요한"],[442610,442880,"인풋"],[442930,443460,"데이터고요."],[444150,444600,"오른쪽에"],[444600,444760,"있는"],[444810,444960,"이"],[444990,445380,"학습된"],[445630,445920,"유저"],[446710,447320,"매트릭스를"],[448030,448380,"인베딩"],[448410,448780,"공간에"],[449010,449320,"그려본"],[449330,449740,"것입니다."],[450290,450600,"학습이"],[450600,450780,"모두"],[450780,451027,"이루어져"],[451027,451167,"있기"],[451167,451500,"때문에"],[451870,452120,"유저"],[452120,452427,"레이턴트"],[452427,452780,"스페이스"],[452790,452940,"즉"],[452990,453300,"인베딩"],[453300,453880,"스페이스에"]],"textEdited":"매트릭스 즉 매트릭스 팩터라이제이션 학습에 필요한 인풋 데이터고요. 오른쪽에 있는 이 학습된 유저 매트릭스를 인베딩 공간에 그려본 것입니다. 학습이 모두 이루어져 있기 때문에 유저 레이턴트 스페이스 즉 인베딩 스페이스에"},{"start":454100,"end":464700,"text":"각각의 유저들이 표현될 수 있습니다. 보시면 우리는 유저 1 유저 2 유저 3 일단 3개의 유저가 있고 이 유저는 각각 p1 p2 p3","confidence":0.9155,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[454390,454800,"각각의"],[454800,455500,"유저들이"],[455530,455880,"표현될"],[455990,456140,"수"],[456570,457000,"있습니다."],[457270,457600,"보시면"],[457810,458080,"우리는"],[458110,458380,"유저"],[458390,458540,"1"],[458590,458820,"유저"],[458820,458960,"2"],[458960,459160,"유저"],[459170,459320,"3"],[459450,459660,"일단"],[459730,460080,"3개의"],[460080,460400,"유저가"],[460410,460700,"있고"],[461310,461460,"이"],[461470,461860,"유저는"],[462150,462440,"각각"],[462570,462920,"p1"],[463390,463820,"p2"],[464050,464440,"p3"]],"textEdited":"각각의 유저들이 표현될 수 있습니다. 보시면 우리는 유저 1 유저 2 유저 3 일단 3개의 유저가 있고 이 유저는 각각 p1 p2 p3"},{"start":464700,"end":473900,"text":"라는 벡터로 표현이 됩니다. 그래서 이 p1 p2 p3라는 벡터를 레이턴트 스페이스에 나타냈는데요. 문제는 여기서 p4","confidence":0.9334,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[464970,465200,"라는"],[465290,465700,"벡터로"],[465950,466340,"표현이"],[466430,466760,"됩니다."],[466950,467140,"그래서"],[467140,467260,"이"],[467290,467560,"p1"],[467610,467900,"p2"],[467900,468460,"p3라는"],[468870,469280,"벡터를"],[469650,470100,"레이턴트"],[470100,470500,"스페이스에"],[470500,471040,"나타냈는데요."],[471710,472040,"문제는"],[472040,472300,"여기서"],[472750,473420,"p4"]],"textEdited":"라는 벡터로 표현이 됩니다. 그래서 이 p1 p2 p3라는 벡터를 레이턴트 스페이스에 나타냈는데요. 문제는 여기서 p4"},{"start":473900,"end":485300,"text":"즉 유저 4가 새로 등장했을 때 이 유저 4를 존의 유저 레이턴트 스페이스에 추가로 표현해 줘야 한다는 것입니다. 이때 유저 간의 유사도를 계산해야 되는데요.","confidence":0.9539,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[474170,474320,"즉"],[474370,474700,"유저"],[474890,475160,"4가"],[475530,475760,"새로"],[475790,476260,"등장했을"],[476270,476420,"때"],[476970,477120,"이"],[477130,477400,"유저"],[477430,477740,"4를"],[478170,478480,"존의"],[478690,478940,"유저"],[478940,479320,"레이턴트"],[479320,479840,"스페이스에"],[480190,480480,"추가로"],[480490,480734,"표현해"],[480734,480887,"줘야"],[480887,481127,"한다는"],[481127,481520,"것입니다."],[481770,482060,"이때"],[482590,482880,"유저"],[482880,483080,"간의"],[483080,483860,"유사도를"],[483890,484287,"계산해야"],[484287,484700,"되는데요."]],"textEdited":"즉 유저 4가 새로 등장했을 때 이 유저 4를 존의 유저 레이턴트 스페이스에 추가로 표현해 줘야 한다는 것입니다. 이때 유저 간의 유사도를 계산해야 되는데요."},{"start":485300,"end":499500,"text":"이제 여기서 계산한 유사도는 각각의 레이팅이 얼마나 겹치는지 자카드 유사도를 사용하였습니다. 이 데이터를 보시면 유저 4와 가장 레이팅이 많이 겹치는 유저는 유저 원입니다. 즉 유저 4와 유저 원이 가장","confidence":0.9254,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[485490,485660,"이제"],[485690,486000,"여기서"],[486000,486300,"계산한"],[486300,486720,"유사도는"],[487330,487680,"각각의"],[487680,488080,"레이팅이"],[488110,488460,"얼마나"],[488930,489440,"겹치는지"],[489610,490080,"자카드"],[490510,490900,"유사도를"],[490900,491500,"사용하였습니다."],[491730,491880,"이"],[491880,492280,"데이터를"],[492280,492600,"보시면"],[493250,493560,"유저"],[493590,493920,"4와"],[494070,494320,"가장"],[494430,494880,"레이팅이"],[494880,495040,"많이"],[495090,495560,"겹치는"],[495730,496120,"유저는"],[496210,496460,"유저"],[496490,496960,"원입니다."],[497210,497360,"즉"],[497810,498100,"유저"],[498130,498400,"4와"],[498410,498660,"유저"],[498660,498920,"원이"],[499010,499280,"가장"]],"textEdited":"이제 여기서 계산한 유사도는 각각의 레이팅이 얼마나 겹치는지 자카드 유사도를 사용하였습니다. 이 데이터를 보시면 유저 4와 가장 레이팅이 많이 겹치는 유저는 유저 원입니다. 즉 유저 4와 유저 원이 가장"},{"start":499500,"end":511700,"text":"유사하다는 것이죠. 그렇기 때문에 새로 학습되는 유저 4에 해당하는 p4라는 유저 4의 레이턴트 벡터는 p1과 제일 유사한 위치에 놓여야 합니다. 즉 뭐 이런 식으로 놓이거나","confidence":0.9191,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[499730,500227,"유사하다는"],[500227,500540,"것이죠."],[500890,501127,"그렇기"],[501127,501480,"때문에"],[501950,502220,"새로"],[502270,502680,"학습되는"],[502690,502940,"유저"],[503010,503320,"4에"],[503320,503740,"해당하는"],[503930,504540,"p4라는"],[504930,505220,"유저"],[505290,505580,"4의"],[505810,506380,"레이턴트"],[506490,506880,"벡터는"],[507370,507900,"p1과"],[507970,508220,"제일"],[508390,508780,"유사한"],[509070,509400,"위치에"],[509400,509627,"놓여야"],[509627,509900,"합니다."],[510130,510280,"즉"],[510490,510640,"뭐"],[510640,510780,"이런"],[510810,511060,"식으로"],[511060,511460,"놓이거나"]],"textEdited":"유사하다는 것이죠. 그렇기 때문에 새로 학습되는 유저 4에 해당하는 p4라는 유저 4의 레이턴트 벡터는 p1과 제일 유사한 위치에 놓여야 합니다. 즉 뭐 이런 식으로 놓이거나"},{"start":511700,"end":526600,"text":"이런 식으로 놓여야겠죠 자 문제는 그 다음인데요. 유저 2와 유저 3 근데 문제는 유저 2와 유저 3인데요. 유저 4가 가장 가까운 유저 1 다음으로 가까운 유저는 보시면 유저 3리가 더 많은","confidence":0.9029,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[511970,512180,"이런"],[512180,512367,"식으로"],[512367,512860,"놓여야겠죠"],[513150,513300,"자"],[513330,513700,"문제는"],[513710,513827,"그"],[513827,514340,"다음인데요."],[514790,515140,"유저"],[515210,515500,"2와"],[515730,515980,"유저"],[515980,516120,"3"],[516830,517080,"근데"],[517210,517640,"문제는"],[518130,518400,"유저"],[518430,518720,"2와"],[518720,518940,"유저"],[518950,519480,"3인데요."],[520330,520620,"유저"],[520620,520880,"4가"],[520930,521160,"가장"],[521250,521600,"가까운"],[521730,521980,"유저"],[521990,522140,"1"],[522870,523340,"다음으로"],[523410,523740,"가까운"],[523770,524360,"유저는"],[524730,525020,"보시면"],[525030,525280,"유저"],[525330,525680,"3리가"],[525710,525860,"더"],[525910,526140,"많은"]],"textEdited":"이런 식으로 놓여야겠죠 자 문제는 그 다음인데요. 유저 2와 유저 3 근데 문제는 유저 2와 유저 3인데요. 유저 4가 가장 가까운 유저 1 다음으로 가까운 유저는 보시면 유저 3리가 더 많은"},{"start":526600,"end":540400,"text":"아이템을 공유하고 있기 때문에 유저 4가 유저 3와 더 가깝습니다. 유저 2보다는 근데 이제 이 레이턴트 스페이스에 표현을 해야 되는데 어떻게 표현을 해도 이 유저 4는 유저 3보다는 유저 2에 가깝게 됩니다.","confidence":0.9369,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[526830,527280,"아이템을"],[527330,527760,"공유하고"],[527760,527920,"있기"],[527920,528280,"때문에"],[528930,529200,"유저"],[529250,529540,"4가"],[530330,530580,"유저"],[530610,530960,"3와"],[530960,531080,"더"],[531080,531560,"가깝습니다."],[531630,531860,"유저"],[531860,532280,"2보다는"],[532770,533000,"근데"],[533000,533160,"이제"],[533170,533320,"이"],[533330,533760,"레이턴트"],[533760,534180,"스페이스에"],[534180,534454,"표현을"],[534454,534640,"해야"],[534640,534980,"되는데"],[535610,535940,"어떻게"],[535970,536247,"표현을"],[536247,536480,"해도"],[536970,537120,"이"],[537120,537360,"유저"],[537370,537680,"4는"],[538250,538520,"유저"],[538550,539120,"3보다는"],[539210,539460,"유저"],[539490,539760,"2에"],[539760,540027,"가깝게"],[540027,540400,"됩니다."]],"textEdited":"아이템을 공유하고 있기 때문에 유저 4가 유저 3와 더 가깝습니다. 유저 2보다는 근데 이제 이 레이턴트 스페이스에 표현을 해야 되는데 어떻게 표현을 해도 이 유저 4는 유저 3보다는 유저 2에 가깝게 됩니다."},{"start":540400,"end":553000,"text":"즉 새로운 유저 유저 포를 이 스페이스에 표현할 때 모순이 발생하는 거죠. 유저 원과 가깝게 표현을 하게 되는 경우 아무리 레이턴트 스페이스의 유저 포를 표현한다 하더라도","confidence":0.9517,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[540690,540840,"즉"],[541270,541580,"새로운"],[541670,541900,"유저"],[542350,542600,"유저"],[542610,542920,"포를"],[543010,543160,"이"],[543160,543780,"스페이스에"],[543930,544300,"표현할"],[544330,544480,"때"],[544690,545020,"모순이"],[545020,545387,"발생하는"],[545387,545640,"거죠."],[546170,546440,"유저"],[546440,546780,"원과"],[546810,547220,"가깝게"],[547290,547620,"표현을"],[547630,547860,"하게"],[547860,548060,"되는"],[548070,548340,"경우"],[548930,549340,"아무리"],[549810,550300,"레이턴트"],[550300,550800,"스페이스의"],[550800,551040,"유저"],[551390,551660,"포를"],[551660,552120,"표현한다"],[552120,552560,"하더라도"]],"textEdited":"즉 새로운 유저 유저 포를 이 스페이스에 표현할 때 모순이 발생하는 거죠. 유저 원과 가깝게 표현을 하게 되는 경우 아무리 레이턴트 스페이스의 유저 포를 표현한다 하더라도"},{"start":553000,"end":566800,"text":"벡터를 유저 2에 비해 유저 3에 가깝게 놓을 수 없다는 것입니다. 이러한 상황에서 기존의 매트리스 팩터 라이제이션의 연산인 닷 프로덕트는 리니어 하기 때문에 최종 예측을 수행할 때 유저 4에 대해서는","confidence":0.9527,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[553310,553760,"벡터를"],[553790,554080,"유저"],[554230,554560,"2에"],[554560,554780,"비해"],[554780,555020,"유저"],[555050,555400,"3에"],[555410,555687,"가깝게"],[555687,555880,"놓을"],[555910,556060,"수"],[556060,556334,"없다는"],[556334,556740,"것입니다."],[557150,557420,"이러한"],[557450,557840,"상황에서"],[558010,558320,"기존의"],[558320,558660,"매트리스"],[558670,558960,"팩터"],[559430,560020,"라이제이션의"],[560030,560420,"연산인"],[560750,560900,"닷"],[560950,561400,"프로덕트는"],[561410,561694,"리니어"],[561694,561847,"하기"],[561847,562220,"때문에"],[563070,563320,"최종"],[563320,563660,"예측을"],[563670,564020,"수행할"],[564050,564200,"때"],[565190,565460,"유저"],[565470,565727,"4에"],[565727,566180,"대해서는"]],"textEdited":"벡터를 유저 2에 비해 유저 3에 가깝게 놓을 수 없다는 것입니다. 이러한 상황에서 기존의 매트리스 팩터 라이제이션의 연산인 닷 프로덕트는 리니어 하기 때문에 최종 예측을 수행할 때 유저 4에 대해서는"},{"start":566800,"end":581500,"text":"유저 2보다는 유저 3와 비슷한 예측 값을 갖게 할 수는 없습니다. 즉 매트리스 팩토라이제이션 모델을 사용해서 예측을 할 경우 항상 유저 4와 유저 3의 평점보다는 유저 4와 유저 2의 평점이 더 비슷하게 추론된다는 것이죠.","confidence":0.9171,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[567090,567360,"유저"],[567370,567920,"2보다는"],[567920,568140,"유저"],[568150,568520,"3와"],[569030,569400,"비슷한"],[569510,569740,"예측"],[569740,570060,"값을"],[570150,570440,"갖게"],[570450,570600,"할"],[570600,570800,"수는"],[570800,571220,"없습니다."],[571650,571800,"즉"],[571950,572287,"매트리스"],[572287,572840,"팩토라이제이션"],[572870,573200,"모델을"],[573200,573620,"사용해서"],[574010,574380,"예측을"],[574380,574500,"할"],[574510,574740,"경우"],[575030,575280,"항상"],[575750,576040,"유저"],[576090,576380,"4와"],[576430,576607,"유저"],[576607,576860,"3의"],[577090,577600,"평점보다는"],[577610,577840,"유저"],[577840,578060,"4와"],[578060,578260,"유저"],[578290,578560,"2의"],[578630,578960,"평점이"],[578960,579100,"더"],[579630,580080,"비슷하게"],[580550,581100,"추론된다는"],[581100,581400,"것이죠."]],"textEdited":"유저 2보다는 유저 3와 비슷한 예측 값을 갖게 할 수는 없습니다. 즉 매트리스 팩토라이제이션 모델을 사용해서 예측을 할 경우 항상 유저 4와 유저 3의 평점보다는 유저 4와 유저 2의 평점이 더 비슷하게 추론된다는 것이죠."},{"start":581500,"end":591600,"text":"네 그래서 새로운 유저 4를 설명하는 벡터 즉 p4는 어떻게 해도 유저 2에 비해서 유저 3에 가깝게 놓을 수가 없습니다.","confidence":0.967,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[581750,581900,"네"],[581930,582220,"그래서"],[582830,583160,"새로운"],[583250,583500,"유저"],[583570,583880,"4를"],[584010,584420,"설명하는"],[584510,584820,"벡터"],[585030,585180,"즉"],[585310,586120,"p4는"],[587190,587620,"어떻게"],[587670,587920,"해도"],[588370,588660,"유저"],[588690,588967,"2에"],[588967,589300,"비해서"],[589330,589560,"유저"],[589610,589980,"3에"],[590010,590360,"가깝게"],[590360,590540,"놓을"],[590590,590820,"수가"],[591030,591480,"없습니다."]],"textEdited":"네 그래서 새로운 유저 4를 설명하는 벡터 즉 p4는 어떻게 해도 유저 2에 비해서 유저 3에 가깝게 놓을 수가 없습니다."},{"start":591600,"end":604400,"text":"이제 이러한 상황에서 기존의 매트릭스 팩토라이제이션의 연산인 닷 프로덕트는 리니어한 연산이기 때문에 최종 예측을 할 때에도 항상 유저 4는 유저 3보다 유저 2에 가깝게 예측이 됩니다.","confidence":0.9633,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[591870,592060,"이제"],[592090,592380,"이러한"],[592430,592820,"상황에서"],[593410,593720,"기존의"],[593730,594100,"매트릭스"],[594110,594900,"팩토라이제이션의"],[594900,595320,"연산인"],[595450,595600,"닷"],[595650,596180,"프로덕트는"],[596490,596920,"리니어한"],[596950,597347,"연산이기"],[597347,597700,"때문에"],[598150,598400,"최종"],[598410,598800,"예측을"],[598810,598960,"할"],[598960,599320,"때에도"],[599410,599680,"항상"],[600310,600560,"유저"],[600570,600880,"4는"],[601350,601620,"유저"],[601630,602060,"3보다"],[602070,602320,"유저"],[602350,602660,"2에"],[603250,603680,"가깝게"],[603730,604027,"예측이"],[604027,604400,"됩니다."]],"textEdited":"이제 이러한 상황에서 기존의 매트릭스 팩토라이제이션의 연산인 닷 프로덕트는 리니어한 연산이기 때문에 최종 예측을 할 때에도 항상 유저 4는 유저 3보다 유저 2에 가깝게 예측이 됩니다."},{"start":604400,"end":617000,"text":"실제로는 유저 4와 유저 3가 더 비슷함에도 불구하고 항상 예측을 할 때는 유저 3보다는 유저 2에 더 가깝게 평점이 구해진다는 것이죠. 그래서 이러한 문제를 해결하기 위해서는","confidence":0.9575,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[604810,605340,"실제로는"],[605870,606140,"유저"],[606170,606460,"4와"],[606460,606647,"유저"],[606647,606940,"3가"],[606940,607060,"더"],[607170,607700,"비슷함에도"],[607700,608140,"불구하고"],[608390,608640,"항상"],[608670,609020,"예측을"],[609020,609160,"할"],[609160,609400,"때는"],[610010,610280,"유저"],[610370,610980,"3보다는"],[610990,611220,"유저"],[611270,611580,"2에"],[611580,611720,"더"],[611790,612200,"가깝게"],[613170,613580,"평점이"],[613590,614067,"구해진다는"],[614067,614380,"것이죠."],[614890,615120,"그래서"],[615130,615400,"이러한"],[615470,615780,"문제를"],[615780,616140,"해결하기"],[616140,616560,"위해서는"]],"textEdited":"실제로는 유저 4와 유저 3가 더 비슷함에도 불구하고 항상 예측을 할 때는 유저 3보다는 유저 2에 더 가깝게 평점이 구해진다는 것이죠. 그래서 이러한 문제를 해결하기 위해서는"},{"start":617000,"end":631100,"text":"매트리스 팩토라이제이션의 레이턴트 스페이스 차원을 다음과 같은 2차원이 아니라 더 큰 차원으로 크게 해서 이 유사도 표현의 문제를 해결할 수 있습니다. 하지만 이제 계속해서 그렇게 차원을 늘려갈 경우에 오버피팅 문제가 발생합니다. 따라서","confidence":0.9413,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[617190,617580,"매트리스"],[617580,618260,"팩토라이제이션의"],[618260,618614,"레이턴트"],[618614,618980,"스페이스"],[618990,619340,"차원을"],[619790,620074,"다음과"],[620074,620260,"같은"],[620270,620680,"2차원이"],[620680,620940,"아니라"],[621070,621220,"더"],[621950,622100,"큰"],[622210,622600,"차원으로"],[622630,622827,"크게"],[622827,623040,"해서"],[623530,623647,"이"],[623647,623960,"유사도"],[623960,624240,"표현의"],[624240,624480,"문제를"],[624480,624707,"해결할"],[624707,624794,"수"],[624794,625160,"있습니다."],[625430,625720,"하지만"],[625770,625940,"이제"],[626110,626560,"계속해서"],[626560,626740,"그렇게"],[626790,627100,"차원을"],[627100,627440,"늘려갈"],[627450,627780,"경우에"],[628350,628860,"오버피팅"],[628870,629160,"문제가"],[629190,629700,"발생합니다."],[630150,630500,"따라서"]],"textEdited":"매트리스 팩토라이제이션의 레이턴트 스페이스 차원을 다음과 같은 2차원이 아니라 더 큰 차원으로 크게 해서 이 유사도 표현의 문제를 해결할 수 있습니다. 하지만 이제 계속해서 그렇게 차원을 늘려갈 경우에 오버피팅 문제가 발생합니다. 따라서"},{"start":631100,"end":644800,"text":"이 뉴럴 컬라버레이팅 필터링 논문은 차원을 계속해서 크게 문제를 해결하는 것이 아니라 이 모델 자체에 논리니어한 표현을 추가하여서 이 문제를 해결하고 싶었고 그래서 이 엠엘피 레이어를 추가하게 되었습니다.","confidence":0.9022,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[631330,631480,"이"],[631480,631740,"뉴럴"],[631790,632220,"컬라버레이팅"],[632270,632600,"필터링"],[632610,632980,"논문은"],[633270,633620,"차원을"],[633620,633920,"계속해서"],[633930,634140,"크게"],[634170,634407,"문제를"],[634407,634707,"해결하는"],[634707,634880,"것이"],[634880,635120,"아니라"],[635870,636020,"이"],[636090,636360,"모델"],[636450,636860,"자체에"],[636970,637720,"논리니어한"],[637790,638100,"표현을"],[638150,639240,"추가하여서"],[640170,640320,"이"],[640320,640527,"문제를"],[640527,640840,"해결하고"],[640840,641200,"싶었고"],[641810,642080,"그래서"],[642210,642360,"이"],[642370,642800,"엠엘피"],[642830,643480,"레이어를"],[643770,644200,"추가하게"],[644200,644780,"되었습니다."]],"textEdited":"이 뉴럴 컬라버레이팅 필터링 논문은 차원을 계속해서 크게 문제를 해결하는 것이 아니라 이 모델 자체에 논리니어한 표현을 추가하여서 이 문제를 해결하고 싶었고 그래서 이 엠엘피 레이어를 추가하게 되었습니다."},{"start":644800,"end":654700,"text":"네 다음 페이지는 이 뉴럴 컬라버레이트 필터링에 새로 추가된 MLP 파트 부분입니다. 그래서 아래에 있는 레이어부터 위로 아웃풋 레이어까지","confidence":0.8799,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[645090,645240,"네"],[645270,645580,"다음"],[645830,646280,"페이지는"],[646470,646620,"이"],[646620,646900,"뉴럴"],[646990,647420,"컬라버레이트"],[647430,648120,"필터링에"],[648290,648520,"새로"],[648570,648940,"추가된"],[649610,650020,"MLP"],[650070,650380,"파트"],[650470,651000,"부분입니다."],[651190,651380,"그래서"],[651430,651740,"아래에"],[651740,651900,"있는"],[652030,652580,"레이어부터"],[652850,653240,"위로"],[653410,653760,"아웃풋"],[653850,654440,"레이어까지"]],"textEdited":"네 다음 페이지는 이 뉴럴 컬라버레이트 필터링에 새로 추가된 MLP 파트 부분입니다. 그래서 아래에 있는 레이어부터 위로 아웃풋 레이어까지"},{"start":654700,"end":666600,"text":"쭉 설명을 드리겠습니다. 먼저 인플레이어는 유저와 아이템에 대한 원핫 인코딩 벡터로 표현이 됩니다. 이제 여기서 유저 레이턴트 벡터 즉 인베딩 매트릭스를 통하여서 각각의 유저와 아이템이","confidence":0.9641,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[654970,655120,"쭉"],[655150,655480,"설명을"],[655480,656040,"드리겠습니다."],[656350,656600,"먼저"],[656650,657360,"인플레이어는"],[657510,657900,"유저와"],[657990,658387,"아이템에"],[658387,658600,"대한"],[658790,659100,"원핫"],[659210,659600,"인코딩"],[659610,660000,"벡터로"],[660010,660274,"표현이"],[660274,660580,"됩니다."],[660910,661080,"이제"],[661130,661440,"여기서"],[662030,662260,"유저"],[662260,662640,"레이턴트"],[662650,662940,"벡터"],[663070,663220,"즉"],[663330,663760,"인베딩"],[663810,664300,"매트릭스를"],[664300,664700,"통하여서"],[664970,665440,"각각의"],[665490,665840,"유저와"],[665890,666380,"아이템이"]],"textEdited":"쭉 설명을 드리겠습니다. 먼저 인플레이어는 유저와 아이템에 대한 원핫 인코딩 벡터로 표현이 됩니다. 이제 여기서 유저 레이턴트 벡터 즉 인베딩 매트릭스를 통하여서 각각의 유저와 아이템이"},{"start":666600,"end":674800,"text":"어떤 댄스한 형태의 인베딩으로 표현이 됩니다. 그 이후에 뉴럴 콜라보레이트 레이어라고 하는 일반적인 MLP 레이어","confidence":0.8806,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[666890,667120,"어떤"],[667230,667900,"댄스한"],[668010,668440,"형태의"],[668830,669360,"인베딩으로"],[669370,669634,"표현이"],[669634,669920,"됩니다."],[670010,670160,"그"],[670170,670500,"이후에"],[670970,671280,"뉴럴"],[671370,671900,"콜라보레이트"],[671910,672400,"레이어라고"],[672410,672620,"하는"],[673270,673740,"일반적인"],[673790,674140,"MLP"],[674150,674460,"레이어"]],"textEdited":"어떤 댄스한 형태의 인베딩으로 표현이 됩니다. 그 이후에 뉴럴 콜라보레이트 레이어라고 하는 일반적인 MLP 레이어"},{"start":674800,"end":688900,"text":"로 들어가게 되는데요. 각각의 유저 레이턴트 팩터, 아이템 레이턴트 팩터를 구한 이후에 이 둘을 컨캐이 네이트 해서 첫 번째 레이어를 만들어 주게 되고 이 레이어를 계속해서 쌓아 나가서 피드 포워드 유뉴널 네트워크의 형태로","confidence":0.8726,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[675030,675180,"로"],[675230,675547,"들어가게"],[675547,675960,"되는데요."],[676630,677000,"각각의"],[677030,677320,"유저"],[677410,677860,"레이턴트"],[677870,678160,"팩터,"],[678170,678460,"아이템"],[678490,678840,"레이턴트"],[678840,679140,"팩터를"],[679170,679420,"구한"],[679450,679760,"이후에"],[679990,680140,"이"],[680140,680380,"둘을"],[680850,681200,"컨캐이"],[681230,681580,"네이트"],[682290,682540,"해서"],[683070,683220,"첫"],[683230,683460,"번째"],[683470,683800,"레이어를"],[683800,684027,"만들어"],[684027,684207,"주게"],[684207,684480,"되고"],[684910,685060,"이"],[685070,685480,"레이어를"],[685510,685920,"계속해서"],[686050,686300,"쌓아"],[686300,686620,"나가서"],[686910,687140,"피드"],[687140,687320,"포워드"],[687320,687620,"유뉴널"],[687630,688380,"네트워크의"],[688410,688740,"형태로"]],"textEdited":"로 들어가게 되는데요. 각각의 유저 레이턴트 팩터, 아이템 레이턴트 팩터를 구한 이후에 이 둘을 컨캐이 네이트 해서 첫 번째 레이어를 만들어 주게 되고 이 레이어를 계속해서 쌓아 나가서 피드 포워드 유뉴널 네트워크의 형태로"},{"start":688900,"end":703800,"text":"스겔의 레이어까지 쌓아주게 됩니다. 그리고 마지막 레이어 스에서 최종적으로 두 유저와 아이템에 대한 레이팅과의 차이 값 y 햇을 구해주게 됩니다. 그래서 이 논문에서는 타겟을 0 또는 1","confidence":0.8779,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[689330,689920,"스겔의"],[689970,690520,"레이어까지"],[690530,690927,"쌓아주게"],[690927,691240,"됩니다."],[691530,691820,"그리고"],[692070,692440,"마지막"],[692650,692900,"레이어"],[693190,693600,"스에서"],[693890,694480,"최종적으로"],[694790,694940,"두"],[695010,695360,"유저와"],[695430,695940,"아이템에"],[695940,696120,"대한"],[696190,697400,"레이팅과의"],[697450,697680,"차이"],[697680,697820,"값"],[698350,698500,"y"],[698550,698860,"햇을"],[699730,700160,"구해주게"],[700160,700460,"됩니다."],[700790,700974,"그래서"],[700974,701100,"이"],[701100,701680,"논문에서는"],[701890,702320,"타겟을"],[702650,702800,"0"],[702930,703180,"또는"],[703250,703400,"1"]],"textEdited":"스겔의 레이어까지 쌓아주게 됩니다. 그리고 마지막 레이어 스에서 최종적으로 두 유저와 아이템에 대한 레이팅과의 차이 값 y 햇을 구해주게 됩니다. 그래서 이 논문에서는 타겟을 0 또는 1"},{"start":703800,"end":715600,"text":"를 예측하는 형태로 구성했는데요. 그래서 마지막 레이어의 액티베이션 펑션은 로지스틱이나 프로빗 함수를 사용했다고 말합니다. 네 그래서 방금 설명했던 MLP 레이어가 이 우측에 들어가고요.","confidence":0.9587,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[704090,704240,"를"],[704250,704720,"예측하는"],[704850,705180,"형태로"],[705180,705720,"구성했는데요."],[706290,706540,"그래서"],[706590,706920,"마지막"],[707170,707540,"레이어의"],[707570,708060,"액티베이션"],[708110,708480,"펑션은"],[708650,709260,"로지스틱이나"],[709290,709580,"프로빗"],[709750,710047,"함수를"],[710047,710600,"사용했다고"],[710690,711120,"말합니다."],[711870,712020,"네"],[712020,712260,"그래서"],[712370,712580,"방금"],[712610,713120,"설명했던"],[713710,714100,"MLP"],[714100,714460,"레이어가"],[714510,714660,"이"],[714710,715100,"우측에"],[715100,715540,"들어가고요."]],"textEdited":"를 예측하는 형태로 구성했는데요. 그래서 마지막 레이어의 액티베이션 펑션은 로지스틱이나 프로빗 함수를 사용했다고 말합니다. 네 그래서 방금 설명했던 MLP 레이어가 이 우측에 들어가고요."},{"start":715600,"end":725800,"text":"이 좌측에 있는 것은 기존에 우리가 4강에서 배웠던 매트리스 팩토라이제이션을 조금 더 일반화한 형태의 표현입니다. 그래서 그림을 보시면 좌측에 있는","confidence":0.9686,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[715850,716000,"이"],[716010,716440,"좌측에"],[716450,716660,"있는"],[716670,716960,"것은"],[717410,717800,"기존에"],[717870,718100,"우리가"],[718190,718700,"4강에서"],[718700,718980,"배웠던"],[719030,719420,"매트리스"],[719420,720340,"팩토라이제이션을"],[720810,721040,"조금"],[721040,721180,"더"],[721210,721680,"일반화한"],[721770,722100,"형태의"],[722100,722580,"표현입니다."],[723070,723340,"그래서"],[723790,724100,"그림을"],[724110,724420,"보시면"],[724810,725280,"좌측에"],[725290,725500,"있는"]],"textEdited":"이 좌측에 있는 것은 기존에 우리가 4강에서 배웠던 매트리스 팩토라이제이션을 조금 더 일반화한 형태의 표현입니다. 그래서 그림을 보시면 좌측에 있는"},{"start":725800,"end":738300,"text":"이 GMF 레이어 제너럴라이제이션 매트리스 팩토라이제이션 레이어는 유저 아이템을 각각 엠프 아이템과 엠프 유저 벡터로 인베딩한 뒤 이후에 이 둘을 엘레멘트 와이즈 프로덕트","confidence":0.786,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[726050,726200,"이"],[726790,727260,"GMF"],[727260,727520,"레이어"],[727890,728700,"제너럴라이제이션"],[729210,729527,"매트리스"],[729527,730020,"팩토라이제이션"],[730030,730400,"레이어는"],[730950,731220,"유저"],[731270,732100,"아이템을"],[732190,732520,"각각"],[732670,733020,"엠프"],[733030,733540,"아이템과"],[733550,733860,"엠프"],[733860,734080,"유저"],[734170,734540,"벡터로"],[734990,735420,"인베딩한"],[735430,735580,"뒤"],[735810,736120,"이후에"],[736490,736640,"이"],[736640,736880,"둘을"],[737030,737407,"엘레멘트"],[737407,737660,"와이즈"],[737660,738040,"프로덕트"]],"textEdited":"이 GMF 레이어 제너럴라이제이션 매트리스 팩토라이제이션 레이어는 유저 아이템을 각각 엠프 아이템과 엠프 유저 벡터로 인베딩한 뒤 이후에 이 둘을 엘레멘트 와이즈 프로덕트"},{"start":738300,"end":752900,"text":"해서 GMF 값을 구해줍니다. 그리고 이 오른쪽에 있는 부분은 방금 설명했던 것처럼 MLP 인베딩과 MLP 아이템 인베딩을 사용하여서 컨케이트네이트를 시켜주고 그 위로 fed for NA 네트워크를 쌓아줍니다. 그래서 각각의 레이어의 아웃풋을","confidence":0.8235,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[738630,738860,"해서"],[739030,739460,"GMF"],[739460,739720,"값을"],[739720,740180,"구해줍니다."],[740450,740720,"그리고"],[741150,741300,"이"],[741300,741627,"오른쪽에"],[741627,741780,"있는"],[741780,742080,"부분은"],[742190,742380,"방금"],[742410,742860,"설명했던"],[742860,743200,"것처럼"],[743690,744160,"MLP"],[744350,744860,"인베딩과"],[745250,745640,"MLP"],[745640,745940,"아이템"],[745950,746360,"인베딩을"],[746360,746840,"사용하여서"],[747130,747860,"컨케이트네이트를"],[747860,748280,"시켜주고"],[748670,748820,"그"],[748820,749040,"위로"],[749090,749340,"fed"],[749340,749474,"for"],[749474,749720,"NA"],[749720,750160,"네트워크를"],[750160,750660,"쌓아줍니다."],[750750,750940,"그래서"],[751010,751420,"각각의"],[751830,752180,"레이어의"],[752180,752660,"아웃풋을"]],"textEdited":"해서 GMF 값을 구해줍니다. 그리고 이 오른쪽에 있는 부분은 방금 설명했던 것처럼 MLP 인베딩과 MLP 아이템 인베딩을 사용하여서 컨케이트네이트를 시켜주고 그 위로 fed for NA 네트워크를 쌓아줍니다. 그래서 각각의 레이어의 아웃풋을"},{"start":752900,"end":766300,"text":"마지막에 컨케이트네이트 해줘서 이 최종적인 뉴럴 매트리스 팩토라이제이션 레이어를 가지고 마지막 타겟 값과 y 햇을 구해서 이 둘을 최대한 비슷하게 예측되도록 모델을 학습하는 것입니다.","confidence":0.9151,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[753190,753640,"마지막에"],[753730,754420,"컨케이트네이트"],[754420,754720,"해줘서"],[754990,755140,"이"],[755170,755620,"최종적인"],[755650,755920,"뉴럴"],[756610,756927,"매트리스"],[756927,757520,"팩토라이제이션"],[757570,758020,"레이어를"],[758030,758420,"가지고"],[758890,759220,"마지막"],[759930,760240,"타겟"],[760240,760560,"값과"],[761190,761340,"y"],[761410,761700,"햇을"],[761700,762020,"구해서"],[762190,762340,"이"],[762340,762640,"둘을"],[763190,763480,"최대한"],[763770,764220,"비슷하게"],[764610,765160,"예측되도록"],[765270,765560,"모델을"],[765560,765887,"학습하는"],[765887,766300,"것입니다."]],"textEdited":"마지막에 컨케이트네이트 해줘서 이 최종적인 뉴럴 매트리스 팩토라이제이션 레이어를 가지고 마지막 타겟 값과 y 햇을 구해서 이 둘을 최대한 비슷하게 예측되도록 모델을 학습하는 것입니다."},{"start":766300,"end":776300,"text":"그래서 이 두 개의 모델을 이렇게 따로따로 구성하는 이유는 각각의 모델의 장점을 살리고 단점을 보완하기 위한 일종의 앙상블 효과를 내기 위함인데요.","confidence":0.9581,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[766770,767040,"그래서"],[767530,767680,"이"],[767730,767880,"두"],[767880,768080,"개의"],[768080,768400,"모델을"],[768400,768640,"이렇게"],[768990,769380,"따로따로"],[769390,769800,"구성하는"],[769810,770120,"이유는"],[770590,771080,"각각의"],[771110,771440,"모델의"],[771530,771980,"장점을"],[772030,772360,"살리고"],[772430,772820,"단점을"],[772850,773247,"보완하기"],[773247,773440,"위한"],[773570,773920,"일종의"],[774370,774820,"앙상블"],[774870,775167,"효과를"],[775167,775380,"내기"],[775380,776180,"위함인데요."]],"textEdited":"그래서 이 두 개의 모델을 이렇게 따로따로 구성하는 이유는 각각의 모델의 장점을 살리고 단점을 보완하기 위한 일종의 앙상블 효과를 내기 위함인데요."},{"start":776300,"end":789200,"text":"한 가지 특이한 점은 매트릭스 팩토라이제이션의 유저 인베딩과 엠엘피의 유저 인베딩은 다른 레이어를 사용했다는 것입니다. 그래서 수식으로 표현하면은 이 부분이 제널라이즈 매트릭스 팩토라이제이션 레이어이고요.","confidence":0.8409,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[776690,776794,"한"],[776794,776980,"가지"],[777010,777300,"특이한"],[777300,777560,"점은"],[778150,778540,"매트릭스"],[778550,779400,"팩토라이제이션의"],[779400,779600,"유저"],[779690,780260,"인베딩과"],[780450,781000,"엠엘피의"],[781000,781220,"유저"],[781250,781720,"인베딩은"],[781870,782160,"다른"],[782290,782680,"레이어를"],[782680,783147,"사용했다는"],[783147,783560,"것입니다."],[783850,784040,"그래서"],[784040,784380,"수식으로"],[784380,784880,"표현하면은"],[785070,785220,"이"],[785220,785540,"부분이"],[786390,786960,"제널라이즈"],[786990,787360,"매트릭스"],[787360,787920,"팩토라이제이션"],[787930,788780,"레이어이고요."]],"textEdited":"한 가지 특이한 점은 매트릭스 팩토라이제이션의 유저 인베딩과 엠엘피의 유저 인베딩은 다른 레이어를 사용했다는 것입니다. 그래서 수식으로 표현하면은 이 부분이 제널라이즈 매트릭스 팩토라이제이션 레이어이고요."},{"start":789200,"end":803900,"text":"이 밑에 있는 부분은 엠엘피 레이어가 됩니다. 그리고 이 둘의 아웃풋을 컨케이트네이트에서 최종적으로 시그모이드 펑션을 통해서 마지막 아웃풋을 예측해 주었습니다. 다음은 제한 모델인 뉴럴 컬래버레이터 필터링 모델","confidence":0.8764,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[789430,789580,"이"],[789590,789827,"밑에"],[789827,790000,"있는"],[790000,790300,"부분은"],[790430,790820,"엠엘피"],[790820,791200,"레이어가"],[791200,791480,"됩니다."],[791670,791900,"그리고"],[791900,792040,"이"],[792090,792400,"둘의"],[792690,793180,"아웃풋을"],[793650,794500,"컨케이트네이트에서"],[794550,795100,"최종적으로"],[795850,796300,"시그모이드"],[796310,796640,"펑션을"],[796640,796920,"통해서"],[797090,797420,"마지막"],[798170,798740,"아웃풋을"],[798870,799240,"예측해"],[799240,799760,"주었습니다."],[800030,800360,"다음은"],[800630,800880,"제한"],[800930,801280,"모델인"],[801810,802080,"뉴럴"],[802190,802720,"컬래버레이터"],[802770,803160,"필터링"],[803330,803580,"모델"]],"textEdited":"이 밑에 있는 부분은 엠엘피 레이어가 됩니다. 그리고 이 둘의 아웃풋을 컨케이트네이트에서 최종적으로 시그모이드 펑션을 통해서 마지막 아웃풋을 예측해 주었습니다. 다음은 제한 모델인 뉴럴 컬래버레이터 필터링 모델"},{"start":803900,"end":816700,"text":"와 기존 모델의 성능을 비교한 결과입니다. 이제 비교 대상은 일반화된 매트릭스 팩토라이제이션 모델인 GMF 그리고 MLP만을 사용한 MLP 모델 그리고 이 두 모델을 앙상블안","confidence":0.9545,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[804310,804460,"와"],[804570,804800,"기존"],[804830,805180,"모델의"],[805250,805560,"성능을"],[805630,805960,"비교한"],[805990,806480,"결과입니다."],[806990,807160,"이제"],[807170,807420,"비교"],[807420,807800,"대상은"],[808750,809200,"일반화된"],[809350,809720,"매트릭스"],[809720,810320,"팩토라이제이션"],[810350,810660,"모델인"],[810930,811500,"GMF"],[811830,812120,"그리고"],[812550,813180,"MLP만을"],[813180,813480,"사용한"],[813570,813960,"MLP"],[813970,814220,"모델"],[814650,814860,"그리고"],[814860,815000,"이"],[815030,815180,"두"],[815330,815740,"모델을"],[815830,816320,"앙상블안"]],"textEdited":"와 기존 모델의 성능을 비교한 결과입니다. 이제 비교 대상은 일반화된 매트릭스 팩토라이제이션 모델인 GMF 그리고 MLP만을 사용한 MLP 모델 그리고 이 두 모델을 앙상블안"},{"start":816700,"end":830500,"text":"이 본 논문에서 제안하고 있는 뉴럴 매트리스 팩토라이제이션이라는 모델입니다. 그래서 뉴 MF가 제안 모델인데요. 결과를 보시면 이 빨간색이 이 본 모델에서 제안하는 두 가지","confidence":0.8783,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[816910,817060,"이"],[817270,817420,"본"],[817450,817860,"논문에서"],[817860,818300,"제안하고"],[818300,818520,"있는"],[819230,819520,"뉴럴"],[819570,819960,"매트리스"],[819960,820820,"팩토라이제이션이라는"],[820850,821360,"모델입니다."],[821710,821900,"그래서"],[822170,822320,"뉴"],[822950,823960,"MF가"],[824230,824480,"제안"],[824490,825020,"모델인데요."],[825670,826040,"결과를"],[826040,826360,"보시면"],[826710,826860,"이"],[826870,827460,"빨간색이"],[828050,828200,"이"],[828210,828360,"본"],[828410,828840,"모델에서"],[829290,829680,"제안하는"],[829770,829887,"두"],[829887,830200,"가지"]],"textEdited":"이 본 논문에서 제안하고 있는 뉴럴 매트리스 팩토라이제이션이라는 모델입니다. 그래서 뉴 MF가 제안 모델인데요. 결과를 보시면 이 빨간색이 이 본 모델에서 제안하는 두 가지"},{"start":830500,"end":841600,"text":"GMF와 MLP를 각각 사용을 합쳐서 사용한 모델입니다. 보시면 트레이닝 로스는 가장 낮으면서 이 무비렌즈 데이터에 대한 히트레이쇼나 엔디cg 성능은","confidence":0.6805,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[830730,831240,"GMF와"],[831240,831720,"MLP를"],[831810,832160,"각각"],[832270,832600,"사용을"],[832990,833400,"합쳐서"],[833530,833820,"사용한"],[833820,834260,"모델입니다."],[834430,834760,"보시면"],[834990,835320,"트레이닝"],[835330,835680,"로스는"],[835710,835940,"가장"],[836470,837100,"낮으면서"],[837590,837740,"이"],[837810,838280,"무비렌즈"],[838280,838687,"데이터에"],[838687,838880,"대한"],[839190,839940,"히트레이쇼나"],[840210,840720,"엔디cg"],[840830,841140,"성능은"]],"textEdited":"GMF와 MLP를 각각 사용을 합쳐서 사용한 모델입니다. 보시면 트레이닝 로스는 가장 낮으면서 이 무비렌즈 데이터에 대한 히트레이쇼나 엔디cg 성능은"},{"start":841600,"end":853600,"text":"좀 더 높음을 알 수 있죠. 그래서 결론적으로는 이 논문 자체가 성능 향상을 크게 보였고 굉장히 추천에 잘 사용된다라기보다는 이 논문은 MLP 레이어를","confidence":0.9099,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[841890,842007,"좀"],[842007,842140,"더"],[842140,842480,"높음을"],[842490,842640,"알"],[842640,842747,"수"],[842747,842980,"있죠."],[843490,843680,"그래서"],[844010,844740,"결론적으로는"],[845030,845180,"이"],[845190,845460,"논문"],[845550,845940,"자체가"],[846170,846440,"성능"],[846450,846740,"향상을"],[846770,847020,"크게"],[847850,848300,"보였고"],[848630,849000,"굉장히"],[849230,849600,"추천에"],[849600,849740,"잘"],[849750,851020,"사용된다라기보다는"],[851730,851880,"이"],[851880,852240,"논문은"],[852270,852700,"MLP"],[852710,853160,"레이어를"]],"textEdited":"좀 더 높음을 알 수 있죠. 그래서 결론적으로는 이 논문 자체가 성능 향상을 크게 보였고 굉장히 추천에 잘 사용된다라기보다는 이 논문은 MLP 레이어를"},{"start":853600,"end":864200,"text":"기존 매트리스 팩토라이제이션에 처음 추가했던 논문이고 그런 점에서 의의가 있습니다. 그래서 추천 모델에서도 이런 MLP레이어 즉 딥러닝적인 접근을 적용했을 때","confidence":0.8778,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[853950,854200,"기존"],[854250,854600,"매트리스"],[854600,855460,"팩토라이제이션에"],[855530,855760,"처음"],[855890,856400,"추가했던"],[856810,857280,"논문이고"],[857930,858120,"그런"],[858130,858420,"점에서"],[858420,858680,"의의가"],[858680,859040,"있습니다."],[859370,859560,"그래서"],[859570,859840,"추천"],[859840,860400,"모델에서도"],[860650,860820,"이런"],[860870,861500,"MLP레이어"],[861500,861640,"즉"],[861690,862260,"딥러닝적인"],[862310,862720,"접근을"],[863310,863800,"적용했을"],[863810,863960,"때"]],"textEdited":"기존 매트리스 팩토라이제이션에 처음 추가했던 논문이고 그런 점에서 의의가 있습니다. 그래서 추천 모델에서도 이런 MLP레이어 즉 딥러닝적인 접근을 적용했을 때"},{"start":864200,"end":875700,"text":"좋은 성능을 보인다라는 것을 처음 보여준 논문입니다. 다음 논문은 딥러닝을 활용한 추천 시스템에서 또 하나의 발자취를 남긴 논문인데요. 딥 뉴럴 네트워크 폴","confidence":0.9634,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[864470,864640,"좋은"],[864810,865100,"성능을"],[865100,865680,"보인다라는"],[865680,865940,"것을"],[866270,866500,"처음"],[866630,866980,"보여준"],[867290,867780,"논문입니다."],[868250,868500,"다음"],[868550,868940,"논문은"],[869670,870260,"딥러닝을"],[870290,870580,"활용한"],[870610,870840,"추천"],[870850,871320,"시스템에서"],[871350,871467,"또"],[871467,871720,"하나의"],[871770,872220,"발자취를"],[872220,872420,"남긴"],[872430,872940,"논문인데요."],[873950,874100,"딥"],[874470,874740,"뉴럴"],[874770,875240,"네트워크"],[875290,875440,"폴"]],"textEdited":"좋은 성능을 보인다라는 것을 처음 보여준 논문입니다. 다음 논문은 딥러닝을 활용한 추천 시스템에서 또 하나의 발자취를 남긴 논문인데요. 딥 뉴럴 네트워크 폴"},{"start":875700,"end":887600,"text":"유튜브 레코멘데이션스라는 이름입니다. 실제로 유튜브는 이 모델을 사용해서 유튜브 서비스의 추천을 제공하고 있다고 합니다. 근데 유튜브에는 셀 수 없을 만큼의 많은 추천 동영상이 존재합니다.","confidence":0.9103,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[876010,876360,"유튜브"],[876360,877420,"레코멘데이션스라는"],[877450,877900,"이름입니다."],[878130,878480,"실제로"],[878490,878980,"유튜브는"],[879230,879380,"이"],[879450,879820,"모델을"],[879830,880280,"사용해서"],[880950,881320,"유튜브"],[881330,881760,"서비스의"],[881790,882120,"추천을"],[882120,882480,"제공하고"],[882480,882760,"있다고"],[883070,883360,"합니다."],[883750,883920,"근데"],[883920,884480,"유튜브에는"],[884630,884780,"셀"],[884910,885060,"수"],[885060,885300,"없을"],[885330,885720,"만큼의"],[885750,885920,"많은"],[886110,886360,"추천"],[886370,886800,"동영상이"],[886830,887360,"존재합니다."]],"textEdited":"유튜브 레코멘데이션스라는 이름입니다. 실제로 유튜브는 이 모델을 사용해서 유튜브 서비스의 추천을 제공하고 있다고 합니다. 근데 유튜브에는 셀 수 없을 만큼의 많은 추천 동영상이 존재합니다."},{"start":887600,"end":900700,"text":"그래서 추천 시스템으로 볼 때도 어떤 서비스보다 가장 많은 유저와 아이템들이 있을 것입니다. 그래서 실제 추천을 적용할 때는 아래와 같은 세 가지의 문제를 해결해야 합니다. 먼저 스케일러빌리티","confidence":0.9668,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[887810,888060,"그래서"],[888150,888400,"추천"],[888430,889200,"시스템으로"],[889210,889360,"볼"],[889370,889640,"때도"],[890190,890480,"어떤"],[890570,891160,"서비스보다"],[891810,892060,"가장"],[892090,892260,"많은"],[892330,892660,"유저와"],[892670,893600,"아이템들이"],[893600,893780,"있을"],[893780,894220,"것입니다."],[894470,894720,"그래서"],[895190,895440,"실제"],[895450,895747,"추천을"],[895747,896060,"적용할"],[896060,896280,"때는"],[896610,896940,"아래와"],[896940,897160,"같은"],[897210,897360,"세"],[897360,897740,"가지의"],[897830,898260,"문제를"],[898450,898840,"해결해야"],[898840,899120,"합니다."],[899550,899780,"먼저"],[899810,900460,"스케일러빌리티"]],"textEdited":"그래서 추천 시스템으로 볼 때도 어떤 서비스보다 가장 많은 유저와 아이템들이 있을 것입니다. 그래서 실제 추천을 적용할 때는 아래와 같은 세 가지의 문제를 해결해야 합니다. 먼저 스케일러빌리티"},{"start":900700,"end":905200,"text":"계속해서 말을 하고 있긴 하지만 특히 유튜브 같은 경우에는 그 유저 아이템 수가","confidence":0.9728,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[900950,901340,"계속해서"],[901340,901580,"말을"],[901590,901800,"하고"],[901800,901960,"있긴"],[901960,902220,"하지만"],[902730,902980,"특히"],[902990,903340,"유튜브"],[903370,903574,"같은"],[903574,903940,"경우에는"],[904070,904220,"그"],[904220,904440,"유저"],[904470,904760,"아이템"],[904760,905000,"수가"]],"textEdited":"계속해서 말을 하고 있긴 하지만 특히 유튜브 같은 경우에는 그 유저 아이템 수가"},{"start":905200,"end":919600,"text":"다른 서비스에 비해서 압도적으로 더 많기 때문에 추천 모델을 학습하는 것도 중요하지만 이 학습한 모델을 효율적으로 서빙해야 합니다. 그리고 두 번째는 프레시니스인데요. 모델이 기존에 학습하고 있던 콘텐츠와 새로 업로드된 콘텐츠","confidence":0.9735,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[905450,905680,"다른"],[905710,906480,"서비스에"],[906480,906760,"비해서"],[906810,907187,"압도적으로"],[907187,907320,"더"],[907330,907640,"많기"],[907640,908020,"때문에"],[908410,908680,"추천"],[908690,909000,"모델을"],[909070,909467,"학습하는"],[909467,909700,"것도"],[909700,910160,"중요하지만"],[910310,910460,"이"],[910490,910820,"학습한"],[910850,911260,"모델을"],[911670,912200,"효율적으로"],[912210,912700,"서빙해야"],[912710,913000,"합니다."],[913230,913420,"그리고"],[913420,913540,"두"],[913540,913880,"번째는"],[913890,914720,"프레시니스인데요."],[915110,915580,"모델이"],[916170,916480,"기존에"],[916510,916927,"학습하고"],[916927,917120,"있던"],[917230,917960,"콘텐츠와"],[918050,918280,"새로"],[918330,918780,"업로드된"],[918870,919300,"콘텐츠"]],"textEdited":"다른 서비스에 비해서 압도적으로 더 많기 때문에 추천 모델을 학습하는 것도 중요하지만 이 학습한 모델을 효율적으로 서빙해야 합니다. 그리고 두 번째는 프레시니스인데요. 모델이 기존에 학습하고 있던 콘텐츠와 새로 업로드된 콘텐츠"},{"start":919600,"end":933100,"text":"를 적절하게 조합해야 한다는 것입니다. 과거에 굉장히 인기 있는 동영상만 계속해서 추천된다든지 혹은 새로운 영상은 하나도 추천이 안 된다든지 이런 경우에는 문제가 될 수 있습니다. 그래서 새로 업로드된 콘텐츠도 적절하게","confidence":0.9792,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[919870,920020,"를"],[920070,920480,"적절하게"],[920480,920887,"조합해야"],[920887,921147,"한다는"],[921147,921540,"것입니다."],[921790,922200,"과거에"],[922290,922560,"굉장히"],[922650,922920,"인기"],[922930,923120,"있는"],[923210,923700,"동영상만"],[923890,924280,"계속해서"],[924290,925040,"추천된다든지"],[925330,925540,"혹은"],[925670,925980,"새로운"],[926550,926900,"영상은"],[926990,927300,"하나도"],[927330,927580,"추천이"],[927580,927654,"안"],[927654,928100,"된다든지"],[928190,928380,"이런"],[928470,928880,"경우에는"],[928910,929220,"문제가"],[929220,929340,"될"],[929350,929440,"수"],[929440,929800,"있습니다."],[929950,930200,"그래서"],[930910,931180,"새로"],[931230,931600,"업로드된"],[931690,932200,"콘텐츠도"],[932270,932820,"적절하게"]],"textEdited":"를 적절하게 조합해야 한다는 것입니다. 과거에 굉장히 인기 있는 동영상만 계속해서 추천된다든지 혹은 새로운 영상은 하나도 추천이 안 된다든지 이런 경우에는 문제가 될 수 있습니다. 그래서 새로 업로드된 콘텐츠도 적절하게"},{"start":933100,"end":940000,"text":"익스플로레이션 하여서 과거에 인기 있는 동영상과 최근에 등장한 동영상이 적절하게 추천이 되어야 합니다.","confidence":0.9841,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[933430,934120,"익스플로레이션"],[934120,934460,"하여서"],[935050,935400,"과거에"],[935410,935607,"인기"],[935607,935780,"있는"],[935790,936300,"동영상과"],[936770,937080,"최근에"],[937110,937400,"등장한"],[937410,937900,"동영상이"],[938310,938760,"적절하게"],[938930,939254,"추천이"],[939254,939507,"되어야"],[939507,939900,"합니다."]],"textEdited":"익스플로레이션 하여서 과거에 인기 있는 동영상과 최근에 등장한 동영상이 적절하게 추천이 되어야 합니다."},{"start":940000,"end":954600,"text":"이제 이러한 기능을 단순하게 룰 베이스로만 해결하기엔 어려움이 있기 때문에 이런 프레시니스라는 정보도 모델이 표현할 수 있도록 모델을 설계하였습니다. 네 그리고 마지막으로 큰 노이즈에 대해서 모델이 잘 대응해야 하는데요.","confidence":0.941,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[940670,940840,"이제"],[940870,941160,"이러한"],[941490,941820,"기능을"],[941910,942360,"단순하게"],[942370,942520,"룰"],[942570,943100,"베이스로만"],[943110,943540,"해결하기엔"],[943540,943827,"어려움이"],[943827,943967,"있기"],[943967,944340,"때문에"],[944770,944940,"이런"],[945010,946220,"프레시니스라는"],[946410,946860,"정보도"],[947210,947640,"모델이"],[948550,948920,"표현할"],[948930,949047,"수"],[949047,949340,"있도록"],[949490,949780,"모델을"],[949790,950420,"설계하였습니다."],[950630,950780,"네"],[950850,951100,"그리고"],[951150,951580,"마지막으로"],[951930,952080,"큰"],[952130,952587,"노이즈에"],[952587,952880,"대해서"],[952930,953240,"모델이"],[953240,953360,"잘"],[953430,953840,"대응해야"],[953840,954200,"하는데요."]],"textEdited":"이제 이러한 기능을 단순하게 룰 베이스로만 해결하기엔 어려움이 있기 때문에 이런 프레시니스라는 정보도 모델이 표현할 수 있도록 모델을 설계하였습니다. 네 그리고 마지막으로 큰 노이즈에 대해서 모델이 잘 대응해야 하는데요."},{"start":954600,"end":959400,"text":"높은 스파 시티 즉 유저 아이템의 개수가 아주 많기 때문에 데이터는 굉장히 스파스해지고요.","confidence":0.9218,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[954910,955180,"높은"],[955230,955460,"스파"],[955510,955800,"시티"],[956010,956160,"즉"],[956210,956480,"유저"],[956530,956920,"아이템의"],[956920,957180,"개수가"],[957180,957340,"아주"],[957340,957580,"많기"],[957580,957900,"때문에"],[957950,958320,"데이터는"],[958320,958520,"굉장히"],[958520,959380,"스파스해지고요."]],"textEdited":"높은 스파 시티 즉 유저 아이템의 개수가 아주 많기 때문에 데이터는 굉장히 스파스해지고요."},{"start":959400,"end":970600,"text":"또 유튜브 서비스 같은 경우에는 다양한 외부 요인이 존재하기 때문에 단순히 좋아요나 구독과 같은 익스플리시 피드백만을 사용하게 되면은 유저의 행동을 예측하기 어렵습니다.","confidence":0.9737,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[959910,960060,"또"],[960060,960460,"유튜브"],[960630,960940,"서비스"],[960940,961134,"같은"],[961134,961420,"경우에는"],[961420,961720,"다양한"],[961730,961940,"외부"],[961940,962240,"요인이"],[962240,962627,"존재하기"],[962627,962980,"때문에"],[963730,964140,"단순히"],[964190,965020,"좋아요나"],[965090,965500,"구독과"],[965500,965760,"같은"],[966130,966680,"익스플리시"],[966710,967260,"피드백만을"],[967260,967800,"사용하게"],[967800,968140,"되면은"],[968830,969160,"유저의"],[969190,969460,"행동을"],[969590,969927,"예측하기"],[969927,970480,"어렵습니다."]],"textEdited":"또 유튜브 서비스 같은 경우에는 다양한 외부 요인이 존재하기 때문에 단순히 좋아요나 구독과 같은 익스플리시 피드백만을 사용하게 되면은 유저의 행동을 예측하기 어렵습니다."},{"start":970600,"end":983100,"text":"따라서 유저가 어떤 동영상을 봤다라는 정보인 인플리시 피드백 데이터를 잘 활용해야 되고 본다면 그 영상을 다 봤는지 적게 봤는지와 같은 형태로 데이터를 가공해서 사용해야 합니다.","confidence":0.9827,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[970990,971340,"따라서"],[972150,972480,"유저가"],[972510,972720,"어떤"],[972750,973120,"동영상을"],[973130,973740,"봤다라는"],[973830,974140,"정보인"],[974410,974880,"인플리시"],[974930,975240,"피드백"],[975270,975700,"데이터를"],[975700,975840,"잘"],[975890,976260,"활용해야"],[976260,976500,"되고"],[977150,977580,"본다면"],[977770,977920,"그"],[977920,978300,"영상을"],[978530,978680,"다"],[978730,979180,"봤는지"],[979190,979440,"적게"],[979450,980120,"봤는지와"],[980150,980420,"같은"],[980950,981280,"형태로"],[981530,981960,"데이터를"],[982010,982420,"가공해서"],[982430,982767,"사용해야"],[982767,983100,"합니다."]],"textEdited":"따라서 유저가 어떤 동영상을 봤다라는 정보인 인플리시 피드백 데이터를 잘 활용해야 되고 본다면 그 영상을 다 봤는지 적게 봤는지와 같은 형태로 데이터를 가공해서 사용해야 합니다."},{"start":983100,"end":993700,"text":"그래서 앞에서 언급한 이 세 가지 문제를 해결하기 위해서 유튜브는 이런 2단계의 추천 모델을 사용하였습니다. 이 부분이 본 논문에서 가장 핵심적인 부분 중의 하나인데요.","confidence":0.9383,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[983370,983600,"그래서"],[983600,983920,"앞에서"],[983950,984320,"언급한"],[984350,984467,"이"],[984467,984567,"세"],[984567,984800,"가지"],[984830,985180,"문제를"],[985180,985560,"해결하기"],[985560,985840,"위해서"],[986150,986640,"유튜브는"],[986830,987000,"이런"],[987670,988300,"2단계의"],[988430,988720,"추천"],[988750,989100,"모델을"],[989100,989800,"사용하였습니다."],[990570,990720,"이"],[990720,991020,"부분이"],[991020,991160,"본"],[991210,991620,"논문에서"],[991710,991960,"가장"],[992110,992580,"핵심적인"],[992630,992840,"부분"],[992850,993027,"중의"],[993027,993520,"하나인데요."]],"textEdited":"그래서 앞에서 언급한 이 세 가지 문제를 해결하기 위해서 유튜브는 이런 2단계의 추천 모델을 사용하였습니다. 이 부분이 본 논문에서 가장 핵심적인 부분 중의 하나인데요."},{"start":993700,"end":1007700,"text":"추천 시스템이 추구해야 하는 목표를 두 가지 모델에 나누어서 적용했습니다. 먼저 첫 번째는 캔디데이 제너레이션입니다. 엄청나게 많은 비디오가 있을 때 주어진 사용자에 대해서 탑 앤 추천 아이템을 생성합니다.","confidence":0.9057,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[994330,994600,"추천"],[994630,995040,"시스템이"],[995090,995500,"추구해야"],[995500,995660,"하는"],[995890,996260,"목표를"],[996350,996500,"두"],[996500,996740,"가지"],[996770,997087,"모델에"],[997087,997480,"나누어서"],[997510,998100,"적용했습니다."],[998650,998880,"먼저"],[998880,999020,"첫"],[999020,999320,"번째는"],[999370,999800,"캔디데이"],[999800,1000420,"제너레이션입니다."],[1001370,1001767,"엄청나게"],[1001767,1001940,"많은"],[1002030,1002440,"비디오가"],[1002440,1002660,"있을"],[1002670,1002820,"때"],[1003930,1004280,"주어진"],[1004330,1004820,"사용자에"],[1004820,1005160,"대해서"],[1005550,1005700,"탑"],[1005830,1005980,"앤"],[1006090,1006320,"추천"],[1006330,1006700,"아이템을"],[1006710,1007200,"생성합니다."]],"textEdited":"추천 시스템이 추구해야 하는 목표를 두 가지 모델에 나누어서 적용했습니다. 먼저 첫 번째는 캔디데이 제너레이션입니다. 엄청나게 많은 비디오가 있을 때 주어진 사용자에 대해서 탑 앤 추천 아이템을 생성합니다."},{"start":1007700,"end":1020000,"text":"탑 n개를 뭐 10개 정도로 생성하는 것이 아니라 헌드레즈 수백 개의 아이템으로 추려주는 형태가 먼저 캔디데이 제너레이션입니다. 그리고 그 캔디데이트들에 대해서 최종 랭킹","confidence":0.9294,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1008050,1008200,"탑"],[1008270,1008680,"n개를"],[1009210,1009360,"뭐"],[1009370,1009680,"10개"],[1009680,1009900,"정도로"],[1009900,1010247,"생성하는"],[1010247,1010414,"것이"],[1010414,1010680,"아니라"],[1011170,1011600,"헌드레즈"],[1012250,1012520,"수백"],[1012520,1012740,"개의"],[1012740,1013260,"아이템으로"],[1013430,1013840,"추려주는"],[1014110,1014460,"형태가"],[1014510,1014760,"먼저"],[1014890,1015227,"캔디데이"],[1015227,1015840,"제너레이션입니다."],[1016950,1017220,"그리고"],[1017390,1017540,"그"],[1017630,1018327,"캔디데이트들에"],[1018327,1018620,"대해서"],[1018770,1019060,"최종"],[1019130,1019500,"랭킹"]],"textEdited":"탑 n개를 뭐 10개 정도로 생성하는 것이 아니라 헌드레즈 수백 개의 아이템으로 추려주는 형태가 먼저 캔디데이 제너레이션입니다. 그리고 그 캔디데이트들에 대해서 최종 랭킹"},{"start":1020000,"end":1031000,"text":"수백 개의 아이템에 대해서 최종적으로 몇 개를 내보낼지 랭킹을 수행하여서 결과적으로는 십수 개의 추천 아이템을 생성해서 이를 유저에게 송출합니다.","confidence":0.9014,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1020250,1020560,"수백"],[1020560,1020760,"개의"],[1020760,1021127,"아이템에"],[1021127,1021460,"대해서"],[1022210,1022860,"최종적으로"],[1023090,1023240,"몇"],[1023250,1023520,"개를"],[1023520,1023980,"내보낼지"],[1024010,1024460,"랭킹을"],[1024490,1025000,"수행하여서"],[1025950,1026600,"결과적으로는"],[1027230,1027527,"십수"],[1027527,1027780,"개의"],[1027990,1028260,"추천"],[1028260,1028640,"아이템을"],[1028690,1029100,"생성해서"],[1029210,1029420,"이를"],[1029650,1030120,"유저에게"],[1030430,1030900,"송출합니다."]],"textEdited":"수백 개의 아이템에 대해서 최종적으로 몇 개를 내보낼지 랭킹을 수행하여서 결과적으로는 십수 개의 추천 아이템을 생성해서 이를 유저에게 송출합니다."},{"start":1031000,"end":1041400,"text":"이제 아이템이 수백 개에서 아니 수백만 개에서 수백 개로 줄어들었기 때문에 이 랭킹을 할 때는 더욱더 유저와 비디오의 피처를 더 풍부하게 사용하여서 랭킹의 정확도를","confidence":0.9656,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1031210,1031380,"이제"],[1031380,1031840,"아이템이"],[1031930,1032200,"수백"],[1032200,1032540,"개에서"],[1032930,1033100,"아니"],[1033150,1033560,"수백만"],[1033560,1033900,"개에서"],[1034150,1034387,"수백"],[1034387,1034620,"개로"],[1034620,1035100,"줄어들었기"],[1035100,1035460,"때문에"],[1035890,1036040,"이"],[1036070,1036480,"랭킹을"],[1036490,1036640,"할"],[1036640,1036880,"때는"],[1036930,1037380,"더욱더"],[1037430,1037800,"유저와"],[1037950,1038300,"비디오의"],[1038330,1038680,"피처를"],[1038680,1038800,"더"],[1038970,1039360,"풍부하게"],[1039360,1039900,"사용하여서"],[1040470,1040840,"랭킹의"],[1040850,1041280,"정확도를"]],"textEdited":"이제 아이템이 수백 개에서 아니 수백만 개에서 수백 개로 줄어들었기 때문에 이 랭킹을 할 때는 더욱더 유저와 비디오의 피처를 더 풍부하게 사용하여서 랭킹의 정확도를"},{"start":1041400,"end":1055000,"text":"높이는 방식을 사용하고 있습니다. 자 그러면 각 단계의 모델과 그 모델이 어떤 문제를 풀어야 하는지 하나씩 살펴봅시다. 첫 번째 테스크는 캔디데이트 제너레이션입니다. 여기서는 주어진 유저에 대해서","confidence":0.9546,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1041710,1042100,"높이는"],[1042190,1042520,"방식을"],[1042520,1042840,"사용하고"],[1042840,1043200,"있습니다."],[1043450,1043600,"자"],[1043610,1043860,"그러면"],[1043890,1044040,"각"],[1044170,1044600,"단계의"],[1044650,1045260,"모델과"],[1045470,1045620,"그"],[1045630,1045980,"모델이"],[1046110,1046360,"어떤"],[1046430,1046760,"문제를"],[1046810,1047120,"풀어야"],[1047120,1047480,"하는지"],[1047930,1048300,"하나씩"],[1048370,1048940,"살펴봅시다."],[1049210,1049360,"첫"],[1049370,1049600,"번째"],[1049610,1050060,"테스크는"],[1050590,1051240,"캔디데이트"],[1051290,1052100,"제너레이션입니다."],[1052670,1053140,"여기서는"],[1053530,1053900,"주어진"],[1053990,1054380,"유저에"],[1054380,1054700,"대해서"]],"textEdited":"높이는 방식을 사용하고 있습니다. 자 그러면 각 단계의 모델과 그 모델이 어떤 문제를 풀어야 하는지 하나씩 살펴봅시다. 첫 번째 테스크는 캔디데이트 제너레이션입니다. 여기서는 주어진 유저에 대해서"},{"start":1055000,"end":1067600,"text":"유저가 좋아할 만한 몇백 개의 비디오를 생성하는 테스크를 수행합니다. 그래서 이를 위해서 학습하는 모델이 풀어야 하는 문제는 바로 멀티 클래스 클래시피케이션입니다. 주어진","confidence":0.9673,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1055250,1055640,"유저가"],[1055690,1056014,"좋아할"],[1056014,1056260,"만한"],[1056550,1056900,"몇백"],[1056900,1057160,"개의"],[1057210,1057680,"비디오를"],[1057730,1058120,"생성하는"],[1058190,1059120,"테스크를"],[1059150,1059600,"수행합니다."],[1060570,1060780,"그래서"],[1060810,1061040,"이를"],[1061090,1061420,"위해서"],[1061610,1062100,"학습하는"],[1062130,1062440,"모델이"],[1062490,1062767,"풀어야"],[1062767,1062920,"하는"],[1062950,1063340,"문제는"],[1064030,1064240,"바로"],[1064250,1064560,"멀티"],[1064560,1064820,"클래스"],[1064890,1065980,"클래시피케이션입니다."],[1066510,1066940,"주어진"]],"textEdited":"유저가 좋아할 만한 몇백 개의 비디오를 생성하는 테스크를 수행합니다. 그래서 이를 위해서 학습하는 모델이 풀어야 하는 문제는 바로 멀티 클래스 클래시피케이션입니다. 주어진"},{"start":1067600,"end":1081200,"text":"유저가 어떤 특정 시간에 컨텍스트를 가지고 있을 때 각각의 비디오를 볼 확률을 계산하는 것인데요. 이제 이 비디오가 한 개가 아니라 수백만 개가 되기 때문에 수백만 개나 되는 비디오를 클래시피케이션 하는","confidence":0.9577,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1067950,1068340,"유저가"],[1068470,1068660,"어떤"],[1068790,1069060,"특정"],[1069090,1069400,"시간에"],[1069450,1070020,"컨텍스트를"],[1070020,1070280,"가지고"],[1070280,1070480,"있을"],[1070510,1070660,"때"],[1071470,1071820,"각각의"],[1071890,1072340,"비디오를"],[1072340,1072480,"볼"],[1072590,1073340,"확률을"],[1073340,1073740,"계산하는"],[1073740,1074140,"것인데요."],[1074890,1075060,"이제"],[1075070,1075220,"이"],[1075230,1075640,"비디오가"],[1075650,1075754,"한"],[1075754,1075900,"개가"],[1075900,1076140,"아니라"],[1076310,1076720,"수백만"],[1076720,1076960,"개가"],[1076960,1077160,"되기"],[1077160,1077500,"때문에"],[1077630,1078100,"수백만"],[1078130,1078900,"개나"],[1078900,1079100,"되는"],[1079170,1079640,"비디오를"],[1080010,1080640,"클래시피케이션"],[1080640,1080820,"하는"]],"textEdited":"유저가 어떤 특정 시간에 컨텍스트를 가지고 있을 때 각각의 비디오를 볼 확률을 계산하는 것인데요. 이제 이 비디오가 한 개가 아니라 수백만 개가 되기 때문에 수백만 개나 되는 비디오를 클래시피케이션 하는"},{"start":1081200,"end":1096000,"text":"즉 익스트림 멀티클래스 클래시피케이션이라고 볼 수 있습니다. 주어진 다양한 유저 벡터를 가지고 맨 마지막에 이 유저가 어떤 비디오를 볼 것인지에 대한 예측을 수행하는 것인데요. 그래서 마지막엔 결국 소프트맥스를 사용하는","confidence":0.9392,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1081410,1081560,"즉"],[1081670,1082080,"익스트림"],[1082150,1082700,"멀티클래스"],[1082890,1083740,"클래시피케이션이라고"],[1083740,1083860,"볼"],[1083860,1083954,"수"],[1083954,1084340,"있습니다."],[1085030,1085400,"주어진"],[1085650,1085940,"다양한"],[1085970,1086200,"유저"],[1086230,1086860,"벡터를"],[1086890,1087240,"가지고"],[1087630,1087780,"맨"],[1087850,1088280,"마지막에"],[1088330,1088480,"이"],[1088480,1088780,"유저가"],[1088930,1089200,"어떤"],[1089310,1089760,"비디오를"],[1089790,1089940,"볼"],[1090010,1090520,"것인지에"],[1090520,1090700,"대한"],[1091590,1091940,"예측을"],[1091940,1092247,"수행하는"],[1092247,1092700,"것인데요."],[1093090,1093280,"그래서"],[1093280,1093720,"마지막엔"],[1093730,1093960,"결국"],[1093990,1094840,"소프트맥스를"],[1095310,1095740,"사용하는"]],"textEdited":"즉 익스트림 멀티클래스 클래시피케이션이라고 볼 수 있습니다. 주어진 다양한 유저 벡터를 가지고 맨 마지막에 이 유저가 어떤 비디오를 볼 것인지에 대한 예측을 수행하는 것인데요. 그래서 마지막엔 결국 소프트맥스를 사용하는"},{"start":1096000,"end":1107800,"text":"수백만 개의 비디오 중에 하나의 비디오를 봤다라는 그 레이블을 예측해야 하는 멀티클래스 클래시피케이션 문제입니다. 그래서 먼저 이 모델이 사용하는 피처들 가운데 가장 중요한 피처는 바로","confidence":0.975,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1096330,1096687,"수백만"],[1096687,1096900,"개의"],[1096910,1097147,"비디오"],[1097147,1097380,"중에"],[1097710,1098000,"하나의"],[1098030,1098400,"비디오를"],[1098410,1098940,"봤다라는"],[1099210,1099360,"그"],[1099930,1100320,"레이블을"],[1100320,1100687,"예측해야"],[1100687,1100880,"하는"],[1101430,1101960,"멀티클래스"],[1101970,1102560,"클래시피케이션"],[1102630,1103140,"문제입니다."],[1103630,1103840,"그래서"],[1103840,1104100,"먼저"],[1104250,1104400,"이"],[1104410,1104720,"모델이"],[1104720,1105080,"사용하는"],[1105150,1105487,"피처들"],[1105487,1105840,"가운데"],[1106030,1106240,"가장"],[1106290,1106580,"중요한"],[1106630,1107000,"피처는"],[1107010,1107300,"바로"]],"textEdited":"수백만 개의 비디오 중에 하나의 비디오를 봤다라는 그 레이블을 예측해야 하는 멀티클래스 클래시피케이션 문제입니다. 그래서 먼저 이 모델이 사용하는 피처들 가운데 가장 중요한 피처는 바로"},{"start":1107800,"end":1122300,"text":"왓치 벡터와 서치 벡터 즉 과거에 유저가 어떤 시청 이력을 가지고 있는지 어떤 검색 이력을 가지고 있는지인데요. 이런 데이터는 사실 다른 추천 모델에서 잘 활용하지는 않았지만 이 유튜브 레코멘데이션에서는","confidence":0.9359,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1108750,1109080,"왓치"],[1109080,1109400,"벡터와"],[1109400,1109680,"서치"],[1109680,1109960,"벡터"],[1110650,1110800,"즉"],[1111230,1111620,"과거에"],[1111970,1112300,"유저가"],[1112430,1112680,"어떤"],[1112790,1113060,"시청"],[1113060,1113340,"이력을"],[1113340,1113587,"가지고"],[1113587,1113900,"있는지"],[1114010,1114280,"어떤"],[1114450,1114780,"검색"],[1114830,1115140,"이력을"],[1115150,1115460,"가지고"],[1115460,1116180,"있는지인데요."],[1117390,1117580,"이런"],[1117650,1118040,"데이터는"],[1118040,1118240,"사실"],[1118250,1118440,"다른"],[1118490,1118740,"추천"],[1118740,1119140,"모델에서"],[1119140,1119280,"잘"],[1119310,1119707,"활용하지는"],[1119707,1120080,"않았지만"],[1120290,1120440,"이"],[1120440,1120760,"유튜브"],[1120760,1121840,"레코멘데이션에서는"]],"textEdited":"왓치 벡터와 서치 벡터 즉 과거에 유저가 어떤 시청 이력을 가지고 있는지 어떤 검색 이력을 가지고 있는지인데요. 이런 데이터는 사실 다른 추천 모델에서 잘 활용하지는 않았지만 이 유튜브 레코멘데이션에서는"},{"start":1122300,"end":1135200,"text":"각각의 유저의 행동 데이터들을 이렇게 인베딩을 한 이후에 이 인베딩을 에버러지 해 가지고 결국 이 에버러지 된 와치 벡터와 서치 벡터를 수행해서 예측을 수행합니다.","confidence":0.9027,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1122650,1123100,"각각의"],[1123110,1123500,"유저의"],[1123870,1124140,"행동"],[1124150,1124720,"데이터들을"],[1125410,1125600,"이렇게"],[1125750,1126280,"인베딩을"],[1126290,1126440,"한"],[1126530,1126860,"이후에"],[1127450,1127600,"이"],[1127610,1128060,"인베딩을"],[1128110,1128560,"에버러지"],[1128560,1128680,"해"],[1128680,1129000,"가지고"],[1130190,1130420,"결국"],[1130420,1130560,"이"],[1130610,1131014,"에버러지"],[1131014,1131140,"된"],[1131250,1131660,"와치"],[1131730,1132080,"벡터와"],[1132090,1132400,"서치"],[1132400,1132780,"벡터를"],[1132830,1133240,"수행해서"],[1133970,1134340,"예측을"],[1134350,1135000,"수행합니다."]],"textEdited":"각각의 유저의 행동 데이터들을 이렇게 인베딩을 한 이후에 이 인베딩을 에버러지 해 가지고 결국 이 에버러지 된 와치 벡터와 서치 벡터를 수행해서 예측을 수행합니다."},{"start":1135200,"end":1146600,"text":"다만 마지막에 검색했던 검색어가 너무 큰 힘을 갖지 않도록 평균을 구했습니다. 그래서 과거의 시청 이력과 검색 이력이 잘 인베딩이 되었으면","confidence":0.9626,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1135910,1136140,"다만"],[1136210,1136740,"마지막에"],[1136770,1137340,"검색했던"],[1137630,1138027,"검색어가"],[1138027,1138200,"너무"],[1138270,1138420,"큰"],[1138470,1138700,"힘을"],[1138710,1138947,"갖지"],[1138947,1139280,"않도록"],[1139710,1140080,"평균을"],[1140170,1140700,"구했습니다."],[1142490,1142720,"그래서"],[1142770,1143120,"과거의"],[1143150,1143420,"시청"],[1143420,1143700,"이력과"],[1143710,1143980,"검색"],[1144090,1144440,"이력이"],[1144610,1144760,"잘"],[1144850,1145207,"인베딩이"],[1145207,1145660,"되었으면"]],"textEdited":"다만 마지막에 검색했던 검색어가 너무 큰 힘을 갖지 않도록 평균을 구했습니다. 그래서 과거의 시청 이력과 검색 이력이 잘 인베딩이 되었으면"},{"start":1146600,"end":1159200,"text":"이제 이 유저가 볼 만한 비디오를 클래시피케이션 할 때 유저가 과거에 뭐 스포츠 관련된 유튜브 동영상을 많이 봤을 경우에 스포츠 동영상이 분류될 확률이 더 높게 되겠죠","confidence":0.9297,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1146930,1147100,"이제"],[1147100,1147220,"이"],[1147220,1147540,"유저가"],[1148250,1148400,"볼"],[1148400,1148660,"만한"],[1148750,1149100,"비디오를"],[1149100,1149680,"클래시피케이션"],[1149680,1149820,"할"],[1149830,1149980,"때"],[1150430,1150760,"유저가"],[1150830,1151140,"과거에"],[1151170,1151320,"뭐"],[1151330,1151700,"스포츠"],[1151710,1152100,"관련된"],[1152790,1153120,"유튜브"],[1153410,1153787,"동영상을"],[1153787,1153960,"많이"],[1154010,1154720,"봤을"],[1154750,1155080,"경우에"],[1155510,1155980,"스포츠"],[1156010,1156500,"동영상이"],[1157070,1157420,"분류될"],[1157790,1158047,"확률이"],[1158047,1158180,"더"],[1158180,1158387,"높게"],[1158387,1158740,"되겠죠"]],"textEdited":"이제 이 유저가 볼 만한 비디오를 클래시피케이션 할 때 유저가 과거에 뭐 스포츠 관련된 유튜브 동영상을 많이 봤을 경우에 스포츠 동영상이 분류될 확률이 더 높게 되겠죠"},{"start":1159200,"end":1173900,"text":"다음은 데모 그래픽 지오 그래픽 피처입니다. 추천 시스템에서 유저 정보 가운데 많이 활용하는 정보가 바로 성별, 연령 혹은 지역과 같은 정보인데요. 이제 이러한 데이터는 적절한 방법으로 인베딩을 해서 사용하고 있고요.","confidence":0.95,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1160490,1160820,"다음은"],[1161230,1161480,"데모"],[1161490,1161820,"그래픽"],[1162010,1162240,"지오"],[1162240,1162480,"그래픽"],[1162530,1163000,"피처입니다."],[1163650,1163900,"추천"],[1163900,1164400,"시스템에서"],[1164770,1165040,"유저"],[1165130,1165420,"정보"],[1165810,1166067,"가운데"],[1166067,1166260,"많이"],[1166290,1166660,"활용하는"],[1166670,1166960,"정보가"],[1166970,1167180,"바로"],[1167250,1167500,"성별,"],[1167530,1167780,"연령"],[1167930,1168120,"혹은"],[1168210,1168580,"지역과"],[1168580,1168760,"같은"],[1168790,1169300,"정보인데요."],[1169970,1170140,"이제"],[1170140,1170400,"이러한"],[1170430,1170880,"데이터는"],[1171570,1171900,"적절한"],[1171910,1172240,"방법으로"],[1172250,1172647,"인베딩을"],[1172647,1172860,"해서"],[1172890,1173227,"사용하고"],[1173227,1173540,"있고요."]],"textEdited":"다음은 데모 그래픽 지오 그래픽 피처입니다. 추천 시스템에서 유저 정보 가운데 많이 활용하는 정보가 바로 성별, 연령 혹은 지역과 같은 정보인데요. 이제 이러한 데이터는 적절한 방법으로 인베딩을 해서 사용하고 있고요."},{"start":1173900,"end":1182200,"text":"그리고 또 중요한 피처가 바로 이 이그잼플 에이지라는 피처입니다. 이 아이템이 언제 생성됐는지에 대한","confidence":0.8954,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1174530,1174760,"그리고"],[1174760,1174900,"또"],[1174930,1175240,"중요한"],[1175290,1175640,"피처가"],[1175640,1175880,"바로"],[1175890,1176040,"이"],[1176070,1176520,"이그잼플"],[1176590,1177060,"에이지라는"],[1177090,1177580,"피처입니다."],[1178810,1178960,"이"],[1179030,1179500,"아이템이"],[1179670,1179960,"언제"],[1180110,1181340,"생성됐는지에"],[1181340,1181580,"대한"]],"textEdited":"그리고 또 중요한 피처가 바로 이 이그잼플 에이지라는 피처입니다. 이 아이템이 언제 생성됐는지에 대한"},{"start":1182200,"end":1195600,"text":"피처를 사용하지 않고 모델을 학습하게 되면 계속해서 과거에 인기 있던 데이터 위주로 편향이 되어서 학습이 됩니다. 따라서 이 시청 로그가 학습 시점으로부터 얼마나 경과했는지","confidence":0.9777,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1182450,1182800,"피처를"],[1182800,1183180,"사용하지"],[1183190,1183460,"않고"],[1183460,1183760,"모델을"],[1183760,1184094,"학습하게"],[1184094,1184320,"되면"],[1184870,1185340,"계속해서"],[1185510,1185960,"과거에"],[1186110,1186400,"인기"],[1186450,1186700,"있던"],[1186790,1187140,"데이터"],[1187490,1187800,"위주로"],[1187850,1188114,"편향이"],[1188114,1188420,"되어서"],[1188420,1188654,"학습이"],[1188654,1188980,"됩니다."],[1190150,1190480,"따라서"],[1191150,1191300,"이"],[1191370,1191660,"시청"],[1191670,1191980,"로그가"],[1193270,1193540,"학습"],[1193550,1194080,"시점으로부터"],[1194150,1194460,"얼마나"],[1194530,1195120,"경과했는지"]],"textEdited":"피처를 사용하지 않고 모델을 학습하게 되면 계속해서 과거에 인기 있던 데이터 위주로 편향이 되어서 학습이 됩니다. 따라서 이 시청 로그가 학습 시점으로부터 얼마나 경과했는지"},{"start":1195600,"end":1205200,"text":"즉 이 데이터가 최근 데이터인지 혹은 과거 데이터인지 그 정보를 이그젠플 에이지라는 값으로 구성하고 그래서","confidence":0.901,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1195830,1195980,"즉"],[1196190,1196340,"이"],[1196450,1196920,"데이터가"],[1197990,1198240,"최근"],[1198270,1198820,"데이터인지"],[1198820,1199000,"혹은"],[1199050,1199300,"과거"],[1199300,1200040,"데이터인지"],[1200710,1200860,"그"],[1201010,1201440,"정보를"],[1202370,1202800,"이그젠플"],[1202800,1203280,"에이지라는"],[1203290,1203660,"값으로"],[1203670,1204120,"구성하고"],[1204670,1204940,"그래서"]],"textEdited":"즉 이 데이터가 최근 데이터인지 혹은 과거 데이터인지 그 정보를 이그젠플 에이지라는 값으로 구성하고 그래서"},{"start":1205200,"end":1217900,"text":"과거 데이터의 경우에는 좀 덜 학습되게 그리고 최신 데이터의 경우에는 더 많이 학습될 수 있도록 이 피처를 예측의 인풋으로 사용해 주는 것입니다. 이렇게 해서 부트 스트래핑 현상은 방지하고","confidence":0.9281,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1205510,1205820,"과거"],[1205830,1206340,"데이터의"],[1206340,1206760,"경우에는"],[1206810,1206960,"좀"],[1207010,1207160,"덜"],[1207250,1207660,"학습되게"],[1207750,1207940,"그리고"],[1207950,1208240,"최신"],[1208240,1208720,"데이터의"],[1208720,1209040,"경우에는"],[1209040,1209160,"더"],[1209160,1209340,"많이"],[1209390,1209740,"학습될"],[1209770,1209887,"수"],[1209887,1210260,"있도록"],[1210970,1211120,"이"],[1211210,1211640,"피처를"],[1212130,1212520,"예측의"],[1212550,1212940,"인풋으로"],[1212940,1213187,"사용해"],[1213187,1213354,"주는"],[1213354,1213760,"것입니다."],[1214370,1214600,"이렇게"],[1214600,1214780,"해서"],[1215810,1216120,"부트"],[1216120,1216440,"스트래핑"],[1216490,1216800,"현상은"],[1216870,1217420,"방지하고"]],"textEdited":"과거 데이터의 경우에는 좀 덜 학습되게 그리고 최신 데이터의 경우에는 더 많이 학습될 수 있도록 이 피처를 예측의 인풋으로 사용해 주는 것입니다. 이렇게 해서 부트 스트래핑 현상은 방지하고"},{"start":1217900,"end":1227400,"text":"이 프레시니스 즉 새로운 동영상이 더 잘 추천될 수 있도록 모델을 변형한 것입니다. 네 그렇게 해서 유저가 과거에 봤던 왓치 벡터와 서치 벡터","confidence":0.9385,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1218110,1218260,"이"],[1218260,1218740,"프레시니스"],[1218810,1218960,"즉"],[1219030,1219340,"새로운"],[1219410,1219820,"동영상이"],[1219820,1219940,"더"],[1219990,1220140,"잘"],[1220230,1220580,"추천될"],[1220610,1220714,"수"],[1220714,1221040,"있도록"],[1221430,1221820,"모델을"],[1222430,1222800,"변형한"],[1222800,1223200,"것입니다."],[1223650,1223800,"네"],[1223800,1224060,"그렇게"],[1224060,1224280,"해서"],[1225050,1225400,"유저가"],[1225450,1225780,"과거에"],[1225790,1226080,"봤던"],[1226170,1226460,"왓치"],[1226460,1226760,"벡터와"],[1226760,1227020,"서치"],[1227020,1227280,"벡터"]],"textEdited":"이 프레시니스 즉 새로운 동영상이 더 잘 추천될 수 있도록 모델을 변형한 것입니다. 네 그렇게 해서 유저가 과거에 봤던 왓치 벡터와 서치 벡터"},{"start":1227400,"end":1242000,"text":"를 인베딩해서 에버러지 하고 그 외에 지오 그래픽이나 이그젠플 에이지 같은 피처를 다 구해주고 이 모든 피처 벡터를 마지막 엠엘피 레이어에서는 하나의 컨케이트네이트 된 벡터로 만들어 줍니다. 그리고 그 위에 댄스 한 레이어","confidence":0.8361,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1227590,1227740,"를"],[1227740,1228220,"인베딩해서"],[1228290,1228660,"에버러지"],[1228660,1228880,"하고"],[1229390,1229540,"그"],[1229540,1229740,"외에"],[1229750,1229980,"지오"],[1229980,1230420,"그래픽이나"],[1230530,1230900,"이그젠플"],[1230900,1231120,"에이지"],[1231120,1231320,"같은"],[1231350,1231740,"피처를"],[1231740,1231860,"다"],[1231930,1232360,"구해주고"],[1232890,1233040,"이"],[1233040,1233260,"모든"],[1233330,1233560,"피처"],[1233560,1233940,"벡터를"],[1235030,1235320,"마지막"],[1235370,1235740,"엠엘피"],[1235740,1236200,"레이어에서는"],[1236200,1236540,"하나의"],[1237290,1237907,"컨케이트네이트"],[1237907,1238040,"된"],[1238090,1238480,"벡터로"],[1239010,1239300,"만들어"],[1239300,1239600,"줍니다."],[1240270,1240480,"그리고"],[1240480,1240620,"그"],[1240630,1240860,"위에"],[1240930,1241260,"댄스"],[1241260,1241380,"한"],[1241430,1241720,"레이어"]],"textEdited":"를 인베딩해서 에버러지 하고 그 외에 지오 그래픽이나 이그젠플 에이지 같은 피처를 다 구해주고 이 모든 피처 벡터를 마지막 엠엘피 레이어에서는 하나의 컨케이트네이트 된 벡터로 만들어 줍니다. 그리고 그 위에 댄스 한 레이어"},{"start":1242000,"end":1251900,"text":"피드 포워드 유뉴럴 네트워크를 쌓아서 최종적으로 유저 벡터를 생성하게 되고 이 유저 벡터에 대해서 마지막에 이 유저가 어떤 비디오를 봤는지","confidence":0.9152,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1242210,1242460,"피드"],[1242460,1242654,"포워드"],[1242654,1242880,"유뉴럴"],[1242880,1243320,"네트워크를"],[1243330,1243720,"쌓아서"],[1244370,1244900,"최종적으로"],[1244930,1245180,"유저"],[1245210,1246040,"벡터를"],[1246070,1246434,"생성하게"],[1246434,1246700,"되고"],[1247350,1247454,"이"],[1247454,1247680,"유저"],[1247710,1248300,"벡터에"],[1248300,1248660,"대해서"],[1249150,1249620,"마지막에"],[1249750,1249900,"이"],[1249900,1250160,"유저가"],[1250190,1250420,"어떤"],[1250570,1250960,"비디오를"],[1250960,1251380,"봤는지"]],"textEdited":"피드 포워드 유뉴럴 네트워크를 쌓아서 최종적으로 유저 벡터를 생성하게 되고 이 유저 벡터에 대해서 마지막에 이 유저가 어떤 비디오를 봤는지"},{"start":1251900,"end":1264600,"text":"멀티클래스 클래시피케이션 테스크를 수행하여서 최종적으로 로스를 구하게 됩니다. 그래서 마지막 아웃 플레이어는 어떤 비디오를 봤는지 클래시피케이션 하는 문제, 즉 소프트맥스 펑션을 사용하는","confidence":0.9254,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1252610,1253140,"멀티클래스"],[1253170,1253840,"클래시피케이션"],[1254090,1254520,"테스크를"],[1254520,1255040,"수행하여서"],[1255630,1256040,"최종적으로"],[1256040,1256380,"로스를"],[1256380,1256627,"구하게"],[1256627,1256920,"됩니다."],[1257610,1257840,"그래서"],[1257840,1258120,"마지막"],[1258130,1258300,"아웃"],[1258300,1258760,"플레이어는"],[1259450,1259700,"어떤"],[1259750,1260080,"비디오를"],[1260080,1260440,"봤는지"],[1260470,1261080,"클래시피케이션"],[1261080,1261260,"하는"],[1261650,1261920,"문제,"],[1262570,1262720,"즉"],[1262750,1263320,"소프트맥스"],[1263450,1263780,"펑션을"],[1263780,1264140,"사용하는"]],"textEdited":"멀티클래스 클래시피케이션 테스크를 수행하여서 최종적으로 로스를 구하게 됩니다. 그래서 마지막 아웃 플레이어는 어떤 비디오를 봤는지 클래시피케이션 하는 문제, 즉 소프트맥스 펑션을 사용하는"},{"start":1264600,"end":1278000,"text":"멀티클래스 클래시피케이션 문제입니다. 다음 내용은 캔디데이 제너레이션 모델이 서빙되는 부분입니다. 보통의 논문들은 모델의 성능을 이야기하긴 하지만 서빙을 어떻게 해야 하는지에 대해서는 서술하지 않는데요.","confidence":0.9208,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1264850,1265420,"멀티클래스"],[1265420,1266020,"클래시피케이션"],[1266050,1266560,"문제입니다."],[1266870,1267120,"다음"],[1267170,1267500,"내용은"],[1267970,1268360,"캔디데이"],[1268360,1268740,"제너레이션"],[1268770,1269200,"모델이"],[1269370,1269900,"서빙되는"],[1269910,1270400,"부분입니다."],[1271390,1271760,"보통의"],[1271770,1272260,"논문들은"],[1272530,1272900,"모델의"],[1273030,1273380,"성능을"],[1273430,1273960,"이야기하긴"],[1273970,1274300,"하지만"],[1274870,1275300,"서빙을"],[1275330,1275640,"어떻게"],[1275640,1275840,"해야"],[1275890,1276640,"하는지에"],[1276640,1277020,"대해서는"],[1277020,1277440,"서술하지"],[1277440,1277800,"않는데요."]],"textEdited":"멀티클래스 클래시피케이션 문제입니다. 다음 내용은 캔디데이 제너레이션 모델이 서빙되는 부분입니다. 보통의 논문들은 모델의 성능을 이야기하긴 하지만 서빙을 어떻게 해야 하는지에 대해서는 서술하지 않는데요."},{"start":1278000,"end":1288700,"text":"이 유튜브 추천 레코멘데이션 논문은 수백만 개의 비디오 가운데서 수백 개의 비디오를 생성하는 이 캔디데이 제너레이션 부분을 어떻게 서빙해야 하는지도 설명하고 있습니다.","confidence":0.9466,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1278690,1278840,"이"],[1278850,1279200,"유튜브"],[1279200,1279440,"추천"],[1279670,1280300,"레코멘데이션"],[1280310,1280660,"논문은"],[1281330,1281740,"수백만"],[1281750,1282000,"개의"],[1282070,1282400,"비디오"],[1282400,1282840,"가운데서"],[1283010,1283267,"수백"],[1283267,1283500,"개의"],[1283510,1283840,"비디오를"],[1283850,1284240,"생성하는"],[1284330,1284480,"이"],[1284550,1284940,"캔디데이"],[1284940,1285360,"제너레이션"],[1285650,1286020,"부분을"],[1286070,1286360,"어떻게"],[1286390,1286880,"서빙해야"],[1286880,1287720,"하는지도"],[1287810,1288220,"설명하고"],[1288220,1288640,"있습니다."]],"textEdited":"이 유튜브 추천 레코멘데이션 논문은 수백만 개의 비디오 가운데서 수백 개의 비디오를 생성하는 이 캔디데이 제너레이션 부분을 어떻게 서빙해야 하는지도 설명하고 있습니다."},{"start":1288700,"end":1303300,"text":"그래서 주어진 유저에 대해서 상위 n개의 비디오를 추출하기 위해서는 우리가 갖고 있는 수백만 개의 비디오에 대한 모든 소프트맥스 프로벌리티를 계산하고 그중에 가장 프로벌리티가 높은 비디오 n개를 추출해야 합니다.","confidence":0.8948,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1288910,1289120,"그래서"],[1289130,1289480,"주어진"],[1289510,1289980,"유저에"],[1289980,1290320,"대해서"],[1290850,1291080,"상위"],[1291150,1291540,"n개의"],[1291550,1291920,"비디오를"],[1291930,1292320,"추출하기"],[1292320,1292700,"위해서는"],[1293250,1293540,"우리가"],[1293610,1293807,"갖고"],[1293807,1293960,"있는"],[1293990,1294380,"수백만"],[1294390,1294660,"개의"],[1294870,1295460,"비디오에"],[1295460,1295700,"대한"],[1296350,1296580,"모든"],[1296790,1297360,"소프트맥스"],[1297360,1297920,"프로벌리티를"],[1297920,1298340,"계산하고"],[1298510,1298800,"그중에"],[1298870,1299120,"가장"],[1299830,1300400,"프로벌리티가"],[1300400,1300680,"높은"],[1300970,1301320,"비디오"],[1301590,1302060,"n개를"],[1302530,1302874,"추출해야"],[1302874,1303200,"합니다."]],"textEdited":"그래서 주어진 유저에 대해서 상위 n개의 비디오를 추출하기 위해서는 우리가 갖고 있는 수백만 개의 비디오에 대한 모든 소프트맥스 프로벌리티를 계산하고 그중에 가장 프로벌리티가 높은 비디오 n개를 추출해야 합니다."},{"start":1303300,"end":1317600,"text":"따라서 주어진 유저에 대해서 수백만 개에 대한 비디오 벡터의 내적을 다 계산해야 하는데요. 이제 이 계산은 굉장히 많은 시간이 소요되고 실제로 이 연산을 통해서 실시간 서빙을 하는 것은 굉장히 불가능한 부분이라고 볼 수 있죠.","confidence":0.9618,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1303550,1303920,"따라서"],[1304270,1304620,"주어진"],[1304650,1304980,"유저에"],[1304980,1305280,"대해서"],[1305770,1306160,"수백만"],[1306170,1306440,"개에"],[1306440,1306660,"대한"],[1306810,1307140,"비디오"],[1307170,1307500,"벡터의"],[1307500,1307860,"내적을"],[1307870,1308020,"다"],[1308090,1308520,"계산해야"],[1308520,1308860,"하는데요."],[1309250,1309420,"이제"],[1309430,1309580,"이"],[1309590,1309940,"계산은"],[1309990,1310380,"굉장히"],[1310910,1311120,"많은"],[1311310,1311600,"시간이"],[1311600,1312080,"소요되고"],[1312530,1312860,"실제로"],[1312890,1313040,"이"],[1313070,1313480,"연산을"],[1313570,1313900,"통해서"],[1314170,1314480,"실시간"],[1314480,1314820,"서빙을"],[1314820,1315000,"하는"],[1315000,1315240,"것은"],[1315590,1315860,"굉장히"],[1315910,1316380,"불가능한"],[1316610,1317000,"부분이라고"],[1317000,1317120,"볼"],[1317120,1317180,"수"],[1317180,1317400,"있죠."]],"textEdited":"따라서 주어진 유저에 대해서 수백만 개에 대한 비디오 벡터의 내적을 다 계산해야 하는데요. 이제 이 계산은 굉장히 많은 시간이 소요되고 실제로 이 연산을 통해서 실시간 서빙을 하는 것은 굉장히 불가능한 부분이라고 볼 수 있죠."},{"start":1317600,"end":1332200,"text":"따라서 우리가 필요한 것은 주어진 유저 벡터에 대해서 가장 내적이 큰 비디오 벡터를 찾아주는 것인데요. 이렇게 소프트맥스 연산을 다 해서 가장 확률이 높은 벡터를 찾는 것이 아니라","confidence":0.9744,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1317770,1318120,"따라서"],[1318710,1318980,"우리가"],[1319030,1319360,"필요한"],[1319360,1319600,"것은"],[1320110,1320480,"주어진"],[1320530,1320780,"유저"],[1320830,1321220,"벡터에"],[1321220,1321540,"대해서"],[1322470,1322720,"가장"],[1322790,1323180,"내적이"],[1323210,1323360,"큰"],[1324270,1324580,"비디오"],[1324590,1324860,"벡터를"],[1324860,1325207,"찾아주는"],[1325207,1325620,"것인데요."],[1326490,1326740,"이렇게"],[1326790,1327307,"소프트맥스"],[1327307,1327620,"연산을"],[1327630,1327780,"다"],[1327970,1328220,"해서"],[1329170,1329400,"가장"],[1329470,1329720,"확률이"],[1329890,1330180,"높은"],[1330750,1331100,"벡터를"],[1331100,1331307,"찾는"],[1331307,1331514,"것이"],[1331514,1331780,"아니라"]],"textEdited":"따라서 우리가 필요한 것은 주어진 유저 벡터에 대해서 가장 내적이 큰 비디오 벡터를 찾아주는 것인데요. 이렇게 소프트맥스 연산을 다 해서 가장 확률이 높은 벡터를 찾는 것이 아니라"},{"start":1332200,"end":1342700,"text":"어노이와 파이스와 같이 주어진 유저 벡터와 가장 유사한 벡터를 찾아주는 에엔의 라이브러리를 여기서 사용하게 됩니다. 그래서 이 부분은 연산을 하지만","confidence":0.873,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1332450,1332920,"어노이와"],[1332950,1333860,"파이스와"],[1333930,1334240,"같이"],[1334850,1335180,"주어진"],[1335190,1335420,"유저"],[1335420,1335780,"벡터와"],[1336370,1336620,"가장"],[1336730,1337080,"유사한"],[1337190,1337560,"벡터를"],[1337570,1337980,"찾아주는"],[1338570,1338940,"에엔의"],[1338950,1339520,"라이브러리를"],[1339690,1339980,"여기서"],[1339990,1340327,"사용하게"],[1340327,1340640,"됩니다."],[1340870,1341100,"그래서"],[1341210,1341360,"이"],[1341360,1341660,"부분은"],[1341690,1342060,"연산을"],[1342060,1342320,"하지만"]],"textEdited":"어노이와 파이스와 같이 주어진 유저 벡터와 가장 유사한 벡터를 찾아주는 에엔의 라이브러리를 여기서 사용하게 됩니다. 그래서 이 부분은 연산을 하지만"},{"start":1342700,"end":1356400,"text":"마지막 부분인 이 소프트맥스를 계산하지 않고 주어진 유저 벡터에 대해서 비디오 벡터가 인베딩 되어 있는 인덱스에서 어프록시메이트 한 탑 n개의 아이템 벡터를 찾아주는 것이죠. 그래서 정확한","confidence":0.8969,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1342930,1343280,"마지막"],[1343310,1343640,"부분인"],[1343730,1343880,"이"],[1343890,1344560,"소프트맥스를"],[1344560,1344940,"계산하지"],[1344950,1345260,"않고"],[1345710,1346060,"주어진"],[1346090,1346320,"유저"],[1346370,1346727,"벡터에"],[1346727,1347080,"대해서"],[1347690,1348040,"비디오"],[1348070,1348400,"벡터가"],[1348430,1348780,"인베딩"],[1348780,1349000,"되어"],[1349030,1349220,"있는"],[1349610,1350980,"인덱스에서"],[1351310,1352007,"어프록시메이트"],[1352007,1352140,"한"],[1352230,1352380,"탑"],[1352490,1352980,"n개의"],[1353350,1353680,"아이템"],[1353690,1354080,"벡터를"],[1354410,1354807,"찾아주는"],[1354807,1355100,"것이죠."],[1355370,1355600,"그래서"],[1355690,1356120,"정확한"]],"textEdited":"마지막 부분인 이 소프트맥스를 계산하지 않고 주어진 유저 벡터에 대해서 비디오 벡터가 인베딩 되어 있는 인덱스에서 어프록시메이트 한 탑 n개의 아이템 벡터를 찾아주는 것이죠. 그래서 정확한"},{"start":1356400,"end":1367400,"text":"소프트맥스 값을 계산하지 않지만 그와 최대한 유사하게 주어진 유저 벡터와 최대한 유사한 아이템 벡터 수백 개를 서빙하는 방식을 취하고 있습니다.","confidence":0.9794,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1356670,1357154,"소프트맥스"],[1357154,1357400,"값을"],[1357400,1357760,"계산하지"],[1357760,1358080,"않지만"],[1358890,1359140,"그와"],[1359550,1359860,"최대한"],[1359950,1360520,"유사하게"],[1361150,1361460,"주어진"],[1361490,1361700,"유저"],[1361710,1362080,"벡터와"],[1362210,1362520,"최대한"],[1362630,1363000,"유사한"],[1363170,1363520,"아이템"],[1363530,1363840,"벡터"],[1364290,1364580,"수백"],[1364610,1364920,"개를"],[1365450,1365920,"서빙하는"],[1366170,1366520,"방식을"],[1366610,1366900,"취하고"],[1366900,1367360,"있습니다."]],"textEdited":"소프트맥스 값을 계산하지 않지만 그와 최대한 유사하게 주어진 유저 벡터와 최대한 유사한 아이템 벡터 수백 개를 서빙하는 방식을 취하고 있습니다."},{"start":1367400,"end":1382000,"text":"자 다음은 방금 전에 캔디딧 제너레이션 모델에서 수백 개의 추천 후보군에 대한 선택이 끝났을 때 끝나고 나서 최종 추천을 제공하기 위한 랭킹 부분의 문제입니다. 2단계 추천 구조의 두 번째 부분이 되겠습니다.","confidence":0.9337,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1367630,1367780,"자"],[1367810,1368160,"다음은"],[1368570,1368807,"방금"],[1368807,1369040,"전에"],[1369090,1369460,"캔디딧"],[1369470,1369880,"제너레이션"],[1369910,1370520,"모델에서"],[1370630,1370900,"수백"],[1370900,1371120,"개의"],[1371130,1371360,"추천"],[1371370,1372127,"후보군에"],[1372127,1372320,"대한"],[1372370,1372720,"선택이"],[1372750,1373160,"끝났을"],[1373710,1373860,"때"],[1374190,1374520,"끝나고"],[1374520,1374780,"나서"],[1375410,1375700,"최종"],[1375790,1376440,"추천을"],[1376470,1376920,"제공하기"],[1376920,1377100,"위한"],[1377410,1377740,"랭킹"],[1377810,1378140,"부분의"],[1378250,1378780,"문제입니다."],[1379150,1379540,"2단계"],[1379570,1379840,"추천"],[1379910,1380240,"구조의"],[1380390,1380540,"두"],[1380540,1380820,"번째"],[1380970,1381300,"부분이"],[1381310,1381800,"되겠습니다."]],"textEdited":"자 다음은 방금 전에 캔디딧 제너레이션 모델에서 수백 개의 추천 후보군에 대한 선택이 끝났을 때 끝나고 나서 최종 추천을 제공하기 위한 랭킹 부분의 문제입니다. 2단계 추천 구조의 두 번째 부분이 되겠습니다."},{"start":1382000,"end":1395800,"text":"네 기본적으로는 주어진 유저 아이템 컨텍스트에 대해서 해당 아이템이 노출되었을 때 클릭한 확률을 구하는 문제이므로 로지스틱 리그레션을 사용하여서","confidence":0.9402,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1383030,1383180,"네"],[1383210,1383840,"기본적으로는"],[1384010,1384380,"주어진"],[1384450,1384720,"유저"],[1384890,1385240,"아이템"],[1385390,1386240,"컨텍스트에"],[1386240,1386580,"대해서"],[1387150,1387400,"해당"],[1387470,1387940,"아이템이"],[1387970,1388680,"노출되었을"],[1388710,1388860,"때"],[1389790,1390220,"클릭한"],[1390650,1391040,"확률을"],[1391350,1391660,"구하는"],[1391670,1392140,"문제이므로"],[1392690,1393120,"로지스틱"],[1393150,1394720,"리그레션을"],[1394810,1395380,"사용하여서"]],"textEdited":"네 기본적으로는 주어진 유저 아이템 컨텍스트에 대해서 해당 아이템이 노출되었을 때 클릭한 확률을 구하는 문제이므로 로지스틱 리그레션을 사용하여서"},{"start":1395800,"end":1410600,"text":"마지막 예측 레이어를 구성합니다. 하지만 뉴럴넷 아키텍처를 사용하기 때문에 다양한 유저와 비디오 피처를 아래와 같이 사용할 수 있는 것이죠. 또한 단순히 클릭 여부를 반영하는 것이 아니라 웨이티드 로지스틱","confidence":0.9641,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1396370,1396680,"마지막"],[1396750,1397020,"예측"],[1397110,1397540,"레이어를"],[1397650,1398160,"구성합니다."],[1398670,1398940,"하지만"],[1399410,1399820,"뉴럴넷"],[1399850,1400500,"아키텍처를"],[1400500,1400807,"사용하기"],[1400807,1401180,"때문에"],[1401790,1402180,"다양한"],[1402490,1402860,"유저와"],[1402950,1403240,"비디오"],[1403250,1403640,"피처를"],[1403810,1404120,"아래와"],[1404120,1404380,"같이"],[1404450,1404780,"사용할"],[1404830,1404980,"수"],[1405030,1405220,"있는"],[1405220,1405520,"것이죠."],[1405950,1406180,"또한"],[1406310,1406700,"단순히"],[1406770,1407040,"클릭"],[1407050,1407460,"여부를"],[1407710,1408140,"반영하는"],[1408140,1408354,"것이"],[1408354,1408620,"아니라"],[1409310,1409780,"웨이티드"],[1409780,1410260,"로지스틱"]],"textEdited":"마지막 예측 레이어를 구성합니다. 하지만 뉴럴넷 아키텍처를 사용하기 때문에 다양한 유저와 비디오 피처를 아래와 같이 사용할 수 있는 것이죠. 또한 단순히 클릭 여부를 반영하는 것이 아니라 웨이티드 로지스틱"},{"start":1410600,"end":1424200,"text":"을 사용하고 있는데요. 이는 클릭한 이후에 시청 시간이 긴지 혹은 짧은지에 대한 값을 가중치로 사용하여서 반영하고 있습니다. 네 먼저 인풋 피처 부분을 살펴봅시다. 이 부분은","confidence":0.9676,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1410890,1411040,"을"],[1411040,1411380,"사용하고"],[1411380,1411720,"있는데요."],[1411910,1412120,"이는"],[1412670,1413060,"클릭한"],[1413130,1413480,"이후에"],[1413770,1414080,"시청"],[1414110,1414420,"시간이"],[1414490,1414880,"긴지"],[1415050,1415260,"혹은"],[1415350,1415960,"짧은지에"],[1415960,1416160,"대한"],[1416690,1417060,"값을"],[1417170,1417760,"가중치로"],[1417770,1418300,"사용하여서"],[1418790,1419220,"반영하고"],[1419230,1419620,"있습니다."],[1420130,1420280,"네"],[1420280,1420520,"먼저"],[1420590,1420840,"인풋"],[1420870,1421140,"피처"],[1421150,1421460,"부분을"],[1421460,1421960,"살펴봅시다."],[1422870,1423020,"이"],[1423020,1423800,"부분은"]],"textEdited":"을 사용하고 있는데요. 이는 클릭한 이후에 시청 시간이 긴지 혹은 짧은지에 대한 값을 가중치로 사용하여서 반영하고 있습니다. 네 먼저 인풋 피처 부분을 살펴봅시다. 이 부분은"},{"start":1424200,"end":1437100,"text":"유저가 과거에 어떤 채널에서 얼마나 많은 영상을 봤는지, 비디오 왓치 팩터들 혹은 어떤 토픽의 동영상을 많이 보고 그 시간이 얼마나 지났는지, 그리고 이 유저가 어떤 랭귀지를 사용하는지,","confidence":0.9546,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1424430,1424820,"유저가"],[1425190,1425560,"과거에"],[1425750,1426040,"어떤"],[1426210,1426580,"채널에서"],[1426710,1426967,"얼마나"],[1426967,1427120,"많은"],[1427170,1427480,"영상을"],[1427490,1427900,"봤는지,"],[1428810,1429120,"비디오"],[1429120,1429400,"왓치"],[1429410,1429840,"팩터들"],[1430270,1430480,"혹은"],[1430670,1430920,"어떤"],[1431250,1431680,"토픽의"],[1431690,1432100,"동영상을"],[1432100,1432260,"많이"],[1432310,1432600,"보고"],[1432930,1433080,"그"],[1433090,1433380,"시간이"],[1433380,1433640,"얼마나"],[1433640,1434120,"지났는지,"],[1434350,1434580,"그리고"],[1434590,1434740,"이"],[1434740,1435100,"유저가"],[1435650,1435880,"어떤"],[1435990,1436400,"랭귀지를"],[1436400,1436940,"사용하는지,"]],"textEdited":"유저가 과거에 어떤 채널에서 얼마나 많은 영상을 봤는지, 비디오 왓치 팩터들 혹은 어떤 토픽의 동영상을 많이 보고 그 시간이 얼마나 지났는지, 그리고 이 유저가 어떤 랭귀지를 사용하는지,"},{"start":1437100,"end":1445100,"text":"비디오의 랭귀지는 무엇인지 등의 다양한 유저 액션 피처와 아이템 피처들을 사용합니다. 사실 이 부분은","confidence":0.9554,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1437350,1437780,"비디오의"],[1437780,1438120,"랭귀지는"],[1438120,1438540,"무엇인지"],[1438550,1438800,"등의"],[1439210,1439560,"다양한"],[1439610,1439860,"유저"],[1439930,1440180,"액션"],[1440290,1440680,"피처와"],[1440810,1441200,"아이템"],[1441310,1441860,"피처들을"],[1442450,1442940,"사용합니다."],[1443370,1443580,"사실"],[1443610,1443727,"이"],[1443727,1444060,"부분은"]],"textEdited":"비디오의 랭귀지는 무엇인지 등의 다양한 유저 액션 피처와 아이템 피처들을 사용합니다. 사실 이 부분은"},{"start":1445100,"end":1453600,"text":"모델 구조가 특별하다기보다는 이 도메인을 잘 아는 전문가, 즉 서비스를 잘 아는 데이터 사이언티스트 같은 인력 등이 분석을 통해서","confidence":0.9826,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1445590,1445860,"모델"],[1445890,1446160,"구조가"],[1446170,1447040,"특별하다기보다는"],[1447350,1447500,"이"],[1447500,1447940,"도메인을"],[1447970,1448120,"잘"],[1448270,1448460,"아는"],[1448570,1448940,"전문가,"],[1449070,1449220,"즉"],[1449220,1449720,"서비스를"],[1449720,1449840,"잘"],[1449850,1450040,"아는"],[1450210,1450540,"데이터"],[1450550,1451027,"사이언티스트"],[1451027,1451240,"같은"],[1451310,1451520,"인력"],[1451550,1451800,"등이"],[1452430,1452820,"분석을"],[1452820,1453120,"통해서"]],"textEdited":"모델 구조가 특별하다기보다는 이 도메인을 잘 아는 전문가, 즉 서비스를 잘 아는 데이터 사이언티스트 같은 인력 등이 분석을 통해서"},{"start":1453600,"end":1466700,"text":"어떤 피처가 가장 좋은지 피처를 잘 셀렉션하고 그 피처를 적당히 잘 가공해야 하는 부분입니다. 그래서 모델 자체가 중요하다기보다는 그 서비스에 맞는 피처를 잘 찾아서 랭킹 모델을 구성하는 것이 더 중요한 부분입니다.","confidence":0.9797,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1453850,1454120,"어떤"],[1454210,1454560,"피처가"],[1454560,1454740,"가장"],[1454770,1455180,"좋은지"],[1455310,1455620,"피처를"],[1455620,1455740,"잘"],[1455970,1456560,"셀렉션하고"],[1456910,1457060,"그"],[1457060,1457380,"피처를"],[1457390,1457720,"적당히"],[1457720,1457860,"잘"],[1457950,1458380,"가공해야"],[1458380,1458540,"하는"],[1458540,1459000,"부분입니다."],[1459250,1459500,"그래서"],[1459590,1459840,"모델"],[1459890,1460240,"자체가"],[1460250,1461300,"중요하다기보다는"],[1461930,1462080,"그"],[1462150,1462620,"서비스에"],[1462620,1462800,"맞는"],[1462870,1463200,"피처를"],[1463200,1463340,"잘"],[1463410,1463740,"찾아서"],[1464050,1464340,"랭킹"],[1464350,1464660,"모델을"],[1464660,1465040,"구성하는"],[1465040,1465320,"것이"],[1465550,1465700,"더"],[1465790,1466080,"중요한"],[1466080,1466640,"부분입니다."]],"textEdited":"어떤 피처가 가장 좋은지 피처를 잘 셀렉션하고 그 피처를 적당히 잘 가공해야 하는 부분입니다. 그래서 모델 자체가 중요하다기보다는 그 서비스에 맞는 피처를 잘 찾아서 랭킹 모델을 구성하는 것이 더 중요한 부분입니다."},{"start":1466700,"end":1479600,"text":"그래서 이 인풋 피처가 마지막 레이어에서 다 합쳐지게 되고요. 이 레이어는 다시 한번 엠엘피 레이어를 통하여서 최종적으로 네트워크를 통과하게 되면은 비디오가 실제로 시청될 확률을 구하게 됩니다.","confidence":0.8896,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1467010,1467240,"그래서"],[1467240,1467360,"이"],[1467360,1467560,"인풋"],[1467590,1467940,"피처가"],[1468450,1468800,"마지막"],[1469350,1469800,"레이어에서"],[1469810,1469960,"다"],[1469960,1470380,"합쳐지게"],[1470380,1470700,"되고요."],[1471130,1471280,"이"],[1471290,1471720,"레이어는"],[1472010,1472194,"다시"],[1472194,1472380,"한번"],[1472410,1472820,"엠엘피"],[1472830,1473200,"레이어를"],[1473230,1473700,"통하여서"],[1474390,1474960,"최종적으로"],[1475350,1475880,"네트워크를"],[1475930,1476354,"통과하게"],[1476354,1476680,"되면은"],[1476810,1477220,"비디오가"],[1477290,1477600,"실제로"],[1477690,1478120,"시청될"],[1478270,1478660,"확률을"],[1478710,1478987,"구하게"],[1478987,1479280,"됩니다."]],"textEdited":"그래서 이 인풋 피처가 마지막 레이어에서 다 합쳐지게 되고요. 이 레이어는 다시 한번 엠엘피 레이어를 통하여서 최종적으로 네트워크를 통과하게 되면은 비디오가 실제로 시청될 확률을 구하게 됩니다."},{"start":1479600,"end":1492500,"text":"그래서 0과 1을 맞추는 CTR 예측 문제와 같다고 볼 수 있습니다. 여기서 로스 펑션은 그냥 기본적인 CTR 예측 문제와는 조금 다르게 구성되는데요. 단순한 바이너리 크로스 엔트로피가 아니라 이 웨이트드","confidence":0.8228,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1479790,1480000,"그래서"],[1480000,1480320,"0과"],[1480350,1480620,"1을"],[1480650,1481020,"맞추는"],[1481210,1481540,"CTR"],[1481550,1481800,"예측"],[1481810,1482160,"문제와"],[1482230,1482560,"같다고"],[1482560,1482680,"볼"],[1482680,1482774,"수"],[1482774,1483120,"있습니다."],[1483570,1483860,"여기서"],[1484170,1484460,"로스"],[1484490,1484920,"펑션은"],[1485830,1486020,"그냥"],[1486090,1486560,"기본적인"],[1486610,1486940,"CTR"],[1486940,1487160,"예측"],[1487160,1487500,"문제와는"],[1487500,1487700,"조금"],[1487730,1488040,"다르게"],[1488040,1488620,"구성되는데요."],[1489390,1489820,"단순한"],[1489910,1490320,"바이너리"],[1490320,1490580,"크로스"],[1490610,1491014,"엔트로피가"],[1491014,1491260,"아니라"],[1491510,1491660,"이"],[1491660,1492140,"웨이트드"]],"textEdited":"그래서 0과 1을 맞추는 CTR 예측 문제와 같다고 볼 수 있습니다. 여기서 로스 펑션은 그냥 기본적인 CTR 예측 문제와는 조금 다르게 구성되는데요. 단순한 바이너리 크로스 엔트로피가 아니라 이 웨이트드"},{"start":1492500,"end":1505600,"text":"랜 크로스 엔트로피를 사용합니다. 즉 비디오를 클릭한 이후에 오래 시청했을 때와 비디오를 클릭하자마자 바로 나갔을 때의 로스 펑션을 다르게 계산하는 것이죠. 비디오를 클릭한 이후에 많이","confidence":0.8952,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1492670,1492820,"랜"],[1492870,1493160,"크로스"],[1493160,1493527,"엔트로피를"],[1493527,1493960,"사용합니다."],[1494190,1494340,"즉"],[1494590,1495120,"비디오를"],[1495850,1496240,"클릭한"],[1496310,1496640,"이후에"],[1496730,1496960,"오래"],[1497070,1497700,"시청했을"],[1497730,1498020,"때와"],[1498270,1498660,"비디오를"],[1498710,1499400,"클릭하자마자"],[1499430,1499640,"바로"],[1499640,1500060,"나갔을"],[1500130,1501140,"때의"],[1501830,1502140,"로스"],[1502170,1502520,"펑션을"],[1502530,1502840,"다르게"],[1502840,1503187,"계산하는"],[1503187,1503500,"것이죠."],[1503790,1504240,"비디오를"],[1504310,1504640,"클릭한"],[1504650,1504920,"이후에"],[1504930,1505160,"많이"]],"textEdited":"랜 크로스 엔트로피를 사용합니다. 즉 비디오를 클릭한 이후에 오래 시청했을 때와 비디오를 클릭하자마자 바로 나갔을 때의 로스 펑션을 다르게 계산하는 것이죠. 비디오를 클릭한 이후에 많이"},{"start":1505600,"end":1516900,"text":"면 많이 볼수록 그 비디오에 대해 만족했다는 것이기 때문에 그 웨이트를 더 높게 주어서 이 모델이 더 그 데이터를 잘 학습할 수 있게 하고요. 반대로 비디오를 클릭하자마자 바로 떠나는","confidence":0.9789,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1505890,1506040,"면"],[1506040,1506200,"많이"],[1506210,1506560,"볼수록"],[1506560,1506680,"그"],[1506680,1507000,"비디오에"],[1507000,1507160,"대해"],[1507190,1507694,"만족했다는"],[1507694,1507947,"것이기"],[1507947,1508300,"때문에"],[1508870,1509020,"그"],[1509020,1509407,"웨이트를"],[1509407,1509540,"더"],[1509540,1509820,"높게"],[1509830,1510180,"주어서"],[1510710,1510860,"이"],[1510860,1511200,"모델이"],[1511210,1511360,"더"],[1511510,1511660,"그"],[1511670,1512040,"데이터를"],[1512040,1512180,"잘"],[1512210,1512560,"학습할"],[1512560,1512654,"수"],[1512654,1512840,"있게"],[1512840,1513140,"하고요."],[1513870,1514220,"반대로"],[1514270,1514660,"비디오를"],[1514730,1515420,"클릭하자마자"],[1515890,1516180,"바로"],[1516230,1516560,"떠나는"]],"textEdited":"면 많이 볼수록 그 비디오에 대해 만족했다는 것이기 때문에 그 웨이트를 더 높게 주어서 이 모델이 더 그 데이터를 잘 학습할 수 있게 하고요. 반대로 비디오를 클릭하자마자 바로 떠나는"},{"start":1516900,"end":1526500,"text":"이런 낚시나 광고성 콘텐츠 같은 경우에는 클릭이 일어나긴 하지만 시청 시간이 아주 짧기 때문에 웨이트가 거의 0에 가까울 것이고 이제 그럼 그러한 데이터는","confidence":0.9457,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1517110,1517280,"이런"],[1517350,1517800,"낚시나"],[1518010,1518480,"광고성"],[1518650,1519000,"콘텐츠"],[1519010,1519227,"같은"],[1519227,1519640,"경우에는"],[1520270,1520574,"클릭이"],[1520574,1520880,"일어나긴"],[1520880,1521160,"하지만"],[1521790,1522060,"시청"],[1522060,1522307,"시간이"],[1522307,1522460,"아주"],[1522470,1522734,"짧기"],[1522734,1523100,"때문에"],[1523230,1523640,"웨이트가"],[1523710,1523887,"거의"],[1523887,1524120,"0에"],[1524130,1524440,"가까울"],[1524450,1524820,"것이고"],[1525150,1525320,"이제"],[1525320,1525480,"그럼"],[1525490,1525760,"그러한"],[1525790,1526220,"데이터는"]],"textEdited":"이런 낚시나 광고성 콘텐츠 같은 경우에는 클릭이 일어나긴 하지만 시청 시간이 아주 짧기 때문에 웨이트가 거의 0에 가까울 것이고 이제 그럼 그러한 데이터는"},{"start":1526500,"end":1539100,"text":"비록 클릭은 했지만 웨이트가 아주 작기 때문에 이 모델의 로스에 거의 반영이 안 될 것입니다. 그래서 그러한 데이터는 학습에 거의 반영이 되지 않을 것입니다. 그래서 본 논문을 요약을 하자면은","confidence":0.9803,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1526730,1526960,"비록"],[1527210,1527520,"클릭은"],[1527530,1527940,"했지만"],[1528470,1528940,"웨이트가"],[1529270,1529480,"아주"],[1529510,1529780,"작기"],[1529780,1530160,"때문에"],[1530390,1530540,"이"],[1530570,1530920,"모델의"],[1530920,1531320,"로스에"],[1531330,1531540,"거의"],[1531570,1531900,"반영이"],[1531900,1532040,"안"],[1532050,1532200,"될"],[1532230,1532640,"것입니다."],[1532870,1533120,"그래서"],[1533170,1533420,"그러한"],[1533430,1533860,"데이터는"],[1534390,1534700,"학습에"],[1534700,1534900,"거의"],[1534930,1535260,"반영이"],[1535260,1535540,"되지"],[1535690,1535920,"않을"],[1535930,1536360,"것입니다."],[1536830,1537060,"그래서"],[1537170,1537320,"본"],[1537370,1537920,"논문을"],[1538070,1538427,"요약을"],[1538427,1538880,"하자면은"]],"textEdited":"비록 클릭은 했지만 웨이트가 아주 작기 때문에 이 모델의 로스에 거의 반영이 안 될 것입니다. 그래서 그러한 데이터는 학습에 거의 반영이 되지 않을 것입니다. 그래서 본 논문을 요약을 하자면은"},{"start":1539100,"end":1548300,"text":"딥러닝 기반의 2단계 추천을 처음으로 제안한 논문입니다. 단순히 학계에서 이야기하는 추천 성능뿐만 아니라 이 모델을 가지고","confidence":0.978,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1539690,1540100,"딥러닝"],[1540100,1540460,"기반의"],[1540550,1540960,"2단계"],[1540990,1541380,"추천을"],[1541470,1541880,"처음으로"],[1541910,1542240,"제안한"],[1542240,1542740,"논문입니다."],[1543630,1543960,"단순히"],[1544010,1544500,"학계에서"],[1545130,1545540,"이야기하는"],[1545550,1545780,"추천"],[1545810,1546260,"성능뿐만"],[1546310,1546580,"아니라"],[1547170,1547320,"이"],[1547330,1547700,"모델을"],[1547700,1548040,"가지고"]],"textEdited":"딥러닝 기반의 2단계 추천을 처음으로 제안한 논문입니다. 단순히 학계에서 이야기하는 추천 성능뿐만 아니라 이 모델을 가지고"},{"start":1548300,"end":1558300,"text":"어떻게 서빙해야 현업에서 사용할 수 있는지까지 제시한 기념비적인 논문이라고 볼 수 있습니다. 그래서 캔디에 제너레이션 부분은 기본적인","confidence":0.9336,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1548630,1549020,"어떻게"],[1549070,1549560,"서빙해야"],[1549690,1550140,"현업에서"],[1550170,1550480,"사용할"],[1550480,1550574,"수"],[1550574,1551100,"있는지까지"],[1551110,1551460,"제시한"],[1552050,1552560,"기념비적인"],[1552590,1553360,"논문이라고"],[1553390,1553540,"볼"],[1553540,1553634,"수"],[1553634,1554000,"있습니다."],[1554910,1555160,"그래서"],[1555310,1555640,"캔디에"],[1555650,1556160,"제너레이션"],[1556350,1556720,"부분은"],[1557370,1557900,"기본적인"]],"textEdited":"어떻게 서빙해야 현업에서 사용할 수 있는지까지 제시한 기념비적인 논문이라고 볼 수 있습니다. 그래서 캔디에 제너레이션 부분은 기본적인"},{"start":1558300,"end":1573300,"text":"시프의 아이디어를 활용하되 기존의 CF 기법은 유저 아이디만을 사용했지만 이 캔디 애니메이션 모델은 유저 아이디 외에 다양한 유저의 피처들, 다양한 아이템의 피처를 활용해서 더 정확한","confidence":0.8117,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1558650,1559500,"시프의"],[1559550,1560160,"아이디어를"],[1560230,1560660,"활용하되"],[1561270,1561620,"기존의"],[1561630,1561920,"CF"],[1561930,1562260,"기법은"],[1562510,1562820,"유저"],[1562890,1563440,"아이디만을"],[1563440,1563940,"사용했지만"],[1564970,1565120,"이"],[1565170,1565420,"캔디"],[1565510,1565900,"애니메이션"],[1565970,1566320,"모델은"],[1566950,1567220,"유저"],[1567230,1567520,"아이디"],[1567520,1567780,"외에"],[1568350,1568700,"다양한"],[1568710,1569040,"유저의"],[1569070,1569480,"피처들,"],[1570430,1570760,"다양한"],[1570760,1571160,"아이템의"],[1571170,1571520,"피처를"],[1571520,1571900,"활용해서"],[1572430,1572580,"더"],[1572650,1573000,"정확한"]],"textEdited":"시프의 아이디어를 활용하되 기존의 CF 기법은 유저 아이디만을 사용했지만 이 캔디 애니메이션 모델은 유저 아이디 외에 다양한 유저의 피처들, 다양한 아이템의 피처를 활용해서 더 정확한"},{"start":1573300,"end":1584700,"text":"탑 엔 아이템을 생성하였습니다. 또한 아이템의 최신 선을 반영하기 위해서 이그잼플 에이즈까지 사용했다는 점에서 현업의 추천에 더 가까운 모델을 제시했습니다.","confidence":0.9039,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1573530,1573680,"탑"],[1573750,1573900,"엔"],[1573950,1574440,"아이템을"],[1574750,1575480,"생성하였습니다."],[1576470,1576700,"또한"],[1576870,1577440,"아이템의"],[1577490,1577734,"최신"],[1577734,1577980,"선을"],[1577990,1578420,"반영하기"],[1578420,1578680,"위해서"],[1578930,1579340,"이그잼플"],[1579410,1580040,"에이즈까지"],[1580090,1580600,"사용했다는"],[1580600,1580940,"점에서"],[1581470,1581840,"현업의"],[1581870,1583060,"추천에"],[1583060,1583200,"더"],[1583250,1583560,"가까운"],[1583610,1583960,"모델을"],[1584050,1584700,"제시했습니다."]],"textEdited":"탑 엔 아이템을 생성하였습니다. 또한 아이템의 최신 선을 반영하기 위해서 이그잼플 에이즈까지 사용했다는 점에서 현업의 추천에 더 가까운 모델을 제시했습니다."},{"start":1584700,"end":1597200,"text":"그리고 랭킹 부분은 과거에 많이 사용된 로지스틱 리게션이나 트리 기반의 리그레션 트리 모델보다 딥러닝 모델이 더 뛰어난 성능을 보여주는데요. 그것은 바로 다양한 피처들을","confidence":0.9442,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1584990,1585220,"그리고"],[1585230,1585540,"랭킹"],[1585570,1585880,"부분은"],[1586570,1586920,"과거에"],[1586920,1587120,"많이"],[1587170,1587560,"사용된"],[1587950,1588340,"로지스틱"],[1588340,1589080,"리게션이나"],[1589290,1589520,"트리"],[1589520,1589840,"기반의"],[1590290,1590680,"리그레션"],[1590710,1590940,"트리"],[1591110,1591580,"모델보다"],[1592270,1592700,"딥러닝"],[1592700,1593000,"모델이"],[1593000,1593120,"더"],[1593190,1593500,"뛰어난"],[1593530,1593820,"성능을"],[1593820,1594380,"보여주는데요."],[1594970,1595280,"그것은"],[1595280,1595540,"바로"],[1595910,1596260,"다양한"],[1596350,1596900,"피처들을"]],"textEdited":"그리고 랭킹 부분은 과거에 많이 사용된 로지스틱 리게션이나 트리 기반의 리그레션 트리 모델보다 딥러닝 모델이 더 뛰어난 성능을 보여주는데요. 그것은 바로 다양한 피처들을"},{"start":1597200,"end":1610700,"text":"마음껏 사용해서 마지막 레이어에서 컨케이트네이트하고 그것을 MLP 레이어를 통해서 예측을 했기 때문입니다. 또한 단순 CTR 예측으로 로스를 계산한 게 아니라 그 비디오를 클릭한 이후에 비디오를 얼마나 봤는지","confidence":0.8671,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1597710,1598100,"마음껏"],[1598100,1598520,"사용해서"],[1598830,1599140,"마지막"],[1599170,1599600,"레이어에서"],[1599650,1600500,"컨케이트네이트하고"],[1601030,1601320,"그것을"],[1601320,1601660,"MLP"],[1601660,1601980,"레이어를"],[1601990,1602300,"통해서"],[1602530,1602827,"예측을"],[1602827,1603060,"했기"],[1603060,1603540,"때문입니다."],[1603930,1604180,"또한"],[1604690,1605000,"단순"],[1605050,1605400,"CTR"],[1605410,1605880,"예측으로"],[1605990,1606340,"로스를"],[1606350,1606700,"계산한"],[1606700,1606807,"게"],[1606807,1607060,"아니라"],[1607970,1608120,"그"],[1608150,1608520,"비디오를"],[1608570,1608940,"클릭한"],[1608950,1609240,"이후에"],[1609350,1609740,"비디오를"],[1609750,1610060,"얼마나"],[1610090,1610520,"봤는지"]],"textEdited":"마음껏 사용해서 마지막 레이어에서 컨케이트네이트하고 그것을 MLP 레이어를 통해서 예측을 했기 때문입니다. 또한 단순 CTR 예측으로 로스를 계산한 게 아니라 그 비디오를 클릭한 이후에 비디오를 얼마나 봤는지"},{"start":1610700,"end":1621000,"text":"익스펙티드 와치 타임을 예측하여서 더 좋은 양질의 추천 결과를 생성하였습니다. 그래서 지금까지 유튜브 추천 모델에 대한 리뷰였습니다. 이 모델 이후에","confidence":0.9662,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1611010,1611560,"익스펙티드"],[1611560,1611840,"와치"],[1611840,1612120,"타임을"],[1612120,1612660,"예측하여서"],[1613190,1613340,"더"],[1613510,1613700,"좋은"],[1613990,1614320,"양질의"],[1614330,1614580,"추천"],[1614650,1615060,"결과를"],[1615670,1616360,"생성하였습니다."],[1616690,1616900,"그래서"],[1616910,1617400,"지금까지"],[1617870,1618220,"유튜브"],[1618250,1618500,"추천"],[1618550,1618827,"모델에"],[1618827,1619000,"대한"],[1619090,1619700,"리뷰였습니다."],[1619970,1620120,"이"],[1620130,1620380,"모델"],[1620430,1620740,"이후에"]],"textEdited":"익스펙티드 와치 타임을 예측하여서 더 좋은 양질의 추천 결과를 생성하였습니다. 그래서 지금까지 유튜브 추천 모델에 대한 리뷰였습니다. 이 모델 이후에"},{"start":1621000,"end":1634300,"text":"유튜브 추천 논문을 레퍼런스화하는 다양한 실용적인 모델들이 등장하게 됐는데요. 그래서 이 유튜브 레코멘데이션 논문은 여러분들이 이 강의 이후에도 다시 한 번 출력하여서 자세히 읽어보기를 추천드립니다.","confidence":0.9121,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1621250,1621560,"유튜브"],[1621560,1621780,"추천"],[1621790,1622220,"논문을"],[1622510,1623160,"레퍼런스화하는"],[1623290,1623660,"다양한"],[1624230,1624660,"실용적인"],[1624850,1625300,"모델들이"],[1625300,1625667,"등장하게"],[1625667,1626080,"됐는데요."],[1626650,1626807,"그래서"],[1626807,1626907,"이"],[1626907,1627180,"유튜브"],[1627180,1627700,"레코멘데이션"],[1627710,1628080,"논문은"],[1628730,1629260,"여러분들이"],[1629270,1629420,"이"],[1629450,1629700,"강의"],[1629730,1630200,"이후에도"],[1630450,1630667,"다시"],[1630667,1630800,"한"],[1630810,1630960,"번"],[1631470,1632000,"출력하여서"],[1632610,1632940,"자세히"],[1632950,1633460,"읽어보기를"],[1633550,1634100,"추천드립니다."]],"textEdited":"유튜브 추천 논문을 레퍼런스화하는 다양한 실용적인 모델들이 등장하게 됐는데요. 그래서 이 유튜브 레코멘데이션 논문은 여러분들이 이 강의 이후에도 다시 한 번 출력하여서 자세히 읽어보기를 추천드립니다."},{"start":1634300,"end":1646300,"text":"그만큼 중요한 논문이기 때문입니다. 다음은 딥러닝 아키텍처 가운데 하나인 오토 인코더의 개념을 이해하고 이 오토 인코더를 활용한 추천 시스템 모델에 대해서 살펴보겠습니다.","confidence":0.9522,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1634550,1634900,"그만큼"],[1634970,1635260,"중요한"],[1635260,1635640,"논문이기"],[1635640,1636100,"때문입니다."],[1636670,1637040,"다음은"],[1637550,1637960,"딥러닝"],[1637970,1638440,"아키텍처"],[1638440,1638687,"가운데"],[1638687,1638960,"하나인"],[1640030,1640300,"오토"],[1640300,1641200,"인코더의"],[1641210,1641540,"개념을"],[1641540,1641940,"이해하고"],[1642450,1642600,"이"],[1642630,1642900,"오토"],[1642900,1643280,"인코더를"],[1643280,1643580,"활용한"],[1644030,1644300,"추천"],[1644330,1644640,"시스템"],[1644640,1644914,"모델에"],[1644914,1645220,"대해서"],[1645430,1646140,"살펴보겠습니다."]],"textEdited":"그만큼 중요한 논문이기 때문입니다. 다음은 딥러닝 아키텍처 가운데 하나인 오토 인코더의 개념을 이해하고 이 오토 인코더를 활용한 추천 시스템 모델에 대해서 살펴보겠습니다."},{"start":1646300,"end":1658400,"text":"네 먼저 오토 인코더에 대해서 간단히 살펴보겠습니다. 오토 인코더는 입력 값을 넣고 그 입력 값을 아웃풋 레이어에서 똑같이 복원하는 언슈퍼바이스 러닝 모델입니다.","confidence":0.9094,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1646630,1646780,"네"],[1646830,1647080,"먼저"],[1647230,1647500,"오토"],[1647510,1647887,"인코더에"],[1647887,1648140,"대해서"],[1648170,1648520,"간단히"],[1648550,1649240,"살펴보겠습니다."],[1650170,1650440,"오토"],[1650440,1650820,"인코더는"],[1650850,1651100,"입력"],[1651100,1651380,"값을"],[1651380,1651700,"넣고"],[1652210,1652360,"그"],[1652390,1652640,"입력"],[1652670,1653040,"값을"],[1653430,1653820,"아웃풋"],[1653890,1654320,"레이어에서"],[1655170,1655580,"똑같이"],[1655610,1656020,"복원하는"],[1656530,1657220,"언슈퍼바이스"],[1657410,1657660,"러닝"],[1657750,1658260,"모델입니다."]],"textEdited":"네 먼저 오토 인코더에 대해서 간단히 살펴보겠습니다. 오토 인코더는 입력 값을 넣고 그 입력 값을 아웃풋 레이어에서 똑같이 복원하는 언슈퍼바이스 러닝 모델입니다."},{"start":1658400,"end":1672600,"text":"아래 그림을 보시면은 인풋 데이터가 있고요. 이 인풋 데이터가 인코더를 통해서 압축된 레프레젠테이션으로 표현되고요. 이 압축된 레프레젠테이션이 다시 디코더를 통해서 기존 인풋과 최대한 비슷한","confidence":0.9782,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1658630,1658840,"아래"],[1658870,1659160,"그림을"],[1659160,1659640,"보시면은"],[1660530,1660820,"인풋"],[1660890,1661740,"데이터가"],[1661740,1662040,"있고요."],[1662150,1662300,"이"],[1662300,1662520,"인풋"],[1662570,1663000,"데이터가"],[1663550,1664040,"인코더를"],[1664040,1664420,"통해서"],[1664950,1665480,"압축된"],[1665690,1666460,"레프레젠테이션으로"],[1666460,1666980,"표현되고요."],[1667530,1667680,"이"],[1667690,1668020,"압축된"],[1668020,1668740,"레프레젠테이션이"],[1668850,1669120,"다시"],[1669170,1669640,"디코더를"],[1669640,1669920,"통해서"],[1670510,1670740,"기존"],[1670850,1671440,"인풋과"],[1671530,1671800,"최대한"],[1671870,1672220,"비슷한"]],"textEdited":"아래 그림을 보시면은 인풋 데이터가 있고요. 이 인풋 데이터가 인코더를 통해서 압축된 레프레젠테이션으로 표현되고요. 이 압축된 레프레젠테이션이 다시 디코더를 통해서 기존 인풋과 최대한 비슷한"},{"start":1672600,"end":1686000,"text":"RC 스트럭트 된 인풋으로 표현되게 됩니다. 그래서 보통 인코더는 보통 오토 인코더는 인코더와 디코더 구조로 쌍을 이루어서 모델을 이루고 있습니다. 그래서 오토 인코더 모델은 방금 언급한 것처럼 주어진 인풋에 대해서","confidence":0.898,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1672830,1673180,"RC"],[1673230,1673660,"스트럭트"],[1673690,1673840,"된"],[1673930,1674380,"인풋으로"],[1674830,1675260,"표현되게"],[1675260,1675560,"됩니다."],[1675670,1675860,"그래서"],[1675870,1676120,"보통"],[1676130,1676560,"인코더는"],[1677230,1677500,"보통"],[1677500,1677707,"오토"],[1677707,1678100,"인코더는"],[1678270,1678760,"인코더와"],[1678830,1679240,"디코더"],[1679270,1679600,"구조로"],[1679670,1679980,"쌍을"],[1680010,1680360,"이루어서"],[1680450,1680780,"모델을"],[1681110,1681347,"이루고"],[1681347,1681720,"있습니다."],[1682090,1682280,"그래서"],[1682280,1682467,"오토"],[1682467,1682740,"인코더"],[1682740,1683020,"모델은"],[1683450,1683640,"방금"],[1683650,1683914,"언급한"],[1683914,1684220,"것처럼"],[1684470,1684840,"주어진"],[1684990,1685354,"인풋에"],[1685354,1685680,"대해서"]],"textEdited":"RC 스트럭트 된 인풋으로 표현되게 됩니다. 그래서 보통 인코더는 보통 오토 인코더는 인코더와 디코더 구조로 쌍을 이루어서 모델을 이루고 있습니다. 그래서 오토 인코더 모델은 방금 언급한 것처럼 주어진 인풋에 대해서"},{"start":1686000,"end":1697100,"text":"추론된 리컨스트럭트 인풋과 차이를 최대한 줄이는 방법으로 로스 펑션을 구성하고 그래서 이미지 데이터와 같은 경우에는 뭐 루트민 스퀘어 같은 에러를 사용하기도 하고요.","confidence":0.9431,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1686530,1686920,"추론된"],[1687050,1687840,"리컨스트럭트"],[1688310,1688780,"인풋과"],[1689030,1689340,"차이를"],[1689430,1689760,"최대한"],[1689850,1690180,"줄이는"],[1690250,1690660,"방법으로"],[1691170,1691420,"로스"],[1691420,1691760,"펑션을"],[1691760,1692160,"구성하고"],[1692930,1693160,"그래서"],[1693160,1693407,"이미지"],[1693407,1693780,"데이터와"],[1693790,1694007,"같은"],[1694007,1694400,"경우에는"],[1694770,1694920,"뭐"],[1694920,1695240,"루트민"],[1695240,1695560,"스퀘어"],[1695590,1695820,"같은"],[1695830,1696140,"에러를"],[1696140,1696527,"사용하기도"],[1696527,1696920,"하고요."]],"textEdited":"추론된 리컨스트럭트 인풋과 차이를 최대한 줄이는 방법으로 로스 펑션을 구성하고 그래서 이미지 데이터와 같은 경우에는 뭐 루트민 스퀘어 같은 에러를 사용하기도 하고요."},{"start":1697100,"end":1711000,"text":"스퍼스 인풋 데이터 같은 경우에는 소프트 맥스 값을 이용해서 로스 값을 구성하기도 합니다. 그래서 보통 오토 인코더가 활용되는 대표적인 분야는 이상치를 탐지하는 어노말리 디텍션 그리고 중간에 이 히든 레이어가","confidence":0.93,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1697370,1697747,"스퍼스"],[1697747,1697940,"인풋"],[1697940,1698220,"데이터"],[1698220,1698414,"같은"],[1698414,1698780,"경우에는"],[1698810,1699140,"소프트"],[1699140,1699340,"맥스"],[1699340,1699620,"값을"],[1699620,1699960,"이용해서"],[1700130,1700400,"로스"],[1700400,1700700,"값을"],[1700770,1701220,"구성하기도"],[1701220,1701480,"합니다."],[1702450,1702720,"그래서"],[1703110,1703380,"보통"],[1703390,1703660,"오토"],[1703660,1704040,"인코더가"],[1704040,1704400,"활용되는"],[1704450,1704840,"대표적인"],[1704870,1705240,"분야는"],[1705950,1706440,"이상치를"],[1706490,1706960,"탐지하는"],[1707150,1707600,"어노말리"],[1707600,1708040,"디텍션"],[1708890,1709140,"그리고"],[1709330,1709700,"중간에"],[1709700,1709820,"이"],[1709830,1710100,"히든"],[1710130,1710580,"레이어가"]],"textEdited":"스퍼스 인풋 데이터 같은 경우에는 소프트 맥스 값을 이용해서 로스 값을 구성하기도 합니다. 그래서 보통 오토 인코더가 활용되는 대표적인 분야는 이상치를 탐지하는 어노말리 디텍션 그리고 중간에 이 히든 레이어가"},{"start":1711000,"end":1724300,"text":"인풋 데이터를 압축하는 압축된 레프레젠테이션으로 표현되기 때문에 이 레프레젠테이션 러닝을 다른 테스크에도 사용하기도 합니다. 그래서 통상적인 레프레젠테이션 러닝에도 이 오토 인코더가 많이 활용되고요.","confidence":0.9609,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1711270,1711560,"인풋"],[1711630,1712100,"데이터를"],[1712210,1712800,"압축하는"],[1713730,1714200,"압축된"],[1714250,1715180,"레프레젠테이션으로"],[1715190,1715567,"표현되기"],[1715567,1715920,"때문에"],[1716410,1716560,"이"],[1716570,1717260,"레프레젠테이션"],[1717270,1717660,"러닝을"],[1717750,1717940,"다른"],[1718010,1718580,"테스크에도"],[1718630,1719080,"사용하기도"],[1719080,1719340,"합니다."],[1720070,1720280,"그래서"],[1720490,1720940,"통상적인"],[1721170,1721900,"레프레젠테이션"],[1721910,1722400,"러닝에도"],[1722730,1722880,"이"],[1722880,1723087,"오토"],[1723087,1723427,"인코더가"],[1723427,1723600,"많이"],[1723600,1724080,"활용되고요."]],"textEdited":"인풋 데이터를 압축하는 압축된 레프레젠테이션으로 표현되기 때문에 이 레프레젠테이션 러닝을 다른 테스크에도 사용하기도 합니다. 그래서 통상적인 레프레젠테이션 러닝에도 이 오토 인코더가 많이 활용되고요."},{"start":1724300,"end":1736400,"text":"또한 이미지 노이즈를 제공하는 이미지 디노이징 테스크에도 활용됩니다. 원래 오토 인코더는 기존의 이미지를 최대한 비슷하게 복원하는 테스크에서 시작했지만 실제 적용 문화를 찾다 보니","confidence":0.9751,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1725130,1725340,"또한"],[1725370,1725680,"이미지"],[1725690,1726080,"노이즈를"],[1726090,1726480,"제공하는"],[1726690,1727040,"이미지"],[1727050,1727480,"디노이징"],[1727510,1728080,"테스크에도"],[1728080,1728540,"활용됩니다."],[1728970,1729220,"원래"],[1729250,1729500,"오토"],[1729500,1729920,"인코더는"],[1730150,1730500,"기존의"],[1730510,1730940,"이미지를"],[1731050,1731400,"최대한"],[1731450,1731900,"비슷하게"],[1731990,1732500,"복원하는"],[1732990,1733520,"테스크에서"],[1733520,1734020,"시작했지만"],[1734710,1735040,"실제"],[1735070,1735340,"적용"],[1735340,1735620,"문화를"],[1735620,1735880,"찾다"],[1735880,1736100,"보니"]],"textEdited":"또한 이미지 노이즈를 제공하는 이미지 디노이징 테스크에도 활용됩니다. 원래 오토 인코더는 기존의 이미지를 최대한 비슷하게 복원하는 테스크에서 시작했지만 실제 적용 문화를 찾다 보니"},{"start":1736400,"end":1748500,"text":"오히려 노이즈가 있는 이미지에서 노이즈를 없애는 테스크에도 반대로 활용할 수 있게 되었고 괜찮은 성능을 보였습니다. 그래서 이 테스크를 더 잘 수행하기 위해서 이 오토 인코더에서 발전된 모델이 있는데요.","confidence":0.9555,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1736630,1736920,"오히려"],[1736920,1737380,"노이즈가"],[1737390,1737560,"있는"],[1737710,1738320,"이미지에서"],[1738430,1738800,"노이즈를"],[1738830,1739140,"없애는"],[1739150,1740300,"테스크에도"],[1740470,1740760,"반대로"],[1740760,1741060,"활용할"],[1741060,1741120,"수"],[1741120,1741247,"있게"],[1741247,1741660,"되었고"],[1742430,1742760,"괜찮은"],[1742790,1743060,"성능을"],[1743060,1743520,"보였습니다."],[1743650,1743880,"그래서"],[1743880,1744000,"이"],[1744000,1744400,"테스크를"],[1744400,1744520,"더"],[1744530,1744680,"잘"],[1744790,1745160,"수행하기"],[1745160,1745440,"위해서"],[1746190,1746340,"이"],[1746350,1746620,"오토"],[1746620,1747040,"인코더에서"],[1747170,1747560,"발전된"],[1747560,1747814,"모델이"],[1747814,1748180,"있는데요."]],"textEdited":"오히려 노이즈가 있는 이미지에서 노이즈를 없애는 테스크에도 반대로 활용할 수 있게 되었고 괜찮은 성능을 보였습니다. 그래서 이 테스크를 더 잘 수행하기 위해서 이 오토 인코더에서 발전된 모델이 있는데요."},{"start":1748500,"end":1761500,"text":"바로 오토 인코더 앞에 이 디노이징이라는 이름이 붙은 디노이징 오토 인코더입니다. 기존의 입력 데이터는 노이즈가 없는 데이터인데요. 여기에 일부러 그 모델을 설계한 사람이 랜덤 노이즈나","confidence":0.9608,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1748730,1749020,"바로"],[1749110,1749360,"오토"],[1749360,1749640,"인코더"],[1749640,1749860,"앞에"],[1750030,1750180,"이"],[1750190,1751020,"디노이징이라는"],[1751030,1751280,"이름이"],[1751280,1751520,"붙은"],[1751710,1752160,"디노이징"],[1752250,1752480,"오토"],[1752480,1753020,"인코더입니다."],[1753450,1753780,"기존의"],[1753810,1754060,"입력"],[1754070,1754540,"데이터는"],[1755050,1755480,"노이즈가"],[1755490,1755680,"없는"],[1755750,1757060,"데이터인데요."],[1757830,1758200,"여기에"],[1758470,1758800,"일부러"],[1758810,1758960,"그"],[1758960,1759260,"모델을"],[1759290,1759607,"설계한"],[1759607,1759920,"사람이"],[1760510,1760800,"랜덤"],[1760810,1761240,"노이즈나"]],"textEdited":"바로 오토 인코더 앞에 이 디노이징이라는 이름이 붙은 디노이징 오토 인코더입니다. 기존의 입력 데이터는 노이즈가 없는 데이터인데요. 여기에 일부러 그 모델을 설계한 사람이 랜덤 노이즈나"},{"start":1761500,"end":1772500,"text":"드로브 아웃 같은 것을 추가하여서 노이지한 인풋을 강제로 생성해 주게 됩니다. 그래서 이 노이즈 한 인풋을 모델의 입력 값으로 사용하고 인코더와 디코더를 거쳐서","confidence":0.9088,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1761690,1761974,"드로브"],[1761974,1762140,"아웃"],[1762150,1762420,"같은"],[1762750,1763020,"것을"],[1763050,1763560,"추가하여서"],[1764290,1764800,"노이지한"],[1764870,1765320,"인풋을"],[1765490,1765860,"강제로"],[1765930,1766214,"생성해"],[1766214,1766420,"주게"],[1766420,1766700,"됩니다."],[1767010,1767240,"그래서"],[1767240,1767360,"이"],[1767360,1767647,"노이즈"],[1767647,1767780,"한"],[1767830,1768220,"인풋을"],[1768230,1768560,"모델의"],[1768590,1768840,"입력"],[1768890,1769280,"값으로"],[1769330,1769780,"사용하고"],[1770430,1770920,"인코더와"],[1771270,1771780,"디코더를"],[1771780,1772120,"거쳐서"]],"textEdited":"드로브 아웃 같은 것을 추가하여서 노이지한 인풋을 강제로 생성해 주게 됩니다. 그래서 이 노이즈 한 인풋을 모델의 입력 값으로 사용하고 인코더와 디코더를 거쳐서"},{"start":1772500,"end":1785500,"text":"노이즈가 없는 원래 오리지널 이미지로 복원될 수 있도록 학습을 구성합니다. 이제 이렇게 학습할 경우 노이즈 한 인풋을 더 잘 복원해 줄 수 있는 로버스트한 모델이 학습되고 학습 데이터","confidence":0.9597,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1772710,1773160,"노이즈가"],[1773170,1773360,"없는"],[1773470,1773760,"원래"],[1773930,1774320,"오리지널"],[1774390,1774820,"이미지로"],[1774930,1775300,"복원될"],[1775350,1775467,"수"],[1775467,1775800,"있도록"],[1776110,1776460,"학습을"],[1776770,1777260,"구성합니다."],[1777610,1777780,"이제"],[1777790,1778080,"이렇게"],[1778130,1778480,"학습할"],[1778510,1778740,"경우"],[1779050,1779387,"노이즈"],[1779387,1779520,"한"],[1779610,1780080,"인풋을"],[1780330,1780480,"더"],[1780730,1780880,"잘"],[1781150,1781520,"복원해"],[1781520,1781660,"줄"],[1781710,1781827,"수"],[1781827,1782000,"있는"],[1782430,1783020,"로버스트한"],[1783030,1783320,"모델이"],[1783320,1783780,"학습되고"],[1784530,1784780,"학습"],[1784780,1785180,"데이터"]],"textEdited":"노이즈가 없는 원래 오리지널 이미지로 복원될 수 있도록 학습을 구성합니다. 이제 이렇게 학습할 경우 노이즈 한 인풋을 더 잘 복원해 줄 수 있는 로버스트한 모델이 학습되고 학습 데이터"},{"start":1785500,"end":1799400,"text":"에 있는 깨끗한 인풋 데이터에만 오버피팅 되는 오토 인코더가 아니라 이러한 오버피팅 되는 기존의 한계를 극복해서 더 좋은 제너럴라이제이션 성능을 보이는 모델로 발전되게 되었습니다. 그래서 이 디노이즈 오토 인코더가","confidence":0.8977,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1785770,1785920,"에"],[1785930,1786120,"있는"],[1786250,1786600,"깨끗한"],[1786610,1786860,"인풋"],[1786890,1787460,"데이터에만"],[1787730,1788220,"오버피팅"],[1788220,1788400,"되는"],[1788470,1788687,"오토"],[1788687,1789014,"인코더가"],[1789014,1789260,"아니라"],[1789850,1790220,"이러한"],[1790730,1791167,"오버피팅"],[1791167,1791340,"되는"],[1791350,1791640,"기존의"],[1791970,1792340,"한계를"],[1792610,1793140,"극복해서"],[1793330,1793480,"더"],[1793550,1793720,"좋은"],[1793930,1794760,"제너럴라이제이션"],[1794850,1795180,"성능을"],[1795350,1795640,"보이는"],[1795690,1796100,"모델로"],[1796630,1797100,"발전되게"],[1797100,1797560,"되었습니다."],[1797670,1797900,"그래서"],[1797900,1798020,"이"],[1798020,1798420,"디노이즈"],[1798450,1798680,"오토"],[1798680,1799120,"인코더가"]],"textEdited":"에 있는 깨끗한 인풋 데이터에만 오버피팅 되는 오토 인코더가 아니라 이러한 오버피팅 되는 기존의 한계를 극복해서 더 좋은 제너럴라이제이션 성능을 보이는 모델로 발전되게 되었습니다. 그래서 이 디노이즈 오토 인코더가"},{"start":1799400,"end":1813400,"text":"일반적인 오토 인코더 제일 기본적인 오토 인코더보다 여러 테스크에서 좋은 성능을 보였습니다. 사실 지노이징 오토 인코더 이후에도 베리에이셔널 오토 인코더나 컨디셔널 오토 인코더와 같은 더 발전된 형태의 오토 인코더가 계속 등장하고","confidence":0.9471,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1799710,1800140,"일반적인"],[1800140,1800380,"오토"],[1800380,1800700,"인코더"],[1800930,1801120,"제일"],[1801150,1801540,"기본적인"],[1801540,1801760,"오토"],[1801760,1802200,"인코더보다"],[1802570,1802760,"여러"],[1802790,1803300,"테스크에서"],[1803350,1803540,"좋은"],[1803650,1803960,"성능을"],[1803990,1804500,"보였습니다."],[1804850,1805100,"사실"],[1805190,1805620,"지노이징"],[1805630,1805880,"오토"],[1805880,1806240,"인코더"],[1806430,1806940,"이후에도"],[1807490,1808040,"베리에이셔널"],[1808040,1808260,"오토"],[1808260,1808660,"인코더나"],[1809050,1809500,"컨디셔널"],[1809510,1809720,"오토"],[1809720,1810060,"인코더와"],[1810060,1810280,"같은"],[1810370,1810520,"더"],[1810630,1811020,"발전된"],[1811070,1811380,"형태의"],[1811390,1811620,"오토"],[1811620,1812020,"인코더가"],[1812390,1812600,"계속"],[1812650,1813140,"등장하고"]],"textEdited":"일반적인 오토 인코더 제일 기본적인 오토 인코더보다 여러 테스크에서 좋은 성능을 보였습니다. 사실 지노이징 오토 인코더 이후에도 베리에이셔널 오토 인코더나 컨디셔널 오토 인코더와 같은 더 발전된 형태의 오토 인코더가 계속 등장하고"},{"start":1813400,"end":1825900,"text":"이러한 모델도 똑같이 추천 시스템에 사용되긴 했지만 저희는 이런 오토 인코더가 어떻게 발전되었는지에 대한 내용보다는 이 오토 인코더가 도대체 추천 시스템에서 어떤 형태로 활용되는지를 배워야 합니다.","confidence":0.9819,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1813630,1813880,"이러한"],[1813890,1814240,"모델도"],[1814350,1814700,"똑같이"],[1814730,1814980,"추천"],[1814980,1815340,"시스템에"],[1815340,1815720,"사용되긴"],[1815720,1816020,"했지만"],[1816790,1817120,"저희는"],[1817130,1817300,"이런"],[1817350,1817600,"오토"],[1817600,1818540,"인코더가"],[1818630,1818920,"어떻게"],[1818970,1819840,"발전되었는지에"],[1819850,1820060,"대한"],[1820230,1820820,"내용보다는"],[1821410,1821560,"이"],[1821560,1821800,"오토"],[1821800,1822160,"인코더가"],[1822160,1822460,"도대체"],[1822510,1822760,"추천"],[1822790,1823280,"시스템에서"],[1823350,1823600,"어떤"],[1823690,1824040,"형태로"],[1824040,1825200,"활용되는지를"],[1825210,1825467,"배워야"],[1825467,1825900,"합니다."]],"textEdited":"이러한 모델도 똑같이 추천 시스템에 사용되긴 했지만 저희는 이런 오토 인코더가 어떻게 발전되었는지에 대한 내용보다는 이 오토 인코더가 도대체 추천 시스템에서 어떤 형태로 활용되는지를 배워야 합니다."},{"start":1825900,"end":1836800,"text":"그래서 앞으로 두 개의 모델을 다루면서 추천 시스템의 오토 인코더가 어떻게 적용되어 있는지 학습해 봅시다. 네 그래서 다음으로 살펴볼 논문은 오토렉입니다.","confidence":0.9299,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1826550,1826820,"그래서"],[1827350,1827740,"앞으로"],[1827830,1827947,"두"],[1827947,1828180,"개의"],[1828190,1828520,"모델을"],[1828520,1828960,"다루면서"],[1829210,1829480,"추천"],[1829490,1829880,"시스템의"],[1829890,1830140,"오토"],[1830140,1830520,"인코더가"],[1830520,1830800,"어떻게"],[1830810,1831220,"적용되어"],[1831220,1831560,"있는지"],[1832050,1832380,"학습해"],[1832380,1832680,"봅시다."],[1833230,1833380,"네"],[1833380,1833600,"그래서"],[1833630,1834080,"다음으로"],[1834150,1834500,"살펴볼"],[1834510,1834880,"논문은"],[1835530,1836680,"오토렉입니다."]],"textEdited":"그래서 앞으로 두 개의 모델을 다루면서 추천 시스템의 오토 인코더가 어떻게 적용되어 있는지 학습해 봅시다. 네 그래서 다음으로 살펴볼 논문은 오토렉입니다."},{"start":1836800,"end":1851800,"text":"이 모델은 굉장히 간단하고 논문의 길이도 두 장으로 굉장히 짧은데요. 기존의 오토인코더를 컬래버레이트 필터링에 적용하여서 유저와 아이템에 대한 인베딩을 더 잘 표현하고 반대로 복잡도는","confidence":0.9448,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1837310,1837460,"이"],[1837490,1838000,"모델은"],[1838190,1838480,"굉장히"],[1838550,1839040,"간단하고"],[1839290,1839680,"논문의"],[1839680,1840000,"길이도"],[1840150,1840300,"두"],[1840300,1840620,"장으로"],[1840630,1840900,"굉장히"],[1840930,1841400,"짧은데요."],[1841870,1842200,"기존의"],[1842200,1842900,"오토인코더를"],[1843610,1844140,"컬래버레이트"],[1844170,1845040,"필터링에"],[1845070,1845660,"적용하여서"],[1846390,1846780,"유저와"],[1846830,1847340,"아이템에"],[1847570,1847780,"대한"],[1847930,1848460,"인베딩을"],[1848890,1849040,"더"],[1849130,1849280,"잘"],[1849370,1849800,"표현하고"],[1849990,1850340,"반대로"],[1850790,1851320,"복잡도는"]],"textEdited":"이 모델은 굉장히 간단하고 논문의 길이도 두 장으로 굉장히 짧은데요. 기존의 오토인코더를 컬래버레이트 필터링에 적용하여서 유저와 아이템에 대한 인베딩을 더 잘 표현하고 반대로 복잡도는"},{"start":1851800,"end":1864300,"text":"줄인 모델입니다. 아까 언급했던 것처럼 오토인코더는 레프레젠테이션 러닝 측면에서 좋은 성능을 내기 때문에 다양한 다운스트림 테스크에 많이 응용된다고 했죠. 이를 그대로 추천 시스템에 적용하면은","confidence":0.9546,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1852050,1852320,"줄인"],[1852370,1852860,"모델입니다."],[1853090,1853320,"아까"],[1853410,1853847,"언급했던"],[1853847,1854180,"것처럼"],[1854570,1855260,"오토인코더는"],[1855970,1856660,"레프레젠테이션"],[1856670,1856920,"러닝"],[1857010,1857400,"측면에서"],[1857510,1857680,"좋은"],[1857830,1858120,"성능을"],[1858120,1858300,"내기"],[1858300,1858640,"때문에"],[1859250,1859580,"다양한"],[1859610,1860060,"다운스트림"],[1860070,1860427,"테스크에"],[1860427,1860600,"많이"],[1860710,1861207,"응용된다고"],[1861207,1861480,"했죠."],[1861890,1862100,"이를"],[1862130,1862400,"그대로"],[1862430,1862680,"추천"],[1862680,1863120,"시스템에"],[1863290,1863840,"적용하면은"]],"textEdited":"줄인 모델입니다. 아까 언급했던 것처럼 오토인코더는 레프레젠테이션 러닝 측면에서 좋은 성능을 내기 때문에 다양한 다운스트림 테스크에 많이 응용된다고 했죠. 이를 그대로 추천 시스템에 적용하면은"},{"start":1864300,"end":1878100,"text":"유저와 아이템의 인베딩을 오토 인코더를 활용하면은 좋은 레프리젠테이션을 만들 수 있기 때문에 이 원리를 사용하여서 오토렉이 등장하게 되었습니다. 본 논문의 아이디어는 다음과 같습니다.","confidence":0.924,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1864590,1865060,"유저와"],[1865090,1865560,"아이템의"],[1865590,1866100,"인베딩을"],[1866330,1866580,"오토"],[1866590,1866980,"인코더를"],[1866980,1867480,"활용하면은"],[1868310,1868480,"좋은"],[1868650,1869400,"레프리젠테이션을"],[1869400,1869660,"만들"],[1869660,1869754,"수"],[1869754,1869894,"있기"],[1869894,1870260,"때문에"],[1870970,1871120,"이"],[1871210,1871520,"원리를"],[1871520,1871960,"사용하여서"],[1872450,1873020,"오토렉이"],[1873230,1873700,"등장하게"],[1873700,1874200,"되었습니다."],[1875730,1875880,"본"],[1875950,1876320,"논문의"],[1876320,1876760,"아이디어는"],[1876760,1877060,"다음과"],[1877060,1877460,"같습니다."]],"textEdited":"유저와 아이템의 인베딩을 오토 인코더를 활용하면은 좋은 레프리젠테이션을 만들 수 있기 때문에 이 원리를 사용하여서 오토렉이 등장하게 되었습니다. 본 논문의 아이디어는 다음과 같습니다."},{"start":1878100,"end":1889800,"text":"오토 인코더의 입력 데이터를 레이팅 벡터, 즉 유저가 아이템에 매긴 평점 벡터로 사용한다는 것입니다. 아까 전에 예시에서는 이미지 데이터를 가지고 복원을 했는데요. 여기서는 이미지 데이터가 아니라","confidence":0.9812,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1878410,1878740,"오토"],[1878750,1879220,"인코더의"],[1879330,1879600,"입력"],[1879690,1880180,"데이터를"],[1880710,1881080,"레이팅"],[1881130,1881420,"벡터,"],[1881490,1881640,"즉"],[1881670,1882000,"유저가"],[1882000,1882380,"아이템에"],[1882380,1882560,"매긴"],[1882690,1883020,"평점"],[1883090,1883440,"벡터로"],[1883440,1883887,"사용한다는"],[1883887,1884300,"것입니다."],[1884910,1885120,"아까"],[1885120,1885380,"전에"],[1885730,1886300,"예시에서는"],[1886450,1886780,"이미지"],[1886780,1887180,"데이터를"],[1887180,1887420,"가지고"],[1887450,1887747,"복원을"],[1887747,1888100,"했는데요."],[1888290,1888620,"여기서는"],[1888630,1888940,"이미지"],[1888940,1889254,"데이터가"],[1889254,1889500,"아니라"]],"textEdited":"오토 인코더의 입력 데이터를 레이팅 벡터, 즉 유저가 아이템에 매긴 평점 벡터로 사용한다는 것입니다. 아까 전에 예시에서는 이미지 데이터를 가지고 복원을 했는데요. 여기서는 이미지 데이터가 아니라"},{"start":1889800,"end":1901100,"text":"레이팅 데이터를 입력으로 하고 출력으로 하여서 이 레이팅 벡터를 복원하는 테스크를 수행합니다. 즉 유저나 아이템을 기준으로 기존에 주어진 평점 데이터를 그대로 복원하는 것이죠.","confidence":0.9387,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1890030,1890440,"레이팅"],[1890470,1890940,"데이터를"],[1891110,1891600,"입력으로"],[1891690,1891920,"하고"],[1892090,1892467,"출력으로"],[1892467,1892760,"하여서"],[1893110,1893260,"이"],[1893270,1893640,"레이팅"],[1893930,1894320,"벡터를"],[1894450,1894860,"복원하는"],[1895110,1895520,"테스크를"],[1895520,1895940,"수행합니다."],[1896290,1896440,"즉"],[1896450,1896820,"유저나"],[1896830,1897240,"아이템을"],[1897240,1897620,"기준으로"],[1897790,1898140,"기존에"],[1898830,1899140,"주어진"],[1899210,1899480,"평점"],[1899480,1899880,"데이터를"],[1900010,1900260,"그대로"],[1900290,1900660,"복원하는"],[1900660,1900940,"것이죠."]],"textEdited":"레이팅 데이터를 입력으로 하고 출력으로 하여서 이 레이팅 벡터를 복원하는 테스크를 수행합니다. 즉 유저나 아이템을 기준으로 기존에 주어진 평점 데이터를 그대로 복원하는 것이죠."},{"start":1901100,"end":1914700,"text":"유저와 아이템의 벡터를 저차원의 레이턴트 피처로 나타내고 이를 사용해 평점을 예측합니다. 다음은 매트리스 팩토라이제이션과 간단히 비교해 볼 텐데요. 이 매트리스 팩토라이제이션은 리니어하고 로우 오더 한 인터랙션","confidence":0.9271,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1901610,1901980,"유저와"],[1902070,1902840,"아이템의"],[1902890,1903280,"벡터를"],[1903630,1904220,"저차원의"],[1904230,1904700,"레이턴트"],[1904700,1905020,"피처로"],[1905020,1905460,"나타내고"],[1905530,1905740,"이를"],[1905750,1906040,"사용해"],[1906110,1906480,"평점을"],[1906570,1907080,"예측합니다."],[1907710,1908060,"다음은"],[1908130,1908480,"매트리스"],[1908480,1909200,"팩토라이제이션과"],[1909210,1909500,"간단히"],[1909500,1909767,"비교해"],[1909767,1909900,"볼"],[1909900,1910220,"텐데요."],[1911090,1911207,"이"],[1911207,1911540,"매트리스"],[1911540,1912240,"팩토라이제이션은"],[1912470,1913100,"리니어하고"],[1913430,1913700,"로우"],[1913700,1913894,"오더"],[1913894,1914020,"한"],[1914090,1914560,"인터랙션"]],"textEdited":"유저와 아이템의 벡터를 저차원의 레이턴트 피처로 나타내고 이를 사용해 평점을 예측합니다. 다음은 매트리스 팩토라이제이션과 간단히 비교해 볼 텐데요. 이 매트리스 팩토라이제이션은 리니어하고 로우 오더 한 인터랙션"},{"start":1914700,"end":1926700,"text":"을 통해 레프레젠테이션이 학습되기 때문에 그 표현력에 어느 정도 한계가 있지만 오토랙 같은 경우에는 논 리니언 a티베이션 펑션을 사용하기 때문에 좀 더 복잡한 인터랙션이","confidence":0.9565,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1914970,1915120,"을"],[1915130,1915360,"통해"],[1915890,1916640,"레프레젠테이션이"],[1916650,1917007,"학습되기"],[1917007,1917360,"때문에"],[1917750,1917900,"그"],[1917950,1918460,"표현력에"],[1918630,1918754,"어느"],[1918754,1918960,"정도"],[1918990,1919320,"한계가"],[1919510,1919820,"있지만"],[1920710,1921080,"오토랙"],[1921090,1921360,"같은"],[1921390,1921780,"경우에는"],[1921890,1922040,"논"],[1922190,1922520,"리니언"],[1922610,1923080,"a티베이션"],[1923170,1923500,"펑션을"],[1923500,1923787,"사용하기"],[1923787,1924160,"때문에"],[1924730,1924880,"좀"],[1924890,1925040,"더"],[1925170,1925560,"복잡한"],[1925590,1926180,"인터랙션이"]],"textEdited":"을 통해 레프레젠테이션이 학습되기 때문에 그 표현력에 어느 정도 한계가 있지만 오토랙 같은 경우에는 논 리니언 a티베이션 펑션을 사용하기 때문에 좀 더 복잡한 인터랙션이"},{"start":1926700,"end":1937300,"text":"표현되게 됩니다. 네 다음은 오토랙을 그림으로 표현해 보았습니다. 상당히 간단한데요. 인풋과 아웃풋은 아까 얘기했던 것처럼","confidence":0.9609,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1927590,1928040,"표현되게"],[1928150,1928480,"됩니다."],[1929290,1929440,"네"],[1929610,1929960,"다음은"],[1930310,1930900,"오토랙을"],[1931330,1931720,"그림으로"],[1931730,1931987,"표현해"],[1931987,1932480,"보았습니다."],[1933250,1933540,"상당히"],[1933570,1934120,"간단한데요."],[1935190,1935620,"인풋과"],[1935620,1936040,"아웃풋은"],[1936050,1936240,"아까"],[1936270,1936647,"얘기했던"],[1936647,1936960,"것처럼"]],"textEdited":"표현되게 됩니다. 네 다음은 오토랙을 그림으로 표현해 보았습니다. 상당히 간단한데요. 인풋과 아웃풋은 아까 얘기했던 것처럼"},{"start":1937300,"end":1950500,"text":"레이팅 벡터가 되는데요. 유저나 아이템을 기준으로 레이팅 벡터를 만들 수 있습니다. 아래 그림은 아이템을 기준으로 전체 유저에 대한 레이팅을 구성한 것입니다. 그래서","confidence":0.9804,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1937590,1937940,"레이팅"],[1937990,1938307,"벡터가"],[1938307,1938700,"되는데요."],[1939450,1939880,"유저나"],[1939910,1940660,"아이템을"],[1940710,1941120,"기준으로"],[1942010,1942340,"레이팅"],[1942370,1942680,"벡터를"],[1942680,1942880,"만들"],[1942880,1942967,"수"],[1942967,1943340,"있습니다."],[1943890,1944120,"아래"],[1944120,1944400,"그림은"],[1944970,1945480,"아이템을"],[1945490,1945840,"기준으로"],[1945970,1946340,"전체"],[1946410,1946727,"유저에"],[1946727,1946920,"대한"],[1946970,1948140,"레이팅을"],[1948750,1949047,"구성한"],[1949047,1949460,"것입니다."],[1949790,1950040,"그래서"]],"textEdited":"레이팅 벡터가 되는데요. 유저나 아이템을 기준으로 레이팅 벡터를 만들 수 있습니다. 아래 그림은 아이템을 기준으로 전체 유저에 대한 레이팅을 구성한 것입니다. 그래서"},{"start":1950500,"end":1961100,"text":"이 알아는 아이템 아의 레이팅 벡터가 되고요. 각각의 이 레이팅 벡터는 하나하나가 개별 유저와 아이템의 평점으로 이루어져 있습니다.","confidence":0.8988,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1950790,1950940,"이"],[1951090,1952100,"알아는"],[1952210,1952560,"아이템"],[1952750,1953880,"아의"],[1953910,1954240,"레이팅"],[1954290,1954607,"벡터가"],[1954607,1954960,"되고요."],[1955330,1955880,"각각의"],[1956090,1956240,"이"],[1956240,1956580,"레이팅"],[1956650,1957060,"벡터는"],[1958090,1958600,"하나하나가"],[1958810,1959060,"개별"],[1959090,1959420,"유저와"],[1959430,1959840,"아이템의"],[1960010,1960380,"평점으로"],[1960380,1960660,"이루어져"],[1960660,1961100,"있습니다."]],"textEdited":"이 알아는 아이템 아의 레이팅 벡터가 되고요. 각각의 이 레이팅 벡터는 하나하나가 개별 유저와 아이템의 평점으로 이루어져 있습니다."},{"start":1961100,"end":1969000,"text":"그래서 이 전체 아이템 벡터의 차원은 m 차원 즉 유저 전체의 수와 같게 되고요. 이제 이 레이팅 벡터는","confidence":0.9798,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1961330,1961580,"그래서"],[1961590,1961740,"이"],[1961770,1962080,"전체"],[1962590,1962960,"아이템"],[1963030,1963420,"벡터의"],[1963510,1963880,"차원은"],[1964270,1964420,"m"],[1964570,1964820,"차원"],[1964950,1965100,"즉"],[1965110,1965380,"유저"],[1965390,1965860,"전체의"],[1965870,1966160,"수와"],[1966170,1966407,"같게"],[1966407,1966720,"되고요."],[1967130,1967300,"이제"],[1967470,1967620,"이"],[1967690,1968040,"레이팅"],[1968070,1968480,"벡터는"]],"textEdited":"그래서 이 전체 아이템 벡터의 차원은 m 차원 즉 유저 전체의 수와 같게 되고요. 이제 이 레이팅 벡터는"},{"start":1969000,"end":1979700,"text":"인코더의 가중치 행렬인 v와 곱해져서 가운데 있는 덴 싼 레프레젠테이션이 표현되게 됩니다. 그리고 다시 이 덴싼 레프레젠테이션은 디코더의 가중치 행렬","confidence":0.8758,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1969710,1970280,"인코더의"],[1970690,1971120,"가중치"],[1971120,1971400,"행렬인"],[1971450,1971780,"v와"],[1971810,1972320,"곱해져서"],[1972590,1972960,"가운데"],[1972990,1973200,"있는"],[1973650,1973800,"덴"],[1973890,1974040,"싼"],[1974170,1974880,"레프레젠테이션이"],[1974880,1975194,"표현되게"],[1975194,1975420,"됩니다."],[1975470,1975720,"그리고"],[1975790,1976060,"다시"],[1976150,1976300,"이"],[1976430,1976720,"덴싼"],[1976750,1977480,"레프레젠테이션은"],[1977870,1978460,"디코더의"],[1978490,1978880,"가중치"],[1978910,1979140,"행렬"]],"textEdited":"인코더의 가중치 행렬인 v와 곱해져서 가운데 있는 덴 싼 레프레젠테이션이 표현되게 됩니다. 그리고 다시 이 덴싼 레프레젠테이션은 디코더의 가중치 행렬"},{"start":1979700,"end":1989500,"text":"웨이트 매트릭스가 곱해져서 다시 원래의 레이팅 매트릭스 즉 m 차원의 아이템 벡터로 복원되게 됩니다. 모델이 학습이 수행될 때는","confidence":0.9594,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1980110,1980400,"웨이트"],[1980400,1980820,"매트릭스가"],[1980820,1981260,"곱해져서"],[1981950,1982220,"다시"],[1982290,1982900,"원래의"],[1983330,1983640,"레이팅"],[1983690,1984300,"매트릭스"],[1984450,1984600,"즉"],[1984650,1984800,"m"],[1984890,1985260,"차원의"],[1985410,1985800,"아이템"],[1985950,1986320,"벡터로"],[1986430,1986880,"복원되게"],[1986880,1987180,"됩니다."],[1987790,1988160,"모델이"],[1988190,1988520,"학습이"],[1988550,1988900,"수행될"],[1988900,1989140,"때는"]],"textEdited":"웨이트 매트릭스가 곱해져서 다시 원래의 레이팅 매트릭스 즉 m 차원의 아이템 벡터로 복원되게 됩니다. 모델이 학습이 수행될 때는"},{"start":1989500,"end":2002200,"text":"기존의 실제 레이팅과 모델을 통해서 리컨스트렉트 된 레이팅에 루트 미스크 에러 즉 두 개의 차이의 제곱의 루트를 씌운 값을 최소화하는 방향으로 학습되게 됩니다.","confidence":0.8938,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1989790,1990160,"기존의"],[1990330,1990580,"실제"],[1990590,1991140,"레이팅과"],[1991510,1991920,"모델을"],[1991920,1992220,"통해서"],[1992470,1993287,"리컨스트렉트"],[1993287,1993420,"된"],[1993530,1994200,"레이팅에"],[1995030,1995287,"루트"],[1995287,1995640,"미스크"],[1995690,1995920,"에러"],[1996350,1996500,"즉"],[1997310,1997427,"두"],[1997427,1997680,"개의"],[1997970,1998320,"차이의"],[1998330,1999360,"제곱의"],[1999360,1999720,"루트를"],[1999720,1999920,"씌운"],[1999950,2000280,"값을"],[2000350,2000800,"최소화하는"],[2000830,2001220,"방향으로"],[2001370,2001787,"학습되게"],[2001787,2002160,"됩니다."]],"textEdited":"기존의 실제 레이팅과 모델을 통해서 리컨스트렉트 된 레이팅에 루트 미스크 에러 즉 두 개의 차이의 제곱의 루트를 씌운 값을 최소화하는 방향으로 학습되게 됩니다."},{"start":2002200,"end":2014700,"text":"그리고 이 에러는 전체 레이팅이 아니라 우리가 갖고 있는 관측된 데이터에 대해서만 학습을 하고 그 관측된 데이터의 로스만 가지고 각각의 파라미터를 업데이트합니다.","confidence":0.9877,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2002430,2002700,"그리고"],[2002790,2002940,"이"],[2003690,2004100,"에러는"],[2004590,2004940,"전체"],[2004970,2005387,"레이팅이"],[2005387,2005640,"아니라"],[2006250,2006500,"우리가"],[2006510,2006707,"갖고"],[2006707,2006860,"있는"],[2006990,2007520,"관측된"],[2007570,2008120,"데이터에"],[2008120,2008600,"대해서만"],[2009090,2009400,"학습을"],[2009400,2009620,"하고"],[2010230,2010380,"그"],[2010410,2010760,"관측된"],[2010760,2011180,"데이터의"],[2011510,2011920,"로스만"],[2011990,2012320,"가지고"],[2012630,2013020,"각각의"],[2013470,2013980,"파라미터를"],[2013980,2014700,"업데이트합니다."]],"textEdited":"그리고 이 에러는 전체 레이팅이 아니라 우리가 갖고 있는 관측된 데이터에 대해서만 학습을 하고 그 관측된 데이터의 로스만 가지고 각각의 파라미터를 업데이트합니다."},{"start":2014700,"end":2029300,"text":"여기에 있는 이 이치라는 수식이 오토 인코더를 나타내는 펑션이고요. 이 치라는 수식을 살펴보면은 원래 레이팅 값에 인코더의 가중치 매트릭스를 곱하고 거기에 이제 뮤를 라는 바이어스를 더해서","confidence":0.8982,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2014910,2015134,"여기에"],[2015134,2015280,"있는"],[2015280,2015400,"이"],[2015430,2016060,"이치라는"],[2016090,2016460,"수식이"],[2016610,2016880,"오토"],[2016890,2017520,"인코더를"],[2017530,2018020,"나타내는"],[2018530,2019080,"펑션이고요."],[2019810,2019960,"이"],[2020110,2020460,"치라는"],[2020490,2020860,"수식을"],[2021270,2021880,"살펴보면은"],[2022630,2022880,"원래"],[2022890,2023240,"레이팅"],[2023290,2023620,"값에"],[2024050,2024560,"인코더의"],[2024990,2025340,"가중치"],[2025340,2025800,"매트릭스를"],[2025810,2026240,"곱하고"],[2026850,2027160,"거기에"],[2027170,2027340,"이제"],[2027490,2027820,"뮤를"],[2028030,2028240,"라는"],[2028270,2028707,"바이어스를"],[2028707,2029040,"더해서"]],"textEdited":"여기에 있는 이 이치라는 수식이 오토 인코더를 나타내는 펑션이고요. 이 치라는 수식을 살펴보면은 원래 레이팅 값에 인코더의 가중치 매트릭스를 곱하고 거기에 이제 뮤를 라는 바이어스를 더해서"},{"start":2029300,"end":2042600,"text":"쥐라는 액티베이션 펑션을 씌우게 되면은 이 쥐라는 값은 가운데에 있는 레프레젠테이션이 되고요. 다시 이 가운데에 있는 레프레젠테이션에 디코더의 매트릭스를 곱하고 다시 거기에 가중치","confidence":0.9318,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2029590,2030060,"쥐라는"],[2030510,2030980,"액티베이션"],[2031030,2031420,"펑션을"],[2031850,2032167,"씌우게"],[2032167,2032520,"되면은"],[2033010,2033160,"이"],[2033210,2033600,"쥐라는"],[2033600,2033900,"값은"],[2034110,2034600,"가운데에"],[2034600,2034760,"있는"],[2034850,2035554,"레프레젠테이션이"],[2035554,2035900,"되고요."],[2036430,2036720,"다시"],[2036810,2036960,"이"],[2037010,2037340,"가운데에"],[2037340,2037480,"있는"],[2037480,2038180,"레프레젠테이션에"],[2038650,2039280,"디코더의"],[2040270,2040720,"매트릭스를"],[2040730,2041140,"곱하고"],[2041310,2041580,"다시"],[2041590,2041860,"거기에"],[2041890,2042340,"가중치"]],"textEdited":"쥐라는 액티베이션 펑션을 씌우게 되면은 이 쥐라는 값은 가운데에 있는 레프레젠테이션이 되고요. 다시 이 가운데에 있는 레프레젠테이션에 디코더의 매트릭스를 곱하고 다시 거기에 가중치"},{"start":2042600,"end":2048800,"text":"바이러스를 더해주면 최종적으로 디코더를 통과한 리컨스트럭티드 레이팅이 구해집니다.","confidence":0.9258,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2042810,2043340,"바이러스를"],[2043350,2043800,"더해주면"],[2044010,2044620,"최종적으로"],[2045370,2045820,"디코더를"],[2045930,2046260,"통과한"],[2046570,2047440,"리컨스트럭티드"],[2047530,2048000,"레이팅이"],[2048230,2048740,"구해집니다."]],"textEdited":"바이러스를 더해주면 최종적으로 디코더를 통과한 리컨스트럭티드 레이팅이 구해집니다."},{"start":2048800,"end":2062300,"text":"그래서 이 치와 실제 레이팅 사이의 차이를 최소화하는 방향으로 각각의 브블 그리고 뮤비가 학습이 됩니다. 본 논문에서는 이 활성화 함수 g와 f","confidence":0.7933,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2049010,2049207,"그래서"],[2049207,2049340,"이"],[2049590,2049900,"치와"],[2050150,2050420,"실제"],[2050420,2050760,"레이팅"],[2050790,2051160,"사이의"],[2051330,2051800,"차이를"],[2052330,2052800,"최소화하는"],[2052830,2053240,"방향으로"],[2053770,2054200,"각각의"],[2054290,2055180,"브블"],[2055510,2055820,"그리고"],[2056290,2056880,"뮤비가"],[2057070,2057347,"학습이"],[2057347,2057680,"됩니다."],[2058450,2058600,"본"],[2058630,2059180,"논문에서는"],[2059930,2060080,"이"],[2060490,2060860,"활성화"],[2060870,2061140,"함수"],[2061290,2061580,"g와"],[2061750,2061900,"f"]],"textEdited":"그래서 이 치와 실제 레이팅 사이의 차이를 최소화하는 방향으로 각각의 브블 그리고 뮤비가 학습이 됩니다. 본 논문에서는 이 활성화 함수 g와 f"},{"start":2062300,"end":2070800,"text":"를 시그모이드와 아이덴티티 펑션으로 사용했다고 말합니다. 어떤 활성화 함수를 사용하느냐에 따라서 약간의 성능 차이는 발생한다고 합니다.","confidence":0.9309,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2062530,2062680,"를"],[2062990,2063900,"시그모이드와"],[2064010,2064580,"아이덴티티"],[2064630,2065080,"펑션으로"],[2065470,2066020,"사용했다고"],[2066020,2066400,"말합니다."],[2066970,2067200,"어떤"],[2067290,2067640,"활성화"],[2067640,2067960,"함수를"],[2067960,2068407,"사용하느냐에"],[2068407,2068700,"따라서"],[2068790,2069140,"약간의"],[2069210,2069460,"성능"],[2069470,2069800,"차이는"],[2069970,2070500,"발생한다고"],[2070500,2070740,"합니다."]],"textEdited":"를 시그모이드와 아이덴티티 펑션으로 사용했다고 말합니다. 어떤 활성화 함수를 사용하느냐에 따라서 약간의 성능 차이는 발생한다고 합니다."},{"start":2070800,"end":2081700,"text":"사실 오토랙 같은 경우에는 지금으로부터 거의 7년 전인 2015년에 발표된 논문이기 때문에 좀 오래된 페이퍼이기도 하고요. 상당히 간단한 딥러닝 구조를 사용하고 있습니다.","confidence":0.9795,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2071090,2071340,"사실"],[2071350,2071740,"오토랙"],[2071830,2072087,"같은"],[2072087,2072520,"경우에는"],[2072850,2073380,"지금으로부터"],[2073380,2073540,"거의"],[2073650,2073920,"7년"],[2073920,2074180,"전인"],[2074250,2074980,"2015년에"],[2075030,2075360,"발표된"],[2075360,2075760,"논문이기"],[2075760,2076120,"때문에"],[2076750,2076900,"좀"],[2076930,2077240,"오래된"],[2077330,2077960,"페이퍼이기도"],[2077960,2078260,"하고요."],[2078970,2079260,"상당히"],[2079370,2079860,"간단한"],[2079970,2080380,"딥러닝"],[2080610,2080920,"구조를"],[2080920,2081240,"사용하고"],[2081240,2081640,"있습니다."]],"textEdited":"사실 오토랙 같은 경우에는 지금으로부터 거의 7년 전인 2015년에 발표된 논문이기 때문에 좀 오래된 페이퍼이기도 하고요. 상당히 간단한 딥러닝 구조를 사용하고 있습니다."},{"start":2081700,"end":2094800,"text":"따라서 당시에 좋은 성능을 보이던 모델도 굉장히 단순한 모델인 r비엠과 매트리스 팩토라이제이션이 있었고 그래서 그 두 가지 모델과의 추천 성능을 비교하였습니다. 이 레이팅을 예측하는 모델이기 때문에","confidence":0.9468,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2081910,2082220,"따라서"],[2082350,2082720,"당시에"],[2082730,2082920,"좋은"],[2083030,2083340,"성능을"],[2083340,2083640,"보이던"],[2083810,2084440,"모델도"],[2084650,2084920,"굉장히"],[2084990,2085340,"단순한"],[2085340,2085660,"모델인"],[2086050,2086680,"r비엠과"],[2087070,2087460,"매트리스"],[2087460,2088307,"팩토라이제이션이"],[2088307,2088680,"있었고"],[2088770,2089000,"그래서"],[2089000,2089140,"그"],[2089150,2089300,"두"],[2089300,2089560,"가지"],[2089630,2090160,"모델과의"],[2090610,2090900,"추천"],[2090970,2091320,"성능을"],[2091610,2092440,"비교하였습니다."],[2092830,2092980,"이"],[2092980,2093400,"레이팅을"],[2093400,2093800,"예측하는"],[2093800,2094127,"모델이기"],[2094127,2094500,"때문에"]],"textEdited":"따라서 당시에 좋은 성능을 보이던 모델도 굉장히 단순한 모델인 r비엠과 매트리스 팩토라이제이션이 있었고 그래서 그 두 가지 모델과의 추천 성능을 비교하였습니다. 이 레이팅을 예측하는 모델이기 때문에"},{"start":2094800,"end":2105500,"text":"로스 펑션은 알엠에스이로 구성하였고, 이 RMSE를 기준으로 기존의 알비엠이나 엠프와 같은 모델보다 더 좋은 성능을 보임을 알 수 있습니다.","confidence":0.6039,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2095030,2095320,"로스"],[2095350,2095720,"펑션은"],[2095850,2097780,"알엠에스이로"],[2097990,2098580,"구성하였고,"],[2099010,2099160,"이"],[2099310,2100080,"RMSE를"],[2100090,2100480,"기준으로"],[2100610,2100920,"기존의"],[2101010,2101600,"알비엠이나"],[2101650,2102400,"엠프와"],[2102430,2102660,"같은"],[2102670,2103120,"모델보다"],[2103290,2103440,"더"],[2103590,2103780,"좋은"],[2103910,2104240,"성능을"],[2104240,2104560,"보임을"],[2104610,2104760,"알"],[2104760,2104834,"수"],[2104834,2105300,"있습니다."]],"textEdited":"로스 펑션은 알엠에스이로 구성하였고, 이 RMSE를 기준으로 기존의 알비엠이나 엠프와 같은 모델보다 더 좋은 성능을 보임을 알 수 있습니다."},{"start":2105500,"end":2116000,"text":"또한 가운데 인코더 디코더 레이어 가운데에 있는 레프리젠테이션 레이어의 노드 개수가 점점 늘어날수록 알엠스는 감소하는 것을 볼 수 있는데요.","confidence":0.8429,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2105770,2106000,"또한"],[2106090,2106540,"가운데"],[2107630,2108020,"인코더"],[2108030,2108380,"디코더"],[2108380,2108620,"레이어"],[2109010,2109480,"가운데에"],[2109480,2109680,"있는"],[2109930,2110620,"레프리젠테이션"],[2110670,2111000,"레이어의"],[2111000,2111240,"노드"],[2111270,2111620,"개수가"],[2111910,2112240,"점점"],[2112270,2112880,"늘어날수록"],[2113710,2114380,"알엠스는"],[2114450,2114847,"감소하는"],[2114847,2115080,"것을"],[2115080,2115200,"볼"],[2115200,2115294,"수"],[2115294,2115860,"있는데요."]],"textEdited":"또한 가운데 인코더 디코더 레이어 가운데에 있는 레프리젠테이션 레이어의 노드 개수가 점점 늘어날수록 알엠스는 감소하는 것을 볼 수 있는데요."},{"start":2116000,"end":2126100,"text":"이 노드의 개수는 가운데에 있는 히든 레이어 즉 유저와 아이템의 벡터를 몇 차원으로 레프레젠테이션 하느냐를 의미하는 것입니다. 물론","confidence":0.9454,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2116230,2116380,"이"],[2116380,2116740,"노드의"],[2116770,2117200,"개수는"],[2117770,2118240,"가운데에"],[2118240,2118400,"있는"],[2118710,2118980,"히든"],[2118990,2119300,"레이어"],[2119450,2119600,"즉"],[2119630,2119980,"유저와"],[2120050,2120620,"아이템의"],[2120750,2121180,"벡터를"],[2121530,2121680,"몇"],[2121810,2122240,"차원으로"],[2122270,2122960,"레프레젠테이션"],[2123210,2123800,"하느냐를"],[2123810,2124220,"의미하는"],[2124220,2124620,"것입니다."],[2125410,2125640,"물론"]],"textEdited":"이 노드의 개수는 가운데에 있는 히든 레이어 즉 유저와 아이템의 벡터를 몇 차원으로 레프레젠테이션 하느냐를 의미하는 것입니다. 물론"},{"start":2126100,"end":2140700,"text":"어느 어느 정도 증가하게 되면 그 알엠스의 감소 폭은 줄어들게 됩니다. 그래서 본 논문 이후에 이 오토 인코더 기법을 좀 더 고급 오토 인코더로 발전한 다양한 컬래버레이트 필터링 논문들이 다음과 같이 등장했는데요.","confidence":0.8543,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2126350,2126540,"어느"],[2126710,2126920,"어느"],[2126920,2127200,"정도"],[2127430,2127794,"증가하게"],[2127794,2128000,"되면"],[2128130,2128280,"그"],[2128280,2128820,"알엠스의"],[2128870,2129120,"감소"],[2129120,2129360,"폭은"],[2129370,2129727,"줄어들게"],[2129727,2130020,"됩니다."],[2130090,2130300,"그래서"],[2130310,2130460,"본"],[2130550,2130800,"논문"],[2130890,2131240,"이후에"],[2131790,2131940,"이"],[2131950,2132220,"오토"],[2132230,2132580,"인코더"],[2132590,2132980,"기법을"],[2133550,2133700,"좀"],[2133700,2133820,"더"],[2133870,2134140,"고급"],[2134190,2134420,"오토"],[2134420,2135560,"인코더로"],[2136050,2136460,"발전한"],[2136910,2137260,"다양한"],[2137310,2137760,"컬래버레이트"],[2137760,2138080,"필터링"],[2138090,2138600,"논문들이"],[2139050,2139347,"다음과"],[2139347,2139540,"같이"],[2139550,2140160,"등장했는데요."]],"textEdited":"어느 어느 정도 증가하게 되면 그 알엠스의 감소 폭은 줄어들게 됩니다. 그래서 본 논문 이후에 이 오토 인코더 기법을 좀 더 고급 오토 인코더로 발전한 다양한 컬래버레이트 필터링 논문들이 다음과 같이 등장했는데요."},{"start":2140700,"end":2153700,"text":"dae 혹은 vae를 활용한 아래의 논문들도 여러분들이 관심이 있으면 찾아보고 공부해 보시길 추천드립니다. 네 그래서 다음은 이 고급 오토 인코더 가운데 디노이징 오토 인코더","confidence":0.9302,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2141090,2141640,"dae"],[2141890,2142080,"혹은"],[2142130,2143340,"vae를"],[2143370,2143680,"활용한"],[2144210,2144540,"아래의"],[2144540,2145160,"논문들도"],[2145510,2145920,"여러분들이"],[2145950,2146254,"관심이"],[2146254,2146520,"있으면"],[2146610,2147160,"찾아보고"],[2147410,2147667,"공부해"],[2147667,2148020,"보시길"],[2148150,2148720,"추천드립니다."],[2149390,2149540,"네"],[2149540,2149760,"그래서"],[2149770,2150140,"다음은"],[2150630,2150780,"이"],[2150830,2151100,"고급"],[2151110,2151340,"오토"],[2151340,2151660,"인코더"],[2151660,2152000,"가운데"],[2152470,2152980,"디노이징"],[2153010,2153240,"오토"],[2153240,2153600,"인코더"]],"textEdited":"dae 혹은 vae를 활용한 아래의 논문들도 여러분들이 관심이 있으면 찾아보고 공부해 보시길 추천드립니다. 네 그래서 다음은 이 고급 오토 인코더 가운데 디노이징 오토 인코더"},{"start":2153700,"end":2166900,"text":"를 컬래버레이트 필터링에 적용한 모델, 즉 컬래버레이트 디노이징 오토인코더라는 cdae 논문입니다. 이름 그대로 디노이징 오토 인코더를 사용하였으며 학습 데이터를 적절하게 가공해서","confidence":0.9386,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2153930,2154080,"를"],[2154530,2155000,"컬래버레이트"],[2155010,2155420,"필터링에"],[2155430,2155760,"적용한"],[2155760,2155980,"모델,"],[2156930,2157080,"즉"],[2157370,2157940,"컬래버레이트"],[2158110,2158560,"디노이징"],[2158710,2159480,"오토인코더라는"],[2159610,2160340,"cdae"],[2160750,2161260,"논문입니다."],[2161870,2162100,"이름"],[2162130,2162440,"그대로"],[2162470,2162920,"디노이징"],[2163010,2163227,"오토"],[2163227,2163580,"인코더를"],[2163580,2164180,"사용하였으며"],[2164690,2164960,"학습"],[2164960,2165420,"데이터를"],[2165570,2165960,"적절하게"],[2165990,2166440,"가공해서"]],"textEdited":"를 컬래버레이트 필터링에 적용한 모델, 즉 컬래버레이트 디노이징 오토인코더라는 cdae 논문입니다. 이름 그대로 디노이징 오토 인코더를 사용하였으며 학습 데이터를 적절하게 가공해서"},{"start":2166900,"end":2179200,"text":"탑 엔 레코멘데이션 즉 웨이팅을 정확하게 예측하는 것이 아니라 아이템에 대한 선호도를 예측하여서 그 아이템 탑 n개를 추천하는 논문으로 구성하였습니다. 네 이 모델은 오토랙과 달리","confidence":0.9225,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2167190,2167340,"탑"],[2167450,2167600,"엔"],[2167670,2168300,"레코멘데이션"],[2168550,2168700,"즉"],[2169110,2169580,"웨이팅을"],[2169580,2169920,"정확하게"],[2169920,2170280,"예측하는"],[2170280,2170487,"것이"],[2170487,2170760,"아니라"],[2171110,2171547,"아이템에"],[2171547,2171740,"대한"],[2171810,2172320,"선호도를"],[2172610,2173140,"예측하여서"],[2173170,2173320,"그"],[2173320,2173640,"아이템"],[2173730,2173880,"탑"],[2173970,2174380,"n개를"],[2174380,2174760,"추천하는"],[2174790,2175240,"논문으로"],[2175590,2176320,"구성하였습니다."],[2176690,2176840,"네"],[2176850,2177000,"이"],[2177000,2177380,"모델은"],[2178030,2178520,"오토랙과"],[2178520,2178760,"달리"]],"textEdited":"탑 엔 레코멘데이션 즉 웨이팅을 정확하게 예측하는 것이 아니라 아이템에 대한 선호도를 예측하여서 그 아이템 탑 n개를 추천하는 논문으로 구성하였습니다. 네 이 모델은 오토랙과 달리"},{"start":2179200,"end":2189200,"text":"평점을 예측하는 레이팅 프로젝션 문제가 아니라 유저에게 탑 엔 추천을 제공하는 모델로 설계하였습니다. 그래서 오토렉의 경우에는 최종 성능 비교를","confidence":0.9464,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2179510,2179940,"평점을"],[2179940,2180360,"예측하는"],[2180390,2180760,"레이팅"],[2180790,2181180,"프로젝션"],[2181550,2181867,"문제가"],[2181867,2182140,"아니라"],[2182650,2183120,"유저에게"],[2183210,2183360,"탑"],[2183470,2183620,"엔"],[2183670,2184040,"추천을"],[2184050,2184440,"제공하는"],[2184930,2185360,"모델로"],[2185470,2186180,"설계하였습니다."],[2186510,2186740,"그래서"],[2186750,2187260,"오토렉의"],[2187260,2187660,"경우에는"],[2187890,2188180,"최종"],[2188330,2188580,"성능"],[2188590,2188980,"비교를"]],"textEdited":"평점을 예측하는 레이팅 프로젝션 문제가 아니라 유저에게 탑 엔 추천을 제공하는 모델로 설계하였습니다. 그래서 오토렉의 경우에는 최종 성능 비교를"},{"start":2189200,"end":2203600,"text":"알엠스 즉 테이터 테스트 데이터의 웨이팅을 얼마나 정확하게 복원했는지로 평가했지만 본 논문 씨디에이는 유저에게 탑 앤 추천을 얼마나 잘 제공했는지 엔디시지와 같은 매트릭으로 추천 성능을 평가하고 있습니다.","confidence":0.7537,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2189410,2189920,"알엠스"],[2190110,2190260,"즉"],[2190370,2190680,"테이터"],[2190750,2191120,"테스트"],[2191120,2191520,"데이터의"],[2191520,2191920,"웨이팅을"],[2191970,2192280,"얼마나"],[2192590,2193020,"정확하게"],[2193050,2194140,"복원했는지로"],[2194190,2194780,"평가했지만"],[2195730,2195880,"본"],[2195910,2196100,"논문"],[2196170,2196820,"씨디에이는"],[2197210,2197660,"유저에게"],[2197710,2197860,"탑"],[2197860,2198000,"앤"],[2198010,2198360,"추천을"],[2198360,2198640,"얼마나"],[2198710,2198860,"잘"],[2198930,2199520,"제공했는지"],[2199890,2200580,"엔디시지와"],[2200610,2200880,"같은"],[2201490,2202020,"매트릭으로"],[2202230,2202480,"추천"],[2202490,2202780,"성능을"],[2202810,2203147,"평가하고"],[2203147,2203560,"있습니다."]],"textEdited":"알엠스 즉 테이터 테스트 데이터의 웨이팅을 얼마나 정확하게 복원했는지로 평가했지만 본 논문 씨디에이는 유저에게 탑 앤 추천을 얼마나 잘 제공했는지 엔디시지와 같은 매트릭으로 추천 성능을 평가하고 있습니다."},{"start":2203600,"end":2209200,"text":"그리고 탑 n 추천 문제로 정의하면서 문제를 단순화하기 위해서 유저 아이템의 레이팅","confidence":0.9671,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2203850,2204060,"그리고"],[2204090,2204240,"탑"],[2204330,2204480,"n"],[2204590,2204860,"추천"],[2204910,2205220,"문제로"],[2205220,2205780,"정의하면서"],[2206110,2206440,"문제를"],[2206490,2207020,"단순화하기"],[2207020,2207300,"위해서"],[2207890,2208180,"유저"],[2208180,2208560,"아이템의"],[2208590,2208980,"레이팅"]],"textEdited":"그리고 탑 n 추천 문제로 정의하면서 문제를 단순화하기 위해서 유저 아이템의 레이팅"},{"start":2209200,"end":2224000,"text":"정보를 실수 값이 아닌 0 또는 1의 바이너리 정보로 바꾸어서 학습 데이터를 사용하였습니다. 어떤 프리퍼런스 즉 얼마나 선호하냐 그 선호도 정보를 학습하게 됩니다. 그리고 이 선호도가 곧바로 탑 앤 추천에 활용됩니다.","confidence":0.9423,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2209470,2209880,"정보를"],[2210110,2210420,"실수"],[2210420,2210634,"값이"],[2210634,2210820,"아닌"],[2211270,2211420,"0"],[2211510,2211740,"또는"],[2211770,2212020,"1의"],[2212050,2212460,"바이너리"],[2212470,2212860,"정보로"],[2213270,2213780,"바꾸어서"],[2214370,2214660,"학습"],[2214660,2215000,"데이터를"],[2215000,2215600,"사용하였습니다."],[2215710,2215940,"어떤"],[2216030,2216540,"프리퍼런스"],[2216570,2216720,"즉"],[2216850,2217180,"얼마나"],[2217690,2218140,"선호하냐"],[2218370,2218520,"그"],[2218520,2218840,"선호도"],[2218870,2219240,"정보를"],[2219610,2219994,"학습하게"],[2219994,2220300,"됩니다."],[2220570,2220780,"그리고"],[2220780,2220900,"이"],[2220900,2221280,"선호도가"],[2221330,2221700,"곧바로"],[2222050,2222200,"탑"],[2222270,2222420,"앤"],[2222510,2222900,"추천에"],[2223290,2223940,"활용됩니다."]],"textEdited":"정보를 실수 값이 아닌 0 또는 1의 바이너리 정보로 바꾸어서 학습 데이터를 사용하였습니다. 어떤 프리퍼런스 즉 얼마나 선호하냐 그 선호도 정보를 학습하게 됩니다. 그리고 이 선호도가 곧바로 탑 앤 추천에 활용됩니다."},{"start":2224000,"end":2237700,"text":"네 다음은 cdae 컬래버레이티브 디노이징 오토 인코더의 특징에 대해서 자세히 살펴봅시다. 가장 큰 차이점은 여기에 있는 da 디노이징 오토 인코더를 사용한다는 점입니다. 한 명의 유저 율을 기준으로","confidence":0.8642,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2224270,2224420,"네"],[2224420,2224780,"다음은"],[2225390,2226180,"cdae"],[2226530,2227200,"컬래버레이티브"],[2227830,2228240,"디노이징"],[2228240,2228460,"오토"],[2228460,2228840,"인코더의"],[2228910,2229194,"특징에"],[2229194,2229480,"대해서"],[2229570,2229860,"자세히"],[2229870,2230380,"살펴봅시다."],[2230630,2230880,"가장"],[2230970,2231120,"큰"],[2231190,2231640,"차이점은"],[2231970,2232194,"여기에"],[2232194,2232340,"있는"],[2232410,2232720,"da"],[2233470,2233940,"디노이징"],[2233970,2234200,"오토"],[2234200,2234860,"인코더를"],[2234890,2235380,"사용한다는"],[2235380,2235740,"점입니다."],[2236010,2236127,"한"],[2236127,2236340,"명의"],[2236350,2236580,"유저"],[2236590,2236940,"율을"],[2236950,2237380,"기준으로"]],"textEdited":"네 다음은 cdae 컬래버레이티브 디노이징 오토 인코더의 특징에 대해서 자세히 살펴봅시다. 가장 큰 차이점은 여기에 있는 da 디노이징 오토 인코더를 사용한다는 점입니다. 한 명의 유저 율을 기준으로"},{"start":2237700,"end":2249300,"text":"모든 아이템에 대한 평점인 yu를 구한 뒤 이 yu를 그대로 사용하지 않고 yu 틸드 값을 사용합니다. 이 yu 틸드는 q의 확률로 의해","confidence":0.9369,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2237990,2238220,"모든"],[2238270,2238687,"아이템에"],[2238687,2238900,"대한"],[2239050,2239480,"평점인"],[2239710,2240240,"yu를"],[2240570,2240840,"구한"],[2240870,2241020,"뒤"],[2241730,2241880,"이"],[2241890,2242380,"yu를"],[2242390,2242660,"그대로"],[2242660,2243040,"사용하지"],[2243050,2243360,"않고"],[2244010,2244440,"yu"],[2244630,2245020,"틸드"],[2245030,2245360,"값을"],[2245360,2245800,"사용합니다."],[2246090,2246240,"이"],[2246250,2246540,"yu"],[2246610,2247040,"틸드는"],[2247590,2247900,"q의"],[2247970,2248380,"확률로"],[2248530,2248800,"의해"]],"textEdited":"모든 아이템에 대한 평점인 yu를 구한 뒤 이 yu를 그대로 사용하지 않고 yu 틸드 값을 사용합니다. 이 yu 틸드는 q의 확률로 의해"},{"start":2249300,"end":2257400,"text":"0으로 드롭아웃 된 벡터입니다. 즉 q의 확률로 어떤 원소는 0이 되고 1 마이너스 q의 확률로는 어떤 원소는","confidence":0.9512,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2249550,2249900,"0으로"],[2249900,2250280,"드롭아웃"],[2250280,2250400,"된"],[2250430,2250880,"벡터입니다."],[2251110,2251260,"즉"],[2252010,2252300,"q의"],[2252310,2252660,"확률로"],[2253670,2253900,"어떤"],[2253970,2254280,"원소는"],[2254280,2254487,"0이"],[2254487,2254760,"되고"],[2255190,2255340,"1"],[2255340,2255660,"마이너스"],[2255660,2255900,"q의"],[2255910,2256280,"확률로는"],[2256390,2256600,"어떤"],[2256650,2256980,"원소는"]],"textEdited":"0으로 드롭아웃 된 벡터입니다. 즉 q의 확률로 어떤 원소는 0이 되고 1 마이너스 q의 확률로는 어떤 원소는"},{"start":2257400,"end":2271800,"text":"기존 평점 값에 델타가 곱해지게 됩니다. 그래서 이렇게 해서 노이즈 한 인풋을 만들어서 디노이징 오토인 코드를 구성하였고요. 또 하나의 차이점은 개별 유저에 대한 브유라는 파라미터가 존재한다는 것입니다.","confidence":0.897,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2257630,2257860,"기존"],[2258330,2258620,"평점"],[2258620,2258900,"값에"],[2259890,2260260,"델타가"],[2260290,2260700,"곱해지게"],[2260700,2261000,"됩니다."],[2261190,2261380,"그래서"],[2261380,2261620,"이렇게"],[2261620,2261800,"해서"],[2261850,2262167,"노이즈"],[2262167,2262300,"한"],[2262370,2262780,"인풋을"],[2262780,2263180,"만들어서"],[2263330,2263740,"디노이징"],[2263770,2264120,"오토인"],[2264120,2264360,"코드를"],[2264360,2264920,"구성하였고요."],[2265890,2266040,"또"],[2266050,2266340,"하나의"],[2266410,2266880,"차이점은"],[2267470,2267740,"개별"],[2267810,2268107,"유저에"],[2268107,2268300,"대한"],[2268470,2270220,"브유라는"],[2270230,2270720,"파라미터가"],[2270730,2271247,"존재한다는"],[2271247,2271680,"것입니다."]],"textEdited":"기존 평점 값에 델타가 곱해지게 됩니다. 그래서 이렇게 해서 노이즈 한 인풋을 만들어서 디노이징 오토인 코드를 구성하였고요. 또 하나의 차이점은 개별 유저에 대한 브유라는 파라미터가 존재한다는 것입니다."},{"start":2271800,"end":2284000,"text":"유저별로 갖는 특징들이 있을 텐데 그 유저별 특징을 이 브유라는 파라미터가 각각 개별 유저에 대해서 학습을 하게 됩니다. 그리고 이는 유저별 탑 앤 추천에 활용돼서 추천 성능을 높여줍니다.","confidence":0.8711,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2272130,2272700,"유저별로"],[2272730,2272960,"갖는"],[2273110,2273560,"특징들이"],[2273560,2273740,"있을"],[2273740,2274000,"텐데"],[2274250,2274400,"그"],[2274430,2274780,"유저별"],[2274870,2275220,"특징을"],[2275490,2275640,"이"],[2275690,2276200,"브유라는"],[2276210,2276720,"파라미터가"],[2277170,2277500,"각각"],[2277550,2277780,"개별"],[2277790,2278120,"유저에"],[2278120,2278420,"대해서"],[2278590,2278880,"학습을"],[2278880,2278994,"하게"],[2278994,2279280,"됩니다."],[2279830,2280027,"그리고"],[2280027,2280240,"이는"],[2280730,2281100,"유저별"],[2281170,2281320,"탑"],[2281350,2281500,"앤"],[2281550,2281880,"추천에"],[2281880,2282340,"활용돼서"],[2282730,2283000,"추천"],[2283030,2283340,"성능을"],[2283340,2283880,"높여줍니다."]],"textEdited":"유저별로 갖는 특징들이 있을 텐데 그 유저별 특징을 이 브유라는 파라미터가 각각 개별 유저에 대해서 학습을 하게 됩니다. 그리고 이는 유저별 탑 앤 추천에 활용돼서 추천 성능을 높여줍니다."},{"start":2284000,"end":2294900,"text":"각각의 유저별로 특징이 다르고 그 특징이 각각의 파라미터를 통해 학습이 되면서 이 모델에 컬래버레이티브라는 이름이 붙게 되었음을 언급 드립니다. 그래서","confidence":0.9671,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2284370,2284760,"각각의"],[2284790,2285360,"유저별로"],[2285830,2286140,"특징이"],[2286140,2286520,"다르고"],[2286950,2287100,"그"],[2287170,2287540,"특징이"],[2287970,2288280,"각각의"],[2288290,2288820,"파라미터를"],[2288820,2288980,"통해"],[2289030,2289274,"학습이"],[2289274,2289660,"되면서"],[2290250,2290400,"이"],[2290410,2290780,"모델에"],[2291210,2292000,"컬래버레이티브라는"],[2292000,2292280,"이름이"],[2292430,2292687,"붙게"],[2292687,2293140,"되었음을"],[2293350,2293580,"언급"],[2293580,2293920,"드립니다."],[2294150,2294460,"그래서"]],"textEdited":"각각의 유저별로 특징이 다르고 그 특징이 각각의 파라미터를 통해 학습이 되면서 이 모델에 컬래버레이티브라는 이름이 붙게 되었음을 언급 드립니다. 그래서"},{"start":2294900,"end":2308200,"text":"이를 수식으로 나타내면 인코더 부분에 노이즈 한 인풋인 와유틸드가 사용되었고 그리고 개별 유저의 벡터인 브이 즉 유저 노드가 사용되어서 가운데에 있는 히든 레이어를 구성하게 됩니다.","confidence":0.8956,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2295130,2295340,"이를"],[2295390,2295760,"수식으로"],[2295760,2296160,"나타내면"],[2296690,2297080,"인코더"],[2297080,2297380,"부분에"],[2297590,2297927,"노이즈"],[2297927,2298060,"한"],[2298090,2298460,"인풋인"],[2298610,2299680,"와유틸드가"],[2299710,2300360,"사용되었고"],[2301090,2301400,"그리고"],[2301790,2302060,"개별"],[2302090,2302420,"유저의"],[2302450,2302800,"벡터인"],[2302890,2303140,"브이"],[2303610,2303760,"즉"],[2303890,2304160,"유저"],[2304170,2304820,"노드가"],[2305230,2305820,"사용되어서"],[2306410,2306754,"가운데에"],[2306754,2306900,"있는"],[2306930,2307180,"히든"],[2307180,2307500,"레이어를"],[2307500,2307807,"구성하게"],[2307807,2308180,"됩니다."]],"textEdited":"이를 수식으로 나타내면 인코더 부분에 노이즈 한 인풋인 와유틸드가 사용되었고 그리고 개별 유저의 벡터인 브이 즉 유저 노드가 사용되어서 가운데에 있는 히든 레이어를 구성하게 됩니다."},{"start":2308200,"end":2319000,"text":"그리고 히든 레이어가 다시 디코더를 통해서 복원되는 것은 기존의 오토 인코더와 동일합니다. 그래서 가장 큰 차이점은 바로 이 yu 틸드를 사용해서 인풋 값을 n이지하게 바꿨다.","confidence":0.9009,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2308410,2308620,"그리고"],[2308630,2308880,"히든"],[2308890,2309340,"레이어가"],[2309470,2309700,"다시"],[2309710,2310200,"디코더를"],[2310200,2310520,"통해서"],[2310930,2311380,"복원되는"],[2311710,2311980,"것은"],[2312350,2312660,"기존의"],[2312660,2312880,"오토"],[2312880,2313220,"인코더와"],[2313220,2313700,"동일합니다."],[2313890,2314080,"그래서"],[2314080,2314300,"가장"],[2314300,2314440,"큰"],[2314450,2314880,"차이점은"],[2314930,2315160,"바로"],[2315160,2315300,"이"],[2315370,2315740,"yu"],[2315770,2316200,"틸드를"],[2316200,2316600,"사용해서"],[2317230,2317560,"인풋"],[2317650,2317980,"값을"],[2317980,2318420,"n이지하게"],[2318470,2318860,"바꿨다."]],"textEdited":"그리고 히든 레이어가 다시 디코더를 통해서 복원되는 것은 기존의 오토 인코더와 동일합니다. 그래서 가장 큰 차이점은 바로 이 yu 틸드를 사용해서 인풋 값을 n이지하게 바꿨다."},{"start":2319000,"end":2332300,"text":"그리고 유저에 대한 파라미터를 추가하여서 유저별 특징을 학습하도록 하였다. 이 두 가지가 앞에서 언급한 오토랩과의 가장 큰 차이점이라고 볼 수 있습니다. 그래서 해당 모델을 사용하여서","confidence":0.965,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2319290,2319600,"그리고"],[2320190,2320867,"유저에"],[2320867,2321060,"대한"],[2321130,2321640,"파라미터를"],[2321690,2322180,"추가하여서"],[2322670,2323020,"유저별"],[2323130,2323480,"특징을"],[2324030,2324540,"학습하도록"],[2324540,2324860,"하였다."],[2325310,2325460,"이"],[2325460,2325547,"두"],[2325547,2325880,"가지가"],[2326390,2326780,"앞에서"],[2326870,2327220,"언급한"],[2327390,2328200,"오토랩과의"],[2328250,2328460,"가장"],[2328550,2328700,"큰"],[2328790,2329400,"차이점이라고"],[2329400,2329540,"볼"],[2329540,2329634,"수"],[2329634,2330000,"있습니다."],[2330510,2330760,"그래서"],[2330830,2331080,"해당"],[2331130,2331460,"모델을"],[2331460,2331980,"사용하여서"]],"textEdited":"그리고 유저에 대한 파라미터를 추가하여서 유저별 특징을 학습하도록 하였다. 이 두 가지가 앞에서 언급한 오토랩과의 가장 큰 차이점이라고 볼 수 있습니다. 그래서 해당 모델을 사용하여서"},{"start":2332300,"end":2346000,"text":"기존의 탑 엔 추천 테스크에서 좋은 성능을 내던 다른 모델과 비교한 결과를 본 논문에서 제시하고 있습니다. 대체적으로 이 n에 관계없이 다른 탑 엔 추천 모델, 즉 아이템 베이스나 MF","confidence":0.9409,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2332530,2332860,"기존의"],[2332870,2333020,"탑"],[2333070,2333220,"엔"],[2333250,2333500,"추천"],[2333530,2334140,"테스크에서"],[2334210,2334400,"좋은"],[2334590,2334900,"성능을"],[2334910,2335160,"내던"],[2335670,2335940,"다른"],[2335970,2336340,"모델과"],[2337110,2337500,"비교한"],[2337570,2337980,"결과를"],[2338450,2338600,"본"],[2338630,2339040,"논문에서"],[2339110,2339454,"제시하고"],[2339454,2339820,"있습니다."],[2340330,2340800,"대체적으로"],[2340830,2340980,"이"],[2340990,2341300,"n에"],[2341350,2341840,"관계없이"],[2342070,2342280,"다른"],[2342370,2342520,"탑"],[2342550,2342700,"엔"],[2342710,2342960,"추천"],[2342970,2343220,"모델,"],[2343450,2343600,"즉"],[2344130,2344480,"아이템"],[2344510,2345100,"베이스나"],[2345310,2345720,"MF"]],"textEdited":"기존의 탑 엔 추천 테스크에서 좋은 성능을 내던 다른 모델과 비교한 결과를 본 논문에서 제시하고 있습니다. 대체적으로 이 n에 관계없이 다른 탑 엔 추천 모델, 즉 아이템 베이스나 MF"},{"start":2346000,"end":2360200,"text":"와 같은 다른 추천 모델에 비해서 이 씨디에이가 좋은 타앤 추천 성능을 보임을 알 수 있습니다. 네 여기까지가 씨디에이 콜라보레이티브 디노이징 오토 인코더에 관한 내용이었습니다.","confidence":0.7575,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2346190,2346340,"와"],[2346390,2346640,"같은"],[2346670,2346900,"다른"],[2347490,2347760,"추천"],[2347760,2348034,"모델에"],[2348034,2348360,"비해서"],[2349170,2349320,"이"],[2349390,2350520,"씨디에이가"],[2350750,2350940,"좋은"],[2351430,2351700,"타앤"],[2351750,2352020,"추천"],[2352070,2353280,"성능을"],[2353310,2353660,"보임을"],[2353790,2353940,"알"],[2353990,2354140,"수"],[2354140,2354520,"있습니다."],[2354970,2355120,"네"],[2355390,2355940,"여기까지가"],[2356170,2356920,"씨디에이"],[2357290,2357980,"콜라보레이티브"],[2358010,2358440,"디노이징"],[2358470,2358720,"오토"],[2358720,2359120,"인코더에"],[2359120,2359340,"관한"],[2359370,2360080,"내용이었습니다."]],"textEdited":"와 같은 다른 추천 모델에 비해서 이 씨디에이가 좋은 타앤 추천 성능을 보임을 알 수 있습니다. 네 여기까지가 씨디에이 콜라보레이티브 디노이징 오토 인코더에 관한 내용이었습니다."},{"start":2360200,"end":2371900,"text":"이 논문 외에도 다른 고급 오토 인코더를 사용한 추천 모델은 계속해서 발표되어 왔는데요. 이 개별 모델에 대한 이해도도 중요하지만 무엇보다 오토 인코더를 활용한 추천 모델이","confidence":0.9774,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2360570,2360720,"이"],[2360720,2360920,"논문"],[2360950,2361300,"외에도"],[2361870,2362080,"다른"],[2362190,2362440,"고급"],[2362550,2362820,"오토"],[2362830,2363300,"인코더를"],[2363300,2363600,"사용한"],[2363710,2363960,"추천"],[2363960,2364280,"모델은"],[2364670,2365080,"계속해서"],[2365230,2365640,"발표되어"],[2365640,2366040,"왔는데요."],[2366910,2367060,"이"],[2367070,2367340,"개별"],[2367390,2367707,"모델에"],[2367707,2367900,"대한"],[2367970,2368380,"이해도도"],[2368410,2368940,"중요하지만"],[2369490,2369920,"무엇보다"],[2369990,2370260,"오토"],[2370260,2370660,"인코더를"],[2370670,2370960,"활용한"],[2371010,2371260,"추천"],[2371260,2371580,"모델이"]],"textEdited":"이 논문 외에도 다른 고급 오토 인코더를 사용한 추천 모델은 계속해서 발표되어 왔는데요. 이 개별 모델에 대한 이해도도 중요하지만 무엇보다 오토 인코더를 활용한 추천 모델이"},{"start":2371900,"end":2381200,"text":"어떻게 유저 아이템 인베딩이 학습되는지를 기억하는 것이 제일 중요하다고 볼 수 있습니다. 네 이상 여섯 번째 강의가 모두 끝났습니다. 오늘도 수고하셨습니다.","confidence":0.9335,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2372230,2372600,"어떻게"],[2372610,2372860,"유저"],[2372890,2373440,"아이템"],[2373530,2373940,"인베딩이"],[2374050,2374940,"학습되는지를"],[2374970,2375440,"기억하는"],[2375440,2375700,"것이"],[2375910,2376120,"제일"],[2376190,2376640,"중요하다고"],[2376640,2376780,"볼"],[2376780,2376860,"수"],[2376860,2377200,"있습니다."],[2377270,2377420,"네"],[2377450,2377660,"이상"],[2377730,2377960,"여섯"],[2377960,2378180,"번째"],[2378190,2378540,"강의가"],[2378710,2378920,"모두"],[2378950,2379460,"끝났습니다."],[2379930,2380240,"오늘도"],[2380240,2380860,"수고하셨습니다."]],"textEdited":"어떻게 유저 아이템 인베딩이 학습되는지를 기억하는 것이 제일 중요하다고 볼 수 있습니다. 네 이상 여섯 번째 강의가 모두 끝났습니다. 오늘도 수고하셨습니다."}],"text":"안녕하세요. 추천 시스템 이론 강의를 맡은 강사 이준원입니다. 이제 강의가 절반 정도 진행되었는데요. 생각해 보면 아직까지 저희는 딥러닝을 사용한 추천 모델을 본격적으로 배우지 않았습니다. 물론 5강에서 아이템 투 백 모델이 간단한 뉴럴넷 랭귀지 모델이긴 하지만 그렇게 복잡한 딥러닝 모델은 아니었죠. 이전에 말씀드린 대로 추천 시스템 분야는 다른 분야에 비해서는 딥러닝 모델이 기존 ML 모델에 비해 월등히 좋은 성능을 내지 못하는 부분이 있습니다. 또한 추천을 수행할 때 이 모델을 서빙하는 레이턴시가 굉장히 중요하기 때문에 또 너무 복잡한 모델을 사용하기에는 실제로는 어렵다는 챌린지도 존재합니다. 그럼에도 불구하고 딥러닝을 사용한 추천 모델은 여전히 활발하게 연구되어 있고 또 일부 구글과 핀터레스트와 같은 추천을 잘하는 회사는 딥러닝을 추천에 적극적으로 활용하고 있습니다. 그래서 이번 시간에는 3강부터 5강까지 배웠던 컬래버레이터의 필터링의 원리를 바탕으로 딥러닝 추천 모델들에 대해 살펴보겠습니다. 네 목차는 다음과 같습니다. 딥러닝이 어떤 장점을 가지는지, 딥러닝에 사용되는 기법은 무엇인지에 대해 간단히 랩업을 하고 나서 이제 이번 시간에는 멀티 레이어 퍼셉트론 제일 기본적인 피드 포워드 뉴럴 네트워크 구조이죠. 그리고 오토 인코더를 기반으로 설계된 대표적인 추천 모델에 대해서 배워보도록 하겠습니다. 먼저 추천 시스템에 딥러닝을 사용하는 것이 왜 좋은가? 딥러닝을 통해 어떻게 추천 모델이 고도화될 수 있는지 살펴봅시다. 네 먼저 딥러닝 모델은 가장 잘 알려진 특징이죠. 논 리니어 트랜스포메이션이 가능합니다. 데이터가 가진 비선형의 패턴을 효과적으로 나타내고 모델링 할 수 있습니다. DNN에서 사용되는 멜루나 탄젠트 하이퍼블릭 같은 활성화 함수들이 이런 논 리니얼리티를 가능하게 하는 것을 이미 배우셨을 것입니다. 이제 이러한 DNN의 논 리니어 트랜스포메이션 성질은 추천 모델 학습에 사용되는 이 유저 아이템의 복잡한 인터랙션을 모델링하는 데 큰 도움을 줍니다. 우리가 4강에서 배웠던 매트리스 팩토라이제이션의 경우 유저 아이템을 임베딩한 이후에는 닷 프로덕트 즉 선형 결합을 통해서 바로 유저의 선호도를 예측하게 됩니다. 그리고 8강에서 배우게 될 대표적인 클래시컬 모델인 팩토라이제이션 머신이나 그 외에 사용하는 다양한 추천 모델의 경우에서도 선형 가정을 토대로 모델이 설계된 경우가 많습니다. 그래서 이러한 가정은 모델을 너무 단순하게 만들고 모델이 가지는 표현력에 큰 한계를 두게 합니다. 따라서 딥뉴럴 네트워크 DNN을 사용하여서 전통적인 추천 모델이 표현할 수 없는 복잡한 인터랙션을 딥러닝 모델이 학습하기를 기대하는 것입니다. 또한 DNN은 주어진 로우 데이터로부터 피처 레프레젠테이션을 직접 할 수 있기 때문에 피처 프리 프로세싱이 훨씬 적고 사람이 직접 피처를 디자인하지 않아도 됩니다. 또한 디엔엔을 사용하면 기존에 사용하기 어려웠던 텍스트나 이미지, 오디오와 같은 데이터도 추천 모델의 피처로 직접 사용할 수 있습니다. 그래서 이러한 레프레젠테이션은 인베딩 레이어나 컨볼루션 레이어와 같은 레이어를 사용하여서 하나의 모델로 엔드 투 엔드로 직접 학습할 수 있게 되고, 그래서 복잡한 피처를 적절한 레프리젠테이션으로 표현할 수 있게 됩니다. 또한 딥러닝 모델은 시퀀스 모델링에 굉장히 뛰어난 성능을 보이고 있습니다. 대표적으로 자연어 처리 머신 트레저레이션이나 음성 인식, 챗봇 과 같은 테스크에서 이런 시퀀스 모델링이 아주 좋은 성능을 보이고 있는데요. 앞선 강의에서 배우셨겠지만 RNN이나 CNN 계열의 모델 그리고 요즘에는 트랜스포머 같은 모델들이 이런 시퀀스 모델링을 아주 잘 하고 있습니다. 추천 시스템에서는 현재까지 소비한 아이템 다음에 넥스트 아이템을 예측하는 넥스트 아이템, 프리딕션이나 같은 세션에서 추천을 수행하는 세션, 베이스 레코멘데이션 같은 데스크에 이런 시퀀스 모델링이 활용될 수 있습니다. 유저나 아이템에 대한 시간적 정보 즉 어떤 시퀀셜한 정보를 그러니까 이 딥러닝 모델이 표현하고 학습할 수 있기 때문입니다. 또한 마지막으로 플렉서빌리티인데요. 이러한 딥러닝 모델을 쉽게 개발할 수 있는 다양한 프레임워크가 이미 있기 때문에 연구와 현업에서도 이런 텐서플로우나 파이터치 같은 것을 잘 활용하여서 활발하게 연구와 개발을 동시에 하고 있습니다. 이러한 프레임웍을 사용하는 커뮤니티도 굉장히 활발하기 때문에 이 딥러닝 분야가 계속 추천 시스템에서도 잘 연구되고 있습니다. 그래서 이러한 이유들로 인해서 추천 시스템에서도 최근에 발생되는 최신 논문들과 기법은 거의 딥러닝 모델 혹은 그러한 접근들을 사용하고 있습니다. 네 이제 제일 기본적인 딥러닝의 레이어 인 멀티 레이어 퍼셉션을 사용한 대표적인 추천 모델 몇 가지를 살펴봅시다. 참고로 지금부터 일곱 번째 강의 즉 다음 강의까지 다양한 딥러닝 모델들을 배우게 될 것인데요. 제 강의에서 소개하는 모델들 그 논문들은 여러 가지 딥러닝 접근법을 추천 시스템의 각 분야에 처음 활용했다는 점에서 각각의 발자취를 남긴 논문이 되겠습니다. 따라서 실제 현업에서 자주 사용되는 기준으로 모델을 혹은 논문을 소개한다기보다는 이론적으로 큰 의미를 가지는 기준으로 소개하는 것임을 참고하시길 바랍니다. 네 멀티 레이어 퍼셉트론 한국말로 다중 퍼셉트론이라고 표현할 수 있는데요. 가장 기본적인 퍼셉션 즉 노드 여러 개의 노드로 이루어진 레이어를 순차적으로 쌓은 구조입니다. 피드 포드 유n 네트워크가 되겠죠 딥러닝이 가지고 있는 가장 기본적인 논 리니어와 문제를 풀 수 있다는 것을 설명하는 레이어이고요. 뭐 아래의 예시는 여러분들이 잘 아시는 엑스알 문제를 통해 엠엘피 레이어로 해결할 수 있다는 것을 보여줍니다. 그래서 RNN CNN 오토 인코더 혹은 트랜스포머 같은 다양한 복잡한 레이어들이 있지만 그 모든 레이어들 이전에 이 기본적인 MLP 레이어로부터 딥러닝 모델이 출발한 것입니다. 네 그래서 처음으로 소개하는 논문은 뉴럴 컬라버레이트 필터링입니다. 추천 시스템에서 가장 많이 사용하던 엠프 매트리스 팩토라이제이션에다가 이 MLP 레이어를 적용한 기법인데요. 매트리스 팩토라이제이션이 가진 한계 즉 아까도 잠깐 언급했지만 이 리니어 모델에 대한 한계를 지적하면서 뉴럴넷 모델을 이 엠프에 추가하여 좀 더 일반화된 모델을 본 논문에서는 제시하고 있습니다. 네 본 논문의 아이디어부터 살펴보겠습니다. 우리가 4강에서 대표적인 추천 모델이었던 매트리스 팩토라이제이션에 대해서 배웠던 거 기억하시죠? 간단하게 수식으로 써보면 rui는 유저 벡터 트랜스포즈 아이템 벡터로 나타낼 수 있죠. 이 수식을 보면은 유저 아이템 사이에 임베딩을 우리가 구했지만 결국 그 둘은 닷 프로덕트 즉 선형 연산으로 곱해지게 됩니다. 그래서 유저와 아이템 사이의 복잡한 관계를 표현해야 하는데 이런 리니어한 인터랙션으로 표현되는 경우에는 표현력에 한계를 가질 수밖에 없다는 것이죠. 그래서 엠프 모델을 통해서 유저 아이템 매트릭스는 각각 유저와 아이템 매트릭스로 나뉘어서 학습이 됩니다. 그래서 아래 그림에 요 왼쪽에 있는 예시를 살펴봅시다. 이 왼쪽에 있는 데이터가 유저 아이템 매트릭스 즉 매트릭스 팩터라이제이션 학습에 필요한 인풋 데이터고요. 오른쪽에 있는 이 학습된 유저 매트릭스를 인베딩 공간에 그려본 것입니다. 학습이 모두 이루어져 있기 때문에 유저 레이턴트 스페이스 즉 인베딩 스페이스에 각각의 유저들이 표현될 수 있습니다. 보시면 우리는 유저 1 유저 2 유저 3 일단 3개의 유저가 있고 이 유저는 각각 p1 p2 p3 라는 벡터로 표현이 됩니다. 그래서 이 p1 p2 p3라는 벡터를 레이턴트 스페이스에 나타냈는데요. 문제는 여기서 p4 즉 유저 4가 새로 등장했을 때 이 유저 4를 존의 유저 레이턴트 스페이스에 추가로 표현해 줘야 한다는 것입니다. 이때 유저 간의 유사도를 계산해야 되는데요. 이제 여기서 계산한 유사도는 각각의 레이팅이 얼마나 겹치는지 자카드 유사도를 사용하였습니다. 이 데이터를 보시면 유저 4와 가장 레이팅이 많이 겹치는 유저는 유저 원입니다. 즉 유저 4와 유저 원이 가장 유사하다는 것이죠. 그렇기 때문에 새로 학습되는 유저 4에 해당하는 p4라는 유저 4의 레이턴트 벡터는 p1과 제일 유사한 위치에 놓여야 합니다. 즉 뭐 이런 식으로 놓이거나 이런 식으로 놓여야겠죠 자 문제는 그 다음인데요. 유저 2와 유저 3 근데 문제는 유저 2와 유저 3인데요. 유저 4가 가장 가까운 유저 1 다음으로 가까운 유저는 보시면 유저 3리가 더 많은 아이템을 공유하고 있기 때문에 유저 4가 유저 3와 더 가깝습니다. 유저 2보다는 근데 이제 이 레이턴트 스페이스에 표현을 해야 되는데 어떻게 표현을 해도 이 유저 4는 유저 3보다는 유저 2에 가깝게 됩니다. 즉 새로운 유저 유저 포를 이 스페이스에 표현할 때 모순이 발생하는 거죠. 유저 원과 가깝게 표현을 하게 되는 경우 아무리 레이턴트 스페이스의 유저 포를 표현한다 하더라도 벡터를 유저 2에 비해 유저 3에 가깝게 놓을 수 없다는 것입니다. 이러한 상황에서 기존의 매트리스 팩터 라이제이션의 연산인 닷 프로덕트는 리니어 하기 때문에 최종 예측을 수행할 때 유저 4에 대해서는 유저 2보다는 유저 3와 비슷한 예측 값을 갖게 할 수는 없습니다. 즉 매트리스 팩토라이제이션 모델을 사용해서 예측을 할 경우 항상 유저 4와 유저 3의 평점보다는 유저 4와 유저 2의 평점이 더 비슷하게 추론된다는 것이죠. 네 그래서 새로운 유저 4를 설명하는 벡터 즉 p4는 어떻게 해도 유저 2에 비해서 유저 3에 가깝게 놓을 수가 없습니다. 이제 이러한 상황에서 기존의 매트릭스 팩토라이제이션의 연산인 닷 프로덕트는 리니어한 연산이기 때문에 최종 예측을 할 때에도 항상 유저 4는 유저 3보다 유저 2에 가깝게 예측이 됩니다. 실제로는 유저 4와 유저 3가 더 비슷함에도 불구하고 항상 예측을 할 때는 유저 3보다는 유저 2에 더 가깝게 평점이 구해진다는 것이죠. 그래서 이러한 문제를 해결하기 위해서는 매트리스 팩토라이제이션의 레이턴트 스페이스 차원을 다음과 같은 2차원이 아니라 더 큰 차원으로 크게 해서 이 유사도 표현의 문제를 해결할 수 있습니다. 하지만 이제 계속해서 그렇게 차원을 늘려갈 경우에 오버피팅 문제가 발생합니다. 따라서 이 뉴럴 컬라버레이팅 필터링 논문은 차원을 계속해서 크게 문제를 해결하는 것이 아니라 이 모델 자체에 논리니어한 표현을 추가하여서 이 문제를 해결하고 싶었고 그래서 이 엠엘피 레이어를 추가하게 되었습니다. 네 다음 페이지는 이 뉴럴 컬라버레이트 필터링에 새로 추가된 MLP 파트 부분입니다. 그래서 아래에 있는 레이어부터 위로 아웃풋 레이어까지 쭉 설명을 드리겠습니다. 먼저 인플레이어는 유저와 아이템에 대한 원핫 인코딩 벡터로 표현이 됩니다. 이제 여기서 유저 레이턴트 벡터 즉 인베딩 매트릭스를 통하여서 각각의 유저와 아이템이 어떤 댄스한 형태의 인베딩으로 표현이 됩니다. 그 이후에 뉴럴 콜라보레이트 레이어라고 하는 일반적인 MLP 레이어 로 들어가게 되는데요. 각각의 유저 레이턴트 팩터, 아이템 레이턴트 팩터를 구한 이후에 이 둘을 컨캐이 네이트 해서 첫 번째 레이어를 만들어 주게 되고 이 레이어를 계속해서 쌓아 나가서 피드 포워드 유뉴널 네트워크의 형태로 스겔의 레이어까지 쌓아주게 됩니다. 그리고 마지막 레이어 스에서 최종적으로 두 유저와 아이템에 대한 레이팅과의 차이 값 y 햇을 구해주게 됩니다. 그래서 이 논문에서는 타겟을 0 또는 1 를 예측하는 형태로 구성했는데요. 그래서 마지막 레이어의 액티베이션 펑션은 로지스틱이나 프로빗 함수를 사용했다고 말합니다. 네 그래서 방금 설명했던 MLP 레이어가 이 우측에 들어가고요. 이 좌측에 있는 것은 기존에 우리가 4강에서 배웠던 매트리스 팩토라이제이션을 조금 더 일반화한 형태의 표현입니다. 그래서 그림을 보시면 좌측에 있는 이 GMF 레이어 제너럴라이제이션 매트리스 팩토라이제이션 레이어는 유저 아이템을 각각 엠프 아이템과 엠프 유저 벡터로 인베딩한 뒤 이후에 이 둘을 엘레멘트 와이즈 프로덕트 해서 GMF 값을 구해줍니다. 그리고 이 오른쪽에 있는 부분은 방금 설명했던 것처럼 MLP 인베딩과 MLP 아이템 인베딩을 사용하여서 컨케이트네이트를 시켜주고 그 위로 fed for NA 네트워크를 쌓아줍니다. 그래서 각각의 레이어의 아웃풋을 마지막에 컨케이트네이트 해줘서 이 최종적인 뉴럴 매트리스 팩토라이제이션 레이어를 가지고 마지막 타겟 값과 y 햇을 구해서 이 둘을 최대한 비슷하게 예측되도록 모델을 학습하는 것입니다. 그래서 이 두 개의 모델을 이렇게 따로따로 구성하는 이유는 각각의 모델의 장점을 살리고 단점을 보완하기 위한 일종의 앙상블 효과를 내기 위함인데요. 한 가지 특이한 점은 매트릭스 팩토라이제이션의 유저 인베딩과 엠엘피의 유저 인베딩은 다른 레이어를 사용했다는 것입니다. 그래서 수식으로 표현하면은 이 부분이 제널라이즈 매트릭스 팩토라이제이션 레이어이고요. 이 밑에 있는 부분은 엠엘피 레이어가 됩니다. 그리고 이 둘의 아웃풋을 컨케이트네이트에서 최종적으로 시그모이드 펑션을 통해서 마지막 아웃풋을 예측해 주었습니다. 다음은 제한 모델인 뉴럴 컬래버레이터 필터링 모델 와 기존 모델의 성능을 비교한 결과입니다. 이제 비교 대상은 일반화된 매트릭스 팩토라이제이션 모델인 GMF 그리고 MLP만을 사용한 MLP 모델 그리고 이 두 모델을 앙상블안 이 본 논문에서 제안하고 있는 뉴럴 매트리스 팩토라이제이션이라는 모델입니다. 그래서 뉴 MF가 제안 모델인데요. 결과를 보시면 이 빨간색이 이 본 모델에서 제안하는 두 가지 GMF와 MLP를 각각 사용을 합쳐서 사용한 모델입니다. 보시면 트레이닝 로스는 가장 낮으면서 이 무비렌즈 데이터에 대한 히트레이쇼나 엔디cg 성능은 좀 더 높음을 알 수 있죠. 그래서 결론적으로는 이 논문 자체가 성능 향상을 크게 보였고 굉장히 추천에 잘 사용된다라기보다는 이 논문은 MLP 레이어를 기존 매트리스 팩토라이제이션에 처음 추가했던 논문이고 그런 점에서 의의가 있습니다. 그래서 추천 모델에서도 이런 MLP레이어 즉 딥러닝적인 접근을 적용했을 때 좋은 성능을 보인다라는 것을 처음 보여준 논문입니다. 다음 논문은 딥러닝을 활용한 추천 시스템에서 또 하나의 발자취를 남긴 논문인데요. 딥 뉴럴 네트워크 폴 유튜브 레코멘데이션스라는 이름입니다. 실제로 유튜브는 이 모델을 사용해서 유튜브 서비스의 추천을 제공하고 있다고 합니다. 근데 유튜브에는 셀 수 없을 만큼의 많은 추천 동영상이 존재합니다. 그래서 추천 시스템으로 볼 때도 어떤 서비스보다 가장 많은 유저와 아이템들이 있을 것입니다. 그래서 실제 추천을 적용할 때는 아래와 같은 세 가지의 문제를 해결해야 합니다. 먼저 스케일러빌리티 계속해서 말을 하고 있긴 하지만 특히 유튜브 같은 경우에는 그 유저 아이템 수가 다른 서비스에 비해서 압도적으로 더 많기 때문에 추천 모델을 학습하는 것도 중요하지만 이 학습한 모델을 효율적으로 서빙해야 합니다. 그리고 두 번째는 프레시니스인데요. 모델이 기존에 학습하고 있던 콘텐츠와 새로 업로드된 콘텐츠 를 적절하게 조합해야 한다는 것입니다. 과거에 굉장히 인기 있는 동영상만 계속해서 추천된다든지 혹은 새로운 영상은 하나도 추천이 안 된다든지 이런 경우에는 문제가 될 수 있습니다. 그래서 새로 업로드된 콘텐츠도 적절하게 익스플로레이션 하여서 과거에 인기 있는 동영상과 최근에 등장한 동영상이 적절하게 추천이 되어야 합니다. 이제 이러한 기능을 단순하게 룰 베이스로만 해결하기엔 어려움이 있기 때문에 이런 프레시니스라는 정보도 모델이 표현할 수 있도록 모델을 설계하였습니다. 네 그리고 마지막으로 큰 노이즈에 대해서 모델이 잘 대응해야 하는데요. 높은 스파 시티 즉 유저 아이템의 개수가 아주 많기 때문에 데이터는 굉장히 스파스해지고요. 또 유튜브 서비스 같은 경우에는 다양한 외부 요인이 존재하기 때문에 단순히 좋아요나 구독과 같은 익스플리시 피드백만을 사용하게 되면은 유저의 행동을 예측하기 어렵습니다. 따라서 유저가 어떤 동영상을 봤다라는 정보인 인플리시 피드백 데이터를 잘 활용해야 되고 본다면 그 영상을 다 봤는지 적게 봤는지와 같은 형태로 데이터를 가공해서 사용해야 합니다. 그래서 앞에서 언급한 이 세 가지 문제를 해결하기 위해서 유튜브는 이런 2단계의 추천 모델을 사용하였습니다. 이 부분이 본 논문에서 가장 핵심적인 부분 중의 하나인데요. 추천 시스템이 추구해야 하는 목표를 두 가지 모델에 나누어서 적용했습니다. 먼저 첫 번째는 캔디데이 제너레이션입니다. 엄청나게 많은 비디오가 있을 때 주어진 사용자에 대해서 탑 앤 추천 아이템을 생성합니다. 탑 n개를 뭐 10개 정도로 생성하는 것이 아니라 헌드레즈 수백 개의 아이템으로 추려주는 형태가 먼저 캔디데이 제너레이션입니다. 그리고 그 캔디데이트들에 대해서 최종 랭킹 수백 개의 아이템에 대해서 최종적으로 몇 개를 내보낼지 랭킹을 수행하여서 결과적으로는 십수 개의 추천 아이템을 생성해서 이를 유저에게 송출합니다. 이제 아이템이 수백 개에서 아니 수백만 개에서 수백 개로 줄어들었기 때문에 이 랭킹을 할 때는 더욱더 유저와 비디오의 피처를 더 풍부하게 사용하여서 랭킹의 정확도를 높이는 방식을 사용하고 있습니다. 자 그러면 각 단계의 모델과 그 모델이 어떤 문제를 풀어야 하는지 하나씩 살펴봅시다. 첫 번째 테스크는 캔디데이트 제너레이션입니다. 여기서는 주어진 유저에 대해서 유저가 좋아할 만한 몇백 개의 비디오를 생성하는 테스크를 수행합니다. 그래서 이를 위해서 학습하는 모델이 풀어야 하는 문제는 바로 멀티 클래스 클래시피케이션입니다. 주어진 유저가 어떤 특정 시간에 컨텍스트를 가지고 있을 때 각각의 비디오를 볼 확률을 계산하는 것인데요. 이제 이 비디오가 한 개가 아니라 수백만 개가 되기 때문에 수백만 개나 되는 비디오를 클래시피케이션 하는 즉 익스트림 멀티클래스 클래시피케이션이라고 볼 수 있습니다. 주어진 다양한 유저 벡터를 가지고 맨 마지막에 이 유저가 어떤 비디오를 볼 것인지에 대한 예측을 수행하는 것인데요. 그래서 마지막엔 결국 소프트맥스를 사용하는 수백만 개의 비디오 중에 하나의 비디오를 봤다라는 그 레이블을 예측해야 하는 멀티클래스 클래시피케이션 문제입니다. 그래서 먼저 이 모델이 사용하는 피처들 가운데 가장 중요한 피처는 바로 왓치 벡터와 서치 벡터 즉 과거에 유저가 어떤 시청 이력을 가지고 있는지 어떤 검색 이력을 가지고 있는지인데요. 이런 데이터는 사실 다른 추천 모델에서 잘 활용하지는 않았지만 이 유튜브 레코멘데이션에서는 각각의 유저의 행동 데이터들을 이렇게 인베딩을 한 이후에 이 인베딩을 에버러지 해 가지고 결국 이 에버러지 된 와치 벡터와 서치 벡터를 수행해서 예측을 수행합니다. 다만 마지막에 검색했던 검색어가 너무 큰 힘을 갖지 않도록 평균을 구했습니다. 그래서 과거의 시청 이력과 검색 이력이 잘 인베딩이 되었으면 이제 이 유저가 볼 만한 비디오를 클래시피케이션 할 때 유저가 과거에 뭐 스포츠 관련된 유튜브 동영상을 많이 봤을 경우에 스포츠 동영상이 분류될 확률이 더 높게 되겠죠 다음은 데모 그래픽 지오 그래픽 피처입니다. 추천 시스템에서 유저 정보 가운데 많이 활용하는 정보가 바로 성별, 연령 혹은 지역과 같은 정보인데요. 이제 이러한 데이터는 적절한 방법으로 인베딩을 해서 사용하고 있고요. 그리고 또 중요한 피처가 바로 이 이그잼플 에이지라는 피처입니다. 이 아이템이 언제 생성됐는지에 대한 피처를 사용하지 않고 모델을 학습하게 되면 계속해서 과거에 인기 있던 데이터 위주로 편향이 되어서 학습이 됩니다. 따라서 이 시청 로그가 학습 시점으로부터 얼마나 경과했는지 즉 이 데이터가 최근 데이터인지 혹은 과거 데이터인지 그 정보를 이그젠플 에이지라는 값으로 구성하고 그래서 과거 데이터의 경우에는 좀 덜 학습되게 그리고 최신 데이터의 경우에는 더 많이 학습될 수 있도록 이 피처를 예측의 인풋으로 사용해 주는 것입니다. 이렇게 해서 부트 스트래핑 현상은 방지하고 이 프레시니스 즉 새로운 동영상이 더 잘 추천될 수 있도록 모델을 변형한 것입니다. 네 그렇게 해서 유저가 과거에 봤던 왓치 벡터와 서치 벡터 를 인베딩해서 에버러지 하고 그 외에 지오 그래픽이나 이그젠플 에이지 같은 피처를 다 구해주고 이 모든 피처 벡터를 마지막 엠엘피 레이어에서는 하나의 컨케이트네이트 된 벡터로 만들어 줍니다. 그리고 그 위에 댄스 한 레이어 피드 포워드 유뉴럴 네트워크를 쌓아서 최종적으로 유저 벡터를 생성하게 되고 이 유저 벡터에 대해서 마지막에 이 유저가 어떤 비디오를 봤는지 멀티클래스 클래시피케이션 테스크를 수행하여서 최종적으로 로스를 구하게 됩니다. 그래서 마지막 아웃 플레이어는 어떤 비디오를 봤는지 클래시피케이션 하는 문제, 즉 소프트맥스 펑션을 사용하는 멀티클래스 클래시피케이션 문제입니다. 다음 내용은 캔디데이 제너레이션 모델이 서빙되는 부분입니다. 보통의 논문들은 모델의 성능을 이야기하긴 하지만 서빙을 어떻게 해야 하는지에 대해서는 서술하지 않는데요. 이 유튜브 추천 레코멘데이션 논문은 수백만 개의 비디오 가운데서 수백 개의 비디오를 생성하는 이 캔디데이 제너레이션 부분을 어떻게 서빙해야 하는지도 설명하고 있습니다. 그래서 주어진 유저에 대해서 상위 n개의 비디오를 추출하기 위해서는 우리가 갖고 있는 수백만 개의 비디오에 대한 모든 소프트맥스 프로벌리티를 계산하고 그중에 가장 프로벌리티가 높은 비디오 n개를 추출해야 합니다. 따라서 주어진 유저에 대해서 수백만 개에 대한 비디오 벡터의 내적을 다 계산해야 하는데요. 이제 이 계산은 굉장히 많은 시간이 소요되고 실제로 이 연산을 통해서 실시간 서빙을 하는 것은 굉장히 불가능한 부분이라고 볼 수 있죠. 따라서 우리가 필요한 것은 주어진 유저 벡터에 대해서 가장 내적이 큰 비디오 벡터를 찾아주는 것인데요. 이렇게 소프트맥스 연산을 다 해서 가장 확률이 높은 벡터를 찾는 것이 아니라 어노이와 파이스와 같이 주어진 유저 벡터와 가장 유사한 벡터를 찾아주는 에엔의 라이브러리를 여기서 사용하게 됩니다. 그래서 이 부분은 연산을 하지만 마지막 부분인 이 소프트맥스를 계산하지 않고 주어진 유저 벡터에 대해서 비디오 벡터가 인베딩 되어 있는 인덱스에서 어프록시메이트 한 탑 n개의 아이템 벡터를 찾아주는 것이죠. 그래서 정확한 소프트맥스 값을 계산하지 않지만 그와 최대한 유사하게 주어진 유저 벡터와 최대한 유사한 아이템 벡터 수백 개를 서빙하는 방식을 취하고 있습니다. 자 다음은 방금 전에 캔디딧 제너레이션 모델에서 수백 개의 추천 후보군에 대한 선택이 끝났을 때 끝나고 나서 최종 추천을 제공하기 위한 랭킹 부분의 문제입니다. 2단계 추천 구조의 두 번째 부분이 되겠습니다. 네 기본적으로는 주어진 유저 아이템 컨텍스트에 대해서 해당 아이템이 노출되었을 때 클릭한 확률을 구하는 문제이므로 로지스틱 리그레션을 사용하여서 마지막 예측 레이어를 구성합니다. 하지만 뉴럴넷 아키텍처를 사용하기 때문에 다양한 유저와 비디오 피처를 아래와 같이 사용할 수 있는 것이죠. 또한 단순히 클릭 여부를 반영하는 것이 아니라 웨이티드 로지스틱 을 사용하고 있는데요. 이는 클릭한 이후에 시청 시간이 긴지 혹은 짧은지에 대한 값을 가중치로 사용하여서 반영하고 있습니다. 네 먼저 인풋 피처 부분을 살펴봅시다. 이 부분은 유저가 과거에 어떤 채널에서 얼마나 많은 영상을 봤는지, 비디오 왓치 팩터들 혹은 어떤 토픽의 동영상을 많이 보고 그 시간이 얼마나 지났는지, 그리고 이 유저가 어떤 랭귀지를 사용하는지, 비디오의 랭귀지는 무엇인지 등의 다양한 유저 액션 피처와 아이템 피처들을 사용합니다. 사실 이 부분은 모델 구조가 특별하다기보다는 이 도메인을 잘 아는 전문가, 즉 서비스를 잘 아는 데이터 사이언티스트 같은 인력 등이 분석을 통해서 어떤 피처가 가장 좋은지 피처를 잘 셀렉션하고 그 피처를 적당히 잘 가공해야 하는 부분입니다. 그래서 모델 자체가 중요하다기보다는 그 서비스에 맞는 피처를 잘 찾아서 랭킹 모델을 구성하는 것이 더 중요한 부분입니다. 그래서 이 인풋 피처가 마지막 레이어에서 다 합쳐지게 되고요. 이 레이어는 다시 한번 엠엘피 레이어를 통하여서 최종적으로 네트워크를 통과하게 되면은 비디오가 실제로 시청될 확률을 구하게 됩니다. 그래서 0과 1을 맞추는 CTR 예측 문제와 같다고 볼 수 있습니다. 여기서 로스 펑션은 그냥 기본적인 CTR 예측 문제와는 조금 다르게 구성되는데요. 단순한 바이너리 크로스 엔트로피가 아니라 이 웨이트드 랜 크로스 엔트로피를 사용합니다. 즉 비디오를 클릭한 이후에 오래 시청했을 때와 비디오를 클릭하자마자 바로 나갔을 때의 로스 펑션을 다르게 계산하는 것이죠. 비디오를 클릭한 이후에 많이 면 많이 볼수록 그 비디오에 대해 만족했다는 것이기 때문에 그 웨이트를 더 높게 주어서 이 모델이 더 그 데이터를 잘 학습할 수 있게 하고요. 반대로 비디오를 클릭하자마자 바로 떠나는 이런 낚시나 광고성 콘텐츠 같은 경우에는 클릭이 일어나긴 하지만 시청 시간이 아주 짧기 때문에 웨이트가 거의 0에 가까울 것이고 이제 그럼 그러한 데이터는 비록 클릭은 했지만 웨이트가 아주 작기 때문에 이 모델의 로스에 거의 반영이 안 될 것입니다. 그래서 그러한 데이터는 학습에 거의 반영이 되지 않을 것입니다. 그래서 본 논문을 요약을 하자면은 딥러닝 기반의 2단계 추천을 처음으로 제안한 논문입니다. 단순히 학계에서 이야기하는 추천 성능뿐만 아니라 이 모델을 가지고 어떻게 서빙해야 현업에서 사용할 수 있는지까지 제시한 기념비적인 논문이라고 볼 수 있습니다. 그래서 캔디에 제너레이션 부분은 기본적인 시프의 아이디어를 활용하되 기존의 CF 기법은 유저 아이디만을 사용했지만 이 캔디 애니메이션 모델은 유저 아이디 외에 다양한 유저의 피처들, 다양한 아이템의 피처를 활용해서 더 정확한 탑 엔 아이템을 생성하였습니다. 또한 아이템의 최신 선을 반영하기 위해서 이그잼플 에이즈까지 사용했다는 점에서 현업의 추천에 더 가까운 모델을 제시했습니다. 그리고 랭킹 부분은 과거에 많이 사용된 로지스틱 리게션이나 트리 기반의 리그레션 트리 모델보다 딥러닝 모델이 더 뛰어난 성능을 보여주는데요. 그것은 바로 다양한 피처들을 마음껏 사용해서 마지막 레이어에서 컨케이트네이트하고 그것을 MLP 레이어를 통해서 예측을 했기 때문입니다. 또한 단순 CTR 예측으로 로스를 계산한 게 아니라 그 비디오를 클릭한 이후에 비디오를 얼마나 봤는지 익스펙티드 와치 타임을 예측하여서 더 좋은 양질의 추천 결과를 생성하였습니다. 그래서 지금까지 유튜브 추천 모델에 대한 리뷰였습니다. 이 모델 이후에 유튜브 추천 논문을 레퍼런스화하는 다양한 실용적인 모델들이 등장하게 됐는데요. 그래서 이 유튜브 레코멘데이션 논문은 여러분들이 이 강의 이후에도 다시 한 번 출력하여서 자세히 읽어보기를 추천드립니다. 그만큼 중요한 논문이기 때문입니다. 다음은 딥러닝 아키텍처 가운데 하나인 오토 인코더의 개념을 이해하고 이 오토 인코더를 활용한 추천 시스템 모델에 대해서 살펴보겠습니다. 네 먼저 오토 인코더에 대해서 간단히 살펴보겠습니다. 오토 인코더는 입력 값을 넣고 그 입력 값을 아웃풋 레이어에서 똑같이 복원하는 언슈퍼바이스 러닝 모델입니다. 아래 그림을 보시면은 인풋 데이터가 있고요. 이 인풋 데이터가 인코더를 통해서 압축된 레프레젠테이션으로 표현되고요. 이 압축된 레프레젠테이션이 다시 디코더를 통해서 기존 인풋과 최대한 비슷한 RC 스트럭트 된 인풋으로 표현되게 됩니다. 그래서 보통 인코더는 보통 오토 인코더는 인코더와 디코더 구조로 쌍을 이루어서 모델을 이루고 있습니다. 그래서 오토 인코더 모델은 방금 언급한 것처럼 주어진 인풋에 대해서 추론된 리컨스트럭트 인풋과 차이를 최대한 줄이는 방법으로 로스 펑션을 구성하고 그래서 이미지 데이터와 같은 경우에는 뭐 루트민 스퀘어 같은 에러를 사용하기도 하고요. 스퍼스 인풋 데이터 같은 경우에는 소프트 맥스 값을 이용해서 로스 값을 구성하기도 합니다. 그래서 보통 오토 인코더가 활용되는 대표적인 분야는 이상치를 탐지하는 어노말리 디텍션 그리고 중간에 이 히든 레이어가 인풋 데이터를 압축하는 압축된 레프레젠테이션으로 표현되기 때문에 이 레프레젠테이션 러닝을 다른 테스크에도 사용하기도 합니다. 그래서 통상적인 레프레젠테이션 러닝에도 이 오토 인코더가 많이 활용되고요. 또한 이미지 노이즈를 제공하는 이미지 디노이징 테스크에도 활용됩니다. 원래 오토 인코더는 기존의 이미지를 최대한 비슷하게 복원하는 테스크에서 시작했지만 실제 적용 문화를 찾다 보니 오히려 노이즈가 있는 이미지에서 노이즈를 없애는 테스크에도 반대로 활용할 수 있게 되었고 괜찮은 성능을 보였습니다. 그래서 이 테스크를 더 잘 수행하기 위해서 이 오토 인코더에서 발전된 모델이 있는데요. 바로 오토 인코더 앞에 이 디노이징이라는 이름이 붙은 디노이징 오토 인코더입니다. 기존의 입력 데이터는 노이즈가 없는 데이터인데요. 여기에 일부러 그 모델을 설계한 사람이 랜덤 노이즈나 드로브 아웃 같은 것을 추가하여서 노이지한 인풋을 강제로 생성해 주게 됩니다. 그래서 이 노이즈 한 인풋을 모델의 입력 값으로 사용하고 인코더와 디코더를 거쳐서 노이즈가 없는 원래 오리지널 이미지로 복원될 수 있도록 학습을 구성합니다. 이제 이렇게 학습할 경우 노이즈 한 인풋을 더 잘 복원해 줄 수 있는 로버스트한 모델이 학습되고 학습 데이터 에 있는 깨끗한 인풋 데이터에만 오버피팅 되는 오토 인코더가 아니라 이러한 오버피팅 되는 기존의 한계를 극복해서 더 좋은 제너럴라이제이션 성능을 보이는 모델로 발전되게 되었습니다. 그래서 이 디노이즈 오토 인코더가 일반적인 오토 인코더 제일 기본적인 오토 인코더보다 여러 테스크에서 좋은 성능을 보였습니다. 사실 지노이징 오토 인코더 이후에도 베리에이셔널 오토 인코더나 컨디셔널 오토 인코더와 같은 더 발전된 형태의 오토 인코더가 계속 등장하고 이러한 모델도 똑같이 추천 시스템에 사용되긴 했지만 저희는 이런 오토 인코더가 어떻게 발전되었는지에 대한 내용보다는 이 오토 인코더가 도대체 추천 시스템에서 어떤 형태로 활용되는지를 배워야 합니다. 그래서 앞으로 두 개의 모델을 다루면서 추천 시스템의 오토 인코더가 어떻게 적용되어 있는지 학습해 봅시다. 네 그래서 다음으로 살펴볼 논문은 오토렉입니다. 이 모델은 굉장히 간단하고 논문의 길이도 두 장으로 굉장히 짧은데요. 기존의 오토인코더를 컬래버레이트 필터링에 적용하여서 유저와 아이템에 대한 인베딩을 더 잘 표현하고 반대로 복잡도는 줄인 모델입니다. 아까 언급했던 것처럼 오토인코더는 레프레젠테이션 러닝 측면에서 좋은 성능을 내기 때문에 다양한 다운스트림 테스크에 많이 응용된다고 했죠. 이를 그대로 추천 시스템에 적용하면은 유저와 아이템의 인베딩을 오토 인코더를 활용하면은 좋은 레프리젠테이션을 만들 수 있기 때문에 이 원리를 사용하여서 오토렉이 등장하게 되었습니다. 본 논문의 아이디어는 다음과 같습니다. 오토 인코더의 입력 데이터를 레이팅 벡터, 즉 유저가 아이템에 매긴 평점 벡터로 사용한다는 것입니다. 아까 전에 예시에서는 이미지 데이터를 가지고 복원을 했는데요. 여기서는 이미지 데이터가 아니라 레이팅 데이터를 입력으로 하고 출력으로 하여서 이 레이팅 벡터를 복원하는 테스크를 수행합니다. 즉 유저나 아이템을 기준으로 기존에 주어진 평점 데이터를 그대로 복원하는 것이죠. 유저와 아이템의 벡터를 저차원의 레이턴트 피처로 나타내고 이를 사용해 평점을 예측합니다. 다음은 매트리스 팩토라이제이션과 간단히 비교해 볼 텐데요. 이 매트리스 팩토라이제이션은 리니어하고 로우 오더 한 인터랙션 을 통해 레프레젠테이션이 학습되기 때문에 그 표현력에 어느 정도 한계가 있지만 오토랙 같은 경우에는 논 리니언 a티베이션 펑션을 사용하기 때문에 좀 더 복잡한 인터랙션이 표현되게 됩니다. 네 다음은 오토랙을 그림으로 표현해 보았습니다. 상당히 간단한데요. 인풋과 아웃풋은 아까 얘기했던 것처럼 레이팅 벡터가 되는데요. 유저나 아이템을 기준으로 레이팅 벡터를 만들 수 있습니다. 아래 그림은 아이템을 기준으로 전체 유저에 대한 레이팅을 구성한 것입니다. 그래서 이 알아는 아이템 아의 레이팅 벡터가 되고요. 각각의 이 레이팅 벡터는 하나하나가 개별 유저와 아이템의 평점으로 이루어져 있습니다. 그래서 이 전체 아이템 벡터의 차원은 m 차원 즉 유저 전체의 수와 같게 되고요. 이제 이 레이팅 벡터는 인코더의 가중치 행렬인 v와 곱해져서 가운데 있는 덴 싼 레프레젠테이션이 표현되게 됩니다. 그리고 다시 이 덴싼 레프레젠테이션은 디코더의 가중치 행렬 웨이트 매트릭스가 곱해져서 다시 원래의 레이팅 매트릭스 즉 m 차원의 아이템 벡터로 복원되게 됩니다. 모델이 학습이 수행될 때는 기존의 실제 레이팅과 모델을 통해서 리컨스트렉트 된 레이팅에 루트 미스크 에러 즉 두 개의 차이의 제곱의 루트를 씌운 값을 최소화하는 방향으로 학습되게 됩니다. 그리고 이 에러는 전체 레이팅이 아니라 우리가 갖고 있는 관측된 데이터에 대해서만 학습을 하고 그 관측된 데이터의 로스만 가지고 각각의 파라미터를 업데이트합니다. 여기에 있는 이 이치라는 수식이 오토 인코더를 나타내는 펑션이고요. 이 치라는 수식을 살펴보면은 원래 레이팅 값에 인코더의 가중치 매트릭스를 곱하고 거기에 이제 뮤를 라는 바이어스를 더해서 쥐라는 액티베이션 펑션을 씌우게 되면은 이 쥐라는 값은 가운데에 있는 레프레젠테이션이 되고요. 다시 이 가운데에 있는 레프레젠테이션에 디코더의 매트릭스를 곱하고 다시 거기에 가중치 바이러스를 더해주면 최종적으로 디코더를 통과한 리컨스트럭티드 레이팅이 구해집니다. 그래서 이 치와 실제 레이팅 사이의 차이를 최소화하는 방향으로 각각의 브블 그리고 뮤비가 학습이 됩니다. 본 논문에서는 이 활성화 함수 g와 f 를 시그모이드와 아이덴티티 펑션으로 사용했다고 말합니다. 어떤 활성화 함수를 사용하느냐에 따라서 약간의 성능 차이는 발생한다고 합니다. 사실 오토랙 같은 경우에는 지금으로부터 거의 7년 전인 2015년에 발표된 논문이기 때문에 좀 오래된 페이퍼이기도 하고요. 상당히 간단한 딥러닝 구조를 사용하고 있습니다. 따라서 당시에 좋은 성능을 보이던 모델도 굉장히 단순한 모델인 r비엠과 매트리스 팩토라이제이션이 있었고 그래서 그 두 가지 모델과의 추천 성능을 비교하였습니다. 이 레이팅을 예측하는 모델이기 때문에 로스 펑션은 알엠에스이로 구성하였고, 이 RMSE를 기준으로 기존의 알비엠이나 엠프와 같은 모델보다 더 좋은 성능을 보임을 알 수 있습니다. 또한 가운데 인코더 디코더 레이어 가운데에 있는 레프리젠테이션 레이어의 노드 개수가 점점 늘어날수록 알엠스는 감소하는 것을 볼 수 있는데요. 이 노드의 개수는 가운데에 있는 히든 레이어 즉 유저와 아이템의 벡터를 몇 차원으로 레프레젠테이션 하느냐를 의미하는 것입니다. 물론 어느 어느 정도 증가하게 되면 그 알엠스의 감소 폭은 줄어들게 됩니다. 그래서 본 논문 이후에 이 오토 인코더 기법을 좀 더 고급 오토 인코더로 발전한 다양한 컬래버레이트 필터링 논문들이 다음과 같이 등장했는데요. dae 혹은 vae를 활용한 아래의 논문들도 여러분들이 관심이 있으면 찾아보고 공부해 보시길 추천드립니다. 네 그래서 다음은 이 고급 오토 인코더 가운데 디노이징 오토 인코더 를 컬래버레이트 필터링에 적용한 모델, 즉 컬래버레이트 디노이징 오토인코더라는 cdae 논문입니다. 이름 그대로 디노이징 오토 인코더를 사용하였으며 학습 데이터를 적절하게 가공해서 탑 엔 레코멘데이션 즉 웨이팅을 정확하게 예측하는 것이 아니라 아이템에 대한 선호도를 예측하여서 그 아이템 탑 n개를 추천하는 논문으로 구성하였습니다. 네 이 모델은 오토랙과 달리 평점을 예측하는 레이팅 프로젝션 문제가 아니라 유저에게 탑 엔 추천을 제공하는 모델로 설계하였습니다. 그래서 오토렉의 경우에는 최종 성능 비교를 알엠스 즉 테이터 테스트 데이터의 웨이팅을 얼마나 정확하게 복원했는지로 평가했지만 본 논문 씨디에이는 유저에게 탑 앤 추천을 얼마나 잘 제공했는지 엔디시지와 같은 매트릭으로 추천 성능을 평가하고 있습니다. 그리고 탑 n 추천 문제로 정의하면서 문제를 단순화하기 위해서 유저 아이템의 레이팅 정보를 실수 값이 아닌 0 또는 1의 바이너리 정보로 바꾸어서 학습 데이터를 사용하였습니다. 어떤 프리퍼런스 즉 얼마나 선호하냐 그 선호도 정보를 학습하게 됩니다. 그리고 이 선호도가 곧바로 탑 앤 추천에 활용됩니다. 네 다음은 cdae 컬래버레이티브 디노이징 오토 인코더의 특징에 대해서 자세히 살펴봅시다. 가장 큰 차이점은 여기에 있는 da 디노이징 오토 인코더를 사용한다는 점입니다. 한 명의 유저 율을 기준으로 모든 아이템에 대한 평점인 yu를 구한 뒤 이 yu를 그대로 사용하지 않고 yu 틸드 값을 사용합니다. 이 yu 틸드는 q의 확률로 의해 0으로 드롭아웃 된 벡터입니다. 즉 q의 확률로 어떤 원소는 0이 되고 1 마이너스 q의 확률로는 어떤 원소는 기존 평점 값에 델타가 곱해지게 됩니다. 그래서 이렇게 해서 노이즈 한 인풋을 만들어서 디노이징 오토인 코드를 구성하였고요. 또 하나의 차이점은 개별 유저에 대한 브유라는 파라미터가 존재한다는 것입니다. 유저별로 갖는 특징들이 있을 텐데 그 유저별 특징을 이 브유라는 파라미터가 각각 개별 유저에 대해서 학습을 하게 됩니다. 그리고 이는 유저별 탑 앤 추천에 활용돼서 추천 성능을 높여줍니다. 각각의 유저별로 특징이 다르고 그 특징이 각각의 파라미터를 통해 학습이 되면서 이 모델에 컬래버레이티브라는 이름이 붙게 되었음을 언급 드립니다. 그래서 이를 수식으로 나타내면 인코더 부분에 노이즈 한 인풋인 와유틸드가 사용되었고 그리고 개별 유저의 벡터인 브이 즉 유저 노드가 사용되어서 가운데에 있는 히든 레이어를 구성하게 됩니다. 그리고 히든 레이어가 다시 디코더를 통해서 복원되는 것은 기존의 오토 인코더와 동일합니다. 그래서 가장 큰 차이점은 바로 이 yu 틸드를 사용해서 인풋 값을 n이지하게 바꿨다. 그리고 유저에 대한 파라미터를 추가하여서 유저별 특징을 학습하도록 하였다. 이 두 가지가 앞에서 언급한 오토랩과의 가장 큰 차이점이라고 볼 수 있습니다. 그래서 해당 모델을 사용하여서 기존의 탑 엔 추천 테스크에서 좋은 성능을 내던 다른 모델과 비교한 결과를 본 논문에서 제시하고 있습니다. 대체적으로 이 n에 관계없이 다른 탑 엔 추천 모델, 즉 아이템 베이스나 MF 와 같은 다른 추천 모델에 비해서 이 씨디에이가 좋은 타앤 추천 성능을 보임을 알 수 있습니다. 네 여기까지가 씨디에이 콜라보레이티브 디노이징 오토 인코더에 관한 내용이었습니다. 이 논문 외에도 다른 고급 오토 인코더를 사용한 추천 모델은 계속해서 발표되어 왔는데요. 이 개별 모델에 대한 이해도도 중요하지만 무엇보다 오토 인코더를 활용한 추천 모델이 어떻게 유저 아이템 인베딩이 학습되는지를 기억하는 것이 제일 중요하다고 볼 수 있습니다. 네 이상 여섯 번째 강의가 모두 끝났습니다. 오늘도 수고하셨습니다.","confidence":0.92444843,"speakers":[{"label":"","name":"","edited":false}],"events":[],"eventTypes":[]}