{"result":"SUCCEEDED","message":"Succeeded","token":"7603429010f545ef92db4b14cd2038f2","version":"ncp_v2_v2.4.6-c00dd1b-20250528__v4.2.20.1_ko_firedepartment_20250923_","params":{"service":"ncp","domain":"general","lang":"ko","completion":"sync","callback":"","diarization":{"enable":false,"speakerCountMin":-1,"speakerCountMax":-1},"sed":{"enable":false},"boostings":[],"forbiddens":"","wordAlignment":true,"fullText":true,"noiseFiltering":true,"priority":0,"userdata":{"_ncp_DomainCode":"tpc-boostcamp","_ncp_DomainId":13807,"_ncp_TaskId":42975813,"_ncp_TraceId":"672800e23ac240eb96e15b0875ef40ca"}},"progress":100,"keywords":{},"segments":[{"start":0,"end":12400,"text":"안녕하세요. 추천 시스템 강의를 맡고 있는 강사 이준원입니다. 이번 시간은 여덟 번째 강의","confidence":0.9556,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[5630,6120,"안녕하세요."],[7010,7280,"추천"],[7310,7660,"시스템"],[7810,8100,"강의를"],[8110,8347,"맡고"],[8347,8540,"있는"],[8770,9060,"강사"],[9190,9940,"이준원입니다."],[10950,11180,"이번"],[11230,11560,"시간은"],[11570,11800,"여덟"],[11800,12040,"번째"],[12050,12260,"강의"]],"textEdited":"안녕하세요. 추천 시스템 강의를 맡고 있는 강사 이준원입니다. 이번 시간은 여덟 번째 강의"},{"start":12400,"end":25900,"text":"컨텍스트의 레코멘데이션이라는 이름으로 진행하겠습니다. 기본적으로 추천 시스템 분야는 유저와 아이템 사이의 상호 작용을 모델링하는 컬라버레이트 필터링으로부터 시작한 모델들이 주를 이룹니다.","confidence":0.8811,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[12750,13460,"컨텍스트의"],[13490,14760,"레코멘데이션이라는"],[14810,15160,"이름으로"],[15210,15900,"진행하겠습니다."],[16290,16800,"기본적으로"],[16850,17140,"추천"],[17170,17540,"시스템"],[17630,18020,"분야는"],[18590,19020,"유저와"],[19110,19540,"아이템"],[19670,20020,"사이의"],[20130,20340,"상호"],[20370,20700,"작용을"],[20700,21220,"모델링하는"],[21910,22400,"컬라버레이트"],[22430,23280,"필터링으로부터"],[23330,23680,"시작한"],[23810,24320,"모델들이"],[24890,25200,"주를"],[25200,25560,"이룹니다."]],"textEdited":"컨텍스트의 레코멘데이션이라는 이름으로 진행하겠습니다. 기본적으로 추천 시스템 분야는 유저와 아이템 사이의 상호 작용을 모델링하는 컬라버레이트 필터링으로부터 시작한 모델들이 주를 이룹니다."},{"start":25900,"end":37600,"text":"하지만 이번 시간에는 유저 아이템, 아이디 피처 외에 다양한 부가 정보 즉 컨텍스트 정보를 풍부하게 활용하여 추천을 제공하는 모델들을 위주로 살펴보겠습니다.","confidence":0.9325,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[26130,26380,"하지만"],[26380,26600,"이번"],[26630,27020,"시간에는"],[27270,27560,"유저"],[27690,28060,"아이템,"],[28130,28480,"아이디"],[28730,29020,"피처"],[29020,29280,"외에"],[29950,30320,"다양한"],[30390,30620,"부가"],[30670,30980,"정보"],[31330,31480,"즉"],[31570,32100,"컨텍스트"],[32110,32560,"정보를"],[33170,33640,"풍부하게"],[33690,34060,"활용하여"],[34170,34560,"추천을"],[34570,34980,"제공하는"],[35010,35880,"모델들을"],[35880,36200,"위주로"],[36690,37480,"살펴보겠습니다."]],"textEdited":"하지만 이번 시간에는 유저 아이템, 아이디 피처 외에 다양한 부가 정보 즉 컨텍스트 정보를 풍부하게 활용하여 추천을 제공하는 모델들을 위주로 살펴보겠습니다."},{"start":37600,"end":52400,"text":"네 먼저 컨텍스트 어여 레코멘데이션 문제가 무엇이고 어떤 분야에 활용되는지 주로 어떤 데이터를 사용하여서 모델링을 하는지 살펴봅시다. 다음으로 콘텍스트 어여 레코멘데이션 가운데 대표적인 문제인 CTR 프리딕션 문제","confidence":0.914,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[38210,38360,"네"],[38370,38640,"먼저"],[38790,39340,"컨텍스트"],[39340,39540,"어여"],[39550,40180,"레코멘데이션"],[40270,40620,"문제가"],[40650,41120,"무엇이고"],[41190,41440,"어떤"],[41530,41860,"분야에"],[41870,42500,"활용되는지"],[42990,43260,"주로"],[43450,43760,"어떤"],[43950,44420,"데이터를"],[44420,44900,"사용하여서"],[44930,45360,"모델링을"],[45360,45720,"하는지"],[46230,46800,"살펴봅시다."],[47350,47760,"다음으로"],[47870,48440,"콘텍스트"],[48440,48640,"어여"],[48640,49240,"레코멘데이션"],[49250,49620,"가운데"],[49830,50280,"대표적인"],[50350,50680,"문제인"],[50850,51240,"CTR"],[51470,51860,"프리딕션"],[51890,52140,"문제"]],"textEdited":"네 먼저 컨텍스트 어여 레코멘데이션 문제가 무엇이고 어떤 분야에 활용되는지 주로 어떤 데이터를 사용하여서 모델링을 하는지 살펴봅시다. 다음으로 콘텍스트 어여 레코멘데이션 가운데 대표적인 문제인 CTR 프리딕션 문제"},{"start":52400,"end":63100,"text":"사용되는 이 FM 팩토라이제이션이 머신과 필드어의 팩토라이제이션 머신 FFM의 모델에 대해서 학습합니다. 이 FM과 FFM 모델은 딥러닝이","confidence":0.8337,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[52910,53380,"사용되는"],[53910,54060,"이"],[54190,54440,"FM"],[54790,55640,"팩토라이제이션이"],[55730,56140,"머신과"],[56310,56800,"필드어의"],[56830,57400,"팩토라이제이션"],[57410,57660,"머신"],[57930,59140,"FFM의"],[59140,59407,"모델에"],[59407,59680,"대해서"],[59730,60220,"학습합니다."],[60550,60700,"이"],[60750,61120,"FM과"],[61190,61600,"FFM"],[61600,61920,"모델은"],[62130,62700,"딥러닝이"]],"textEdited":"사용되는 이 FM 팩토라이제이션이 머신과 필드어의 팩토라이제이션 머신 FFM의 모델에 대해서 학습합니다. 이 FM과 FFM 모델은 딥러닝이"},{"start":63100,"end":76900,"text":"등장하기 전에 이 분야에서 가장 뛰어난 성능을 보인 머신러닝 모델이고요. 지금 현재도 현업에서 활발하게 사용되고 있습니다. 마지막으로 CTR 예측 문제를 포함하여서 그 외에 다양한 컴퍼티션에서","confidence":0.9723,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[63490,63887,"등장하기"],[63887,64180,"전에"],[64690,64840,"이"],[64850,65280,"분야에서"],[65310,65540,"가장"],[65690,66040,"뛰어난"],[66150,66480,"성능을"],[66490,66700,"보인"],[67070,67560,"머신러닝"],[67570,68420,"모델이고요."],[69110,69380,"지금"],[69710,70100,"현재도"],[70130,70540,"현업에서"],[70910,71360,"활발하게"],[71390,71800,"사용되고"],[71800,72160,"있습니다."],[72590,73060,"마지막으로"],[73170,73520,"CTR"],[73550,73820,"예측"],[73820,74120,"문제를"],[74170,74700,"포함하여서"],[74950,75100,"그"],[75100,75300,"외에"],[75390,75740,"다양한"],[75890,76640,"컴퍼티션에서"]],"textEdited":"등장하기 전에 이 분야에서 가장 뛰어난 성능을 보인 머신러닝 모델이고요. 지금 현재도 현업에서 활발하게 사용되고 있습니다. 마지막으로 CTR 예측 문제를 포함하여서 그 외에 다양한 컴퍼티션에서"},{"start":76900,"end":88100,"text":"다양한 캐글 컴퍼티션에서 좋은 성능을 내고 있는 그레디언트 부스팅 머신에 대해서 다뤄보겠습니다. 첫 번째 컨텍스트의 레코멘데이션이 무엇인지","confidence":0.8666,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[77210,77520,"다양한"],[77610,77880,"캐글"],[77910,78580,"컴퍼티션에서"],[79170,79360,"좋은"],[79550,79880,"성능을"],[79880,80120,"내고"],[80120,80320,"있는"],[80930,81440,"그레디언트"],[81450,81820,"부스팅"],[81870,82860,"머신에"],[82860,83220,"대해서"],[83570,84440,"다뤄보겠습니다."],[84910,85060,"첫"],[85060,85300,"번째"],[85890,86560,"컨텍스트의"],[86560,87180,"레코멘데이션이"],[87210,87840,"무엇인지"]],"textEdited":"다양한 캐글 컴퍼티션에서 좋은 성능을 내고 있는 그레디언트 부스팅 머신에 대해서 다뤄보겠습니다. 첫 번째 컨텍스트의 레코멘데이션이 무엇인지"},{"start":88100,"end":100700,"text":"앞에서 다룬 컬래버이트 필터링과 어떻게 다른지를 이해하고 이 테스크가 어떠한 양상으로 발전해 왔는지를 간단하게 살펴보겠습니다. 컨텍스트와 레코멘데이션 문제를 정의하기 이전에","confidence":0.9202,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[88410,88800,"앞에서"],[88810,89080,"다룬"],[89750,90220,"컬래버이트"],[90230,90720,"필터링과"],[90870,91180,"어떻게"],[91190,91640,"다른지를"],[91650,92100,"이해하고"],[92830,92980,"이"],[93310,93740,"테스크가"],[93810,94100,"어떠한"],[94190,94620,"양상으로"],[94710,95120,"발전해"],[95120,95620,"왔는지를"],[95750,96200,"간단하게"],[96370,97160,"살펴보겠습니다."],[97770,98360,"컨텍스트와"],[98410,98960,"레코멘데이션"],[99030,99360,"문제를"],[99410,99920,"정의하기"],[99920,100300,"이전에"]],"textEdited":"앞에서 다룬 컬래버이트 필터링과 어떻게 다른지를 이해하고 이 테스크가 어떠한 양상으로 발전해 왔는지를 간단하게 살펴보겠습니다. 컨텍스트와 레코멘데이션 문제를 정의하기 이전에"},{"start":100700,"end":115500,"text":"우리가 지금까지 추천 시스템에서 사용했던 데이터는 크게 세 가지로 분류할 수 있습니다. 유저 정보와 아이템 정보 그리고 유저와 아이템의 상호작용 정보 있죠? 우리가 지난 7강까지 학습했던 모델들은 주로 유저의","confidence":0.9671,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[100910,101180,"우리가"],[101290,101740,"지금까지"],[101770,102060,"추천"],[102110,102680,"시스템에서"],[102710,103180,"사용했던"],[103230,103740,"데이터는"],[104230,104460,"크게"],[104590,104740,"세"],[104740,105160,"가지로"],[105310,105700,"분류할"],[105730,105880,"수"],[105880,106260,"있습니다."],[107070,107340,"유저"],[107370,107740,"정보와"],[108010,108400,"아이템"],[108490,108780,"정보"],[108930,109200,"그리고"],[109390,109740,"유저와"],[109790,110400,"아이템의"],[110550,111040,"상호작용"],[111090,111340,"정보"],[111340,111560,"있죠?"],[111990,112220,"우리가"],[112250,112440,"지난"],[112550,113080,"7강까지"],[113110,113580,"학습했던"],[113670,114160,"모델들은"],[114390,114680,"주로"],[114750,115160,"유저의"]],"textEdited":"우리가 지금까지 추천 시스템에서 사용했던 데이터는 크게 세 가지로 분류할 수 있습니다. 유저 정보와 아이템 정보 그리고 유저와 아이템의 상호작용 정보 있죠? 우리가 지난 7강까지 학습했던 모델들은 주로 유저의"},{"start":115500,"end":130300,"text":"아이디와 아이템 아이디 정보를 사용하고 그 외에 유저와 아이템의 상호작용 정보를 주로 잘 사용해서 이 모델에 반영하는 컬라버레이트 필터링 기반의 모델이었습니다. 그래서 유저와 아이템의","confidence":0.9506,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[115850,116360,"아이디와"],[116430,116740,"아이템"],[116770,117060,"아이디"],[117090,117980,"정보를"],[117990,118460,"사용하고"],[119050,119200,"그"],[119210,119460,"외에"],[119830,120220,"유저와"],[120290,120740,"아이템의"],[120810,121320,"상호작용"],[121370,121740,"정보를"],[122370,122640,"주로"],[122730,122880,"잘"],[123010,123460,"사용해서"],[124110,124260,"이"],[124270,124620,"모델에"],[124710,125180,"반영하는"],[125470,125980,"컬라버레이트"],[125990,126320,"필터링"],[126320,126660,"기반의"],[126790,127540,"모델이었습니다."],[127910,128140,"그래서"],[128190,128920,"유저와"],[129470,130000,"아이템의"]],"textEdited":"아이디와 아이템 아이디 정보를 사용하고 그 외에 유저와 아이템의 상호작용 정보를 주로 잘 사용해서 이 모델에 반영하는 컬라버레이트 필터링 기반의 모델이었습니다. 그래서 유저와 아이템의"},{"start":130300,"end":135200,"text":"고유한 아이디 외에 다른 이런 성별이나 연령이라든지 혹은 아이템의","confidence":0.9897,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[130570,130860,"고유한"],[130890,131200,"아이디"],[131230,131520,"외에"],[131690,131920,"다른"],[132510,132680,"이런"],[132870,133360,"성별이나"],[133410,134240,"연령이라든지"],[134270,134460,"혹은"],[134530,135020,"아이템의"]],"textEdited":"고유한 아이디 외에 다른 이런 성별이나 연령이라든지 혹은 아이템의"},{"start":135200,"end":145800,"text":"적혀 있는 카테고리나 출시 연도 같은 유저 아이템의 메타 데이터 정보는 사용하지 않거나 혹은 사용하기 어려운 모델들이 주로 많았습니다.","confidence":0.9364,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[135450,135760,"적혀"],[135760,135920,"있는"],[136070,136640,"카테고리나"],[137070,137327,"출시"],[137327,137540,"연도"],[137540,137780,"같은"],[138310,138580,"유저"],[138610,139000,"아이템의"],[139010,139260,"메타"],[139260,139580,"데이터"],[139710,140120,"정보는"],[140570,141040,"사용하지"],[141110,141540,"않거나"],[141730,141960,"혹은"],[142130,142560,"사용하기"],[142690,142980,"어려운"],[143090,143600,"모델들이"],[144890,145120,"주로"],[145120,145660,"많았습니다."]],"textEdited":"적혀 있는 카테고리나 출시 연도 같은 유저 아이템의 메타 데이터 정보는 사용하지 않거나 혹은 사용하기 어려운 모델들이 주로 많았습니다."},{"start":145800,"end":154400,"text":"가장 대표적인 CF 컬라버레이트 필터링 모델인 MF 매트리스 팩토라이제이션 모델이죠. 이것을 학습하기 위한 학습 데이터를","confidence":0.9048,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[146290,146540,"가장"],[146730,147160,"대표적인"],[147630,148040,"CF"],[148190,148680,"컬라버레이트"],[148690,149040,"필터링"],[149040,149380,"모델인"],[149770,150220,"MF"],[150550,150940,"매트리스"],[150940,151540,"팩토라이제이션"],[151550,152040,"모델이죠."],[152370,152700,"이것을"],[152750,153220,"학습하기"],[153220,153400,"위한"],[153570,153800,"학습"],[153800,154240,"데이터를"]],"textEdited":"가장 대표적인 CF 컬라버레이트 필터링 모델인 MF 매트리스 팩토라이제이션 모델이죠. 이것을 학습하기 위한 학습 데이터를"},{"start":154400,"end":163800,"text":"기억해 봅시다. 이 유저의 데모 그래픽 혹은 아이템의 카테고리와 같은 정보들 풍부한 정보들이 존재함에도 불구하고 이러한 특성들을 사용할 수 없었습니다.","confidence":0.9867,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[154650,155020,"기억해"],[155020,155360,"봅시다."],[155790,155907,"이"],[155907,156240,"유저의"],[156250,156500,"데모"],[156510,156860,"그래픽"],[157170,157360,"혹은"],[157390,157800,"아이템의"],[157810,158267,"카테고리와"],[158267,158500,"같은"],[158590,158960,"정보들"],[159190,159480,"풍부한"],[159550,159960,"정보들이"],[159990,160680,"존재함에도"],[160710,161280,"불구하고"],[161770,162040,"이러한"],[162170,162700,"특성들을"],[162730,163080,"사용할"],[163080,163187,"수"],[163187,163740,"없었습니다."]],"textEdited":"기억해 봅시다. 이 유저의 데모 그래픽 혹은 아이템의 카테고리와 같은 정보들 풍부한 정보들이 존재함에도 불구하고 이러한 특성들을 사용할 수 없었습니다."},{"start":163800,"end":177100,"text":"왜냐하면 매트릭스 팩토라이제이션은 유저와 아이템으로 이루어진 유저 아이템 매트릭스 데이터를 가지고 학습 데이터를 활용했기 때문에 그 외에 다른 정보들은 사용할 수가 없는 모델이었죠. 이와 같이","confidence":0.9622,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[163990,164227,"왜냐하면"],[164227,164540,"매트릭스"],[164540,165220,"팩토라이제이션은"],[165590,166280,"유저와"],[166430,167040,"아이템으로"],[167070,167480,"이루어진"],[167930,168180,"유저"],[168230,168520,"아이템"],[168530,168920,"매트릭스"],[168920,169540,"데이터를"],[169570,169960,"가지고"],[170350,170600,"학습"],[170600,170980,"데이터를"],[170980,171367,"활용했기"],[171367,171720,"때문에"],[172530,172680,"그"],[172690,172920,"외에"],[172950,173140,"다른"],[173250,173680,"정보들은"],[174150,174480,"사용할"],[174490,174700,"수가"],[174730,174940,"없는"],[175090,175680,"모델이었죠."],[176050,176280,"이와"],[176280,176560,"같이"]],"textEdited":"왜냐하면 매트릭스 팩토라이제이션은 유저와 아이템으로 이루어진 유저 아이템 매트릭스 데이터를 가지고 학습 데이터를 활용했기 때문에 그 외에 다른 정보들은 사용할 수가 없는 모델이었죠. 이와 같이"},{"start":177100,"end":189800,"text":"이 MF의 학습 데이터는 오로지 유저가 어떤 아이템을 소비했다라는 상호작용 데이터만으로 구성되는데요. 이 경우에 상호 작용 정보가 아직 부족하거나 혹은 아예 데이터가 없는 유저 아이템에 대해서","confidence":0.9483,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[177430,177580,"이"],[177650,178160,"MF의"],[178210,178440,"학습"],[178440,178840,"데이터는"],[178850,179220,"오로지"],[179630,180160,"유저가"],[180290,180480,"어떤"],[180490,180880,"아이템을"],[180910,181560,"소비했다라는"],[181650,182120,"상호작용"],[182120,182720,"데이터만으로"],[182730,183340,"구성되는데요."],[183830,183947,"이"],[183947,184240,"경우에"],[184410,184640,"상호"],[184650,184900,"작용"],[184950,185260,"정보가"],[185270,185480,"아직"],[185590,186300,"부족하거나"],[186870,187100,"혹은"],[187270,187500,"아예"],[187570,188040,"데이터가"],[188090,188280,"없는"],[188430,188720,"유저"],[188810,189280,"아이템에"],[189280,189580,"대해서"]],"textEdited":"이 MF의 학습 데이터는 오로지 유저가 어떤 아이템을 소비했다라는 상호작용 데이터만으로 구성되는데요. 이 경우에 상호 작용 정보가 아직 부족하거나 혹은 아예 데이터가 없는 유저 아이템에 대해서"},{"start":189800,"end":201900,"text":"이 엠프 추천 모델을 사용할 경우 좋은 추천을 제공하기가 어렵습니다. 그래서 이러한 문제를 콜드 스타트라고 하는데요. 이제 이 엠프와 같은 모델들은 콜드 스타트에 대한 대처가 어려운 부분이 있죠.","confidence":0.8633,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[189970,190120,"이"],[190130,190460,"엠프"],[190490,190720,"추천"],[190720,191040,"모델을"],[191040,191360,"사용할"],[191370,191620,"경우"],[192070,192240,"좋은"],[192410,192800,"추천을"],[192930,193460,"제공하기가"],[193460,193940,"어렵습니다."],[194210,194400,"그래서"],[194400,194640,"이러한"],[194730,195100,"문제를"],[195590,195880,"콜드"],[195880,196860,"스타트라고"],[196860,197240,"하는데요."],[197830,198000,"이제"],[198010,198160,"이"],[198210,198660,"엠프와"],[198660,198840,"같은"],[198840,199260,"모델들은"],[199470,199720,"콜드"],[199720,200074,"스타트에"],[200074,200240,"대한"],[200370,200740,"대처가"],[200930,201200,"어려운"],[201310,201587,"부분이"],[201587,201820,"있죠."]],"textEdited":"이 엠프 추천 모델을 사용할 경우 좋은 추천을 제공하기가 어렵습니다. 그래서 이러한 문제를 콜드 스타트라고 하는데요. 이제 이 엠프와 같은 모델들은 콜드 스타트에 대한 대처가 어려운 부분이 있죠."},{"start":201900,"end":215400,"text":"그래서 컨텍스트 어어 레코멘데이션은 유저 아이디 혹은 아이템 아이디 말고 그 유저가 가지고 있는 혹은 아이템이 가지고 있는 다양한 특성들을 추천 시스템에 오히려 반영할 수 있게 발전돼 왔습니다.","confidence":0.9488,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[202190,202440,"그래서"],[202790,203300,"컨텍스트"],[203350,203580,"어어"],[203590,204280,"레코멘데이션은"],[204530,204820,"유저"],[205450,205780,"아이디"],[206070,206240,"혹은"],[206270,206560,"아이템"],[206560,206840,"아이디"],[206870,207180,"말고"],[207490,207607,"그"],[207607,207920,"유저가"],[207950,208260,"가지고"],[208260,208400,"있는"],[208430,208600,"혹은"],[208610,209060,"아이템이"],[209090,209400,"가지고"],[209400,209560,"있는"],[209710,210040,"다양한"],[210610,211120,"특성들을"],[211650,211920,"추천"],[211930,212300,"시스템에"],[212300,212540,"오히려"],[212730,213080,"반영할"],[213090,213240,"수"],[213240,213480,"있게"],[214210,214620,"발전돼"],[214630,215220,"왔습니다."]],"textEdited":"그래서 컨텍스트 어어 레코멘데이션은 유저 아이디 혹은 아이템 아이디 말고 그 유저가 가지고 있는 혹은 아이템이 가지고 있는 다양한 특성들을 추천 시스템에 오히려 반영할 수 있게 발전돼 왔습니다."},{"start":215400,"end":230300,"text":"컨텍스트 기반 추천 시스템의 경우 유저와 아이템의 상호작용 정보는 가장 중요하기 때문에 당연히 필수적으로 사용하지만 그뿐만이 아니라 해당 상호작용이 일어났던 맥락적 정보 컨텍스트 정보를 함께 사용합니다.","confidence":0.9425,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[215710,216167,"컨텍스트"],[216167,216360,"기반"],[216430,216680,"추천"],[216710,217140,"시스템의"],[217140,217360,"경우"],[217910,218280,"유저와"],[218310,218820,"아이템의"],[218910,219400,"상호작용"],[219470,219840,"정보는"],[220610,220840,"가장"],[220890,221207,"중요하기"],[221207,221480,"때문에"],[221490,221800,"당연히"],[221850,222280,"필수적으로"],[222280,222760,"사용하지만"],[223410,223934,"그뿐만이"],[223934,224220,"아니라"],[224750,224980,"해당"],[225110,225640,"상호작용이"],[225670,226160,"일어났던"],[226870,227320,"맥락적"],[227370,227620,"정보"],[228050,228600,"컨텍스트"],[228630,229020,"정보를"],[229370,229680,"함께"],[229730,230160,"사용합니다."]],"textEdited":"컨텍스트 기반 추천 시스템의 경우 유저와 아이템의 상호작용 정보는 가장 중요하기 때문에 당연히 필수적으로 사용하지만 그뿐만이 아니라 해당 상호작용이 일어났던 맥락적 정보 컨텍스트 정보를 함께 사용합니다."},{"start":230300,"end":238400,"text":"여기서 이 컨텍스트라는 단어 안에는 유저의 부가 정보와 아이템의 부가 정보도 들어가고요. 유저와 아이템 정보 외에","confidence":0.9615,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[230670,230894,"여기서"],[230894,231020,"이"],[231020,231760,"컨텍스트라는"],[231810,232100,"단어"],[232110,232520,"안에는"],[233030,233460,"유저의"],[233510,233740,"부가"],[233810,234180,"정보와"],[234180,234580,"아이템의"],[234580,234780,"부가"],[234850,235300,"정보도"],[235300,235840,"들어가고요."],[236290,236880,"유저와"],[236990,237380,"아이템"],[237470,237720,"정보"],[237750,238100,"외에"]],"textEdited":"여기서 이 컨텍스트라는 단어 안에는 유저의 부가 정보와 아이템의 부가 정보도 들어가고요. 유저와 아이템 정보 외에"},{"start":238400,"end":251700,"text":"그 추천이 일어났던 그 아이템의 소비가 일어났던 당시의 시간이나 공간적 정보 같은 다양한 정보들이 다 컨텍스트라는 단어로 표현됩니다. 그래서 이 컨텍스트 정보는 서비스와 데이터마다 모두 형태와","confidence":0.966,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[239310,239460,"그"],[239510,239920,"추천이"],[239920,240340,"일어났던"],[240450,240600,"그"],[240600,240960,"아이템의"],[240970,241340,"소비가"],[241370,241840,"일어났던"],[242030,242360,"당시의"],[242410,242760,"시간이나"],[242790,243160,"공간적"],[243310,243580,"정보"],[243590,243860,"같은"],[244270,244580,"다양한"],[244630,245020,"정보들이"],[245020,245140,"다"],[245470,246160,"컨텍스트라는"],[246190,246560,"단어로"],[247110,247700,"표현됩니다."],[248110,248274,"그래서"],[248274,248400,"이"],[248410,248980,"컨텍스트"],[249050,249440,"정보는"],[249570,250120,"서비스와"],[250150,250700,"데이터마다"],[250730,250940,"모두"],[251050,251480,"형태와"]],"textEdited":"그 추천이 일어났던 그 아이템의 소비가 일어났던 당시의 시간이나 공간적 정보 같은 다양한 정보들이 다 컨텍스트라는 단어로 표현됩니다. 그래서 이 컨텍스트 정보는 서비스와 데이터마다 모두 형태와"},{"start":251700,"end":266600,"text":"사용되는 종류가 다르기 때문에 그러한 피처들을 모두 담을 수 있는 제너럴한 모델이 설계되어야 합니다. 따라서 기존의 CF 기반의 추천 모델이 해결하는 문제와 접근 방법이 달라지고 그에 따라서 데이터를","confidence":0.9444,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[251950,252420,"사용되는"],[252530,252840,"종류가"],[252840,253147,"다르기"],[253147,253520,"때문에"],[254050,254260,"그러한"],[254350,254820,"피처들을"],[254910,255140,"모두"],[255190,255480,"담을"],[255530,255647,"수"],[255647,255840,"있는"],[256250,256740,"제너럴한"],[256770,257120,"모델이"],[257230,257860,"설계되어야"],[257870,258160,"합니다."],[258810,259160,"따라서"],[259970,260360,"기존의"],[260450,260880,"CF"],[260950,261300,"기반의"],[261310,261580,"추천"],[261590,261920,"모델이"],[261950,262420,"해결하는"],[262510,262900,"문제와"],[263670,263980,"접근"],[263990,264280,"방법이"],[264290,264780,"달라지고"],[265150,265327,"그에"],[265327,265660,"따라서"],[265770,266360,"데이터를"]],"textEdited":"사용되는 종류가 다르기 때문에 그러한 피처들을 모두 담을 수 있는 제너럴한 모델이 설계되어야 합니다. 따라서 기존의 CF 기반의 추천 모델이 해결하는 문제와 접근 방법이 달라지고 그에 따라서 데이터를"},{"start":266600,"end":279700,"text":"구성하는 방법도 달라지게 됩니다. 가장 큰 차이점은 유저 아이템 매트릭스의 빈 공간을 채우는 게 아니라 다음과 같이 주어진 x에 대해서 y 값을 추론하는 우리가 보통 일반적인 예측 문제를","confidence":0.9576,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[266910,267300,"구성하는"],[267390,267800,"방법도"],[267850,268227,"달라지게"],[268227,268540,"됩니다."],[268910,269160,"가장"],[269230,269380,"큰"],[269450,269940,"차이점은"],[270370,270660,"유저"],[270670,271000,"아이템"],[271050,271620,"매트릭스의"],[271710,271860,"빈"],[271890,272260,"공간을"],[272330,272680,"채우는"],[272680,272767,"게"],[272767,273040,"아니라"],[273570,273900,"다음과"],[273900,274200,"같이"],[274510,274860,"주어진"],[275230,275520,"x에"],[275520,275840,"대해서"],[275970,276120,"y"],[276290,276640,"값을"],[276650,277020,"추론하는"],[277130,277380,"우리가"],[277450,277760,"보통"],[278250,278700,"일반적인"],[278730,279000,"예측"],[279030,279460,"문제를"]],"textEdited":"구성하는 방법도 달라지게 됩니다. 가장 큰 차이점은 유저 아이템 매트릭스의 빈 공간을 채우는 게 아니라 다음과 같이 주어진 x에 대해서 y 값을 추론하는 우리가 보통 일반적인 예측 문제를"},{"start":279700,"end":293700,"text":"접근할 때 어떤 x가 주어지고 그 x에 대한 y 값을 예측하는 문제로 풀게 되죠. 그래서 이런 식의 데이터로 구성을 해야 한다는 것입니다. 이제 아래 데이터가 방금 전 슬라이드의 유저와 아이템 매트릭스의 데이터와 같은 데이터인데요.","confidence":0.9757,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[279990,280400,"접근할"],[280430,280580,"때"],[281090,281300,"어떤"],[281530,281760,"x가"],[281830,282240,"주어지고"],[282270,282420,"그"],[282470,282620,"x에"],[282620,282760,"대한"],[282760,282900,"y"],[282970,283280,"값을"],[283330,283780,"예측하는"],[283790,284300,"문제로"],[284310,284514,"풀게"],[284514,284760,"되죠."],[285090,285280,"그래서"],[285290,285480,"이런"],[285730,285960,"식의"],[285960,286400,"데이터로"],[286590,286847,"구성을"],[286847,286994,"해야"],[286994,287267,"한다는"],[287267,287660,"것입니다."],[287830,288000,"이제"],[288010,288240,"아래"],[288250,288720,"데이터가"],[289310,289600,"방금"],[289600,289740,"전"],[289830,290360,"슬라이드의"],[290370,290780,"유저와"],[290850,291200,"아이템"],[291230,292160,"매트릭스의"],[292190,292600,"데이터와"],[292650,292940,"같은"],[292950,293560,"데이터인데요."]],"textEdited":"접근할 때 어떤 x가 주어지고 그 x에 대한 y 값을 예측하는 문제로 풀게 되죠. 그래서 이런 식의 데이터로 구성을 해야 한다는 것입니다. 이제 아래 데이터가 방금 전 슬라이드의 유저와 아이템 매트릭스의 데이터와 같은 데이터인데요."},{"start":293700,"end":306700,"text":"이 하나의 로우가 하나의 데이터 포인트가 됩니다. 즉 유저 3이라는 사람이 아이템 1을 소비하고 그 외에 다른 컨텍스트 피처들이 있을 때 그때의 선호도는 3점","confidence":0.9366,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[293970,294120,"이"],[294290,294620,"하나의"],[294670,295020,"로우가"],[295490,295780,"하나의"],[295810,296100,"데이터"],[296130,296487,"포인트가"],[296487,296820,"됩니다."],[297290,297440,"즉"],[297690,298020,"유저"],[298070,298640,"3이라는"],[298850,299220,"사람이"],[299830,300200,"아이템"],[300270,300600,"1을"],[300630,301220,"소비하고"],[301750,301900,"그"],[301900,302120,"외에"],[302120,302300,"다른"],[302410,303000,"컨텍스트"],[303090,303540,"피처들이"],[303540,303740,"있을"],[303770,303920,"때"],[304490,304820,"그때의"],[304830,305280,"선호도는"],[305330,306440,"3점"]],"textEdited":"이 하나의 로우가 하나의 데이터 포인트가 됩니다. 즉 유저 3이라는 사람이 아이템 1을 소비하고 그 외에 다른 컨텍스트 피처들이 있을 때 그때의 선호도는 3점"},{"start":306700,"end":319000,"text":"이다. 즉 x는 유저와 아이템과 컨텍스트로 이루어져 있고 y는 레이팅을 예측하는 것이죠. 그래서 이러한 형태는 보통 제너럴한 프리딕터의 모델 구조","confidence":0.9695,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[306890,307120,"이다."],[307170,307320,"즉"],[308030,308300,"x는"],[308350,308700,"유저와"],[308710,309140,"아이템과"],[309170,309820,"컨텍스트로"],[309830,310160,"이루어져"],[310160,310440,"있고"],[310690,311080,"y는"],[311150,312340,"레이팅을"],[312370,312787,"예측하는"],[312787,313100,"것이죠."],[313450,313680,"그래서"],[314050,314340,"이러한"],[315410,315740,"형태는"],[315810,316060,"보통"],[316070,316500,"제너럴한"],[316510,317660,"프리딕터의"],[318010,318260,"모델"],[318330,318580,"구조"]],"textEdited":"이다. 즉 x는 유저와 아이템과 컨텍스트로 이루어져 있고 y는 레이팅을 예측하는 것이죠. 그래서 이러한 형태는 보통 제너럴한 프리딕터의 모델 구조"},{"start":319000,"end":331100,"text":"가 됩니다. 그래서 원하는 만큼 유저 아이템 컨텍스트 그 컨텍스트가 하나가 아니라 되게 다양한 피쳐들이 있을 수 있겠죠. 내가 원하는 만큼 모델을 만드는 사람이 원하는 만큼 컨텍스트 피처를 옆으로","confidence":0.9476,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[319230,319380,"가"],[319380,319660,"됩니다."],[320310,320500,"그래서"],[320500,320840,"원하는"],[320840,321160,"만큼"],[321650,321940,"유저"],[321940,322240,"아이템"],[322330,322880,"컨텍스트"],[323830,323980,"그"],[323980,324520,"컨텍스트가"],[324630,324880,"하나가"],[324880,325120,"아니라"],[325130,325320,"되게"],[325330,325660,"다양한"],[325750,326067,"피쳐들이"],[326067,326207,"있을"],[326207,326294,"수"],[326294,326620,"있겠죠."],[327050,327260,"내가"],[327260,327580,"원하는"],[327590,327880,"만큼"],[327950,328360,"모델을"],[328510,328860,"만드는"],[328860,329100,"사람이"],[329100,329380,"원하는"],[329380,329720,"만큼"],[329870,330300,"컨텍스트"],[330300,330600,"피처를"],[330600,330900,"옆으로"]],"textEdited":"가 됩니다. 그래서 원하는 만큼 유저 아이템 컨텍스트 그 컨텍스트가 하나가 아니라 되게 다양한 피쳐들이 있을 수 있겠죠. 내가 원하는 만큼 모델을 만드는 사람이 원하는 만큼 컨텍스트 피처를 옆으로"},{"start":331100,"end":343300,"text":"붙일 수 있고요. 그래서 이러한 피쳐를 통해서 결국에 최종 예측하는 값은 유저의 상호작용 정보인 웨이팅이 됩니다. 네 이제 이러한 컨텍스터 레코멘데이션 줄여서 car","confidence":0.9128,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[331330,331640,"붙일"],[331640,331734,"수"],[331734,332040,"있고요."],[332610,332840,"그래서"],[332840,333060,"이러한"],[333090,333500,"피쳐를"],[333510,333820,"통해서"],[334250,334580,"결국에"],[334630,334880,"최종"],[334890,335320,"예측하는"],[335320,335620,"값은"],[336270,336600,"유저의"],[336610,337040,"상호작용"],[337050,337480,"정보인"],[337480,338160,"웨이팅이"],[338160,338460,"됩니다."],[339570,339720,"네"],[339910,340080,"이제"],[340150,340440,"이러한"],[340830,341300,"컨텍스터"],[341370,341940,"레코멘데이션"],[342190,342520,"줄여서"],[342610,343020,"car"]],"textEdited":"붙일 수 있고요. 그래서 이러한 피쳐를 통해서 결국에 최종 예측하는 값은 유저의 상호작용 정보인 웨이팅이 됩니다. 네 이제 이러한 컨텍스터 레코멘데이션 줄여서 car"},{"start":343300,"end":351000,"text":"이라고 불리는 테스크의 대표적인 분야는 CTR 예측 도메인입니다. 이 CTR 예측 문제는","confidence":0.6973,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[343550,343840,"이라고"],[343840,344100,"불리는"],[344430,344880,"테스크의"],[344930,345360,"대표적인"],[345510,345880,"분야는"],[346690,347060,"CTR"],[347070,347340,"예측"],[348390,349000,"도메인입니다."],[349290,349440,"이"],[349440,349780,"CTR"],[349790,350040,"예측"],[350070,350560,"문제는"]],"textEdited":"이라고 불리는 테스크의 대표적인 분야는 CTR 예측 도메인입니다. 이 CTR 예측 문제는"},{"start":351000,"end":358800,"text":"유저가 해당 아이템이 주어졌을 때 그 아이템을 클릭할 확률을 예측하는 문제입니다. 추천 시스템에서","confidence":0.9928,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[351270,351660,"유저가"],[352070,352320,"해당"],[352330,352760,"아이템이"],[352760,353200,"주어졌을"],[353200,353340,"때"],[353530,353680,"그"],[353690,354120,"아이템을"],[354190,354560,"클릭할"],[354670,355360,"확률을"],[355690,356200,"예측하는"],[356250,356760,"문제입니다."],[357290,357580,"추천"],[357630,358200,"시스템에서"]],"textEdited":"유저가 해당 아이템이 주어졌을 때 그 아이템을 클릭할 확률을 예측하는 문제입니다. 추천 시스템에서"},{"start":358800,"end":372600,"text":"이제 온라인 에이비 테스트를 한다고 했을 때 가장 많이 사용되는 지표가 매출 혹은 CTR이라고 첫 번째 강의에서 언급했었습니다. 사실 매출이라는 지표는 추천 외에도 다른 요인이 굉장히 많기 때문에 보통","confidence":0.9021,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[358990,359160,"이제"],[359230,359580,"온라인"],[359610,359880,"에이비"],[359910,360400,"테스트를"],[360670,361000,"한다고"],[361000,361240,"했을"],[361270,361420,"때"],[361550,361820,"가장"],[361830,362020,"많이"],[362070,362480,"사용되는"],[362530,362880,"지표가"],[363330,363640,"매출"],[363650,363860,"혹은"],[363910,364540,"CTR이라고"],[364850,365000,"첫"],[365050,365300,"번째"],[365310,365640,"강의에서"],[365650,366360,"언급했었습니다."],[366770,367020,"사실"],[367090,367880,"매출이라는"],[367950,368340,"지표는"],[368810,369080,"추천"],[369090,369420,"외에도"],[369430,369640,"다른"],[369670,370000,"요인이"],[370050,370420,"굉장히"],[370670,371020,"많기"],[371020,371400,"때문에"],[371930,372260,"보통"]],"textEdited":"이제 온라인 에이비 테스트를 한다고 했을 때 가장 많이 사용되는 지표가 매출 혹은 CTR이라고 첫 번째 강의에서 언급했었습니다. 사실 매출이라는 지표는 추천 외에도 다른 요인이 굉장히 많기 때문에 보통"},{"start":372600,"end":385500,"text":"추천 시스템을 적용했을 때 좋아졌다 좋아지지 않았다라는 것을 평가하기 위한 지표는 CTR을 많이 사용합니다. 그 말은 추천 후보 아이템의 예측 CTR이 높은 것을","confidence":0.9647,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[372870,373140,"추천"],[373190,373740,"시스템을"],[373770,374134,"적용했을"],[374134,374260,"때"],[374260,374680,"좋아졌다"],[375310,375740,"좋아지지"],[375740,376260,"않았다라는"],[376810,377080,"것을"],[377110,377527,"평가하기"],[377527,377700,"위한"],[377770,378140,"지표는"],[378230,378760,"CTR을"],[378760,378940,"많이"],[378970,379480,"사용합니다."],[380530,380680,"그"],[380680,381000,"말은"],[381730,382060,"추천"],[382190,382440,"후보"],[382490,383000,"아이템의"],[383070,383360,"예측"],[383410,383840,"CTR이"],[383840,384120,"높은"],[384670,384980,"것을"]],"textEdited":"추천 시스템을 적용했을 때 좋아졌다 좋아지지 않았다라는 것을 평가하기 위한 지표는 CTR을 많이 사용합니다. 그 말은 추천 후보 아이템의 예측 CTR이 높은 것을"},{"start":385500,"end":399400,"text":"잘 추천해 준다면은 그에 따른 CTR이 상승할 수 있다는 것이죠. 따라서 추천 시스템에서는 CF 기반의 모델도 사용하지만 CTR 예측 모델을 사용한 추천 시스템도 굉장히 많이","confidence":0.99,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[385790,385940,"잘"],[386050,386347,"추천해"],[386347,386820,"준다면은"],[387190,387480,"그에"],[387490,387740,"따른"],[388290,388820,"CTR이"],[389310,389700,"상승할"],[389700,389840,"수"],[390010,390340,"있다는"],[390340,390640,"것이죠."],[390890,391200,"따라서"],[391250,391480,"추천"],[391490,392120,"시스템에서는"],[392670,393100,"CF"],[393110,393440,"기반의"],[393440,394160,"모델도"],[394190,394700,"사용하지만"],[395290,395620,"CTR"],[395630,395880,"예측"],[395890,396220,"모델을"],[396220,396520,"사용한"],[397030,397320,"추천"],[397870,398340,"시스템도"],[398390,398740,"굉장히"],[398750,398980,"많이"]],"textEdited":"잘 추천해 준다면은 그에 따른 CTR이 상승할 수 있다는 것이죠. 따라서 추천 시스템에서는 CF 기반의 모델도 사용하지만 CTR 예측 모델을 사용한 추천 시스템도 굉장히 많이"},{"start":399400,"end":414200,"text":"사용하고 있습니다. 그래서 CTR 예측 문제는 예측해야 하는 y 값이 클릭을 했냐 안 했냐 0과 1이기 때문에 바이너리 클래시피케이션 문제라고 볼 수 있습니다. 근데 우리가 원하는 값은 0이냐 1이냐가 아니라","confidence":0.9686,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[399650,400060,"사용하고"],[400060,400440,"있습니다."],[401010,401200,"그래서"],[401250,401600,"CTR"],[401630,401900,"예측"],[401970,402600,"문제는"],[403610,404160,"예측해야"],[404160,404340,"하는"],[404530,404680,"y"],[404870,405240,"값이"],[405610,405960,"클릭을"],[405990,406240,"했냐"],[406240,406347,"안"],[406347,406580,"했냐"],[407110,407480,"0과"],[407530,407960,"1이기"],[407960,408320,"때문에"],[409010,409440,"바이너리"],[409440,410140,"클래시피케이션"],[410150,410540,"문제라고"],[410540,410680,"볼"],[410680,410774,"수"],[410774,411140,"있습니다."],[411310,411467,"근데"],[411467,411680,"우리가"],[411680,411940,"원하는"],[411950,412240,"값은"],[412390,412760,"0이냐"],[412770,413620,"1이냐가"],[413620,413900,"아니라"]],"textEdited":"사용하고 있습니다. 그래서 CTR 예측 문제는 예측해야 하는 y 값이 클릭을 했냐 안 했냐 0과 1이기 때문에 바이너리 클래시피케이션 문제라고 볼 수 있습니다. 근데 우리가 원하는 값은 0이냐 1이냐가 아니라"},{"start":414200,"end":426800,"text":"클릭할 확률이기 때문에 0과 1 사이의 확률로 아이템의 CTR이 출력되어야 합니다. 그래서 예측 모델을 다 만든 이후에 그 출력 값을 최종적으로 시그모이드 함수에 통과시켜서","confidence":0.9147,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[414630,415000,"클릭할"],[415130,415700,"확률이기"],[415700,416100,"때문에"],[416690,417040,"0과"],[417070,417220,"1"],[417250,417540,"사이의"],[417630,418060,"확률로"],[418570,419120,"아이템의"],[419950,420360,"CTR이"],[420390,420900,"출력되어야"],[420900,421140,"합니다."],[421550,421760,"그래서"],[421810,422080,"예측"],[422090,422367,"모델을"],[422367,422500,"다"],[422570,422840,"만든"],[422890,423180,"이후에"],[423310,423460,"그"],[423510,423760,"출력"],[423770,424100,"값을"],[424230,424740,"최종적으로"],[424870,425440,"시그모이드"],[425490,425840,"함수에"],[425890,426540,"통과시켜서"]],"textEdited":"클릭할 확률이기 때문에 0과 1 사이의 확률로 아이템의 CTR이 출력되어야 합니다. 그래서 예측 모델을 다 만든 이후에 그 출력 값을 최종적으로 시그모이드 함수에 통과시켜서"},{"start":426800,"end":439500,"text":"0과 1 사이의 값으로 출력되게 하고요. 그 값이 곧 예측 CTR 값이 됩니다. 이 CTR 예측은 주로 광고 추천에서 가장 많이 사용되는데요. 광고 추천을 잘하면","confidence":0.8706,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[427070,427460,"0과"],[427530,427680,"1"],[427790,428200,"사이의"],[428250,428700,"값으로"],[429170,429620,"출력되게"],[429620,429920,"하고요."],[430370,430520,"그"],[430570,430940,"값이"],[431010,431160,"곧"],[431430,431740,"예측"],[431830,432240,"CTR"],[432290,432660,"값이"],[432850,433180,"됩니다."],[433710,433860,"이"],[433870,434180,"CTR"],[434190,434560,"예측은"],[434810,435060,"주로"],[435230,435600,"광고"],[435730,436260,"추천에서"],[436350,436600,"가장"],[436600,436800,"많이"],[436810,437480,"사용되는데요."],[438270,438520,"광고"],[438550,438847,"추천을"],[438847,439200,"잘하면"]],"textEdited":"0과 1 사이의 값으로 출력되게 하고요. 그 값이 곧 예측 CTR 값이 됩니다. 이 CTR 예측은 주로 광고 추천에서 가장 많이 사용되는데요. 광고 추천을 잘하면"},{"start":439500,"end":453500,"text":"광고주로부터 돈을 많이 받기 때문에 바로 돈이 됩니다. 그래서 광고 추천이 굉장히 많이 연구되었고 또 중요한 분야 중에 하나가 되었습니다. 이제 광고가 노출된 상황에 다양한 유저 광고 컨텍스트 피처가 존재하고","confidence":0.98,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[439870,440480,"광고주로부터"],[440480,440760,"돈을"],[440760,440920,"많이"],[440950,441147,"받기"],[441147,441480,"때문에"],[441930,442220,"바로"],[442220,442467,"돈이"],[442467,442780,"됩니다."],[443370,443600,"그래서"],[443650,443860,"광고"],[443890,444320,"추천이"],[444790,445100,"굉장히"],[445130,445320,"많이"],[445430,446120,"연구되었고"],[446330,446480,"또"],[446550,446880,"중요한"],[446950,447200,"분야"],[447410,447620,"중에"],[447620,447887,"하나가"],[447887,448400,"되었습니다."],[448750,448920,"이제"],[449030,449380,"광고가"],[449410,449920,"노출된"],[450010,450340,"상황에"],[450510,450880,"다양한"],[450970,451240,"유저"],[451430,451680,"광고"],[451750,452240,"컨텍스트"],[452270,452620,"피처가"],[452630,453140,"존재하고"]],"textEdited":"광고주로부터 돈을 많이 받기 때문에 바로 돈이 됩니다. 그래서 광고 추천이 굉장히 많이 연구되었고 또 중요한 분야 중에 하나가 되었습니다. 이제 광고가 노출된 상황에 다양한 유저 광고 컨텍스트 피처가 존재하고"},{"start":453500,"end":464900,"text":"이 다양한 피처들을 위치하게 사용하여서 씨티알 예측의 정확도를 높이는 테스크가 많이 이루어지고 있습니다. 어떠한 데이터 같은 경우에는 유저 아이디가 아예 존재하지 않는 데이터도 있는데요.","confidence":0.886,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[453750,453900,"이"],[454110,454420,"다양한"],[454530,454980,"피처들을"],[455090,455600,"위치하게"],[455630,456180,"사용하여서"],[456570,456940,"씨티알"],[456940,457280,"예측의"],[457280,457700,"정확도를"],[457950,458320,"높이는"],[458870,459280,"테스크가"],[459280,459460,"많이"],[459460,459880,"이루어지고"],[459880,460240,"있습니다."],[460590,460940,"어떠한"],[460950,461280,"데이터"],[461290,461494,"같은"],[461494,461900,"경우에는"],[462030,462340,"유저"],[462350,462760,"아이디가"],[462790,462960,"아예"],[463070,463600,"존재하지"],[463610,463820,"않는"],[463850,464207,"데이터도"],[464207,464580,"있는데요."]],"textEdited":"이 다양한 피처들을 위치하게 사용하여서 씨티알 예측의 정확도를 높이는 테스크가 많이 이루어지고 있습니다. 어떠한 데이터 같은 경우에는 유저 아이디가 아예 존재하지 않는 데이터도 있는데요."},{"start":464900,"end":474800,"text":"우리가 지금 콜라보레이트 필터링 문제를 푸는 것이 아니기 때문에 유저 아이디가 존재하지 않더라도 다른 유저 피처나 컨텍스트 피처를 사용하여서 해당 아이템의 씨티알을 예측할 수 있습니다.","confidence":0.8794,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[465130,465380,"우리가"],[465380,465520,"지금"],[465550,466060,"콜라보레이트"],[466060,466347,"필터링"],[466347,466600,"문제를"],[466600,466774,"푸는"],[466774,467000,"것이"],[467000,467247,"아니기"],[467247,467600,"때문에"],[467810,468047,"유저"],[468047,468380,"아이디가"],[468410,468940,"존재하지"],[468950,469440,"않더라도"],[469910,470120,"다른"],[470150,470360,"유저"],[470370,470720,"피처나"],[470770,471240,"컨텍스트"],[471240,471560,"피처를"],[471560,472060,"사용하여서"],[472490,472720,"해당"],[472750,473140,"아이템의"],[473170,473680,"씨티알을"],[473690,474060,"예측할"],[474070,474220,"수"],[474220,474760,"있습니다."]],"textEdited":"우리가 지금 콜라보레이트 필터링 문제를 푸는 것이 아니기 때문에 유저 아이디가 존재하지 않더라도 다른 유저 피처나 컨텍스트 피처를 사용하여서 해당 아이템의 씨티알을 예측할 수 있습니다."},{"start":474800,"end":487200,"text":"현업에서는 실제로 유저 아이디를 피처로 사용하지 않는 경우가 광고 추천에서는 굉장히 잦은 일입니다. 네 다음은 가장 기본적인 CTR 예측 모델인 로지스틱 리그레션을 간단하게 언급하고 넘어가겠습니다.","confidence":0.8975,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[475150,475620,"현업에서는"],[475630,475960,"실제로"],[475990,476240,"유저"],[476240,476580,"아이디를"],[476630,476980,"피처로"],[477190,477580,"사용하지"],[477580,477780,"않는"],[477830,478180,"경우가"],[478510,478760,"광고"],[478760,479200,"추천에서는"],[479200,479520,"굉장히"],[479970,480240,"잦은"],[480240,480620,"일입니다."],[481410,481560,"네"],[481570,481940,"다음은"],[482230,482500,"가장"],[482670,483220,"기본적인"],[483310,483620,"CTR"],[483620,483880,"예측"],[483880,484280,"모델인"],[484670,485060,"로지스틱"],[485060,485520,"리그레션을"],[485550,485980,"간단하게"],[486010,486400,"언급하고"],[486400,487060,"넘어가겠습니다."]],"textEdited":"현업에서는 실제로 유저 아이디를 피처로 사용하지 않는 경우가 광고 추천에서는 굉장히 잦은 일입니다. 네 다음은 가장 기본적인 CTR 예측 모델인 로지스틱 리그레션을 간단하게 언급하고 넘어가겠습니다."},{"start":487200,"end":498100,"text":"기본적인 선형 모델에다가 시그모이드를 씌운 모델인데요. 이제 우리가 정의한 유저 아이템 컨텍스트 피처들은 이 x아라는 입력 변수로","confidence":0.8965,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[487670,488220,"기본적인"],[488250,488540,"선형"],[488550,489060,"모델에다가"],[489210,490060,"시그모이드를"],[490430,490680,"씌운"],[490680,491220,"모델인데요."],[491890,492060,"이제"],[492070,492340,"우리가"],[492430,492780,"정의한"],[493430,493720,"유저"],[493770,494160,"아이템"],[494390,494980,"컨텍스트"],[495030,495480,"피처들은"],[495590,495740,"이"],[496050,496740,"x아라는"],[497030,497320,"입력"],[497370,497760,"변수로"]],"textEdited":"기본적인 선형 모델에다가 시그모이드를 씌운 모델인데요. 이제 우리가 정의한 유저 아이템 컨텍스트 피처들은 이 x아라는 입력 변수로"},{"start":498100,"end":507400,"text":"사용되게 되고 이제 입력 변수에 대한 선형 모델링을 통해서 클릭 예측 확률을 예측하는 가장 기본적인 로지스틱 리액션","confidence":0.955,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[498550,498967,"사용되게"],[498967,499220,"되고"],[499830,500000,"이제"],[500030,500280,"입력"],[500310,500587,"변수에"],[500587,500780,"대한"],[500950,501220,"선형"],[501220,501960,"모델링을"],[501990,502320,"통해서"],[502890,503140,"클릭"],[503230,503480,"예측"],[503590,504280,"확률을"],[504930,505380,"예측하는"],[505570,505800,"가장"],[505870,506280,"기본적인"],[506350,506700,"로지스틱"],[506700,507080,"리액션"]],"textEdited":"사용되게 되고 이제 입력 변수에 대한 선형 모델링을 통해서 클릭 예측 확률을 예측하는 가장 기본적인 로지스틱 리액션"},{"start":507400,"end":517300,"text":"모델이 있습니다. 이제 앞으로 배울 다양한 CTR 예측 모델 앞으로 FM이나 FFM 그리고 이 다음 아홉 번째 강의인 딥 CTR 모델","confidence":0.8824,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[507710,508100,"모델이"],[508510,508920,"있습니다."],[509150,509320,"이제"],[509410,509760,"앞으로"],[509790,510020,"배울"],[510190,510540,"다양한"],[510650,511020,"CTR"],[511030,511280,"예측"],[511280,511520,"모델"],[511890,512160,"앞으로"],[512350,512760,"FM이나"],[512810,513260,"FFM"],[513330,513620,"그리고"],[514250,514400,"이"],[514410,514700,"다음"],[515150,515360,"아홉"],[515390,515660,"번째"],[515690,516000,"강의인"],[516190,516340,"딥"],[516430,516820,"CTR"],[516830,517060,"모델"]],"textEdited":"모델이 있습니다. 이제 앞으로 배울 다양한 CTR 예측 모델 앞으로 FM이나 FFM 그리고 이 다음 아홉 번째 강의인 딥 CTR 모델"},{"start":517300,"end":532300,"text":"들이 다 이 로지스틱 리그레션으로부터 발전된 것을 기억해 두시기 바랍니다. 이 수식을 보면 로지스틱 리그레션은 어떤 변수 간의 상호 작용을 전혀 모델링 할 수 없습니다. 즉 유저 정보와 아이템 정보 간의 다양한 상호 작용","confidence":0.8876,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[517470,517720,"들이"],[517720,517860,"다"],[518350,518500,"이"],[518510,518940,"로지스틱"],[518950,519920,"리그레션으로부터"],[520330,520780,"발전된"],[520780,521060,"것을"],[521450,521767,"기억해"],[521767,522060,"두시기"],[522060,522420,"바랍니다."],[522810,522960,"이"],[522960,523300,"수식을"],[523300,523500,"보면"],[523990,524380,"로지스틱"],[524390,524920,"리그레션은"],[525330,525560,"어떤"],[525670,525987,"변수"],[525987,526220,"간의"],[526250,526460,"상호"],[526470,526780,"작용을"],[526830,527060,"전혀"],[527090,527420,"모델링"],[527420,527560,"할"],[527560,527667,"수"],[527667,528060,"없습니다."],[528790,528940,"즉"],[529110,529420,"유저"],[529450,529800,"정보와"],[529990,530340,"아이템"],[530430,530780,"정보"],[530780,531000,"간의"],[531070,531340,"다양한"],[531430,531640,"상호"],[531670,531960,"작용"]],"textEdited":"들이 다 이 로지스틱 리그레션으로부터 발전된 것을 기억해 두시기 바랍니다. 이 수식을 보면 로지스틱 리그레션은 어떤 변수 간의 상호 작용을 전혀 모델링 할 수 없습니다. 즉 유저 정보와 아이템 정보 간의 다양한 상호 작용"},{"start":532300,"end":543100,"text":"이 모델에 반영되지 않는다는 것인데요. 추천 모델에서는 그 피처들 간의 상호작용을 모델에서 반영하는 것이 사실 추천 모델뿐만이 아니라 모든 머신 러닝 모델에 대해서는","confidence":0.949,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[532550,532700,"이"],[533070,533400,"모델에"],[533410,533820,"반영되지"],[533830,534260,"않는다는"],[534260,534660,"것인데요."],[535470,535740,"추천"],[535740,536260,"모델에서는"],[536630,536780,"그"],[536910,537247,"피처들"],[537247,537460,"간의"],[537470,538000,"상호작용을"],[538170,538640,"모델에서"],[538690,539120,"반영하는"],[539120,539360,"것이"],[539670,539920,"사실"],[539950,540167,"추천"],[540167,540634,"모델뿐만이"],[540634,540880,"아니라"],[541130,541360,"모든"],[541450,541694,"머신"],[541694,541900,"러닝"],[541900,542220,"모델에"],[542230,542840,"대해서는"]],"textEdited":"이 모델에 반영되지 않는다는 것인데요. 추천 모델에서는 그 피처들 간의 상호작용을 모델에서 반영하는 것이 사실 추천 모델뿐만이 아니라 모든 머신 러닝 모델에 대해서는"},{"start":543100,"end":555000,"text":"피처 간의 상호작용을 반영하는 것이 굉장히 중요하기 때문에 단순하게 이렇게 선형 모델 즉 로지스틱 리그레션만 사용하게 된다면은 예측 성능이 굉장히 떨어지게 됩니다. 따라서 아래와 같이","confidence":0.917,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[543330,543587,"피처"],[543587,543800,"간의"],[543800,544320,"상호작용을"],[544570,544947,"반영하는"],[544947,545180,"것이"],[545180,545420,"굉장히"],[545510,545907,"중요하기"],[545907,546300,"때문에"],[546950,547420,"단순하게"],[547430,547700,"이렇게"],[548130,548440,"선형"],[548450,548700,"모델"],[548950,549100,"즉"],[549110,549467,"로지스틱"],[549467,549940,"리그레션만"],[549950,550300,"사용하게"],[550300,550760,"된다면은"],[551270,551560,"예측"],[551610,551920,"성능이"],[551930,552220,"굉장히"],[552220,552587,"떨어지게"],[552587,552900,"됩니다."],[553410,553720,"따라서"],[553790,554120,"아래와"],[554130,554440,"같이"]],"textEdited":"피처 간의 상호작용을 반영하는 것이 굉장히 중요하기 때문에 단순하게 이렇게 선형 모델 즉 로지스틱 리그레션만 사용하게 된다면은 예측 성능이 굉장히 떨어지게 됩니다. 따라서 아래와 같이"},{"start":555000,"end":566800,"text":"강제로 두 개의 변수를 상호작용을 만들어서 이 상호작용을 카테시안 프로덕트라고 하는데요. 카테시안 프로덕트를 만들어 가지고 강제로 두 개의 변수","confidence":0.9032,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[556090,556520,"강제로"],[556610,556760,"두"],[556760,557020,"개의"],[557070,557580,"변수를"],[559070,559640,"상호작용을"],[559640,560060,"만들어서"],[560410,560560,"이"],[560560,561000,"상호작용을"],[561170,561600,"카테시안"],[561600,562067,"프로덕트라고"],[562067,562420,"하는데요."],[562850,563280,"카테시안"],[563280,563680,"프로덕트를"],[563680,563980,"만들어"],[563980,564320,"가지고"],[564950,565340,"강제로"],[565710,565860,"두"],[565860,566080,"개의"],[566150,566560,"변수"]],"textEdited":"강제로 두 개의 변수를 상호작용을 만들어서 이 상호작용을 카테시안 프로덕트라고 하는데요. 카테시안 프로덕트를 만들어 가지고 강제로 두 개의 변수"},{"start":566800,"end":577200,"text":"상호작용을 w아제라는 파라미터로 학습하게 합니다. 이것을 폴리노미얼 모델이라고 하는데요. 즉 1차 항 말고 2차 이상의 항이 존재한다는 것을 의미합니다.","confidence":0.8271,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[567170,567720,"상호작용을"],[568010,568860,"w아제라는"],[568870,569440,"파라미터로"],[569610,570020,"학습하게"],[570030,570320,"합니다."],[570730,571000,"이것을"],[571030,571520,"폴리노미얼"],[571520,571960,"모델이라고"],[571960,572320,"하는데요."],[572830,572980,"즉"],[573430,573760,"1차"],[573770,573920,"항"],[573920,574240,"말고"],[574750,575020,"2차"],[575070,575347,"이상의"],[575347,575560,"항이"],[575570,576187,"존재한다는"],[576187,576420,"것을"],[576420,576860,"의미합니다."]],"textEdited":"상호작용을 w아제라는 파라미터로 학습하게 합니다. 이것을 폴리노미얼 모델이라고 하는데요. 즉 1차 항 말고 2차 이상의 항이 존재한다는 것을 의미합니다."},{"start":577200,"end":591600,"text":"가장 큰 이 모델의 취약점은 파라미터 수가 급격하게 증가한다는 점입니다. 세컨오더 폴리노미얼 모델만 확인해도 파라미터 수가 엔 곱하기 n 즉 n의 제곱 배로 증가하게 되는데요. 그래서 이러한","confidence":0.943,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[577590,577840,"가장"],[577930,578080,"큰"],[578210,578360,"이"],[578370,578700,"모델의"],[578730,579220,"취약점은"],[579830,580280,"파라미터"],[580290,580560,"수가"],[581110,581560,"급격하게"],[581630,582127,"증가한다는"],[582127,582540,"점입니다."],[583090,583600,"세컨오더"],[583750,584200,"폴리노미얼"],[584200,584540,"모델만"],[584590,585040,"확인해도"],[585830,586220,"파라미터"],[586220,586460,"수가"],[587150,587300,"엔"],[587550,587900,"곱하기"],[587900,588040,"n"],[588190,588340,"즉"],[588410,588680,"n의"],[588690,588940,"제곱"],[588940,589160,"배로"],[589210,589567,"증가하게"],[589567,589980,"되는데요."],[590550,590740,"그래서"],[590750,591000,"이러한"]],"textEdited":"가장 큰 이 모델의 취약점은 파라미터 수가 급격하게 증가한다는 점입니다. 세컨오더 폴리노미얼 모델만 확인해도 파라미터 수가 엔 곱하기 n 즉 n의 제곱 배로 증가하게 되는데요. 그래서 이러한"},{"start":591600,"end":599800,"text":"상호작용을 단순하게 카테시안 프로덕트로 표현하는 것은 한계가 있습니다. 그래서 이 한계를 극복한 모델이 우리가 이후에 배울","confidence":0.9323,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[591950,592500,"상호작용을"],[592590,593100,"단순하게"],[593370,593820,"카테시안"],[593820,594260,"프로덕트로"],[594550,594940,"표현하는"],[594940,595180,"것은"],[595490,595820,"한계가"],[595830,596220,"있습니다."],[596750,596947,"그래서"],[596947,597080,"이"],[597130,597460,"한계를"],[597490,597860,"극복한"],[597890,598260,"모델이"],[598450,598680,"우리가"],[598790,599200,"이후에"],[599250,599480,"배울"]],"textEdited":"상호작용을 단순하게 카테시안 프로덕트로 표현하는 것은 한계가 있습니다. 그래서 이 한계를 극복한 모델이 우리가 이후에 배울"},{"start":599800,"end":613200,"text":"프엠과 프프엠이고 이 프엠과 프엠의 모델에 대한 자세한 내용은 이 뒤에 있는 파트에서 다루겠습니다. 자 그렇다면 씨티알 예측 모델에는 다양한 유저 아이템 컨텍스트 피처 등을 사용할 수가 있는데요.","confidence":0.7196,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[600250,600620,"프엠과"],[600710,601420,"프프엠이고"],[601850,602000,"이"],[602050,602380,"프엠과"],[602430,602940,"프엠의"],[602970,603267,"모델에"],[603267,603460,"대한"],[603510,603820,"자세한"],[603820,604080,"내용은"],[604490,604640,"이"],[604640,604827,"뒤에"],[604827,604980,"있는"],[605050,605520,"파트에서"],[605830,606480,"다루겠습니다."],[607070,607220,"자"],[607220,607600,"그렇다면"],[607630,607980,"씨티알"],[607980,608220,"예측"],[608220,608660,"모델에는"],[609350,609720,"다양한"],[609870,610160,"유저"],[610290,610660,"아이템"],[610970,611420,"컨텍스트"],[611430,611680,"피처"],[611680,611900,"등을"],[611950,612300,"사용할"],[612300,612480,"수가"],[612480,613100,"있는데요."]],"textEdited":"프엠과 프프엠이고 이 프엠과 프엠의 모델에 대한 자세한 내용은 이 뒤에 있는 파트에서 다루겠습니다. 자 그렇다면 씨티알 예측 모델에는 다양한 유저 아이템 컨텍스트 피처 등을 사용할 수가 있는데요."},{"start":613200,"end":628000,"text":"이제 이러한 피처들은 보통 두 가지 분류로 나눌 수가 있습니다. 첫 번째는 댄스 피처인데요. 벡터로 표현했을 때 비교적 작은 공간에 밀집되어 분포하는 수치형 변수를 의미합니다. 유저가 아이템에 매긴 절대 평점 1점부터 5점까지","confidence":0.9614,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[613350,613520,"이제"],[613530,613800,"이러한"],[613850,614240,"피처들은"],[614250,614540,"보통"],[614730,614880,"두"],[614880,615160,"가지"],[615230,615560,"분류로"],[615560,615740,"나눌"],[615750,615960,"수가"],[615970,616380,"있습니다."],[616890,617040,"첫"],[617040,617340,"번째는"],[617350,617740,"댄스"],[617870,618800,"피처인데요."],[619350,619700,"벡터로"],[619700,620140,"표현했을"],[620170,620320,"때"],[620390,620740,"비교적"],[620830,621080,"작은"],[621190,621840,"공간에"],[621930,622460,"밀집되어"],[622530,622980,"분포하는"],[623370,623760,"수치형"],[623790,624080,"변수를"],[624080,624520,"의미합니다."],[624990,625320,"유저가"],[625320,625700,"아이템에"],[625700,625920,"매긴"],[626150,626480,"절대"],[626550,626840,"평점"],[626930,627380,"1점부터"],[627380,627860,"5점까지"]],"textEdited":"이제 이러한 피처들은 보통 두 가지 분류로 나눌 수가 있습니다. 첫 번째는 댄스 피처인데요. 벡터로 표현했을 때 비교적 작은 공간에 밀집되어 분포하는 수치형 변수를 의미합니다. 유저가 아이템에 매긴 절대 평점 1점부터 5점까지"},{"start":628000,"end":642000,"text":"있는 평점을 피처로 사용한다면 댄스한 피처가 될 수 있고요. 그리고 어떤 수치로 나타날 수 있는 다른 기온이나 시간과 같은 정보도 수치형 벡터 댄스한 피처가 되겠죠. 그와 그의 반대로 스파스한 피처","confidence":0.8744,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[628270,628460,"있는"],[628530,628920,"평점을"],[629130,629407,"피처로"],[629407,629880,"사용한다면"],[630110,630440,"댄스한"],[630450,630707,"피처가"],[630707,630840,"될"],[630850,630940,"수"],[630940,631240,"있고요."],[631770,632020,"그리고"],[632070,632320,"어떤"],[632910,633280,"수치로"],[633280,633580,"나타날"],[633580,633674,"수"],[633674,633840,"있는"],[633930,634140,"다른"],[634410,634880,"기온이나"],[634950,635267,"시간과"],[635267,635480,"같은"],[635530,635960,"정보도"],[636470,636860,"수치형"],[637010,637280,"벡터"],[637490,637860,"댄스한"],[637890,638207,"피처가"],[638207,638540,"되겠죠."],[639050,639320,"그와"],[639690,640060,"그의"],[640150,640540,"반대로"],[640790,641300,"스파스한"],[641330,641580,"피처"]],"textEdited":"있는 평점을 피처로 사용한다면 댄스한 피처가 될 수 있고요. 그리고 어떤 수치로 나타날 수 있는 다른 기온이나 시간과 같은 정보도 수치형 벡터 댄스한 피처가 되겠죠. 그와 그의 반대로 스파스한 피처"},{"start":642000,"end":655800,"text":"벡터로 표현했을 때 비교적 넓은 공간에 분포하는 피처가 스퍼스 피처입니다. 사실 이 두 개념은 여러분들이 앞선 강의에서도 충분히 많이 배웠을 텐데요. 유저의 아이템의 아이디 같은 경우라든지 혹은 요일이나","confidence":0.9588,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[642350,642700,"벡터로"],[642700,643080,"표현했을"],[643080,643200,"때"],[643250,643580,"비교적"],[643590,643880,"넓은"],[643970,644340,"공간에"],[644930,645320,"분포하는"],[645350,645940,"피처가"],[645950,646300,"스퍼스"],[646300,646700,"피처입니다."],[647190,647420,"사실"],[647420,647560,"이"],[647560,647700,"두"],[647730,648020,"개념은"],[648020,648480,"여러분들이"],[648610,648900,"앞선"],[648930,649400,"강의에서도"],[649470,649780,"충분히"],[649780,649980,"많이"],[650190,650580,"배웠을"],[650590,650900,"텐데요."],[651690,652080,"유저의"],[652130,652660,"아이템의"],[652730,653080,"아이디"],[653150,653420,"같은"],[653420,653980,"경우라든지"],[654030,654240,"혹은"],[654810,655340,"요일이나"]],"textEdited":"벡터로 표현했을 때 비교적 넓은 공간에 분포하는 피처가 스퍼스 피처입니다. 사실 이 두 개념은 여러분들이 앞선 강의에서도 충분히 많이 배웠을 텐데요. 유저의 아이템의 아이디 같은 경우라든지 혹은 요일이나"},{"start":655800,"end":667900,"text":"뭐 키워드 태그 같은 정보들이 다 스프레스한 피처입니다. 요일과 같은 경우에는 월요일부터 일요일까지 총 7개의 공간이 있기 때문에 수요일 금요일이 다음과 같이 원핫 인코딩으로 표현될 수가 있고요.","confidence":0.9146,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[656110,656260,"뭐"],[656350,656700,"키워드"],[656750,657020,"태그"],[657020,657260,"같은"],[657290,657760,"정보들이"],[657760,657900,"다"],[658330,658840,"스프레스한"],[658870,659340,"피처입니다."],[659730,660100,"요일과"],[660100,660267,"같은"],[660267,660660,"경우에는"],[661170,661680,"월요일부터"],[661680,662140,"일요일까지"],[662150,662300,"총"],[662450,662760,"7개의"],[662760,663027,"공간이"],[663027,663187,"있기"],[663187,663560,"때문에"],[664070,664400,"수요일"],[664450,664840,"금요일이"],[664850,665160,"다음과"],[665160,665400,"같이"],[665950,666240,"원핫"],[666250,666940,"인코딩으로"],[666950,667280,"표현될"],[667280,667447,"수가"],[667447,667740,"있고요."]],"textEdited":"뭐 키워드 태그 같은 정보들이 다 스프레스한 피처입니다. 요일과 같은 경우에는 월요일부터 일요일까지 총 7개의 공간이 있기 때문에 수요일 금요일이 다음과 같이 원핫 인코딩으로 표현될 수가 있고요."},{"start":667900,"end":681400,"text":"이제 키워드나 태그 같은 경우에는 아이템 하나가 1개가 아닌 2개 이상의 키워드나 태그를 가질 수도 있죠. 따라서 이 경우에는 멀티샷 인코딩으로 표현되긴 하지만 여전히 그 그 피처는 스퍼스 한 피처입니다.","confidence":0.9235,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[668210,668400,"이제"],[668590,669080,"키워드나"],[669130,669360,"태그"],[669360,669567,"같은"],[669567,670000,"경우에는"],[670210,670580,"아이템"],[670630,670940,"하나가"],[671330,671667,"1개가"],[671667,671840,"아닌"],[671970,672240,"2개"],[672240,672820,"이상의"],[672910,673340,"키워드나"],[673370,673680,"태그를"],[673680,673900,"가질"],[673910,674080,"수도"],[674080,674300,"있죠."],[674890,675200,"따라서"],[675210,675327,"이"],[675327,675680,"경우에는"],[675790,676280,"멀티샷"],[676370,676860,"인코딩으로"],[676860,677280,"표현되긴"],[677280,677600,"하지만"],[678090,678440,"여전히"],[678470,678620,"그"],[679050,679200,"그"],[679630,680000,"피처는"],[680270,680694,"스퍼스"],[680694,680820,"한"],[680850,681400,"피처입니다."]],"textEdited":"이제 키워드나 태그 같은 경우에는 아이템 하나가 1개가 아닌 2개 이상의 키워드나 태그를 가질 수도 있죠. 따라서 이 경우에는 멀티샷 인코딩으로 표현되긴 하지만 여전히 그 그 피처는 스퍼스 한 피처입니다."},{"start":681400,"end":695300,"text":"이제 이 두 개의 피처를 봤을 때 씨티알 예측 문제에서 가장 많이 사용되는 피처는 이 위에 댄스 피처가 아니라 대부분 스퍼스 피처입니다. 다음 공개되어 있는 씨티알 예측 모델링을 위한 데이터를 살펴봅시다.","confidence":0.8152,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[681750,681920,"이제"],[681920,682040,"이"],[682050,682167,"두"],[682167,682400,"개의"],[682410,682740,"피처를"],[682740,683060,"봤을"],[683070,683220,"때"],[683870,684240,"씨티알"],[684240,684460,"예측"],[684490,685020,"문제에서"],[685230,685460,"가장"],[685510,685780,"많이"],[686270,686660,"사용되는"],[686690,687060,"피처는"],[687730,687880,"이"],[687880,688100,"위에"],[688130,688440,"댄스"],[688470,688754,"피처가"],[688754,689000,"아니라"],[689270,689620,"대부분"],[689690,690200,"스퍼스"],[690470,690980,"피처입니다."],[691490,691720,"다음"],[691850,692260,"공개되어"],[692260,692440,"있는"],[692530,692940,"씨티알"],[692950,693200,"예측"],[693250,693627,"모델링을"],[693627,693780,"위한"],[693830,694520,"데이터를"],[694550,695060,"살펴봅시다."]],"textEdited":"이제 이 두 개의 피처를 봤을 때 씨티알 예측 문제에서 가장 많이 사용되는 피처는 이 위에 댄스 피처가 아니라 대부분 스퍼스 피처입니다. 다음 공개되어 있는 씨티알 예측 모델링을 위한 데이터를 살펴봅시다."},{"start":695300,"end":709000,"text":"이제 이 데이터를 살펴보면 대부분의 피처가 스퍼스 한 피처라는 것을 알 수 있는데요. 이 하나하나의 컬럼이 피처를 의미합니다. 이제 공개 데이터 셋이기 때문에 모두 암호화가 된 해시 값으로 이루어져 있긴 하지만","confidence":0.9054,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[695510,695647,"이제"],[695647,695747,"이"],[695747,696120,"데이터를"],[696120,696520,"살펴보면"],[696890,697380,"대부분의"],[697510,697880,"피처가"],[697910,698340,"스퍼스"],[698340,698460,"한"],[698490,698960,"피처라는"],[698960,699220,"것을"],[699270,699420,"알"],[699420,699514,"수"],[699514,699880,"있는데요."],[700850,701000,"이"],[701030,701540,"하나하나의"],[701630,702000,"컬럼이"],[702410,702900,"피처를"],[702950,703440,"의미합니다."],[704190,704360,"이제"],[704390,704620,"공개"],[704620,704920,"데이터"],[704920,705207,"셋이기"],[705207,705520,"때문에"],[705550,705800,"모두"],[706030,706520,"암호화가"],[706520,706640,"된"],[706730,707000,"해시"],[707000,707320,"값으로"],[707320,707640,"이루어져"],[707670,707880,"있긴"],[707880,708220,"하지만"]],"textEdited":"이제 이 데이터를 살펴보면 대부분의 피처가 스퍼스 한 피처라는 것을 알 수 있는데요. 이 하나하나의 컬럼이 피처를 의미합니다. 이제 공개 데이터 셋이기 때문에 모두 암호화가 된 해시 값으로 이루어져 있긴 하지만"},{"start":709000,"end":723000,"text":"이 전체 데이터 가운데 전체 피처 가운데 파란색으로 씌워져 있는 모든 피처들은 다 카테고리컬 데이터 즉 스파스한 피처로 나타나야 한다는 것입니다. 뭐 사이트의 아이디라든지 광고가 노출된 도메인 같은","confidence":0.953,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[709190,709340,"이"],[709370,709640,"전체"],[709650,710020,"데이터"],[710230,710620,"가운데"],[710990,711260,"전체"],[711310,711600,"피처"],[711600,711940,"가운데"],[712050,712860,"파란색으로"],[713190,713540,"씌워져"],[713540,713700,"있는"],[713770,714000,"모든"],[714170,714600,"피처들은"],[714610,714760,"다"],[715550,716140,"카테고리컬"],[716190,716500,"데이터"],[716710,716860,"즉"],[716870,717400,"스파스한"],[717430,717760,"피처로"],[717910,718420,"나타나야"],[718470,718754,"한다는"],[718754,719180,"것입니다."],[719590,719740,"뭐"],[719770,720260,"사이트의"],[720290,721100,"아이디라든지"],[721330,721680,"광고가"],[721710,722120,"노출된"],[722170,722500,"도메인"],[722590,722840,"같은"]],"textEdited":"이 전체 데이터 가운데 전체 피처 가운데 파란색으로 씌워져 있는 모든 피처들은 다 카테고리컬 데이터 즉 스파스한 피처로 나타나야 한다는 것입니다. 뭐 사이트의 아이디라든지 광고가 노출된 도메인 같은"},{"start":723000,"end":735700,"text":"것들은 다 스트링 값이고 이 스트링 값을 모델의 입력 변수를 사용하기 위해서는 보통 원핫 인코딩으로 표현해야 하기 때문에 각각의 피처들은 다 스프레스 한 피처로 표현되게 됩니다.","confidence":0.9462,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[723230,723520,"것들은"],[723520,723640,"다"],[723710,724060,"스트링"],[724130,724540,"값이고"],[725050,725200,"이"],[725210,725520,"스트링"],[725520,725800,"값을"],[725830,726180,"모델의"],[726210,726460,"입력"],[726490,726760,"변수를"],[726760,727120,"사용하기"],[727120,727520,"위해서는"],[727650,727940,"보통"],[728150,728460,"원핫"],[728510,729020,"인코딩으로"],[729030,729400,"표현해야"],[729450,729607,"하기"],[729607,729980,"때문에"],[730570,731060,"각각의"],[731390,731800,"피처들은"],[731800,731940,"다"],[732510,732947,"스프레스"],[732947,733080,"한"],[733110,733500,"피처로"],[734330,734740,"표현되게"],[734740,735240,"됩니다."]],"textEdited":"것들은 다 스트링 값이고 이 스트링 값을 모델의 입력 변수를 사용하기 위해서는 보통 원핫 인코딩으로 표현해야 하기 때문에 각각의 피처들은 다 스프레스 한 피처로 표현되게 됩니다."},{"start":735700,"end":748100,"text":"그래서 CTR 예측 문제의 데이터를 모두 다 원핫 인코딩만으로 표현하여서 모델링을 할 경우에는 학습 파라미터 수가 그 차원의 개수만큼 생기기 때문에 아주 많아질 수 있고,","confidence":0.931,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[735970,736260,"그래서"],[736550,736940,"CTR"],[736970,737220,"예측"],[737250,737560,"문제의"],[737560,738000,"데이터를"],[738550,738800,"모두"],[738800,738920,"다"],[738950,739220,"원핫"],[739250,739960,"인코딩만으로"],[739970,740500,"표현하여서"],[740530,741040,"모델링을"],[741040,741180,"할"],[741210,741660,"경우에는"],[742330,742580,"학습"],[742580,742980,"파라미터"],[742980,743240,"수가"],[743810,743960,"그"],[743970,744300,"차원의"],[744300,744840,"개수만큼"],[745910,746167,"생기기"],[746167,746500,"때문에"],[746570,746780,"아주"],[746790,747160,"많아질"],[747190,747307,"수"],[747307,747600,"있고,"]],"textEdited":"그래서 CTR 예측 문제의 데이터를 모두 다 원핫 인코딩만으로 표현하여서 모델링을 할 경우에는 학습 파라미터 수가 그 차원의 개수만큼 생기기 때문에 아주 많아질 수 있고,"},{"start":748100,"end":753200,"text":"학습 데이터에 등장하는 빈도에 따라서 특정 카테고리나 특정 피처는","confidence":0.9726,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[748430,748700,"학습"],[748700,749140,"데이터에"],[749210,749620,"등장하는"],[749730,750127,"빈도에"],[750127,750500,"따라서"],[751170,751520,"특정"],[751590,752080,"카테고리나"],[752170,752420,"특정"],[752470,752880,"피처는"]],"textEdited":"학습 데이터에 등장하는 빈도에 따라서 특정 카테고리나 특정 피처는"},{"start":753200,"end":764100,"text":"과적합되거나 즉 오버 피팅 되거나 언더피팅 될 수 있습니다. 이를 막기 위해서 원아 인코딩을 보통 그대로 사용하지 않고 피처 인베딩을 합니다.","confidence":0.8658,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[753470,754620,"과적합되거나"],[754850,755000,"즉"],[755030,755240,"오버"],[755240,755480,"피팅"],[755480,755760,"되거나"],[755760,756260,"언더피팅"],[756290,756440,"될"],[756530,756680,"수"],[756930,757360,"있습니다."],[757770,757980,"이를"],[758030,758327,"막기"],[758327,758640,"위해서"],[759450,759740,"원아"],[759750,760200,"인코딩을"],[760310,760680,"보통"],[760750,761040,"그대로"],[761050,761460,"사용하지"],[761470,761800,"않고"],[762630,762960,"피처"],[763110,763620,"인베딩을"],[763620,763920,"합니다."]],"textEdited":"과적합되거나 즉 오버 피팅 되거나 언더피팅 될 수 있습니다. 이를 막기 위해서 원아 인코딩을 보통 그대로 사용하지 않고 피처 인베딩을 합니다."},{"start":764100,"end":777600,"text":"이 인베딩도 사실 이전 시간에 굉장히 많이 배웠죠. 우리가 5강에서 배웠던 아이템 투 백이나 혹은 자연어 처리에 사용되는 LDA와 같은 토픽 모델링이나 혹은","confidence":0.9432,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[764610,764760,"이"],[764760,765280,"인베딩도"],[765650,765880,"사실"],[766070,766320,"이전"],[766410,766700,"시간에"],[766710,767000,"굉장히"],[767010,767200,"많이"],[767210,767600,"배웠죠."],[768250,768500,"우리가"],[769210,769680,"5강에서"],[769680,770040,"배웠던"],[770410,770780,"아이템"],[770810,770960,"투"],[770960,772200,"백이나"],[772270,772480,"혹은"],[772930,773300,"자연어"],[773300,773600,"처리에"],[773600,774020,"사용되는"],[774610,775260,"LDA와"],[775330,775600,"같은"],[775930,776200,"토픽"],[776200,776740,"모델링이나"],[776950,777160,"혹은"]],"textEdited":"이 인베딩도 사실 이전 시간에 굉장히 많이 배웠죠. 우리가 5강에서 배웠던 아이템 투 백이나 혹은 자연어 처리에 사용되는 LDA와 같은 토픽 모델링이나 혹은"},{"start":777600,"end":791600,"text":"이제 버트와 같은 프리트 랭귀지 모델의 인베딩도 다 피처를 임베딩하는 기법이고 이 인베딩을 CTR 예측 모델의 피처 데이터로 사용할 수 있습니다. 그래서 우리가 앞으로 배울 CTR 모델","confidence":0.7992,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[777890,778060,"이제"],[778130,778560,"버트와"],[778570,778840,"같은"],[779090,779400,"프리트"],[779570,779860,"랭귀지"],[779860,780440,"모델의"],[780850,781460,"인베딩도"],[781850,782000,"다"],[782670,783000,"피처를"],[783000,783440,"임베딩하는"],[783450,783900,"기법이고"],[784090,784240,"이"],[784250,784700,"인베딩을"],[784930,785240,"CTR"],[785240,785480,"예측"],[785480,785820,"모델의"],[786450,786720,"피처"],[786720,787120,"데이터로"],[787310,787660,"사용할"],[787690,787840,"수"],[787910,788340,"있습니다."],[789050,789300,"그래서"],[789310,789540,"우리가"],[789610,789980,"앞으로"],[790050,790280,"배울"],[790410,790780,"CTR"],[790950,791200,"모델"]],"textEdited":"이제 버트와 같은 프리트 랭귀지 모델의 인베딩도 다 피처를 임베딩하는 기법이고 이 인베딩을 CTR 예측 모델의 피처 데이터로 사용할 수 있습니다. 그래서 우리가 앞으로 배울 CTR 모델"},{"start":791600,"end":804600,"text":"공통점이 있는데요. 첫째로는 스퍼스 한 피쳐를 인베딩을 통해 잘 표현하는 것 인베딩, 둘째로는 이 스프레스 한 피처들","confidence":0.8638,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[792030,792560,"공통점이"],[792560,792920,"있는데요."],[793750,794220,"첫째로는"],[794270,794727,"스퍼스"],[794727,794860,"한"],[795030,795480,"피쳐를"],[795670,796180,"인베딩을"],[796230,796440,"통해"],[796510,796660,"잘"],[796830,797220,"표현하는"],[797220,797360,"것"],[797970,798320,"인베딩,"],[802010,802520,"둘째로는"],[802950,803100,"이"],[803290,803680,"스프레스"],[803680,803800,"한"],[803850,804240,"피처들"]],"textEdited":"공통점이 있는데요. 첫째로는 스퍼스 한 피쳐를 인베딩을 통해 잘 표현하는 것 인베딩, 둘째로는 이 스프레스 한 피처들"},{"start":804600,"end":817300,"text":"간의 상호작용을 모델 설계에서 고려한다는 점입니다. 상호작용은 인터랙션이 되겠죠. 그래서 이 두 가지를 어떻게 모델에서 잘 표현할 것인가를 생각하시면서","confidence":0.9837,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[804830,805140,"간의"],[805350,805940,"상호작용을"],[806510,806780,"모델"],[806850,807220,"설계에서"],[807220,807720,"고려한다는"],[807720,808120,"점입니다."],[808790,809240,"상호작용은"],[809290,809794,"인터랙션이"],[809794,810120,"되겠죠."],[810970,811200,"그래서"],[811270,811420,"이"],[812070,812220,"두"],[812220,812620,"가지를"],[812830,813180,"어떻게"],[813250,813700,"모델에서"],[813730,813880,"잘"],[814030,814460,"표현할"],[814470,815820,"것인가를"],[816030,816720,"생각하시면서"]],"textEdited":"간의 상호작용을 모델 설계에서 고려한다는 점입니다. 상호작용은 인터랙션이 되겠죠. 그래서 이 두 가지를 어떻게 모델에서 잘 표현할 것인가를 생각하시면서"},{"start":817300,"end":832000,"text":"이 이후의 내용들을 배우시면 크게 도움이 될 것입니다. 그래서 간단하게 컨텍스트 레코멘데이션 추천 알고리즘의 변천사를 살펴보면은 먼저 딥러닝 이전 AI에서는 로지스틱 리그레션과 SVM 모델이 등장하였고요.","confidence":0.8701,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[817590,817740,"이"],[817740,818040,"이후의"],[818040,818560,"내용들을"],[819050,819520,"배우시면"],[819750,819980,"크게"],[820010,820300,"도움이"],[820300,820420,"될"],[820430,820840,"것입니다."],[821410,821660,"그래서"],[821910,822340,"간단하게"],[822510,823040,"컨텍스트"],[823150,823760,"레코멘데이션"],[824430,824700,"추천"],[824750,825220,"알고리즘의"],[825270,825780,"변천사를"],[825790,826380,"살펴보면은"],[827130,827340,"먼저"],[827370,827780,"딥러닝"],[827790,828020,"이전"],[828170,828800,"AI에서는"],[829310,829740,"로지스틱"],[829750,830280,"리그레션과"],[830390,830780,"SVM"],[830780,831100,"모델이"],[831170,831800,"등장하였고요."]],"textEdited":"이 이후의 내용들을 배우시면 크게 도움이 될 것입니다. 그래서 간단하게 컨텍스트 레코멘데이션 추천 알고리즘의 변천사를 살펴보면은 먼저 딥러닝 이전 AI에서는 로지스틱 리그레션과 SVM 모델이 등장하였고요."},{"start":832000,"end":844900,"text":"그 이후에 매트리스 팩토라이제이션과 함께 추천 시스템 연구 분야가 크게 발전하였습니다. 그다음에 이제 컨텍스트의 레코멘데이션이라는 개념이 등장하고 전통적인 머신 러닝 모델들과 인베딩을 결합한 기법들이 많이 사용되었습니다.","confidence":0.9256,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[832230,832380,"그"],[832390,832680,"이후에"],[833270,833660,"매트리스"],[833660,834600,"팩토라이제이션과"],[834600,834860,"함께"],[834990,835260,"추천"],[835310,835620,"시스템"],[835630,835840,"연구"],[835840,836120,"분야가"],[836150,836360,"크게"],[836410,837120,"발전하였습니다."],[837810,838160,"그다음에"],[838170,838340,"이제"],[838390,839040,"컨텍스트의"],[839040,839800,"레코멘데이션이라는"],[839810,840140,"개념이"],[840150,840660,"등장하고"],[841270,841760,"전통적인"],[841790,841980,"머신"],[841980,842180,"러닝"],[842180,842660,"모델들과"],[842730,843200,"인베딩을"],[843200,843520,"결합한"],[843550,843967,"기법들이"],[843967,844140,"많이"],[844170,844840,"사용되었습니다."]],"textEdited":"그 이후에 매트리스 팩토라이제이션과 함께 추천 시스템 연구 분야가 크게 발전하였습니다. 그다음에 이제 컨텍스트의 레코멘데이션이라는 개념이 등장하고 전통적인 머신 러닝 모델들과 인베딩을 결합한 기법들이 많이 사용되었습니다."},{"start":844900,"end":859500,"text":"이제 그 이후에 우리가 배울 팩토라이제이션 머신과 필드 어이어 팩토라이제이션 머신이 출연하였고 이 두 가지 모델에 대해서 자세히 살펴보겠습니다. 네 이번 파트는 팩토라이제이션 머신 모델과 해당 논문에 대해서 리뷰하겠습니다.","confidence":0.9161,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[845310,845480,"이제"],[845480,845620,"그"],[845620,845860,"이후에"],[845860,846060,"우리가"],[846070,846300,"배울"],[846430,847040,"팩토라이제이션"],[847070,847500,"머신과"],[847770,848060,"필드"],[848060,848240,"어이어"],[848250,848780,"팩토라이제이션"],[848780,849160,"머신이"],[849650,850200,"출연하였고"],[850670,850820,"이"],[850820,850960,"두"],[850960,851160,"가지"],[851170,851467,"모델에"],[851467,851780,"대해서"],[852310,852620,"자세히"],[852630,853340,"살펴보겠습니다."],[854070,854220,"네"],[854950,855160,"이번"],[855230,855580,"파트는"],[855750,856480,"팩토라이제이션"],[856510,856800,"머신"],[856810,857380,"모델과"],[857470,857700,"해당"],[857750,858087,"논문에"],[858087,858400,"대해서"],[858570,859300,"리뷰하겠습니다."]],"textEdited":"이제 그 이후에 우리가 배울 팩토라이제이션 머신과 필드 어이어 팩토라이제이션 머신이 출연하였고 이 두 가지 모델에 대해서 자세히 살펴보겠습니다. 네 이번 파트는 팩토라이제이션 머신 모델과 해당 논문에 대해서 리뷰하겠습니다."},{"start":859500,"end":871800,"text":"이 FM 모델의 등장 배경과 장점을 이해하고 그 원리가 어떻게 작동하는지 살펴보겠습니다. 팩토라이제이션 머신은 2010년에 동일한 이름의 논문을 통해 발표된 모델입니다.","confidence":0.8937,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[859790,859940,"이"],[860130,860400,"FM"],[860490,860820,"모델의"],[860870,861140,"등장"],[861230,861600,"배경과"],[861690,862100,"장점을"],[862130,862560,"이해하고"],[862830,862980,"그"],[863030,863400,"원리가"],[863710,864060,"어떻게"],[864330,864900,"작동하는지"],[865070,865800,"살펴보겠습니다."],[866430,867140,"팩토라이제이션"],[867170,867800,"머신은"],[868050,868680,"2010년에"],[869250,869600,"동일한"],[869750,870080,"이름의"],[870130,870540,"논문을"],[870550,870760,"통해"],[870830,871180,"발표된"],[871230,871740,"모델입니다."]],"textEdited":"이 FM 모델의 등장 배경과 장점을 이해하고 그 원리가 어떻게 작동하는지 살펴보겠습니다. 팩토라이제이션 머신은 2010년에 동일한 이름의 논문을 통해 발표된 모델입니다."},{"start":871800,"end":884800,"text":"당시 ML 모델 가운데 가장 많이 사용되었던 이 SVM과 MF와 같은 팩토라이제이션 모델의 장점을 결합한 논문입니다. 이 팩토라이제이션 모델의 대표적인 모델이 바로 아까 4강에서 배웠던","confidence":0.9618,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[872110,872380,"당시"],[872450,872680,"ML"],[872750,873020,"모델"],[873050,873420,"가운데"],[873570,873820,"가장"],[873870,874060,"많이"],[874130,874740,"사용되었던"],[874750,874900,"이"],[874930,875700,"SVM과"],[876550,877060,"MF와"],[877070,877340,"같은"],[877550,878260,"팩토라이제이션"],[878290,878620,"모델의"],[878750,879180,"장점을"],[879290,879680,"결합한"],[879710,880200,"논문입니다."],[880570,880720,"이"],[880730,881280,"팩토라이제이션"],[881280,881740,"모델의"],[881850,882280,"대표적인"],[882370,882660,"모델이"],[882660,882900,"바로"],[883150,883360,"아까"],[883810,884207,"4강에서"],[884207,884560,"배웠던"]],"textEdited":"당시 ML 모델 가운데 가장 많이 사용되었던 이 SVM과 MF와 같은 팩토라이제이션 모델의 장점을 결합한 논문입니다. 이 팩토라이제이션 모델의 대표적인 모델이 바로 아까 4강에서 배웠던"},{"start":884800,"end":894200,"text":"지난 4강에서 배웠던 MF입니다. 먼저 FM의 등장 배경입니다. 이 딥러닝이 등장하기 전에는 서포트 벡터 머신이 가장","confidence":0.9549,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[885090,885300,"지난"],[885330,885687,"4강에서"],[885687,886000,"배웠던"],[886210,886840,"MF입니다."],[887610,887860,"먼저"],[887950,888260,"FM의"],[888310,888580,"등장"],[888630,889120,"배경입니다."],[889870,890020,"이"],[890020,890480,"딥러닝이"],[890510,890980,"등장하기"],[890980,891400,"전에는"],[892230,892660,"서포트"],[892660,892900,"벡터"],[892900,893260,"머신이"],[893450,893700,"가장"]],"textEdited":"지난 4강에서 배웠던 MF입니다. 먼저 FM의 등장 배경입니다. 이 딥러닝이 등장하기 전에는 서포트 벡터 머신이 가장"},{"start":894200,"end":904300,"text":"ML 분야에서 많이 사용되는 모델 중에 하나였습니다. 커널 공간을 사용한 논 리니어 데이터셋에 대해서 이 SVM이 가장 높은 성능을 보였습니다.","confidence":0.9451,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[894570,894800,"ML"],[894850,895260,"분야에서"],[895260,895440,"많이"],[895490,895920,"사용되는"],[895930,896160,"모델"],[896160,896347,"중에"],[896347,896960,"하나였습니다."],[897650,897960,"커널"],[898030,899000,"공간을"],[899290,899620,"사용한"],[900450,900600,"논"],[900710,901020,"리니어"],[901020,901527,"데이터셋에"],[901527,901800,"대해서"],[901830,901980,"이"],[901980,902600,"SVM이"],[902650,902880,"가장"],[902890,903140,"높은"],[903270,903600,"성능을"],[903630,904140,"보였습니다."]],"textEdited":"ML 분야에서 많이 사용되는 모델 중에 하나였습니다. 커널 공간을 사용한 논 리니어 데이터셋에 대해서 이 SVM이 가장 높은 성능을 보였습니다."},{"start":904300,"end":918500,"text":"모델링을 하기에 가장 어려운 게 이런 비선형 데이터 셋이었는데요. 랜덤 플러스 같은 모델도 괜찮은 성능을 그 당시에 냈지만 SVM 즉 커너를 사용한 SVM이 당시에 가장 좋은 성능을 보였습니다. 이제 그럼에도 불구하고","confidence":0.9319,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[904650,905200,"모델링을"],[905210,905520,"하기에"],[905530,905740,"가장"],[905790,906080,"어려운"],[906370,906520,"게"],[906520,906680,"이런"],[906770,907120,"비선형"],[907120,907380,"데이터"],[907380,907960,"셋이었는데요."],[908690,908960,"랜덤"],[908960,909207,"플러스"],[909207,909420,"같은"],[909420,909780,"모델도"],[909910,910220,"괜찮은"],[910270,910540,"성능을"],[910540,910614,"그"],[910614,910827,"당시에"],[910827,911200,"냈지만"],[911730,912220,"SVM"],[912330,912480,"즉"],[912550,912920,"커너를"],[912920,913160,"사용한"],[913230,913740,"SVM이"],[914190,914500,"당시에"],[914550,914800,"가장"],[915170,915340,"좋은"],[915490,915800,"성능을"],[915850,916380,"보였습니다."],[916890,917060,"이제"],[917070,917440,"그럼에도"],[917450,917920,"불구하고"]],"textEdited":"모델링을 하기에 가장 어려운 게 이런 비선형 데이터 셋이었는데요. 랜덤 플러스 같은 모델도 괜찮은 성능을 그 당시에 냈지만 SVM 즉 커너를 사용한 SVM이 당시에 가장 좋은 성능을 보였습니다. 이제 그럼에도 불구하고"},{"start":918500,"end":932100,"text":"콜라버레이트 필터링 환경에서는 MF 계열의 모델이 SVM보다 더 좋은 성능을 내왔습니다. 이 CF 문제 CF 환경이라는 것은 앞에서 많이 다루었는데요.","confidence":0.6717,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[918870,919440,"콜라버레이트"],[919490,919900,"필터링"],[920050,921760,"환경에서는"],[922530,922920,"MF"],[922930,923240,"계열의"],[923670,924040,"모델이"],[924430,925100,"SVM보다"],[925100,925240,"더"],[925240,925400,"좋은"],[925590,925940,"성능을"],[926970,927540,"내왔습니다."],[928210,928360,"이"],[928470,928880,"CF"],[928930,929180,"문제"],[929350,929700,"CF"],[929750,930260,"환경이라는"],[930260,930480,"것은"],[930530,930860,"앞에서"],[930860,931040,"많이"],[931070,931700,"다루었는데요."]],"textEdited":"콜라버레이트 필터링 환경에서는 MF 계열의 모델이 SVM보다 더 좋은 성능을 내왔습니다. 이 CF 문제 CF 환경이라는 것은 앞에서 많이 다루었는데요."},{"start":932100,"end":942900,"text":"유저 아이템에 대한 평점을 예측하는 것입니다. 이 CF 환경은 유저 아이템이 굉장히 개수가 많기 때문에 굉장히 스퍼스한 데이터로 이루어져 있고","confidence":0.933,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[932450,932820,"유저"],[933050,933607,"아이템에"],[933607,933820,"대한"],[934010,934400,"평점을"],[934430,934827,"예측하는"],[934827,935240,"것입니다."],[935670,935820,"이"],[935850,936300,"CF"],[936590,936940,"환경은"],[937570,937880,"유저"],[938010,938520,"아이템이"],[938590,938980,"굉장히"],[939310,939680,"개수가"],[939690,940020,"많기"],[940020,940360,"때문에"],[940570,940840,"굉장히"],[940890,941500,"스퍼스한"],[941530,941940,"데이터로"],[941940,942220,"이루어져"],[942220,942480,"있고"]],"textEdited":"유저 아이템에 대한 평점을 예측하는 것입니다. 이 CF 환경은 유저 아이템이 굉장히 개수가 많기 때문에 굉장히 스퍼스한 데이터로 이루어져 있고"},{"start":942900,"end":957800,"text":"이런 스파이스한 데이터는 SVM이 좋은 성능을 내지 못하는 분야였습니다. 하지만 MF 모델은 여러분들이 잘 아시다시피 특별한 환경과 특별한 데이터에 대해서만 적용할 수 있는데요. 그 특별한 환경이랑","confidence":0.8636,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[943090,943280,"이런"],[943330,943940,"스파이스한"],[943940,944380,"데이터는"],[944730,945340,"SVM이"],[945390,945580,"좋은"],[945750,946080,"성능을"],[946080,946320,"내지"],[946350,946740,"못하는"],[947070,947760,"분야였습니다."],[948310,948620,"하지만"],[949510,949880,"MF"],[950170,951340,"모델은"],[951350,951727,"여러분들이"],[951727,951860,"잘"],[951890,952440,"아시다시피"],[953050,953380,"특별한"],[953490,953880,"환경과"],[953970,954260,"특별한"],[954290,954687,"데이터에"],[954687,955040,"대해서만"],[955050,955400,"적용할"],[955400,955487,"수"],[955487,955820,"있는데요."],[956490,956640,"그"],[956710,957000,"특별한"],[957030,957420,"환경이랑"]],"textEdited":"이런 스파이스한 데이터는 SVM이 좋은 성능을 내지 못하는 분야였습니다. 하지만 MF 모델은 여러분들이 잘 아시다시피 특별한 환경과 특별한 데이터에 대해서만 적용할 수 있는데요. 그 특별한 환경이랑"},{"start":957800,"end":971200,"text":"아 아래와 같이 주어진 스가 유저 아이템일 때 예측해야 되는 것이 레이팅 이렇게 구성된 데이터를 말하고요. 이 데이터에 대해서만 엠프 모델링이 가능했습니다.","confidence":0.902,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[958070,958220,"아"],[958450,958780,"아래와"],[958810,959100,"같이"],[959730,960080,"주어진"],[960290,960540,"스가"],[960630,960900,"유저"],[961010,962300,"아이템일"],[962350,962500,"때"],[963130,963547,"예측해야"],[963547,963740,"되는"],[963740,963980,"것이"],[964030,964420,"레이팅"],[965430,965700,"이렇게"],[965710,966060,"구성된"],[966130,966920,"데이터를"],[966920,967280,"말하고요."],[967370,967520,"이"],[967550,968040,"데이터에"],[968040,968440,"대해서만"],[969250,969580,"엠프"],[969580,970040,"모델링이"],[970390,971100,"가능했습니다."]],"textEdited":"아 아래와 같이 주어진 스가 유저 아이템일 때 예측해야 되는 것이 레이팅 이렇게 구성된 데이터를 말하고요. 이 데이터에 대해서만 엠프 모델링이 가능했습니다."},{"start":971200,"end":985800,"text":"그래서 본 논문 팩토라이제이션 머신이라는 논문은 SVM과 MF 모델의 장점을 결합할 수 없을까라는 아이디어에서 시작했습니다. 자 그래서 다음은 FM 모델의 수식을 나타냈습니다.","confidence":0.8512,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[971650,971880,"그래서"],[971880,972020,"본"],[972090,972320,"논문"],[972690,973280,"팩토라이제이션"],[973290,973740,"머신이라는"],[973740,974060,"논문은"],[974930,976180,"SVM과"],[976870,977240,"MF"],[977240,977540,"모델의"],[977870,978340,"장점을"],[978340,978700,"결합할"],[978730,978847,"수"],[978847,979760,"없을까라는"],[979790,980380,"아이디어에서"],[980670,981320,"시작했습니다."],[981990,982140,"자"],[982140,982340,"그래서"],[982350,982700,"다음은"],[983490,983760,"FM"],[983770,984080,"모델의"],[984110,984940,"수식을"],[984970,985580,"나타냈습니다."]],"textEdited":"그래서 본 논문 팩토라이제이션 머신이라는 논문은 SVM과 MF 모델의 장점을 결합할 수 없을까라는 아이디어에서 시작했습니다. 자 그래서 다음은 FM 모델의 수식을 나타냈습니다."},{"start":985800,"end":998800,"text":"먼저 입력 변수는 x1부터 xn 총 n개의 변수가 존재하고요. 이 FM에서 학습하는 파라미터는 먼저 글로벌 바이어스가 있고요. 그리고 각각의 변수마다 대응되는","confidence":0.9641,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[986330,986600,"먼저"],[986750,987000,"입력"],[987050,987380,"변수는"],[987610,988140,"x1부터"],[988310,988600,"xn"],[988850,989000,"총"],[989090,989580,"n개의"],[989770,990140,"변수가"],[990190,990780,"존재하고요."],[991570,991720,"이"],[991770,992200,"FM에서"],[992330,992740,"학습하는"],[992740,993260,"파라미터는"],[993770,993980,"먼저"],[994010,994320,"글로벌"],[994320,994840,"바이어스가"],[994840,995160,"있고요."],[996030,996320,"그리고"],[996810,997160,"각각의"],[997210,997740,"변수마다"],[997850,998360,"대응되는"]],"textEdited":"먼저 입력 변수는 x1부터 xn 총 n개의 변수가 존재하고요. 이 FM에서 학습하는 파라미터는 먼저 글로벌 바이어스가 있고요. 그리고 각각의 변수마다 대응되는"},{"start":998800,"end":1011200,"text":"1차 파라미터 WI가 존재합니다. 그리고 제일 중요한 부분이 바로 이 두 번째 텀 팩토라이제이션 텀입니다. 여기서 학습하는 파라미터는","confidence":0.9262,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[999070,999360,"1차"],[999390,999820,"파라미터"],[999930,1000440,"WI가"],[1000470,1001000,"존재합니다."],[1001750,1001960,"그리고"],[1002010,1002240,"제일"],[1002350,1002680,"중요한"],[1002710,1003040,"부분이"],[1003070,1003360,"바로"],[1003970,1004120,"이"],[1004130,1004280,"두"],[1004310,1004600,"번째"],[1004610,1004760,"텀"],[1007330,1008020,"팩토라이제이션"],[1008030,1008520,"텀입니다."],[1009250,1009560,"여기서"],[1009590,1010020,"학습하는"],[1010090,1010700,"파라미터는"]],"textEdited":"1차 파라미터 WI가 존재합니다. 그리고 제일 중요한 부분이 바로 이 두 번째 텀 팩토라이제이션 텀입니다. 여기서 학습하는 파라미터는"},{"start":1011200,"end":1026200,"text":"VI와 VJ이고 이 VI와 VJ는 스칼라 값이 아니라 k 차원의 벡터로 이루어진 파라미터입니다. 그래서 XI와 xj가 상호작용을 할 때 그 XI에 해당되는 VI","confidence":0.9121,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1011530,1012120,"VI와"],[1012150,1012740,"VJ이고"],[1012790,1012940,"이"],[1012940,1013300,"VI와"],[1013300,1013760,"VJ는"],[1014290,1014640,"스칼라"],[1014640,1014840,"값이"],[1014840,1015080,"아니라"],[1015750,1015900,"k"],[1016070,1016460,"차원의"],[1017230,1017660,"벡터로"],[1017660,1017960,"이루어진"],[1017990,1018680,"파라미터입니다."],[1019830,1020020,"그래서"],[1020210,1020700,"XI와"],[1020890,1021440,"xj가"],[1022030,1022960,"상호작용을"],[1022990,1023140,"할"],[1023190,1023340,"때"],[1023890,1024040,"그"],[1024270,1024800,"XI에"],[1024800,1025220,"해당되는"],[1025290,1025660,"VI"]],"textEdited":"VI와 VJ이고 이 VI와 VJ는 스칼라 값이 아니라 k 차원의 벡터로 이루어진 파라미터입니다. 그래서 XI와 xj가 상호작용을 할 때 그 XI에 해당되는 VI"},{"start":1026200,"end":1041000,"text":"x 제에 해당되는 VJ가 각각 곱해져서 상호작용 즉 피처 간의 상호작용을 모델링하고 있습니다. 이 둘의 곱은 스칼라 곱 즉 내적을 의미합니다. 이제 이 수식과 앞서 다루었던","confidence":0.8969,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1026650,1026800,"x"],[1026800,1027087,"제에"],[1027087,1027540,"해당되는"],[1027590,1028240,"VJ가"],[1028650,1028920,"각각"],[1028950,1029460,"곱해져서"],[1030070,1030580,"상호작용"],[1031130,1031280,"즉"],[1031390,1031647,"피처"],[1031647,1031860,"간의"],[1031860,1032360,"상호작용을"],[1032360,1032840,"모델링하고"],[1032840,1033180,"있습니다."],[1034130,1034280,"이"],[1034280,1034520,"둘의"],[1034530,1034800,"곱은"],[1035570,1035940,"스칼라"],[1035940,1036060,"곱"],[1036190,1036340,"즉"],[1036610,1037040,"내적을"],[1037090,1037580,"의미합니다."],[1038250,1038440,"이제"],[1038440,1038560,"이"],[1038590,1039060,"수식과"],[1039770,1040060,"앞서"],[1040070,1040600,"다루었던"]],"textEdited":"x 제에 해당되는 VJ가 각각 곱해져서 상호작용 즉 피처 간의 상호작용을 모델링하고 있습니다. 이 둘의 곱은 스칼라 곱 즉 내적을 의미합니다. 이제 이 수식과 앞서 다루었던"},{"start":1041000,"end":1054700,"text":"로지스틱 리그레션을 비교해 보도록 하겠습니다. 이 아래에 있는 수식이 로지스틱 리그레션의 수식인데요. 앞에 있는 이 부분이 로지스틱 리그레션과 동일함을 알 수 있습니다. 그런데 팩토라이제이션 머신은 뒤에","confidence":0.9376,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1041290,1041740,"로지스틱"],[1041770,1042280,"리그레션을"],[1042290,1042574,"비교해"],[1042574,1042860,"보도록"],[1042860,1043340,"하겠습니다."],[1044190,1044340,"이"],[1044340,1044587,"아래에"],[1044587,1044780,"있는"],[1044930,1045280,"수식이"],[1045830,1046260,"로지스틱"],[1046260,1046740,"리그레션의"],[1046740,1047280,"수식인데요."],[1048070,1048360,"앞에"],[1048370,1048540,"있는"],[1048610,1048760,"이"],[1048760,1049060,"부분이"],[1049630,1050000,"로지스틱"],[1050000,1050980,"리그레션과"],[1050990,1051460,"동일함을"],[1051470,1051620,"알"],[1051620,1051694,"수"],[1051694,1052040,"있습니다."],[1052610,1052800,"그런데"],[1052810,1053400,"팩토라이제이션"],[1053400,1053720,"머신은"],[1053850,1054100,"뒤에"]],"textEdited":"로지스틱 리그레션을 비교해 보도록 하겠습니다. 이 아래에 있는 수식이 로지스틱 리그레션의 수식인데요. 앞에 있는 이 부분이 로지스틱 리그레션과 동일함을 알 수 있습니다. 그런데 팩토라이제이션 머신은 뒤에"},{"start":1054700,"end":1067800,"text":"두 피처의 상호작용을 표현할 수 있는 팩토라이제이션 텀이 추가된 것이죠. 로지스틱 리그레션은 아까 설명한 대로 두 피처의 상호 작용을 모델링 할 수 없다고 말씀드렸습니다. 자 그리고","confidence":0.9079,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1055350,1055500,"두"],[1055630,1056060,"피처의"],[1056090,1056700,"상호작용을"],[1057030,1057380,"표현할"],[1057410,1057514,"수"],[1057514,1057680,"있는"],[1057990,1058700,"팩토라이제이션"],[1058730,1059040,"텀이"],[1059530,1059827,"추가된"],[1059827,1060140,"것이죠."],[1061270,1061660,"로지스틱"],[1061660,1062100,"리그레션은"],[1062290,1062480,"아까"],[1062550,1062827,"설명한"],[1062827,1063060,"대로"],[1063270,1063420,"두"],[1063470,1063820,"피처의"],[1063830,1064020,"상호"],[1064030,1064380,"작용을"],[1064450,1064800,"모델링"],[1064800,1064920,"할"],[1064920,1065060,"수"],[1065060,1065380,"없다고"],[1065390,1066120,"말씀드렸습니다."],[1066690,1066840,"자"],[1066840,1067120,"그리고"]],"textEdited":"두 피처의 상호작용을 표현할 수 있는 팩토라이제이션 텀이 추가된 것이죠. 로지스틱 리그레션은 아까 설명한 대로 두 피처의 상호 작용을 모델링 할 수 없다고 말씀드렸습니다. 자 그리고"},{"start":1067800,"end":1080700,"text":"두 피처의 상호 작용을 강제로 카테시안 프로덕트를 만들어 가지고 이 wij라는 파라미터를 정의한 모델이 바로 이 폴리노미얼 모델이었습니다. 이제 이 두 수식을 비교해 보면은","confidence":0.8898,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1068050,1068200,"두"],[1068390,1068840,"피처의"],[1068890,1069100,"상호"],[1069110,1069460,"작용을"],[1070510,1070880,"강제로"],[1070950,1071400,"카테시안"],[1071400,1071787,"프로덕트를"],[1071787,1072060,"만들어"],[1072060,1072340,"가지고"],[1072450,1072600,"이"],[1072750,1073800,"wij라는"],[1073910,1075020,"파라미터를"],[1075050,1075380,"정의한"],[1075390,1075680,"모델이"],[1075680,1075827,"바로"],[1075827,1075960,"이"],[1076010,1076540,"폴리노미얼"],[1076730,1077400,"모델이었습니다."],[1077890,1078060,"이제"],[1078130,1078280,"이"],[1078310,1078460,"두"],[1078610,1078980,"수식을"],[1079410,1079800,"비교해"],[1079800,1080160,"보면은"]],"textEdited":"두 피처의 상호 작용을 강제로 카테시안 프로덕트를 만들어 가지고 이 wij라는 파라미터를 정의한 모델이 바로 이 폴리노미얼 모델이었습니다. 이제 이 두 수식을 비교해 보면은"},{"start":1080700,"end":1095100,"text":"이 앞에 있는 글로벌 바이어스와 1차 텀은 동일하지만 두 상호작용을 모델링하는 텀이 달라짐을 알 수 있습니다. 이 폴리노미 모델은 XI와 xj의 상호작용을 wij라는 하나의 파라미터로 표현했다면은","confidence":0.9102,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1081010,1081160,"이"],[1081210,1081480,"앞에"],[1081510,1081720,"있는"],[1082150,1082460,"글로벌"],[1082490,1083060,"바이어스와"],[1083290,1083620,"1차"],[1083670,1083960,"텀은"],[1084050,1084580,"동일하지만"],[1085470,1085620,"두"],[1085730,1086280,"상호작용을"],[1086290,1086820,"모델링하는"],[1086850,1087120,"텀이"],[1087130,1087580,"달라짐을"],[1087610,1087760,"알"],[1087760,1087834,"수"],[1087834,1088220,"있습니다."],[1089110,1089260,"이"],[1089290,1089720,"폴리노미"],[1089730,1090080,"모델은"],[1090610,1091040,"XI와"],[1091090,1091540,"xj의"],[1091540,1092060,"상호작용을"],[1092370,1093220,"wij라는"],[1093270,1093560,"하나의"],[1093590,1094060,"파라미터로"],[1094060,1094700,"표현했다면은"]],"textEdited":"이 앞에 있는 글로벌 바이어스와 1차 텀은 동일하지만 두 상호작용을 모델링하는 텀이 달라짐을 알 수 있습니다. 이 폴리노미 모델은 XI와 xj의 상호작용을 wij라는 하나의 파라미터로 표현했다면은"},{"start":1095100,"end":1106400,"text":"FM 같은 경우에는 XI와 xj의 상호작용을 각각 VI와 v제 즉 k 차원의 팩토라이제이션 파라미터로 표현하여서 좀 더 일반화시켰습니다.","confidence":0.5904,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1095450,1095700,"FM"],[1095710,1095947,"같은"],[1095947,1096340,"경우에는"],[1096490,1096940,"XI와"],[1097030,1097500,"xj의"],[1097510,1098080,"상호작용을"],[1098350,1098700,"각각"],[1098870,1099480,"VI와"],[1099490,1099860,"v제"],[1100350,1100500,"즉"],[1101090,1101240,"k"],[1101350,1101680,"차원의"],[1101810,1102400,"팩토라이제이션"],[1102410,1102920,"파라미터로"],[1103030,1103560,"표현하여서"],[1103710,1103860,"좀"],[1103890,1104040,"더"],[1104810,1105800,"일반화시켰습니다."]],"textEdited":"FM 같은 경우에는 XI와 xj의 상호작용을 각각 VI와 v제 즉 k 차원의 팩토라이제이션 파라미터로 표현하여서 좀 더 일반화시켰습니다."},{"start":1106400,"end":1121200,"text":"자 그렇다면 이 FM 모델을 가지고 스파스한 데이터를 직접 예측해 보겠습니다. 우리가 제일 많이 다루었던 제일 익숙한 데이터는 바로 컬래버레이트 필터링에서 다루었던 유저와 영화 아이템에 대한 평점 데이터입니다.","confidence":0.8969,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1106730,1106880,"자"],[1106990,1107380,"그렇다면"],[1107380,1107520,"이"],[1107690,1107960,"FM"],[1107970,1108320,"모델을"],[1108320,1108640,"가지고"],[1108790,1109360,"스파스한"],[1109370,1109780,"데이터를"],[1109870,1110100,"직접"],[1110110,1110427,"예측해"],[1110427,1110940,"보겠습니다."],[1111410,1111680,"우리가"],[1111810,1112220,"제일"],[1112290,1112500,"많이"],[1112550,1113160,"다루었던"],[1114230,1114440,"제일"],[1114550,1114860,"익숙한"],[1114870,1115260,"데이터는"],[1115270,1115480,"바로"],[1115550,1116040,"컬래버레이트"],[1116050,1116600,"필터링에서"],[1116600,1117040,"다루었던"],[1117890,1118700,"유저와"],[1119030,1119280,"영화"],[1119330,1119767,"아이템에"],[1119767,1119980,"대한"],[1120190,1120500,"평점"],[1120500,1121020,"데이터입니다."]],"textEdited":"자 그렇다면 이 FM 모델을 가지고 스파스한 데이터를 직접 예측해 보겠습니다. 우리가 제일 많이 다루었던 제일 익숙한 데이터는 바로 컬래버레이트 필터링에서 다루었던 유저와 영화 아이템에 대한 평점 데이터입니다."},{"start":1121200,"end":1130100,"text":"이 유저 아이템 매트릭스에서 다루던 평점 데이터는 대표적인 하이 스프레시티 스프레시티가 굉장히 높은 데이터라는 것입니다. 그 데이터를 한번 보시면","confidence":0.9451,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1121510,1121660,"이"],[1121690,1121960,"유저"],[1121960,1122220,"아이템"],[1122220,1122740,"매트릭스에서"],[1122750,1123040,"다루던"],[1123590,1123847,"평점"],[1123847,1124260,"데이터는"],[1124410,1124880,"대표적인"],[1125130,1125400,"하이"],[1125400,1125980,"스프레시티"],[1126150,1126660,"스프레시티가"],[1126660,1126900,"굉장히"],[1126930,1127220,"높은"],[1127310,1127927,"데이터라는"],[1127927,1128360,"것입니다."],[1128750,1128867,"그"],[1128867,1129207,"데이터를"],[1129207,1129400,"한번"],[1129410,1129760,"보시면"]],"textEdited":"이 유저 아이템 매트릭스에서 다루던 평점 데이터는 대표적인 하이 스프레시티 스프레시티가 굉장히 높은 데이터라는 것입니다. 그 데이터를 한번 보시면"},{"start":1130100,"end":1143600,"text":"이 아래 데이터가 여러분들이 잘 아시는 유저와 아이템 아이디에 대해서 평점이 주어져 있는 데이터입니다. 일반적인 CF 문제 입력 데이터와 같죠 이제 우리는 이 데이터를 일반적인 제너럴 프리딕터","confidence":0.9868,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1130310,1130460,"이"],[1130460,1130680,"아래"],[1130690,1131100,"데이터가"],[1131230,1131640,"여러분들이"],[1131640,1131780,"잘"],[1131870,1132200,"아시는"],[1132310,1132800,"유저와"],[1132990,1133360,"아이템"],[1133410,1133900,"아이디에"],[1133900,1134220,"대해서"],[1134770,1135140,"평점이"],[1135140,1135387,"주어져"],[1135387,1135560,"있는"],[1135560,1136080,"데이터입니다."],[1136730,1137180,"일반적인"],[1137270,1137600,"CF"],[1137610,1137840,"문제"],[1137910,1138120,"입력"],[1138120,1138480,"데이터와"],[1138490,1138760,"같죠"],[1139970,1140160,"이제"],[1140170,1140420,"우리는"],[1140590,1140740,"이"],[1140740,1141180,"데이터를"],[1141930,1142440,"일반적인"],[1142590,1142960,"제너럴"],[1142970,1143420,"프리딕터"]],"textEdited":"이 아래 데이터가 여러분들이 잘 아시는 유저와 아이템 아이디에 대해서 평점이 주어져 있는 데이터입니다. 일반적인 CF 문제 입력 데이터와 같죠 이제 우리는 이 데이터를 일반적인 제너럴 프리딕터"},{"start":1143600,"end":1158100,"text":"가 소화할 수 있는 스와로 바꿔서 이 아래와 같이 표현해 보도록 하겠습니다. 일반적인 입력 데이터로 바꾸면 여기 있는 유저 원의 영화 2가 5점 평점을 갖는다는 것을 이렇게 표현할 수 있습니다.","confidence":0.899,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1143930,1144080,"가"],[1144430,1144840,"소화할"],[1144840,1144934,"수"],[1144934,1145080,"있는"],[1145330,1145840,"스와로"],[1145970,1146380,"바꿔서"],[1147110,1147260,"이"],[1147350,1147680,"아래와"],[1147690,1147920,"같이"],[1147970,1148227,"표현해"],[1148227,1148520,"보도록"],[1148520,1149000,"하겠습니다."],[1149570,1150020,"일반적인"],[1150070,1150280,"입력"],[1150280,1150640,"데이터로"],[1150690,1151060,"바꾸면"],[1151950,1152180,"여기"],[1152190,1152360,"있는"],[1152450,1152740,"유저"],[1152770,1153140,"원의"],[1153210,1153500,"영화"],[1153650,1153920,"2가"],[1154730,1155060,"5점"],[1155170,1155520,"평점을"],[1155520,1155867,"갖는다는"],[1155867,1156160,"것을"],[1156770,1157120,"이렇게"],[1157150,1157460,"표현할"],[1157460,1157554,"수"],[1157554,1158000,"있습니다."]],"textEdited":"가 소화할 수 있는 스와로 바꿔서 이 아래와 같이 표현해 보도록 하겠습니다. 일반적인 입력 데이터로 바꾸면 여기 있는 유저 원의 영화 2가 5점 평점을 갖는다는 것을 이렇게 표현할 수 있습니다."},{"start":1158100,"end":1172300,"text":"그래서 이 처음에 있는 앞에 유의 차원이 유저 전체가 되고요. 뒤에 있는 이 m이 영화 전체의 차원이 됩니다. 그래서 유저 1이 영화 2를 봤을 때 5점을 매겼다는 것은 유저 1에 해당하는","confidence":0.9645,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1158330,1158507,"그래서"],[1158507,1158640,"이"],[1158670,1159000,"처음에"],[1159000,1159160,"있는"],[1159270,1159540,"앞에"],[1160250,1160600,"유의"],[1160650,1161020,"차원이"],[1161110,1161380,"유저"],[1161410,1161820,"전체가"],[1161820,1162180,"되고요."],[1162570,1162840,"뒤에"],[1162840,1163000,"있는"],[1163070,1163187,"이"],[1163187,1163500,"m이"],[1163970,1164220,"영화"],[1164290,1164700,"전체의"],[1164700,1164954,"차원이"],[1164954,1165260,"됩니다."],[1166070,1166300,"그래서"],[1166310,1166600,"유저"],[1166650,1167740,"1이"],[1167810,1168040,"영화"],[1168070,1168340,"2를"],[1168370,1168660,"봤을"],[1168660,1168800,"때"],[1168870,1169187,"5점을"],[1169187,1169587,"매겼다는"],[1169587,1169840,"것은"],[1170390,1170640,"유저"],[1170640,1170840,"1에"],[1170840,1171220,"해당하는"]],"textEdited":"그래서 이 처음에 있는 앞에 유의 차원이 유저 전체가 되고요. 뒤에 있는 이 m이 영화 전체의 차원이 됩니다. 그래서 유저 1이 영화 2를 봤을 때 5점을 매겼다는 것은 유저 1에 해당하는"},{"start":1172300,"end":1186000,"text":"원 핫 인코딩이 1 유저 2에 해당하는 원화 인코딩이 1이고 최종 예측값은 5다. 마찬가지로 유저 3은 세 번째 차원이 1이고 영화 1은 첫 번째 차원이 1인","confidence":0.9191,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1173710,1173827,"원"],[1173827,1173960,"핫"],[1173960,1174380,"인코딩이"],[1174390,1174540,"1"],[1175090,1175360,"유저"],[1175360,1175554,"2에"],[1175554,1175880,"해당하는"],[1175880,1176060,"원화"],[1176060,1176500,"인코딩이"],[1176570,1177080,"1이고"],[1177590,1177840,"최종"],[1177850,1178360,"예측값은"],[1178410,1179040,"5다."],[1180030,1180520,"마찬가지로"],[1180570,1180800,"유저"],[1180800,1181080,"3은"],[1181310,1181460,"세"],[1181470,1181820,"번째"],[1182770,1183100,"차원이"],[1183100,1183460,"1이고"],[1184030,1184300,"영화"],[1184330,1184600,"1은"],[1184810,1184960,"첫"],[1184960,1185180,"번째"],[1185180,1185480,"차원이"],[1185480,1185720,"1인"]],"textEdited":"원 핫 인코딩이 1 유저 2에 해당하는 원화 인코딩이 1이고 최종 예측값은 5다. 마찬가지로 유저 3은 세 번째 차원이 1이고 영화 1은 첫 번째 차원이 1인"},{"start":1186000,"end":1198700,"text":"이것이 x가 되겠고요. 얘가 y가 되겠죠. 그래서 입력 값의 차원이 전체 유저와 아이템 수만큼 증가한다는 것입니다. 그런데 이 데이터셋을 보시면 아주 적은","confidence":0.8967,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1186390,1186720,"이것이"],[1186810,1186987,"x가"],[1186987,1187420,"되겠고요."],[1187450,1187680,"얘가"],[1187710,1187987,"y가"],[1187987,1188340,"되겠죠."],[1189370,1189580,"그래서"],[1189590,1189860,"입력"],[1189860,1190080,"값의"],[1190090,1190460,"차원이"],[1191010,1191420,"전체"],[1191510,1191860,"유저와"],[1191910,1192260,"아이템"],[1192290,1192780,"수만큼"],[1194550,1195087,"증가한다는"],[1195087,1195500,"것입니다."],[1195990,1196134,"그런데"],[1196134,1196214,"이"],[1196214,1196720,"데이터셋을"],[1196720,1197020,"보시면"],[1197350,1197600,"아주"],[1197770,1198080,"적은"]],"textEdited":"이것이 x가 되겠고요. 얘가 y가 되겠죠. 그래서 입력 값의 차원이 전체 유저와 아이템 수만큼 증가한다는 것입니다. 그런데 이 데이터셋을 보시면 아주 적은"},{"start":1198700,"end":1212600,"text":"변수만 1이고 나머지 모두 다 0이죠. 이제 이러한 데이터가 바로 하이 스프레시티 데이터라는 것입니다. 네 그렇다면 프엠에서 가장 중요한 것은 이 스파스한 피처들의 인터랙션이 어떻게 학습되느냐입니다.","confidence":0.8884,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1199050,1199460,"변수만"],[1199570,1199920,"1이고"],[1199970,1200360,"나머지"],[1200410,1200607,"모두"],[1200607,1200740,"다"],[1200750,1201740,"0이죠."],[1202230,1202400,"이제"],[1202450,1202740,"이러한"],[1202790,1203160,"데이터가"],[1203160,1203400,"바로"],[1203650,1203900,"하이"],[1203900,1204380,"스프레시티"],[1204380,1205000,"데이터라는"],[1205000,1205400,"것입니다."],[1205830,1205980,"네"],[1205980,1206360,"그렇다면"],[1206630,1207080,"프엠에서"],[1207150,1207380,"가장"],[1207530,1207860,"중요한"],[1207860,1208120,"것은"],[1208350,1208500,"이"],[1208530,1209220,"스파스한"],[1209350,1209840,"피처들의"],[1209890,1210520,"인터랙션이"],[1211050,1211440,"어떻게"],[1211530,1212380,"학습되느냐입니다."]],"textEdited":"변수만 1이고 나머지 모두 다 0이죠. 이제 이러한 데이터가 바로 하이 스프레시티 데이터라는 것입니다. 네 그렇다면 프엠에서 가장 중요한 것은 이 스파스한 피처들의 인터랙션이 어떻게 학습되느냐입니다."},{"start":1212600,"end":1224100,"text":"다음 예시를 통해 살펴보겠습니다. 먼저 유저 a를 기준으로 유저 a가 이미 봤던 영화들은 여기 데이터 3개에 표현되어 있습니다.","confidence":0.8806,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1213650,1213880,"다음"],[1213950,1214300,"예시를"],[1214300,1214500,"통해"],[1214530,1215240,"살펴보겠습니다."],[1216570,1216760,"먼저"],[1216760,1217020,"유저"],[1217090,1217460,"a를"],[1217470,1217900,"기준으로"],[1218410,1218680,"유저"],[1218710,1219020,"a가"],[1219310,1219520,"이미"],[1219670,1219980,"봤던"],[1220050,1220480,"영화들은"],[1220510,1220720,"여기"],[1220770,1221120,"데이터"],[1221170,1221560,"3개에"],[1222190,1222600,"표현되어"],[1222600,1223280,"있습니다."]],"textEdited":"다음 예시를 통해 살펴보겠습니다. 먼저 유저 a를 기준으로 유저 a가 이미 봤던 영화들은 여기 데이터 3개에 표현되어 있습니다."},{"start":1224100,"end":1234900,"text":"이 유저 a에 해당하는 영화 하나 둘 세 개 즉 이 유저 a는 ti와 NHSW 총 3개의 영화에 대해 평가를 5점 3점 1점으로","confidence":0.9192,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1224330,1224480,"이"],[1224480,1224760,"유저"],[1224990,1225287,"a에"],[1225287,1225720,"해당하는"],[1226030,1226300,"영화"],[1226970,1227200,"하나"],[1227370,1227520,"둘"],[1227750,1227854,"세"],[1227854,1227980,"개"],[1228430,1228580,"즉"],[1228670,1228787,"이"],[1228787,1229020,"유저"],[1229020,1229280,"a는"],[1229410,1229920,"ti와"],[1230130,1230980,"NHSW"],[1231130,1231280,"총"],[1231350,1231720,"3개의"],[1231720,1232060,"영화에"],[1232060,1232240,"대해"],[1232350,1232740,"평가를"],[1233250,1233560,"5점"],[1233850,1234160,"3점"],[1234190,1234680,"1점으로"]],"textEdited":"이 유저 a에 해당하는 영화 하나 둘 세 개 즉 이 유저 a는 ti와 NHSW 총 3개의 영화에 대해 평가를 5점 3점 1점으로"},{"start":1234900,"end":1249600,"text":"진행했지만 ST에 대한 영화 ST 영화에 대한 평가는 내리지 않았습니다. 그래서 우리는 이 모델을 통해서 유저 a의 ST에 대한 평점을 예측하고 싶은데요. 어떻게 예측값을 구할 수 있는지 보겠습니다.","confidence":0.8123,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1235190,1235740,"진행했지만"],[1236850,1237580,"ST에"],[1237580,1237760,"대한"],[1237830,1238080,"영화"],[1238490,1238780,"ST"],[1238830,1239107,"영화에"],[1239107,1239280,"대한"],[1239410,1239707,"평가는"],[1239707,1239907,"내리지"],[1239907,1240380,"않았습니다."],[1241090,1241320,"그래서"],[1241320,1241527,"우리는"],[1241527,1241660,"이"],[1241670,1242020,"모델을"],[1242020,1242360,"통해서"],[1243110,1243380,"유저"],[1243430,1243700,"a의"],[1243810,1244160,"ST에"],[1244160,1244340,"대한"],[1244450,1244800,"평점을"],[1244810,1245200,"예측하고"],[1245200,1245600,"싶은데요."],[1246370,1246740,"어떻게"],[1246790,1247700,"예측값을"],[1247710,1247960,"구할"],[1247960,1248067,"수"],[1248067,1248400,"있는지"],[1248670,1249220,"보겠습니다."]],"textEdited":"진행했지만 ST에 대한 영화 ST 영화에 대한 평가는 내리지 않았습니다. 그래서 우리는 이 모델을 통해서 유저 a의 ST에 대한 평점을 예측하고 싶은데요. 어떻게 예측값을 구할 수 있는지 보겠습니다."},{"start":1249600,"end":1261300,"text":"자 이 둘의 상호 작용을 구하기 위해서는 여기 있는 데이터를 가지고 a라는 유저와 에스티라는 영화에 대한 학습 파라미터가 학습될 텐데요.","confidence":0.8097,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1250770,1250920,"자"],[1250970,1251120,"이"],[1251230,1251640,"둘의"],[1251930,1252160,"상호"],[1252190,1252580,"작용을"],[1252650,1252960,"구하기"],[1252960,1253340,"위해서는"],[1254030,1254260,"여기"],[1254270,1254440,"있는"],[1254470,1254920,"데이터를"],[1254920,1255300,"가지고"],[1256490,1256960,"a라는"],[1256990,1257360,"유저와"],[1257550,1258060,"에스티라는"],[1258090,1258407,"영화에"],[1258407,1258620,"대한"],[1259330,1259560,"학습"],[1259560,1260080,"파라미터가"],[1260330,1260680,"학습될"],[1260690,1261000,"텐데요."]],"textEdited":"자 이 둘의 상호 작용을 구하기 위해서는 여기 있는 데이터를 가지고 a라는 유저와 에스티라는 영화에 대한 학습 파라미터가 학습될 텐데요."},{"start":1261300,"end":1275700,"text":"그 파라미터 가운데 제일 중요한 것이 바로 이 팩토라이제이션 파라미터입니다. 그래서 이 a에 대한 팩토라이제이션 파라미터와 ST에 대한 팩토라이제이션 파라미터가 어떻게 학습되는지를 살펴보면 이 둘이 상호 작용을 했을 때","confidence":0.9468,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1261530,1261680,"그"],[1261680,1262080,"파라미터"],[1262080,1262420,"가운데"],[1262470,1262660,"제일"],[1262710,1263020,"중요한"],[1263020,1263194,"것이"],[1263194,1263367,"바로"],[1263367,1263500,"이"],[1263590,1264220,"팩토라이제이션"],[1264230,1265060,"파라미터입니다."],[1265870,1266060,"그래서"],[1266060,1266180,"이"],[1266210,1266507,"a에"],[1266507,1266700,"대한"],[1266770,1267340,"팩토라이제이션"],[1267350,1267900,"파라미터와"],[1268390,1268920,"ST에"],[1268920,1269600,"대한"],[1269790,1270400,"팩토라이제이션"],[1270400,1270900,"파라미터가"],[1271370,1271700,"어떻게"],[1271710,1272960,"학습되는지를"],[1273050,1273480,"살펴보면"],[1274130,1274280,"이"],[1274280,1274500,"둘이"],[1274500,1274700,"상호"],[1274700,1275000,"작용을"],[1275000,1275240,"했을"],[1275250,1275400,"때"]],"textEdited":"그 파라미터 가운데 제일 중요한 것이 바로 이 팩토라이제이션 파라미터입니다. 그래서 이 a에 대한 팩토라이제이션 파라미터와 ST에 대한 팩토라이제이션 파라미터가 어떻게 학습되는지를 살펴보면 이 둘이 상호 작용을 했을 때"},{"start":1275700,"end":1287800,"text":"예측 값이 정확하게 나올 것이다라는 것을 확인할 수 있겠죠. 먼저 이 VST 영화 ST에 대한 팩토라이제이션 학습 파라미터 같은 경우에는","confidence":0.9563,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1275950,1276220,"예측"],[1276230,1276600,"값이"],[1276850,1277207,"정확하게"],[1277207,1277380,"나올"],[1277410,1278020,"것이다라는"],[1278020,1278300,"것을"],[1278550,1278900,"확인할"],[1278900,1279007,"수"],[1279007,1279320,"있겠죠."],[1281290,1281520,"먼저"],[1281520,1281660,"이"],[1281660,1282340,"VST"],[1282510,1282740,"영화"],[1282890,1283387,"ST에"],[1283387,1283600,"대한"],[1284190,1284840,"팩토라이제이션"],[1284910,1285120,"학습"],[1285120,1285480,"파라미터"],[1285510,1285727,"같은"],[1285727,1286160,"경우에는"]],"textEdited":"예측 값이 정확하게 나올 것이다라는 것을 확인할 수 있겠죠. 먼저 이 VST 영화 ST에 대한 팩토라이제이션 학습 파라미터 같은 경우에는"},{"start":1287800,"end":1299800,"text":"이 ST라는 영화가 유저 b와 유저 c가 이미 평가를 했음을 알 수 있습니다. 그리고 또 유저 b와 c는 동시에","confidence":0.964,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1288570,1288720,"이"],[1288830,1289300,"ST라는"],[1289310,1289680,"영화가"],[1291330,1291640,"유저"],[1291850,1292200,"b와"],[1292270,1292520,"유저"],[1292590,1294420,"c가"],[1294710,1294900,"이미"],[1295010,1295307,"평가를"],[1295307,1295640,"했음을"],[1295640,1295780,"알"],[1295780,1295874,"수"],[1295874,1296280,"있습니다."],[1297550,1297740,"그리고"],[1297740,1297860,"또"],[1297860,1298100,"유저"],[1298100,1298380,"b와"],[1298410,1298700,"c는"],[1298910,1299360,"동시에"]],"textEdited":"이 ST라는 영화가 유저 b와 유저 c가 이미 평가를 했음을 알 수 있습니다. 그리고 또 유저 b와 c는 동시에"},{"start":1299800,"end":1304100,"text":"스블라는 영화를 같이 평가했습니다.","confidence":0.747,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1300450,1301400,"스블라는"],[1301450,1301840,"영화를"],[1302650,1303000,"같이"],[1303350,1304040,"평가했습니다."]],"textEdited":"스블라는 영화를 같이 평가했습니다."},{"start":1304100,"end":1316100,"text":"그래서 유저 b씨가 동시에 스티와 스블 영화를 보았기 때문에 이 스티라는 영화가 sw에 비해서 상대적으로 어떤 특징을 가졌는지가 학습될 것이고요.","confidence":0.6665,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1305130,1305360,"그래서"],[1305360,1305620,"유저"],[1305690,1306240,"b씨가"],[1306490,1306900,"동시에"],[1307170,1307660,"스티와"],[1308110,1308580,"스블"],[1308650,1309040,"영화를"],[1309530,1309887,"보았기"],[1309887,1310240,"때문에"],[1310930,1311080,"이"],[1311230,1311700,"스티라는"],[1311710,1312040,"영화가"],[1312310,1313047,"sw에"],[1313047,1313340,"비해서"],[1313410,1313780,"상대적으로"],[1313790,1314020,"어떤"],[1314150,1314460,"특징을"],[1314470,1315180,"가졌는지가"],[1315210,1315540,"학습될"],[1315550,1315980,"것이고요."]],"textEdited":"그래서 유저 b씨가 동시에 스티와 스블 영화를 보았기 때문에 이 스티라는 영화가 sw에 비해서 상대적으로 어떤 특징을 가졌는지가 학습될 것이고요."},{"start":1316100,"end":1329500,"text":"그 학습을 통해서 이 VST가 적절하게 학습이 되겠죠. 반대로 이 vaa에 대한 팩토라이제션 파라미터의 경우에도","confidence":0.7768,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1316390,1316540,"그"],[1316590,1316900,"학습을"],[1316900,1317200,"통해서"],[1317710,1317860,"이"],[1317870,1318620,"VST가"],[1319110,1319700,"적절하게"],[1320310,1320587,"학습이"],[1320587,1320920,"되겠죠."],[1323290,1323600,"반대로"],[1323670,1323820,"이"],[1323820,1324840,"vaa에"],[1324840,1325060,"대한"],[1327030,1327580,"팩토라이제션"],[1327580,1328100,"파라미터의"],[1328170,1328600,"경우에도"]],"textEdited":"그 학습을 통해서 이 VST가 적절하게 학습이 되겠죠. 반대로 이 vaa에 대한 팩토라이제션 파라미터의 경우에도"},{"start":1329500,"end":1343200,"text":"보시면은 유저 a가 평가했으면서 동시에 유저 BC도 같이 평가한 영화가 존재합니다. 바로 이 sw라는 영화인데요. 이 sw라는 영화는 유저 a b c가 동시에 같이 평가했죠.","confidence":0.9361,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1330050,1330520,"보시면은"],[1331630,1331940,"유저"],[1332050,1332400,"a가"],[1332510,1333340,"평가했으면서"],[1334310,1334680,"동시에"],[1334710,1334960,"유저"],[1335030,1335520,"BC도"],[1335570,1335860,"같이"],[1335970,1336320,"평가한"],[1336330,1336620,"영화가"],[1336620,1337100,"존재합니다."],[1337130,1337307,"바로"],[1337307,1337440,"이"],[1337590,1338280,"sw라는"],[1338280,1338680,"영화인데요."],[1338790,1338940,"이"],[1338970,1339520,"sw라는"],[1339520,1339820,"영화는"],[1340350,1340600,"유저"],[1340670,1340820,"a"],[1340930,1341080,"b"],[1341110,1341380,"c가"],[1341490,1341920,"동시에"],[1342270,1342560,"같이"],[1342630,1343140,"평가했죠."]],"textEdited":"보시면은 유저 a가 평가했으면서 동시에 유저 BC도 같이 평가한 영화가 존재합니다. 바로 이 sw라는 영화인데요. 이 sw라는 영화는 유저 a b c가 동시에 같이 평가했죠."},{"start":1343200,"end":1355900,"text":"그래서 이 데이터를 학습하게 되면은 유저 b c와는 또 다른 유저 a의 특징이 이 VA라는 팩토라이제이션 파라미터에 학습이 될 것입니다. 그래서","confidence":0.9289,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1343750,1343927,"그래서"],[1343927,1344060,"이"],[1344070,1344640,"데이터를"],[1344710,1345127,"학습하게"],[1345127,1345500,"되면은"],[1346230,1346540,"유저"],[1346670,1346820,"b"],[1347070,1347580,"c와는"],[1347690,1347840,"또"],[1347870,1348160,"다른"],[1348270,1348540,"유저"],[1348690,1349040,"a의"],[1349170,1349580,"특징이"],[1350270,1350420,"이"],[1350450,1351600,"VA라는"],[1352170,1352780,"팩토라이제이션"],[1352830,1353340,"파라미터에"],[1353370,1353614,"학습이"],[1353614,1353740,"될"],[1353750,1354160,"것입니다."],[1355110,1355340,"그래서"]],"textEdited":"그래서 이 데이터를 학습하게 되면은 유저 b c와는 또 다른 유저 a의 특징이 이 VA라는 팩토라이제이션 파라미터에 학습이 될 것입니다. 그래서"},{"start":1355900,"end":1369900,"text":"이 둘의 인터랙션 데이터는 없지만 여기에 있는 다른 데이터를 통해서 각각의 팩토라이제이션 파라미터가 학습이 잘될 것이고 그 파라미터를 통해서 최종적으로 유저 a의","confidence":0.9614,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1356130,1356280,"이"],[1356310,1356680,"둘의"],[1357410,1357880,"인터랙션"],[1357880,1358520,"데이터는"],[1358590,1359040,"없지만"],[1360350,1360647,"여기에"],[1360647,1360840,"있는"],[1361390,1361640,"다른"],[1361710,1362180,"데이터를"],[1362190,1362680,"통해서"],[1363410,1363880,"각각의"],[1363970,1364580,"팩토라이제이션"],[1364610,1365120,"파라미터가"],[1365150,1365440,"학습이"],[1365440,1365740,"잘될"],[1365790,1366140,"것이고"],[1366830,1366980,"그"],[1367110,1367620,"파라미터를"],[1367630,1367920,"통해서"],[1367970,1368520,"최종적으로"],[1368770,1369080,"유저"],[1369210,1369560,"a의"]],"textEdited":"이 둘의 인터랙션 데이터는 없지만 여기에 있는 다른 데이터를 통해서 각각의 팩토라이제이션 파라미터가 학습이 잘될 것이고 그 파라미터를 통해서 최종적으로 유저 a의"},{"start":1369900,"end":1381500,"text":"아직 보지 않은 영화 ST에 대한 평점 예측이 정확하게 구해집니다. 여기서는 유저와 아이템의 예시만을 들었지만 또 다른 장점은 이 뒤에 있는 부분인데요.","confidence":0.9405,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1370170,1370420,"아직"],[1370470,1370760,"보지"],[1370790,1370980,"않은"],[1371030,1371280,"영화"],[1371430,1371800,"ST에"],[1371800,1371980,"대한"],[1372150,1372540,"평점"],[1372730,1373120,"예측이"],[1373550,1374020,"정확하게"],[1374390,1374900,"구해집니다."],[1376550,1376920,"여기서는"],[1376930,1377280,"유저와"],[1377370,1377860,"아이템의"],[1377860,1378380,"예시만을"],[1378380,1378780,"들었지만"],[1379350,1379500,"또"],[1379500,1379680,"다른"],[1379750,1380100,"장점은"],[1380110,1380260,"이"],[1380290,1380560,"뒤에"],[1380560,1380720,"있는"],[1380720,1381220,"부분인데요."]],"textEdited":"아직 보지 않은 영화 ST에 대한 평점 예측이 정확하게 구해집니다. 여기서는 유저와 아이템의 예시만을 들었지만 또 다른 장점은 이 뒤에 있는 부분인데요."},{"start":1381500,"end":1391100,"text":"유저 아이템 아이디 외에 뒤에 있는 다양한 콘텍스트 정보를 계속 붙일 수 있다는 점입니다. 그리고 이 서로 서로의 인터랙션들","confidence":0.9582,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1382290,1382600,"유저"],[1382630,1383040,"아이템"],[1383430,1383740,"아이디"],[1383750,1384020,"외에"],[1384490,1384740,"뒤에"],[1384740,1384880,"있는"],[1384990,1385320,"다양한"],[1385590,1386080,"콘텍스트"],[1386110,1386520,"정보를"],[1386910,1387160,"계속"],[1387210,1387500,"붙일"],[1387510,1387614,"수"],[1387614,1387867,"있다는"],[1387867,1388260,"점입니다."],[1388690,1388960,"그리고"],[1389710,1389827,"이"],[1389827,1390047,"서로"],[1390047,1390340,"서로의"],[1390340,1390920,"인터랙션들"]],"textEdited":"유저 아이템 아이디 외에 뒤에 있는 다양한 콘텍스트 정보를 계속 붙일 수 있다는 점입니다. 그리고 이 서로 서로의 인터랙션들"},{"start":1391100,"end":1404600,"text":"이 둘의 인터랙션 말고도 이들의 인터랙션 그리고 이 안에서의 인터랙션들도 다 FM에서 모델링이 된다는 것이죠. 그래서 이렇게 스프레스 한 데이터셋에 대해서 FM은 효율적으로 피처 간의 인터랙션을 표현하고","confidence":0.9287,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1391490,1391640,"이"],[1391640,1391880,"둘의"],[1391880,1392280,"인터랙션"],[1392290,1392680,"말고도"],[1393050,1393360,"이들의"],[1393370,1393800,"인터랙션"],[1393990,1394220,"그리고"],[1394230,1394347,"이"],[1394347,1394667,"안에서의"],[1394667,1395340,"인터랙션들도"],[1395670,1395820,"다"],[1395990,1396440,"FM에서"],[1396470,1396847,"모델링이"],[1396847,1397167,"된다는"],[1397167,1397480,"것이죠."],[1398430,1398620,"그래서"],[1398620,1398820,"이렇게"],[1398850,1399274,"스프레스"],[1399274,1399400,"한"],[1399410,1400027,"데이터셋에"],[1400027,1400360,"대해서"],[1400670,1401020,"FM은"],[1401450,1402020,"효율적으로"],[1402330,1402587,"피처"],[1402587,1402820,"간의"],[1402820,1403420,"인터랙션을"],[1403930,1404420,"표현하고"]],"textEdited":"이 둘의 인터랙션 말고도 이들의 인터랙션 그리고 이 안에서의 인터랙션들도 다 FM에서 모델링이 된다는 것이죠. 그래서 이렇게 스프레스 한 데이터셋에 대해서 FM은 효율적으로 피처 간의 인터랙션을 표현하고"},{"start":1404600,"end":1414200,"text":"좋은 예측 성능을 보입니다. 마지막으로 2개 모델 SVM과 MF의 장점을 결합한 모델이 FM이라고 했는데요.","confidence":0.9729,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1404910,1405100,"좋은"],[1405590,1405880,"예측"],[1405970,1406320,"성능을"],[1406650,1407080,"보입니다."],[1408490,1409000,"마지막으로"],[1409010,1409260,"2개"],[1409270,1409500,"모델"],[1409630,1410720,"SVM과"],[1410770,1411240,"MF의"],[1411310,1412060,"장점을"],[1412090,1412440,"결합한"],[1412450,1412760,"모델이"],[1412890,1413307,"FM이라고"],[1413307,1413660,"했는데요."]],"textEdited":"좋은 예측 성능을 보입니다. 마지막으로 2개 모델 SVM과 MF의 장점을 결합한 모델이 FM이라고 했는데요."},{"start":1414200,"end":1428000,"text":"각각의 모델에 비해서 에프엠이 어떤 것이 좋은지 어떤 장점을 가지고 있는지 정리하면서 프엠 모델의 설명을 마치도록 합니다. 먼저 에브엠 같은 경우에는 어 스파스한 데이터에 대해서 예측 성능이 나쁘다고 했는데요.","confidence":0.8509,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1414510,1415060,"각각의"],[1415070,1415407,"모델에"],[1415407,1415800,"비해서"],[1416230,1416660,"에프엠이"],[1416670,1416920,"어떤"],[1416920,1417180,"것이"],[1417180,1417600,"좋은지"],[1417830,1418060,"어떤"],[1418170,1418520,"장점을"],[1418520,1418800,"가지고"],[1418800,1419140,"있는지"],[1419570,1420120,"정리하면서"],[1420490,1420720,"프엠"],[1420720,1421060,"모델의"],[1421270,1421580,"설명을"],[1421580,1421960,"마치도록"],[1421960,1422220,"합니다."],[1422810,1423000,"먼저"],[1423030,1423520,"에브엠"],[1423570,1423787,"같은"],[1423787,1424220,"경우에는"],[1424830,1424980,"어"],[1425050,1425600,"스파스한"],[1425630,1426007,"데이터에"],[1426007,1426260,"대해서"],[1426470,1426740,"예측"],[1426770,1427040,"성능이"],[1427050,1427467,"나쁘다고"],[1427467,1427820,"했는데요."]],"textEdited":"각각의 모델에 비해서 에프엠이 어떤 것이 좋은지 어떤 장점을 가지고 있는지 정리하면서 프엠 모델의 설명을 마치도록 합니다. 먼저 에브엠 같은 경우에는 어 스파스한 데이터에 대해서 예측 성능이 나쁘다고 했는데요."},{"start":1428000,"end":1437500,"text":"그에 비해서 에프엠은 굉장히 스파스한 피처를 가지고도 높은 예측 성능을 보이고 있습니다. 또한 자세히 설명하진 않았지만 sv엠에 비해서 FM은","confidence":0.778,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1428250,1428447,"그에"],[1428447,1428720,"비해서"],[1428730,1429140,"에프엠은"],[1429370,1429640,"굉장히"],[1429670,1430240,"스파스한"],[1430330,1430800,"피처를"],[1430890,1431320,"가지고도"],[1431330,1431560,"높은"],[1431630,1431860,"예측"],[1431910,1432220,"성능을"],[1432270,1432527,"보이고"],[1432527,1432880,"있습니다."],[1433450,1433680,"또한"],[1434290,1434600,"자세히"],[1434630,1435020,"설명하진"],[1435020,1435400,"않았지만"],[1435570,1436180,"sv엠에"],[1436180,1436520,"비해서"],[1436870,1437220,"FM은"]],"textEdited":"그에 비해서 에프엠은 굉장히 스파스한 피처를 가지고도 높은 예측 성능을 보이고 있습니다. 또한 자세히 설명하진 않았지만 sv엠에 비해서 FM은"},{"start":1437500,"end":1449000,"text":"학습할 때 선형 복잡도를 가지기 때문에 학습 데이터가 굉장히 많더라도 이 모델은 빠르게 학습이 됩니다. 반면에 에브엠 같은 경우에는 학습 데이터가 굉장히 많이 늘어날수록 학습 시간은","confidence":0.9367,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1437790,1438220,"학습할"],[1438220,1438360,"때"],[1438360,1438620,"선형"],[1438630,1439060,"복잡도를"],[1439060,1439307,"가지기"],[1439307,1439680,"때문에"],[1440170,1440400,"학습"],[1440400,1440720,"데이터가"],[1440790,1441160,"굉장히"],[1441170,1441680,"많더라도"],[1442330,1442480,"이"],[1442480,1442800,"모델은"],[1442810,1443100,"빠르게"],[1443110,1443347,"학습이"],[1443347,1443640,"됩니다."],[1444230,1444580,"반면에"],[1444610,1445080,"에브엠"],[1445090,1445307,"같은"],[1445307,1445660,"경우에는"],[1445710,1445907,"학습"],[1445907,1446280,"데이터가"],[1446330,1446620,"굉장히"],[1446690,1446900,"많이"],[1446910,1447440,"늘어날수록"],[1447890,1448140,"학습"],[1448140,1448520,"시간은"]],"textEdited":"학습할 때 선형 복잡도를 가지기 때문에 학습 데이터가 굉장히 많더라도 이 모델은 빠르게 학습이 됩니다. 반면에 에브엠 같은 경우에는 학습 데이터가 굉장히 많이 늘어날수록 학습 시간은"},{"start":1449000,"end":1459900,"text":"이 5m보다 더 많이 증가하기 때문에 학습 데이터가 아주 많은 데이터에 대해서는 에비엠 학습을 하기가 어렵습니다. 굉장히 오래 걸리기 때문이죠.","confidence":0.8346,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1449890,1450040,"이"],[1450070,1450660,"5m보다"],[1450670,1450820,"더"],[1451330,1451560,"많이"],[1451690,1452067,"증가하기"],[1452067,1452440,"때문에"],[1453690,1453920,"학습"],[1453920,1454260,"데이터가"],[1454290,1454480,"아주"],[1454490,1454740,"많은"],[1455070,1455467,"데이터에"],[1455467,1455860,"대해서는"],[1455930,1456360,"에비엠"],[1456450,1456780,"학습을"],[1456790,1457100,"하기가"],[1457750,1458280,"어렵습니다."],[1458650,1458920,"굉장히"],[1458920,1459100,"오래"],[1459100,1459307,"걸리기"],[1459307,1459720,"때문이죠."]],"textEdited":"이 5m보다 더 많이 증가하기 때문에 학습 데이터가 아주 많은 데이터에 대해서는 에비엠 학습을 하기가 어렵습니다. 굉장히 오래 걸리기 때문이죠."},{"start":1459900,"end":1471900,"text":"그다음에 매트리스 팩터라이제이션과도 비교해 보면 이제 매트리스 팩터라이제이션은 오로지 콜라버레이트 필터링 환경으로 구성된 데이터만 소화할 수 있었는데요. 이 FM 같은 경우에는","confidence":0.9446,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1460650,1461040,"그다음에"],[1461130,1461540,"매트리스"],[1461550,1462440,"팩터라이제이션과도"],[1462440,1462707,"비교해"],[1462707,1462940,"보면"],[1463570,1463740,"이제"],[1463740,1464080,"매트리스"],[1464080,1464700,"팩터라이제이션은"],[1465110,1465440,"오로지"],[1465530,1466080,"콜라버레이트"],[1466110,1466500,"필터링"],[1466570,1467000,"환경으로"],[1467010,1467320,"구성된"],[1467370,1468160,"데이터만"],[1468970,1469307,"소화할"],[1469307,1469394,"수"],[1469394,1469880,"있었는데요."],[1470290,1470440,"이"],[1470510,1470760,"FM"],[1470770,1471027,"같은"],[1471027,1471440,"경우에는"]],"textEdited":"그다음에 매트리스 팩터라이제이션과도 비교해 보면 이제 매트리스 팩터라이제이션은 오로지 콜라버레이트 필터링 환경으로 구성된 데이터만 소화할 수 있었는데요. 이 FM 같은 경우에는"},{"start":1471900,"end":1481800,"text":"콜라버트 필터링 형태의 모양이 아닌 다양한 예측 문제에도 활용 가능한 일반적인 제너럴 프리딕터임을 아까 설명드렸습니다. 그래서","confidence":0.9616,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1472170,1472640,"콜라버트"],[1472640,1472960,"필터링"],[1473110,1473440,"형태의"],[1473440,1473800,"모양이"],[1473800,1474020,"아닌"],[1474330,1474680,"다양한"],[1474750,1475040,"예측"],[1475090,1476260,"문제에도"],[1476490,1476760,"활용"],[1476760,1477080,"가능한"],[1477730,1478280,"일반적인"],[1478650,1479000,"제너럴"],[1479000,1479840,"프리딕터임을"],[1479930,1480120,"아까"],[1480190,1480880,"설명드렸습니다."],[1481170,1481440,"그래서"]],"textEdited":"콜라버트 필터링 형태의 모양이 아닌 다양한 예측 문제에도 활용 가능한 일반적인 제너럴 프리딕터임을 아까 설명드렸습니다. 그래서"},{"start":1481800,"end":1496700,"text":"엠프와 비교했을 때 유저 아이디와 아이템 아이디만 피처로 사용하는 것이 아니라 그 외에 다른 부가 정보들 즉 컨텍스트 정보들을 입력 값으로 사용하고 더 정확한 예측을 할 수 있습니다. 네 그래서 여기까지가 에프엠 모델에 대한 내용이었고요.","confidence":0.8959,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1482010,1482460,"엠프와"],[1482460,1482880,"비교했을"],[1482890,1483040,"때"],[1483290,1483600,"유저"],[1483630,1484040,"아이디와"],[1484070,1484360,"아이템"],[1484390,1484840,"아이디만"],[1485170,1485447,"피처로"],[1485447,1485767,"사용하는"],[1485767,1485967,"것이"],[1485967,1486240,"아니라"],[1486750,1486900,"그"],[1486900,1487100,"외에"],[1487110,1487320,"다른"],[1487430,1487660,"부가"],[1487670,1488000,"정보들"],[1488150,1488300,"즉"],[1488390,1488860,"컨텍스트"],[1488870,1489360,"정보들을"],[1489870,1490140,"입력"],[1490150,1490440,"값으로"],[1490440,1490880,"사용하고"],[1491130,1491280,"더"],[1491390,1491740,"정확한"],[1491770,1492140,"예측을"],[1492150,1492300,"할"],[1492330,1492480,"수"],[1492610,1493040,"있습니다."],[1493530,1493680,"네"],[1493680,1493847,"그래서"],[1493847,1494360,"여기까지가"],[1494770,1495120,"에프엠"],[1495150,1495407,"모델에"],[1495407,1495600,"대한"],[1495690,1496320,"내용이었고요."]],"textEdited":"엠프와 비교했을 때 유저 아이디와 아이템 아이디만 피처로 사용하는 것이 아니라 그 외에 다른 부가 정보들 즉 컨텍스트 정보들을 입력 값으로 사용하고 더 정확한 예측을 할 수 있습니다. 네 그래서 여기까지가 에프엠 모델에 대한 내용이었고요."},{"start":1496700,"end":1508400,"text":"다음은 프프엠 필드 어웨어 팩토라이제이션 머신입니다. 이 모델의 원리를 이해하고 방금 전에 배웠던 프엠 모델과의 차이점을 살펴보도록 하겠습니다.","confidence":0.7963,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1497430,1497760,"다음은"],[1498090,1498500,"프프엠"],[1499150,1499500,"필드"],[1499550,1499880,"어웨어"],[1500010,1500680,"팩토라이제이션"],[1500730,1501420,"머신입니다."],[1502230,1502380,"이"],[1502380,1502680,"모델의"],[1502690,1503000,"원리를"],[1503000,1503420,"이해하고"],[1504010,1504300,"방금"],[1504300,1504540,"전에"],[1504540,1504920,"배웠던"],[1505330,1505600,"프엠"],[1505650,1506180,"모델과의"],[1506310,1506820,"차이점을"],[1507070,1507600,"살펴보도록"],[1507610,1508140,"하겠습니다."]],"textEdited":"다음은 프프엠 필드 어웨어 팩토라이제이션 머신입니다. 이 모델의 원리를 이해하고 방금 전에 배웠던 프엠 모델과의 차이점을 살펴보도록 하겠습니다."},{"start":1508400,"end":1517100,"text":"네 본 논문은 FM을 변형시킨 모델인 FFM을 제안하였고 이 FFM 모델은 CTR 예측 데이터셋 즉","confidence":0.9726,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1508670,1508820,"네"],[1508870,1509020,"본"],[1509110,1509520,"논문은"],[1510290,1510680,"FM을"],[1510680,1511140,"변형시킨"],[1511190,1511880,"모델인"],[1512090,1512980,"FFM을"],[1513010,1513620,"제안하였고"],[1513990,1514140,"이"],[1514190,1514580,"FFM"],[1514580,1514880,"모델은"],[1515470,1515820,"CTR"],[1515820,1516040,"예측"],[1516040,1516480,"데이터셋"],[1516650,1516800,"즉"]],"textEdited":"네 본 논문은 FM을 변형시킨 모델인 FFM을 제안하였고 이 FFM 모델은 CTR 예측 데이터셋 즉"},{"start":1517100,"end":1528600,"text":"컨텍스트어 레코멘데이션에서 가장 활발하게 풀리고 있는 그 문제에 대해서 높은 성능을 보였다고 이야기하고 있습니다. 먼저 앞서 설명했듯이 FM은 예측 문제","confidence":0.9011,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1517790,1518340,"컨텍스트어"],[1518370,1519100,"레코멘데이션에서"],[1519110,1519340,"가장"],[1519530,1519920,"활발하게"],[1519950,1520187,"풀리고"],[1520187,1520360,"있는"],[1520690,1520840,"그"],[1520890,1521300,"문제에"],[1521300,1521640,"대해서"],[1522190,1522440,"높은"],[1522570,1522880,"성능을"],[1522880,1523380,"보였다고"],[1523550,1524007,"이야기하고"],[1524007,1524400,"있습니다."],[1524810,1525040,"먼저"],[1525040,1525280,"앞서"],[1525310,1525920,"설명했듯이"],[1526630,1527460,"FM은"],[1527590,1527900,"예측"],[1527950,1528260,"문제"]],"textEdited":"컨텍스트어 레코멘데이션에서 가장 활발하게 풀리고 있는 그 문제에 대해서 높은 성능을 보였다고 이야기하고 있습니다. 먼저 앞서 설명했듯이 FM은 예측 문제"},{"start":1528600,"end":1542800,"text":"두루두루 적용 가능한 제너럴한 프리딕터 모델이라고 말씀드렸고요. 특히 스파스한 데이터에 아주 강력하다고 했는데요. 우리가 처음에 CTR 예측 모델 문제를 이야기할 때 CTR 예측 문제의 피처들은 대부분 스파스하다고 했죠.","confidence":0.9405,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1529090,1529520,"두루두루"],[1529530,1529800,"적용"],[1529830,1530140,"가능한"],[1530290,1530680,"제너럴한"],[1530690,1531080,"프리딕터"],[1531080,1531560,"모델이라고"],[1531560,1532180,"말씀드렸고요."],[1532610,1532920,"특히"],[1533530,1534200,"스파스한"],[1534250,1534760,"데이터에"],[1534830,1535020,"아주"],[1535070,1535554,"강력하다고"],[1535554,1535920,"했는데요."],[1536610,1536860,"우리가"],[1537030,1537320,"처음에"],[1537350,1537680,"CTR"],[1537680,1537900,"예측"],[1537910,1538140,"모델"],[1538210,1538540,"문제를"],[1538630,1539040,"이야기할"],[1539050,1539200,"때"],[1539330,1539660,"CTR"],[1539660,1539880,"예측"],[1540650,1540960,"문제의"],[1540970,1541360,"피처들은"],[1541360,1541640,"대부분"],[1541650,1542287,"스파스하다고"],[1542287,1542540,"했죠."]],"textEdited":"두루두루 적용 가능한 제너럴한 프리딕터 모델이라고 말씀드렸고요. 특히 스파스한 데이터에 아주 강력하다고 했는데요. 우리가 처음에 CTR 예측 모델 문제를 이야기할 때 CTR 예측 문제의 피처들은 대부분 스파스하다고 했죠."},{"start":1542800,"end":1554600,"text":"따라서 이 CTR 예측 문제에서 FM은 굉장히 좋은 성능을 내고 있었습니다. 이제 여기서 필드 어웨어라는 말이 FM 앞에 붙었고요. 이게 FFM인데요. FFM은","confidence":0.95,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1543150,1543500,"따라서"],[1543790,1543940,"이"],[1543950,1544260,"CTR"],[1544260,1544460,"예측"],[1544470,1544900,"문제에서"],[1545030,1545400,"FM은"],[1545550,1545840,"굉장히"],[1545890,1546060,"좋은"],[1546230,1546560,"성능을"],[1546670,1546920,"내고"],[1546920,1547400,"있었습니다."],[1547890,1548060,"이제"],[1548060,1548360,"여기서"],[1548930,1549280,"필드"],[1549330,1549860,"어웨어라는"],[1549870,1550160,"말이"],[1550510,1550800,"FM"],[1550870,1551100,"앞에"],[1551110,1552260,"붙었고요."],[1552470,1552660,"이게"],[1552770,1553420,"FFM인데요."],[1553810,1554320,"FFM은"]],"textEdited":"따라서 이 CTR 예측 문제에서 FM은 굉장히 좋은 성능을 내고 있었습니다. 이제 여기서 필드 어웨어라는 말이 FM 앞에 붙었고요. 이게 FFM인데요. FFM은"},{"start":1554600,"end":1569200,"text":"FM을 발전시킨 모델로서 이 pitf라는 모델에서 아이디어를 얻었습니다. 그래서 이 pitf 모델에 대해서 간단히 설명을 드릴 텐데요. pitf 모델은 매트리스 팩토라이제이션 모델을 발전시킨 모델인데요.","confidence":0.7475,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1555050,1555440,"FM을"],[1555530,1556120,"발전시킨"],[1556170,1556700,"모델로서"],[1557350,1557500,"이"],[1557590,1558580,"pitf라는"],[1558590,1559020,"모델에서"],[1559050,1559460,"아이디어를"],[1559460,1559920,"얻었습니다."],[1560750,1560894,"그래서"],[1560894,1561020,"이"],[1561020,1561620,"pitf"],[1561620,1561867,"모델에"],[1561867,1562120,"대해서"],[1562150,1562480,"간단히"],[1562490,1562780,"설명을"],[1562780,1562960,"드릴"],[1562960,1563280,"텐데요."],[1564330,1564980,"pitf"],[1564980,1565320,"모델은"],[1566010,1566460,"매트리스"],[1566470,1567100,"팩토라이제이션"],[1567130,1567520,"모델을"],[1567790,1568280,"발전시킨"],[1568280,1568780,"모델인데요."]],"textEdited":"FM을 발전시킨 모델로서 이 pitf라는 모델에서 아이디어를 얻었습니다. 그래서 이 pitf 모델에 대해서 간단히 설명을 드릴 텐데요. pitf 모델은 매트리스 팩토라이제이션 모델을 발전시킨 모델인데요."},{"start":1569200,"end":1580300,"text":"어떻게 발전시켰냐면은 매트리스 팩토라이제이션 같은 경우에는 2차원 매트릭스로 유저 아이디와 아이템 아이디로 구성되어 있지만 이 pitf는 텐서 팩토라이제이션 즉 3차원으로","confidence":0.9574,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1569470,1569740,"어떻게"],[1569740,1570400,"발전시켰냐면은"],[1570450,1570780,"매트리스"],[1570780,1571280,"팩토라이제이션"],[1571290,1571494,"같은"],[1571494,1571840,"경우에는"],[1571930,1572300,"2차원"],[1572350,1572920,"매트릭스로"],[1573170,1573460,"유저"],[1573490,1573880,"아이디와"],[1573880,1574160,"아이템"],[1574170,1574520,"아이디로"],[1574520,1574840,"구성되어"],[1574840,1575120,"있지만"],[1575770,1575920,"이"],[1575950,1576820,"pitf는"],[1577410,1577780,"텐서"],[1577830,1578440,"팩토라이제이션"],[1578550,1578700,"즉"],[1579230,1579960,"3차원으로"]],"textEdited":"어떻게 발전시켰냐면은 매트리스 팩토라이제이션 같은 경우에는 2차원 매트릭스로 유저 아이디와 아이템 아이디로 구성되어 있지만 이 pitf는 텐서 팩토라이제이션 즉 3차원으로"},{"start":1580300,"end":1590000,"text":"엠프를 확장시킨 모델입니다. 그래서 pitf에는 유저 아이디와 아이템 아이디에다가 태그 아이디까지 총 3개의 필드로 구성되어 있습니다.","confidence":0.7451,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1580510,1580980,"엠프를"],[1581030,1581520,"확장시킨"],[1581530,1582000,"모델입니다."],[1582290,1582480,"그래서"],[1582480,1583300,"pitf에는"],[1583490,1583780,"유저"],[1583810,1584240,"아이디와"],[1584270,1584560,"아이템"],[1584590,1585800,"아이디에다가"],[1585990,1586320,"태그"],[1586330,1586960,"아이디까지"],[1587030,1587180,"총"],[1587310,1587740,"3개의"],[1587950,1588340,"필드로"],[1588970,1589440,"구성되어"],[1589450,1589860,"있습니다."]],"textEdited":"엠프를 확장시킨 모델입니다. 그래서 pitf에는 유저 아이디와 아이템 아이디에다가 태그 아이디까지 총 3개의 필드로 구성되어 있습니다."},{"start":1590000,"end":1601200,"text":"그래서 이 pitf는 유저와 아이템 인베딩 외에 태그의 인베딩까지 총 3개의 인베딩을 학습하게 됩니다. 3차원 텐서이기 때문에 원래 MF는 이 둘의","confidence":0.9674,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1590270,1590454,"그래서"],[1590454,1590580,"이"],[1590580,1591300,"pitf는"],[1591690,1592080,"유저와"],[1592150,1592460,"아이템"],[1592530,1592880,"인베딩"],[1592890,1593140,"외에"],[1593330,1593720,"태그의"],[1593770,1594420,"인베딩까지"],[1594470,1594620,"총"],[1594730,1595080,"3개의"],[1595150,1595660,"인베딩을"],[1595770,1596127,"학습하게"],[1596127,1596440,"됩니다."],[1597390,1597820,"3차원"],[1597890,1598307,"텐서이기"],[1598307,1598680,"때문에"],[1599270,1599540,"원래"],[1599650,1600180,"MF는"],[1600270,1600420,"이"],[1600430,1600800,"둘의"]],"textEdited":"그래서 이 pitf는 유저와 아이템 인베딩 외에 태그의 인베딩까지 총 3개의 인베딩을 학습하게 됩니다. 3차원 텐서이기 때문에 원래 MF는 이 둘의"},{"start":1601200,"end":1614100,"text":"곱으로만 이루어져 있지만 3차원 텐서 같은 경우에는 유저와 아이템 아이템과 태그 태그와 유저 각각의 인터랙션이 모두 가능한데요. 이제 여기서 pitf의 핵심적인 아이디어는","confidence":0.9125,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1601610,1602040,"곱으로만"],[1602050,1602380,"이루어져"],[1602380,1602680,"있지만"],[1603450,1603900,"3차원"],[1604370,1604660,"텐서"],[1604670,1604854,"같은"],[1604854,1605280,"경우에는"],[1605510,1605920,"유저와"],[1605970,1606300,"아이템"],[1606510,1606960,"아이템과"],[1607030,1607280,"태그"],[1607390,1607780,"태그와"],[1607810,1608060,"유저"],[1608710,1609240,"각각의"],[1609430,1609960,"인터랙션이"],[1609960,1610140,"모두"],[1610190,1610760,"가능한데요."],[1611210,1611347,"이제"],[1611347,1611600,"여기서"],[1611610,1612440,"pitf의"],[1612590,1612980,"핵심적인"],[1613010,1613520,"아이디어는"]],"textEdited":"곱으로만 이루어져 있지만 3차원 텐서 같은 경우에는 유저와 아이템 아이템과 태그 태그와 유저 각각의 인터랙션이 모두 가능한데요. 이제 여기서 pitf의 핵심적인 아이디어는"},{"start":1614100,"end":1628700,"text":"유저가 아이템이랑 곱해질 때의 레이턴트 팩터와 유저가 태그와 곱해질 때 레이턴트 팩터를 서로 다른 레이턴트 팩터 즉 서로 다른 인베딩을 정의하여서 구했다는 것입니다. 하나의 인베딩만을 사용해서는 서로 다른","confidence":0.9688,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1614330,1614720,"유저가"],[1614750,1615340,"아이템이랑"],[1615390,1615780,"곱해질"],[1615850,1616140,"때의"],[1616250,1616680,"레이턴트"],[1616680,1617060,"팩터와"],[1617450,1617800,"유저가"],[1617950,1618340,"태그와"],[1618430,1618780,"곱해질"],[1618780,1618920,"때"],[1618920,1619280,"레이턴트"],[1619280,1619640,"팩터를"],[1619640,1619900,"서로"],[1620410,1620660,"다른"],[1620730,1621160,"레이턴트"],[1621160,1621440,"팩터"],[1621590,1621740,"즉"],[1621750,1621980,"서로"],[1621980,1622200,"다른"],[1622290,1622760,"인베딩을"],[1622830,1623380,"정의하여서"],[1623870,1624274,"구했다는"],[1624274,1624680,"것입니다."],[1625330,1625700,"하나의"],[1625810,1626500,"인베딩만을"],[1626510,1627120,"사용해서는"],[1627670,1627940,"서로"],[1627970,1628260,"다른"]],"textEdited":"유저가 아이템이랑 곱해질 때의 레이턴트 팩터와 유저가 태그와 곱해질 때 레이턴트 팩터를 서로 다른 레이턴트 팩터 즉 서로 다른 인베딩을 정의하여서 구했다는 것입니다. 하나의 인베딩만을 사용해서는 서로 다른"},{"start":1628700,"end":1640000,"text":"필드와의 인터랙션을 표현하기에는 그 인베딩의 표현력이 부족했기 때문에 곱해지는 반대편의 필드가 무엇인지에 따라서 서로 다른 인베딩을 사용하는 것입니다.","confidence":0.9557,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1629010,1629580,"필드와의"],[1629650,1630180,"인터랙션을"],[1630180,1630800,"표현하기에는"],[1631270,1631420,"그"],[1631850,1632360,"인베딩의"],[1632410,1632860,"표현력이"],[1632860,1633280,"부족했기"],[1633280,1633660,"때문에"],[1634810,1635360,"곱해지는"],[1635490,1636180,"반대편의"],[1636350,1636760,"필드가"],[1636790,1637314,"무엇인지에"],[1637314,1637640,"따라서"],[1637690,1637900,"서로"],[1637900,1638140,"다른"],[1638230,1638740,"인베딩을"],[1639150,1639494,"사용하는"],[1639494,1639900,"것입니다."]],"textEdited":"필드와의 인터랙션을 표현하기에는 그 인베딩의 표현력이 부족했기 때문에 곱해지는 반대편의 필드가 무엇인지에 따라서 서로 다른 인베딩을 사용하는 것입니다."},{"start":1640000,"end":1653000,"text":"그리고 프프엠은 방금 얘기했던 이 pitf에 서로 다른 레이턴트 팩터 즉 서로 다른 인베딩을 사용하는 그 아이디어를 일반화하여서 여러 개의 필드에 대해서 이 레이턴트 팩터를 정의한 것입니다.","confidence":0.8125,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1640250,1640460,"그리고"],[1640530,1641080,"프프엠은"],[1641670,1641920,"방금"],[1641930,1642360,"얘기했던"],[1642390,1642540,"이"],[1642570,1643420,"pitf에"],[1644030,1644260,"서로"],[1644260,1644440,"다른"],[1644490,1644880,"레이턴트"],[1644880,1645160,"팩터"],[1645510,1645660,"즉"],[1645670,1645867,"서로"],[1645867,1646060,"다른"],[1646110,1646540,"인베딩을"],[1646540,1646880,"사용하는"],[1646910,1647060,"그"],[1647090,1647680,"아이디어를"],[1648110,1648840,"일반화하여서"],[1649490,1649820,"여러"],[1649820,1650080,"개의"],[1650210,1650600,"필드에"],[1650600,1650940,"대해서"],[1651270,1651420,"이"],[1651420,1651800,"레이턴트"],[1651800,1652080,"팩터를"],[1652090,1652460,"정의한"],[1652460,1652940,"것입니다."]],"textEdited":"그리고 프프엠은 방금 얘기했던 이 pitf에 서로 다른 레이턴트 팩터 즉 서로 다른 인베딩을 사용하는 그 아이디어를 일반화하여서 여러 개의 필드에 대해서 이 레이턴트 팩터를 정의한 것입니다."},{"start":1653000,"end":1662900,"text":"pitf는 필드가 3개지만 FFM은 사용자가 정의하는 개수만큼 필드를 늘려서 인베딩에 인터랙션을 시킬 수 있다는 것입니다.","confidence":0.9221,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1653310,1653980,"pitf는"],[1654010,1654320,"필드가"],[1654350,1654820,"3개지만"],[1655390,1655900,"FFM은"],[1656030,1656480,"사용자가"],[1656530,1656940,"정의하는"],[1657030,1657560,"개수만큼"],[1657590,1657980,"필드를"],[1658650,1659100,"늘려서"],[1660130,1660680,"인베딩에"],[1660950,1661460,"인터랙션을"],[1661460,1661700,"시킬"],[1661700,1661807,"수"],[1661807,1662054,"있다는"],[1662054,1662460,"것입니다."]],"textEdited":"pitf는 필드가 3개지만 FFM은 사용자가 정의하는 개수만큼 필드를 늘려서 인베딩에 인터랙션을 시킬 수 있다는 것입니다."},{"start":1662900,"end":1675200,"text":"앞서 말한 대로 FFM은 주어진 입력 변수에 이 필드라는 속성을 추가합니다. 그리고 필드별로 서로 다른 레이턴트 팩터를 가지도록 하고 그렇게 해서 팩토라이즈를 합니다.","confidence":0.9574,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1663470,1663740,"앞서"],[1663740,1664000,"말한"],[1664000,1664220,"대로"],[1664870,1665400,"FFM은"],[1666070,1666440,"주어진"],[1666550,1666820,"입력"],[1666890,1667280,"변수에"],[1667310,1667460,"이"],[1667590,1668120,"필드라는"],[1668230,1668580,"속성을"],[1668650,1669140,"추가합니다."],[1669890,1670140,"그리고"],[1670270,1670840,"필드별로"],[1671090,1671360,"서로"],[1671450,1671740,"다른"],[1671850,1672320,"레이턴트"],[1672330,1672700,"팩터를"],[1672700,1673140,"가지도록"],[1673170,1673440,"하고"],[1673850,1674047,"그렇게"],[1674047,1674260,"해서"],[1674270,1674840,"팩토라이즈를"],[1674840,1675120,"합니다."]],"textEdited":"앞서 말한 대로 FFM은 주어진 입력 변수에 이 필드라는 속성을 추가합니다. 그리고 필드별로 서로 다른 레이턴트 팩터를 가지도록 하고 그렇게 해서 팩토라이즈를 합니다."},{"start":1675200,"end":1686200,"text":"기존의 FM은 하나의 변수 x1에 대해서 k g로 팩토라이즈 하는 vk라는 하나의 팩토라이제이션 파라미터만을 가졌지만 FFM은","confidence":0.9139,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1675630,1675980,"기존의"],[1676070,1676440,"FM은"],[1677090,1677420,"하나의"],[1677450,1677720,"변수"],[1677870,1678440,"x1에"],[1678440,1678760,"대해서"],[1679530,1679680,"k"],[1679770,1680020,"g로"],[1680020,1680480,"팩토라이즈"],[1680490,1680720,"하는"],[1681070,1681960,"vk라는"],[1682250,1682560,"하나의"],[1682630,1683320,"팩토라이제이션"],[1683350,1684040,"파라미터만을"],[1684040,1684500,"가졌지만"],[1685310,1685860,"FFM은"]],"textEdited":"기존의 FM은 하나의 변수 x1에 대해서 k g로 팩토라이즈 하는 vk라는 하나의 팩토라이제이션 파라미터만을 가졌지만 FFM은"},{"start":1686200,"end":1699600,"text":"필드가 총 2개 있다고 했을 때 프개의 팩토라이제이션 파라미터를 갖습니다. 자 그렇다면 필드를 보통 어떻게 정의하고 어떻게 나눌까요? 이제 필드는 모델을 설계할 때 사용자가 정의하는 것입니다.","confidence":0.8728,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1686450,1686800,"필드가"],[1686890,1687040,"총"],[1687150,1687440,"2개"],[1687450,1687727,"있다고"],[1687727,1687980,"했을"],[1688030,1688180,"때"],[1688890,1689640,"프개의"],[1690290,1690920,"팩토라이제이션"],[1690930,1691860,"파라미터를"],[1691890,1692320,"갖습니다."],[1692810,1692960,"자"],[1692960,1693260,"그렇다면"],[1693330,1693720,"필드를"],[1693730,1693960,"보통"],[1693990,1694380,"어떻게"],[1694750,1695180,"정의하고"],[1695180,1695460,"어떻게"],[1695460,1695940,"나눌까요?"],[1696250,1696420,"이제"],[1696470,1696860,"필드는"],[1697130,1697500,"모델을"],[1697530,1697887,"설계할"],[1697887,1698020,"때"],[1698050,1698540,"사용자가"],[1698650,1699047,"정의하는"],[1699047,1699460,"것입니다."]],"textEdited":"필드가 총 2개 있다고 했을 때 프개의 팩토라이제이션 파라미터를 갖습니다. 자 그렇다면 필드를 보통 어떻게 정의하고 어떻게 나눌까요? 이제 필드는 모델을 설계할 때 사용자가 정의하는 것입니다."},{"start":1699600,"end":1710700,"text":"이 모델이 알아서 정해주는 것이 아니라 사용자가 어떤 변수를 같은 필드로 묶을지를 정해야 하는데요. 보통 이제 유저나 아이템이나 콘텍스트 피처를 사용할 때","confidence":0.9791,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1699930,1700080,"이"],[1700080,1700420,"모델이"],[1700630,1700920,"알아서"],[1700920,1701287,"정해주는"],[1701287,1701460,"것이"],[1701460,1701740,"아니라"],[1702270,1702740,"사용자가"],[1702850,1703080,"어떤"],[1703170,1703600,"변수를"],[1703870,1704140,"같은"],[1704270,1704640,"필드로"],[1704690,1705240,"묶을지를"],[1705270,1705660,"정해야"],[1705670,1706060,"하는데요."],[1706570,1706900,"보통"],[1707530,1707700,"이제"],[1708290,1708660,"유저나"],[1708660,1709100,"아이템이나"],[1709130,1709560,"콘텍스트"],[1709560,1709820,"피처를"],[1709820,1710160,"사용할"],[1710210,1710360,"때"]],"textEdited":"이 모델이 알아서 정해주는 것이 아니라 사용자가 어떤 변수를 같은 필드로 묶을지를 정해야 하는데요. 보통 이제 유저나 아이템이나 콘텍스트 피처를 사용할 때"},{"start":1710700,"end":1723200,"text":"보통 우리가 시멘틱하게 성별이나 디바이스 같은 피처를 사용한다고 하지만 이 성별은 사실 남자 여자 그리고 디바이스 같은 경우에는 뭐 안드로이드 아이폰 같이 2개 이상의 피처 공간으로 표현하게 되겠죠.","confidence":0.933,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1710990,1711240,"보통"],[1711240,1711460,"우리가"],[1711510,1712140,"시멘틱하게"],[1712330,1712780,"성별이나"],[1712810,1713260,"디바이스"],[1713270,1713520,"같은"],[1713590,1713920,"피처를"],[1713920,1714347,"사용한다고"],[1714347,1714640,"하지만"],[1715090,1715240,"이"],[1715290,1715660,"성별은"],[1715730,1715960,"사실"],[1716110,1716480,"남자"],[1716790,1717080,"여자"],[1717490,1717680,"그리고"],[1717710,1718120,"디바이스"],[1718120,1718294,"같은"],[1718294,1718580,"경우에는"],[1718580,1718700,"뭐"],[1718710,1719180,"안드로이드"],[1719210,1719520,"아이폰"],[1719810,1720120,"같이"],[1720490,1720760,"2개"],[1720770,1721060,"이상의"],[1721110,1721360,"피처"],[1721430,1721880,"공간으로"],[1722330,1722734,"표현하게"],[1722734,1723040,"되겠죠."]],"textEdited":"보통 우리가 시멘틱하게 성별이나 디바이스 같은 피처를 사용한다고 하지만 이 성별은 사실 남자 여자 그리고 디바이스 같은 경우에는 뭐 안드로이드 아이폰 같이 2개 이상의 피처 공간으로 표현하게 되겠죠."},{"start":1723200,"end":1737600,"text":"그러면 그 두 개 이상의 변수가 하나의 필드가 되는 거죠. 그래서 성별 필드 디바이스 필드 운영 체제 필드 될 수 있고요. 아이템 같은 경우에는 카테고리 필드 등이 존재할 수 있는 거죠. 카테고리가 하나가 아니라 10개가 있으면은","confidence":0.9436,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1723490,1723740,"그러면"],[1723790,1723940,"그"],[1724470,1724620,"두"],[1724620,1724740,"개"],[1724740,1725020,"이상의"],[1725090,1725500,"변수가"],[1725550,1725840,"하나의"],[1725950,1726227,"필드가"],[1726227,1726440,"되는"],[1726440,1726660,"거죠."],[1726950,1727180,"그래서"],[1727310,1727600,"성별"],[1727710,1728020,"필드"],[1728410,1728900,"디바이스"],[1728950,1729260,"필드"],[1729450,1729680,"운영"],[1729690,1729900,"체제"],[1729930,1730200,"필드"],[1730570,1730720,"될"],[1730720,1730814,"수"],[1730814,1731100,"있고요."],[1731570,1731920,"아이템"],[1731950,1732220,"같은"],[1732220,1732620,"경우에는"],[1732770,1733180,"카테고리"],[1733190,1733480,"필드"],[1733750,1734000,"등이"],[1734050,1734420,"존재할"],[1734420,1734480,"수"],[1734480,1734594,"있는"],[1734594,1734820,"거죠."],[1735070,1735620,"카테고리가"],[1735730,1736007,"하나가"],[1736007,1736260,"아니라"],[1736430,1736800,"10개가"],[1736800,1737180,"있으면은"]],"textEdited":"그러면 그 두 개 이상의 변수가 하나의 필드가 되는 거죠. 그래서 성별 필드 디바이스 필드 운영 체제 필드 될 수 있고요. 아이템 같은 경우에는 카테고리 필드 등이 존재할 수 있는 거죠. 카테고리가 하나가 아니라 10개가 있으면은"},{"start":1737600,"end":1750900,"text":"그 카테고리는 10개의 원핫 인코딩으로 표현돼야 되기 때문에 10개의 변수로 표현되고요. 그 10개의 변수가 하나의 카테고리 필드에 포함되는 것이죠. 그래서 이 외에도 CTR 예측에는 훨씬 더 다양한","confidence":0.9288,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1737870,1738020,"그"],[1738310,1738840,"카테고리는"],[1739070,1739620,"10개의"],[1739670,1739940,"원핫"],[1740410,1740860,"인코딩으로"],[1740860,1741207,"표현돼야"],[1741207,1741354,"되기"],[1741354,1741680,"때문에"],[1741850,1742280,"10개의"],[1742330,1742700,"변수로"],[1742700,1743180,"표현되고요."],[1743530,1743680,"그"],[1743710,1744120,"10개의"],[1744150,1744520,"변수가"],[1744690,1745020,"하나의"],[1745350,1745820,"카테고리"],[1745870,1746260,"필드에"],[1746670,1747120,"포함되는"],[1747120,1747420,"것이죠."],[1747610,1747800,"그래서"],[1747800,1747940,"이"],[1747940,1748280,"외에도"],[1748430,1748740,"CTR"],[1748740,1749180,"예측에는"],[1749650,1749894,"훨씬"],[1749894,1750020,"더"],[1750090,1750500,"다양한"]],"textEdited":"그 카테고리는 10개의 원핫 인코딩으로 표현돼야 되기 때문에 10개의 변수로 표현되고요. 그 10개의 변수가 하나의 카테고리 필드에 포함되는 것이죠. 그래서 이 외에도 CTR 예측에는 훨씬 더 다양한"},{"start":1750900,"end":1760700,"text":"피처가 사용되는데요. 보통 피처의 개수만큼 필드를 정의하여서 사용하게 됩니다. 자 다음은 FFM의 수식을","confidence":0.9063,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1751110,1751427,"피처가"],[1751427,1752020,"사용되는데요."],[1752470,1752740,"보통"],[1752810,1753180,"피처의"],[1753230,1753860,"개수만큼"],[1754010,1754360,"필드를"],[1754410,1755020,"정의하여서"],[1755370,1755780,"사용하게"],[1755780,1756080,"됩니다."],[1756490,1756640,"자"],[1756670,1756980,"다음은"],[1757630,1758220,"FFM의"],[1758250,1758640,"수식을"]],"textEdited":"피처가 사용되는데요. 보통 피처의 개수만큼 필드를 정의하여서 사용하게 됩니다. 자 다음은 FFM의 수식을"},{"start":1760700,"end":1774300,"text":"다음과 같이 표현하였는데요. 보시면 이 앞에 있는 이 부분은 이제 리니어한 부분 로직스 리그레션 부분이고요. 이제 가장 큰 차이는 FM과 비교했을 때 여기 팩토라이제이션 더이","confidence":0.8775,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1761070,1761367,"다음과"],[1761367,1761560,"같이"],[1761560,1762180,"표현하였는데요."],[1762970,1763320,"보시면"],[1763330,1763480,"이"],[1763490,1763780,"앞에"],[1763890,1764080,"있는"],[1764190,1764340,"이"],[1764730,1765080,"부분은"],[1765450,1765620,"이제"],[1765710,1766780,"리니어한"],[1766790,1766980,"부분"],[1767310,1767640,"로직스"],[1767670,1768040,"리그레션"],[1768050,1768540,"부분이고요."],[1769050,1769220,"이제"],[1769490,1769720,"가장"],[1769870,1770020,"큰"],[1770090,1770420,"차이는"],[1771050,1771420,"FM과"],[1771450,1771900,"비교했을"],[1771950,1772100,"때"],[1772590,1772800,"여기"],[1772850,1773560,"팩토라이제이션"],[1773610,1773960,"더이"]],"textEdited":"다음과 같이 표현하였는데요. 보시면 이 앞에 있는 이 부분은 이제 리니어한 부분 로직스 리그레션 부분이고요. 이제 가장 큰 차이는 FM과 비교했을 때 여기 팩토라이제이션 더이"},{"start":1774300,"end":1784400,"text":"가장 큰 차이가 됩니다. 기존의 FM은 2개의 xixj 즉 2개의 변수가 인터랙션 할 때 각각에 해당하는 k 차원","confidence":0.9203,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1774610,1774860,"가장"],[1774890,1775040,"큰"],[1775050,1775307,"차이가"],[1775307,1775620,"됩니다."],[1775870,1776200,"기존의"],[1776310,1776680,"FM은"],[1777590,1778000,"2개의"],[1778250,1779040,"xixj"],[1779550,1779700,"즉"],[1779830,1780240,"2개의"],[1780330,1780720,"변수가"],[1780720,1781140,"인터랙션"],[1781150,1781300,"할"],[1781310,1781460,"때"],[1782070,1782440,"각각에"],[1782440,1782880,"해당하는"],[1783530,1783680,"k"],[1783830,1784080,"차원"]],"textEdited":"가장 큰 차이가 됩니다. 기존의 FM은 2개의 xixj 즉 2개의 변수가 인터랙션 할 때 각각에 해당하는 k 차원"},{"start":1784400,"end":1792100,"text":"내 파라미터를 내적이 되는 형태로 이 모델에서는 그 인터랙션을 표현하였는데요. 이제 보시면은","confidence":0.932,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1785310,1785460,"내"],[1785510,1786140,"파라미터를"],[1786870,1787234,"내적이"],[1787234,1787420,"되는"],[1787450,1787820,"형태로"],[1788570,1788720,"이"],[1788730,1789260,"모델에서는"],[1789310,1789460,"그"],[1789460,1789880,"인터랙션을"],[1789880,1790480,"표현하였는데요."],[1790950,1791120,"이제"],[1791120,1791620,"보시면은"]],"textEdited":"내 파라미터를 내적이 되는 형태로 이 모델에서는 그 인터랙션을 표현하였는데요. 이제 보시면은"},{"start":1792100,"end":1803100,"text":"FFM 같은 경우에는 단순히 XI에 해당하는 VI가 아니라 이 뒤에 f제가 포함되어 있습니다. 이것은 무엇이냐 XI","confidence":0.675,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1793510,1793940,"FFM"],[1793950,1794167,"같은"],[1794167,1794560,"경우에는"],[1794910,1795320,"단순히"],[1795630,1796114,"XI에"],[1796114,1796460,"해당하는"],[1796510,1797200,"VI가"],[1797200,1797440,"아니라"],[1797790,1797940,"이"],[1797940,1798200,"뒤에"],[1798610,1799180,"f제가"],[1799210,1799547,"포함되어"],[1799547,1799900,"있습니다."],[1800310,1800600,"이것은"],[1800600,1800940,"무엇이냐"],[1801910,1802380,"XI"]],"textEdited":"FFM 같은 경우에는 단순히 XI에 해당하는 VI가 아니라 이 뒤에 f제가 포함되어 있습니다. 이것은 무엇이냐 XI"},{"start":1803100,"end":1816500,"text":"그러니까 곱해지는 반대편인 xj의 필드에 해당하는 팩토라이제이션 파라미터를 사용한다는 것이죠. 그래서 이 하나의 변수는 총 2개의 필드를 갖고 각 필드별로","confidence":0.8966,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1803390,1803660,"그러니까"],[1803690,1804200,"곱해지는"],[1804290,1804820,"반대편인"],[1804990,1805640,"xj의"],[1805970,1806900,"필드에"],[1806930,1807380,"해당하는"],[1808370,1808940,"팩토라이제이션"],[1808950,1809400,"파라미터를"],[1809400,1809807,"사용한다는"],[1809807,1810120,"것이죠."],[1810290,1810540,"그래서"],[1811110,1811260,"이"],[1811330,1811780,"하나의"],[1812590,1813040,"변수는"],[1813530,1813680,"총"],[1813910,1814300,"2개의"],[1814330,1814660,"필드를"],[1814660,1814940,"갖고"],[1815090,1815240,"각"],[1815390,1816080,"필드별로"]],"textEdited":"그러니까 곱해지는 반대편인 xj의 필드에 해당하는 팩토라이제이션 파라미터를 사용한다는 것이죠. 그래서 이 하나의 변수는 총 2개의 필드를 갖고 각 필드별로"},{"start":1816500,"end":1830700,"text":"팩토라이제이션 파라미터가 정의되는 것입니다. 수식이 좀 복잡할 수 있으니 다음 슬라이드에서 예시를 통해 좀 더 쉽게 이해해 보겠습니다. 다음과 같은 광고 클릭 데이터가 존재하고 이제 이 데이터를 FM과 FM","confidence":0.9779,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1816790,1817440,"팩토라이제이션"],[1817450,1817980,"파라미터가"],[1818310,1818727,"정의되는"],[1818727,1819140,"것입니다."],[1819650,1819927,"수식이"],[1819927,1820060,"좀"],[1820150,1820560,"복잡할"],[1820570,1820687,"수"],[1820687,1820960,"있으니"],[1821110,1821320,"다음"],[1821450,1822020,"슬라이드에서"],[1822090,1822440,"예시를"],[1822440,1822640,"통해"],[1822640,1822780,"좀"],[1822780,1822900,"더"],[1822950,1823240,"쉽게"],[1823470,1823707,"이해해"],[1823707,1824220,"보겠습니다."],[1825030,1825460,"다음과"],[1825460,1825700,"같은"],[1826130,1826440,"광고"],[1826530,1826760,"클릭"],[1826790,1827220,"데이터가"],[1827230,1827760,"존재하고"],[1828270,1828440,"이제"],[1828510,1828660,"이"],[1828690,1829140,"데이터를"],[1829370,1829840,"FM과"],[1830030,1830300,"FM"]],"textEdited":"팩토라이제이션 파라미터가 정의되는 것입니다. 수식이 좀 복잡할 수 있으니 다음 슬라이드에서 예시를 통해 좀 더 쉽게 이해해 보겠습니다. 다음과 같은 광고 클릭 데이터가 존재하고 이제 이 데이터를 FM과 FM"},{"start":1830700,"end":1841200,"text":"FFM 모델을 사용하여서 각각 표현해 보겠습니다. 먼저 좌측에 있는 FM인데요. FM은 필드가 존재하지 않기 때문에 각각 하나의 변수에 대해서","confidence":0.9847,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1831030,1831500,"FFM"],[1831510,1831860,"모델을"],[1831860,1832340,"사용하여서"],[1832430,1832760,"각각"],[1832970,1833247,"표현해"],[1833247,1833740,"보겠습니다."],[1833890,1834140,"먼저"],[1834410,1834847,"좌측에"],[1834847,1835000,"있는"],[1835170,1835820,"FM인데요."],[1836650,1836960,"FM은"],[1836970,1837300,"필드가"],[1837310,1837800,"존재하지"],[1837850,1838120,"않기"],[1838120,1838520,"때문에"],[1839230,1839500,"각각"],[1839530,1839840,"하나의"],[1839930,1840440,"변수에"],[1840440,1840780,"대해서"]],"textEdited":"FFM 모델을 사용하여서 각각 표현해 보겠습니다. 먼저 좌측에 있는 FM인데요. FM은 필드가 존재하지 않기 때문에 각각 하나의 변수에 대해서"},{"start":1841200,"end":1856100,"text":"하나의 팩토라이제이션 파라미터만 존재합니다. 그래서 이 왼쪽에 이 수식을 표현해 보면은 글로벌 바이오스가 있고요. 각각의 변수가 하나씩 있기 때문에 ESPN 블크 블메일 이 부분은 1차 항이죠.","confidence":0.7661,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1841490,1841820,"하나의"],[1841930,1842600,"팩토라이제이션"],[1842630,1843180,"파라미터만"],[1843270,1843800,"존재합니다."],[1843970,1844160,"그래서"],[1844160,1844300,"이"],[1844330,1845007,"왼쪽에"],[1845007,1845140,"이"],[1845140,1845520,"수식을"],[1845570,1845847,"표현해"],[1845847,1846220,"보면은"],[1846750,1847080,"글로벌"],[1847090,1848140,"바이오스가"],[1848140,1848440,"있고요."],[1848810,1849180,"각각의"],[1849710,1850060,"변수가"],[1850230,1850580,"하나씩"],[1850590,1850787,"있기"],[1850787,1851160,"때문에"],[1852390,1852880,"ESPN"],[1852970,1853460,"블크"],[1853570,1853940,"블메일"],[1854150,1854300,"이"],[1854300,1854600,"부분은"],[1854710,1855000,"1차"],[1855310,1855760,"항이죠."]],"textEdited":"하나의 팩토라이제이션 파라미터만 존재합니다. 그래서 이 왼쪽에 이 수식을 표현해 보면은 글로벌 바이오스가 있고요. 각각의 변수가 하나씩 있기 때문에 ESPN 블크 블메일 이 부분은 1차 항이죠."},{"start":1856100,"end":1868600,"text":"이제 이 뒤에 있는 부분이 팩토라이제이션 텀인데요. 각각의 변수에 해당하는 팩토라이제이션 파라미터가 선택돼서 이 둘이 내적으로 곱해지게 됩니다. 반면에","confidence":0.9769,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1856350,1856540,"이제"],[1856540,1856660,"이"],[1856670,1856940,"뒤에"],[1856940,1857140,"있는"],[1857210,1857760,"부분이"],[1858010,1858720,"팩토라이제이션"],[1858720,1859160,"텀인데요."],[1860070,1860580,"각각의"],[1860970,1861400,"변수에"],[1861400,1861780,"해당하는"],[1862010,1862720,"팩토라이제이션"],[1862730,1864220,"파라미터가"],[1864770,1865200,"선택돼서"],[1865270,1865387,"이"],[1865387,1865640,"둘이"],[1865770,1866280,"내적으로"],[1866430,1866807,"곱해지게"],[1866807,1867120,"됩니다."],[1867850,1868260,"반면에"]],"textEdited":"이제 이 뒤에 있는 부분이 팩토라이제이션 텀인데요. 각각의 변수에 해당하는 팩토라이제이션 파라미터가 선택돼서 이 둘이 내적으로 곱해지게 됩니다. 반면에"},{"start":1868600,"end":1883500,"text":"프프엠은 이 앞에 있는 글로벌 바이어스와 1차 텀은 똑같지만 이 뒤에 있는 팩토라이제이션 텀이 다소 복잡하게 되어 있습니다. 자 요 텀과 이 텀만을 비교해 보도록 하겠습니다.","confidence":0.8736,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1868990,1869600,"프프엠은"],[1870170,1870320,"이"],[1870390,1870720,"앞에"],[1870810,1871020,"있는"],[1871510,1871800,"글로벌"],[1871810,1872380,"바이어스와"],[1873150,1873460,"1차"],[1873810,1874120,"텀은"],[1874210,1874720,"똑같지만"],[1874890,1875040,"이"],[1875090,1875380,"뒤에"],[1875380,1875560,"있는"],[1875670,1876480,"팩토라이제이션"],[1876530,1876840,"텀이"],[1877110,1877400,"다소"],[1877470,1877940,"복잡하게"],[1877940,1878140,"되어"],[1878140,1878540,"있습니다."],[1878930,1879080,"자"],[1880070,1880220,"요"],[1880330,1880660,"텀과"],[1881310,1881460,"이"],[1881510,1881980,"텀만을"],[1882170,1882467,"비교해"],[1882467,1882780,"보도록"],[1882810,1883380,"하겠습니다."]],"textEdited":"프프엠은 이 앞에 있는 글로벌 바이어스와 1차 텀은 똑같지만 이 뒤에 있는 팩토라이제이션 텀이 다소 복잡하게 되어 있습니다. 자 요 텀과 이 텀만을 비교해 보도록 하겠습니다."},{"start":1883500,"end":1896200,"text":"이제 FM에서는 이 ESPN이라는 변수에 해당되는 파라미터가 단순히 vesp엔 하나였고 그 ESPN이 반대편인 나이키와 곱해지게 됐는데요.","confidence":0.4892,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1883930,1884100,"이제"],[1884190,1884780,"FM에서는"],[1885010,1885160,"이"],[1885410,1886600,"ESPN이라는"],[1887270,1887760,"변수에"],[1887760,1888160,"해당되는"],[1888170,1888700,"파라미터가"],[1889290,1889600,"단순히"],[1889600,1890320,"vesp엔"],[1890370,1890920,"하나였고"],[1891290,1891440,"그"],[1892190,1892780,"ESPN이"],[1893010,1893460,"반대편인"],[1893460,1894480,"나이키와"],[1894530,1894934,"곱해지게"],[1894934,1895380,"됐는데요."]],"textEdited":"이제 FM에서는 이 ESPN이라는 변수에 해당되는 파라미터가 단순히 vesp엔 하나였고 그 ESPN이 반대편인 나이키와 곱해지게 됐는데요."},{"start":1896200,"end":1909400,"text":"이 에프엠에서는 먼저 확인해야 될 게 이 ESPN이라는 피처 변수는 퍼블리셔 필드에 속해 있고 나이키라는 변수는 광고주 에드벌 타이스 필드에 속해 있고","confidence":0.7507,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1896450,1896600,"이"],[1896890,1897700,"에프엠에서는"],[1898230,1898480,"먼저"],[1898710,1899047,"확인해야"],[1899047,1899180,"될"],[1899190,1899340,"게"],[1899530,1899680,"이"],[1899730,1900720,"ESPN이라는"],[1900790,1901060,"피처"],[1901470,1901900,"변수는"],[1902430,1902940,"퍼블리셔"],[1902990,1903340,"필드에"],[1903340,1903600,"속해"],[1903600,1903860,"있고"],[1904610,1905940,"나이키라는"],[1906270,1906620,"변수는"],[1907230,1907600,"광고주"],[1907650,1907940,"에드벌"],[1907950,1908280,"타이스"],[1908310,1908620,"필드에"],[1908620,1908880,"속해"],[1908880,1909120,"있고"]],"textEdited":"이 에프엠에서는 먼저 확인해야 될 게 이 ESPN이라는 피처 변수는 퍼블리셔 필드에 속해 있고 나이키라는 변수는 광고주 에드벌 타이스 필드에 속해 있고"},{"start":1909400,"end":1923600,"text":"이 메일은 성별 필드에 속해 있음을 사용자가 지정을 했습니다. 자 그 상황에서 이 ESPN과 나이키의 인터랙션은 ESPN의 반대편 곱해지는 나이키가 바로 에드벌 타이스 필드이기 때문에","confidence":0.7157,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1909630,1909780,"이"],[1909810,1910180,"메일은"],[1910430,1910740,"성별"],[1910830,1911160,"필드에"],[1911170,1911460,"속해"],[1911460,1911780,"있음을"],[1912030,1912460,"사용자가"],[1912470,1912760,"지정을"],[1912760,1913160,"했습니다."],[1913410,1913560,"자"],[1913560,1913700,"그"],[1913700,1914080,"상황에서"],[1914830,1914980,"이"],[1915050,1915820,"ESPN과"],[1915830,1916340,"나이키의"],[1916340,1916940,"인터랙션은"],[1917570,1918240,"ESPN의"],[1918330,1918760,"반대편"],[1919070,1919540,"곱해지는"],[1919550,1920600,"나이키가"],[1920890,1921160,"바로"],[1921510,1921880,"에드벌"],[1921970,1922280,"타이스"],[1922310,1922740,"필드이기"],[1922740,1923080,"때문에"]],"textEdited":"이 메일은 성별 필드에 속해 있음을 사용자가 지정을 했습니다. 자 그 상황에서 이 ESPN과 나이키의 인터랙션은 ESPN의 반대편 곱해지는 나이키가 바로 에드벌 타이스 필드이기 때문에"},{"start":1923600,"end":1934400,"text":"브이피엔 콤마 에 즉 2스피엔 변수면서 에드벌 타이즈 필드가 곱해진다는 의미인 이 파라미터를 사용하게 됩니다.","confidence":0.5587,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1923870,1925040,"브이피엔"],[1925130,1925360,"콤마"],[1925450,1925600,"에"],[1926030,1926180,"즉"],[1926730,1927520,"2스피엔"],[1928270,1929040,"변수면서"],[1929570,1929940,"에드벌"],[1929990,1930300,"타이즈"],[1930330,1930680,"필드가"],[1930710,1931400,"곱해진다는"],[1931490,1931800,"의미인"],[1932390,1932540,"이"],[1932610,1933260,"파라미터를"],[1933450,1933860,"사용하게"],[1933860,1934220,"됩니다."]],"textEdited":"브이피엔 콤마 에 즉 2스피엔 변수면서 에드벌 타이즈 필드가 곱해진다는 의미인 이 파라미터를 사용하게 됩니다."},{"start":1934400,"end":1946300,"text":"반대로 이 나이키 같은 경우에는 반대편 곱해지는 ESPN이 바로 퍼블리셔 필드에 속해 있기 때문에 브나이키 콤마 피라는 파라미터를 사용하여서","confidence":0.804,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1934790,1935200,"반대로"],[1935730,1935880,"이"],[1935880,1936300,"나이키"],[1936370,1936640,"같은"],[1936640,1937040,"경우에는"],[1937330,1937760,"반대편"],[1937850,1938300,"곱해지는"],[1938330,1939000,"ESPN이"],[1939410,1939640,"바로"],[1939730,1940300,"퍼블리셔"],[1940370,1940940,"필드에"],[1940950,1941207,"속해"],[1941207,1941354,"있기"],[1941354,1941720,"때문에"],[1942270,1943040,"브나이키"],[1943770,1944020,"콤마"],[1944130,1944600,"피라는"],[1944890,1945420,"파라미터를"],[1945420,1945920,"사용하여서"]],"textEdited":"반대로 이 나이키 같은 경우에는 반대편 곱해지는 ESPN이 바로 퍼블리셔 필드에 속해 있기 때문에 브나이키 콤마 피라는 파라미터를 사용하여서"},{"start":1946300,"end":1960800,"text":"팩토라이제이션을 합니다. 그래서 이렇게 곱해지는 반대편 즉 인터랙션이 일어나는 반대편 변수의 필드를 고려하여서 팩토라이제이션을 수행하기 때문에 그래서 이름이 바로 필드 어웨어 팩토라이제이션 머신인 것입니다.","confidence":0.9817,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1946610,1947207,"팩토라이제이션을"],[1947207,1947480,"합니다."],[1947950,1948160,"그래서"],[1948160,1948400,"이렇게"],[1948790,1949380,"곱해지는"],[1949870,1950300,"반대편"],[1950410,1950560,"즉"],[1950610,1951107,"인터랙션이"],[1951107,1951440,"일어나는"],[1951690,1952060,"반대편"],[1952130,1952500,"변수의"],[1952550,1952980,"필드를"],[1953090,1953740,"고려하여서"],[1954390,1955320,"팩토라이제이션을"],[1955670,1956060,"수행하기"],[1956060,1956420,"때문에"],[1956930,1957160,"그래서"],[1957170,1957460,"이름이"],[1957460,1957680,"바로"],[1957790,1958160,"필드"],[1958230,1958580,"어웨어"],[1958730,1959380,"팩토라이제이션"],[1959470,1959987,"머신인"],[1959987,1960740,"것입니다."]],"textEdited":"팩토라이제이션을 합니다. 그래서 이렇게 곱해지는 반대편 즉 인터랙션이 일어나는 반대편 변수의 필드를 고려하여서 팩토라이제이션을 수행하기 때문에 그래서 이름이 바로 필드 어웨어 팩토라이제이션 머신인 것입니다."},{"start":1960800,"end":1974200,"text":"그래서 에프엠 모델은 주로 CTR 예측 문제에 많이 사용되고 이 문제 데이터의 대부분은 카테고리컬 피처라고 언급하였습니다. 그래서 카테고리컬 피처는 보통 같은 피처 그룹을 같은 필드로 묶어서 정의한다고 했습니다.","confidence":0.7991,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1961070,1961300,"그래서"],[1961300,1961800,"에프엠"],[1961800,1962100,"모델은"],[1962110,1962360,"주로"],[1962590,1962960,"CTR"],[1962960,1963200,"예측"],[1963210,1963520,"문제에"],[1963520,1963680,"많이"],[1963690,1964180,"사용되고"],[1964830,1964980,"이"],[1965010,1965280,"문제"],[1965550,1966040,"데이터의"],[1966090,1966560,"대부분은"],[1966650,1967180,"카테고리컬"],[1967180,1967580,"피처라고"],[1967610,1968280,"언급하였습니다."],[1968670,1968860,"그래서"],[1968860,1969340,"카테고리컬"],[1969350,1969700,"피처는"],[1969710,1969980,"보통"],[1970710,1970980,"같은"],[1971070,1971360,"피처"],[1971370,1971660,"그룹을"],[1971950,1972260,"같은"],[1972470,1972800,"필드로"],[1972810,1973120,"묶어서"],[1973150,1973647,"정의한다고"],[1973647,1974020,"했습니다."]],"textEdited":"그래서 에프엠 모델은 주로 CTR 예측 문제에 많이 사용되고 이 문제 데이터의 대부분은 카테고리컬 피처라고 언급하였습니다. 그래서 카테고리컬 피처는 보통 같은 피처 그룹을 같은 필드로 묶어서 정의한다고 했습니다."},{"start":1974200,"end":1989200,"text":"그래서 에프엠 같은 경우에는 필드가 필요 없지만 이 아래에 있는 에프엠은 각각의 변수가 속한 피처 그룹을 필드로 정의합니다. 그래서 이스피에는 이 피처가 퍼블리셔 피처였기 때문에 퍼블리셔 필드라고 정의하였고요.","confidence":0.8094,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1974630,1974840,"그래서"],[1974890,1975220,"에프엠"],[1975270,1975560,"같은"],[1975570,1976040,"경우에는"],[1976310,1976680,"필드가"],[1976850,1977080,"필요"],[1977080,1977380,"없지만"],[1977770,1977920,"이"],[1977920,1978174,"아래에"],[1978174,1978340,"있는"],[1978410,1979400,"에프엠은"],[1980130,1980460,"각각의"],[1980510,1980920,"변수가"],[1980930,1981220,"속한"],[1981310,1981580,"피처"],[1981610,1982380,"그룹을"],[1982510,1982820,"필드로"],[1982820,1983300,"정의합니다."],[1983970,1984160,"그래서"],[1984160,1984860,"이스피에는"],[1985270,1985420,"이"],[1985450,1985800,"피처가"],[1985910,1986340,"퍼블리셔"],[1986350,1986747,"피처였기"],[1986747,1987100,"때문에"],[1987370,1987760,"퍼블리셔"],[1987790,1988200,"필드라고"],[1988200,1988800,"정의하였고요."]],"textEdited":"그래서 에프엠 같은 경우에는 필드가 필요 없지만 이 아래에 있는 에프엠은 각각의 변수가 속한 피처 그룹을 필드로 정의합니다. 그래서 이스피에는 이 피처가 퍼블리셔 피처였기 때문에 퍼블리셔 필드라고 정의하였고요."},{"start":1989200,"end":2000500,"text":"이 뒤에 있는 것도 마찬가지로 각각의 피처가 속해 있는 필드를 사용하였습니다. 문제는 뉴메릭 피처인데요. FFM은 모든 변수가 반드시","confidence":0.9443,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1989430,1989580,"이"],[1989580,1989767,"뒤에"],[1989767,1989907,"있는"],[1989907,1990160,"것도"],[1990160,1990720,"마찬가지로"],[1991250,1991620,"각각의"],[1991670,1992020,"피처가"],[1992030,1992340,"속해"],[1992390,1992580,"있는"],[1992830,1993240,"필드를"],[1994650,1995380,"사용하였습니다."],[1996070,1996420,"문제는"],[1996450,1996860,"뉴메릭"],[1996870,1997400,"피처인데요."],[1998270,1998820,"FFM은"],[1998930,1999180,"모든"],[1999290,1999700,"변수가"],[1999810,2000220,"반드시"]],"textEdited":"이 뒤에 있는 것도 마찬가지로 각각의 피처가 속해 있는 필드를 사용하였습니다. 문제는 뉴메릭 피처인데요. FFM은 모든 변수가 반드시"},{"start":2000500,"end":2011600,"text":"어떤 필드에 속해야 하는데요. 실수 피처 같은 경우에는 필드에 할당하기가 다소 부족합니다. 하나의 피처가 0 콤마 1 같은 원 핫 인코딩으로 표현되는 것이 아니라","confidence":0.9122,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2000750,2000980,"어떤"],[2001110,2001560,"필드에"],[2001570,2001947,"속해야"],[2001947,2002340,"하는데요."],[2002990,2003380,"실수"],[2003390,2003680,"피처"],[2003930,2004180,"같은"],[2004180,2004600,"경우에는"],[2005130,2005880,"필드에"],[2006130,2006580,"할당하기가"],[2006580,2006780,"다소"],[2006780,2007260,"부족합니다."],[2007610,2007920,"하나의"],[2007990,2008320,"피처가"],[2008350,2008500,"0"],[2008670,2008900,"콤마"],[2008930,2009080,"1"],[2009170,2009380,"같은"],[2009430,2009580,"원"],[2009580,2009720,"핫"],[2009730,2010280,"인코딩으로"],[2010280,2010660,"표현되는"],[2010660,2010867,"것이"],[2010867,2011160,"아니라"]],"textEdited":"어떤 필드에 속해야 하는데요. 실수 피처 같은 경우에는 필드에 할당하기가 다소 부족합니다. 하나의 피처가 0 콤마 1 같은 원 핫 인코딩으로 표현되는 것이 아니라"},{"start":2011600,"end":2025400,"text":"그냥 하나의 변수의 실수 값을 갖기 때문에 첫 번째 방법은 더미 필드를 사용하는 것입니다. 이 오른쪽에 있는 각각의 피처와 이 값들이 모두 예측 모델에 사용돼야 되는 입력 변수인데요.","confidence":0.9132,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2011810,2011980,"그냥"],[2012070,2012400,"하나의"],[2012630,2013100,"변수의"],[2013190,2013447,"실수"],[2013447,2013740,"값을"],[2013790,2014027,"갖기"],[2014027,2014380,"때문에"],[2015230,2015380,"첫"],[2015410,2015660,"번째"],[2015730,2016080,"방법은"],[2016910,2017240,"더미"],[2017290,2017640,"필드를"],[2017640,2017927,"사용하는"],[2017927,2018340,"것입니다."],[2018490,2018640,"이"],[2018640,2019060,"오른쪽에"],[2019060,2019200,"있는"],[2019210,2019540,"각각의"],[2019570,2019960,"피처와"],[2020130,2020280,"이"],[2020450,2020940,"값들이"],[2021050,2021320,"모두"],[2023130,2023400,"예측"],[2023410,2023700,"모델에"],[2023700,2024140,"사용돼야"],[2024140,2024320,"되는"],[2024410,2024640,"입력"],[2024690,2025240,"변수인데요."]],"textEdited":"그냥 하나의 변수의 실수 값을 갖기 때문에 첫 번째 방법은 더미 필드를 사용하는 것입니다. 이 오른쪽에 있는 각각의 피처와 이 값들이 모두 예측 모델에 사용돼야 되는 입력 변수인데요."},{"start":2025400,"end":2034200,"text":"더미 필드 같은 경우에는 그냥 하나의 변수에 하나의 필드만을 할당하고 그 외에 다른 변수는 이 에알이라는 필드를 사용하지 않습니다.","confidence":0.8829,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2025970,2026240,"더미"],[2026270,2026520,"필드"],[2026520,2026707,"같은"],[2026707,2027120,"경우에는"],[2027490,2027660,"그냥"],[2027670,2028000,"하나의"],[2028090,2028560,"변수에"],[2028710,2029040,"하나의"],[2029930,2030360,"필드만을"],[2030360,2030800,"할당하고"],[2030970,2031120,"그"],[2031130,2031340,"외에"],[2031350,2031560,"다른"],[2031610,2031980,"변수는"],[2032310,2032460,"이"],[2032550,2033080,"에알이라는"],[2033090,2033367,"필드를"],[2033367,2033687,"사용하지"],[2033687,2034140,"않습니다."]],"textEdited":"더미 필드 같은 경우에는 그냥 하나의 변수에 하나의 필드만을 할당하고 그 외에 다른 변수는 이 에알이라는 필드를 사용하지 않습니다."},{"start":2034200,"end":2049000,"text":"즉 피처 1개당 하나의 필드만을 할당하기 때문에 실제로 이 필드는 큰 의미를 가지진 않죠. 그렇기 때문에 더미 필드라고 명명을 하였고요. 두 번째 방법은 이 각각의 실수 피처를","confidence":0.9609,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2035070,2035220,"즉"],[2035310,2035600,"피처"],[2035650,2036020,"1개당"],[2036610,2036920,"하나의"],[2037010,2037460,"필드만을"],[2037490,2038060,"할당하기"],[2038060,2038400,"때문에"],[2038590,2038880,"실제로"],[2038880,2039000,"이"],[2039030,2039400,"필드는"],[2039430,2039580,"큰"],[2039650,2040000,"의미를"],[2040000,2040280,"가지진"],[2040290,2040560,"않죠."],[2041150,2041354,"그렇기"],[2041354,2041580,"때문에"],[2041580,2041860,"더미"],[2041910,2042440,"필드라고"],[2043210,2043580,"명명을"],[2043580,2044020,"하였고요."],[2045370,2045520,"두"],[2045520,2045760,"번째"],[2045790,2046100,"방법은"],[2046870,2047020,"이"],[2047470,2047800,"각각의"],[2047850,2048180,"실수"],[2048190,2048620,"피처를"]],"textEdited":"즉 피처 1개당 하나의 필드만을 할당하기 때문에 실제로 이 필드는 큰 의미를 가지진 않죠. 그렇기 때문에 더미 필드라고 명명을 하였고요. 두 번째 방법은 이 각각의 실수 피처를"},{"start":2049000,"end":2063800,"text":"어떤 n 개의 구간으로 나누는 디스크리타이즈 방법입니다. 그러면 이제 이 실수 값이 n 개의 구간으로 나눠지기 때문에 n 차원의 원핫 인코딩으로 표현될 것이고 그 n 차원의 원핫 인코딩은 총 n개의","confidence":0.9452,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2049250,2049520,"어떤"],[2049950,2050100,"n"],[2050150,2050440,"개의"],[2050470,2050860,"구간으로"],[2050860,2051160,"나누는"],[2051250,2052020,"디스크리타이즈"],[2052020,2052500,"방법입니다."],[2053390,2053640,"그러면"],[2053890,2054060,"이제"],[2054110,2054260,"이"],[2054310,2054600,"실수"],[2054600,2054940,"값이"],[2055130,2055280,"n"],[2055280,2055520,"개의"],[2055530,2055860,"구간으로"],[2055860,2056240,"나눠지기"],[2056240,2056580,"때문에"],[2057430,2057580,"n"],[2057710,2058060,"차원의"],[2058110,2058400,"원핫"],[2058590,2059080,"인코딩으로"],[2059080,2059420,"표현될"],[2059430,2059780,"것이고"],[2060490,2060640,"그"],[2060710,2060860,"n"],[2060950,2061360,"차원의"],[2061910,2062160,"원핫"],[2062160,2062580,"인코딩은"],[2062630,2062780,"총"],[2062870,2063460,"n개의"]],"textEdited":"어떤 n 개의 구간으로 나누는 디스크리타이즈 방법입니다. 그러면 이제 이 실수 값이 n 개의 구간으로 나눠지기 때문에 n 차원의 원핫 인코딩으로 표현될 것이고 그 n 차원의 원핫 인코딩은 총 n개의"},{"start":2063800,"end":2076900,"text":"입력 변수가 되겠죠. 그래서 그 값을 하나의 AR 필드 hidx라는 필드로 매핑하고 그 n개의 변수를 하나의 필드로 사용하여서 FFM 모델링을 수행합니다.","confidence":0.9134,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2064050,2064300,"입력"],[2064330,2064594,"변수가"],[2064594,2064920,"되겠죠."],[2065770,2066000,"그래서"],[2066000,2066140,"그"],[2066150,2066640,"값을"],[2067170,2067460,"하나의"],[2067590,2067880,"AR"],[2067970,2068260,"필드"],[2068930,2069840,"hidx라는"],[2069890,2070280,"필드로"],[2071030,2071580,"매핑하고"],[2072090,2072240,"그"],[2072290,2072680,"n개의"],[2072710,2073140,"변수를"],[2073290,2073560,"하나의"],[2073630,2073980,"필드로"],[2074130,2074660,"사용하여서"],[2074950,2075360,"FFM"],[2075360,2075820,"모델링을"],[2076130,2076620,"수행합니다."]],"textEdited":"입력 변수가 되겠죠. 그래서 그 값을 하나의 AR 필드 hidx라는 필드로 매핑하고 그 n개의 변수를 하나의 필드로 사용하여서 FFM 모델링을 수행합니다."},{"start":2076900,"end":2091900,"text":"그래서 이 두 가지 방법은 모두 정답이 있는 것은 아니고 각 피처가 가진 특징을 적합하게 고려하여서 선택하시면 됩니다. 그래서 논문의 최종 결과입니다. 이 논문에서는 우리가 다루었던","confidence":0.9817,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2077110,2077287,"그래서"],[2077287,2077420,"이"],[2077420,2077507,"두"],[2077507,2077720,"가지"],[2077770,2078080,"방법은"],[2078080,2078280,"모두"],[2078350,2078780,"정답이"],[2078780,2078980,"있는"],[2078980,2079187,"것은"],[2079187,2079480,"아니고"],[2080090,2080240,"각"],[2080350,2080720,"피처가"],[2080720,2080900,"가진"],[2081230,2081600,"특징을"],[2081750,2082300,"적합하게"],[2083390,2083940,"고려하여서"],[2084590,2085180,"선택하시면"],[2085190,2085500,"됩니다."],[2086230,2086500,"그래서"],[2087470,2087840,"논문의"],[2087850,2088100,"최종"],[2088110,2088680,"결과입니다."],[2089930,2090080,"이"],[2090090,2090620,"논문에서는"],[2090630,2090860,"우리가"],[2090870,2091360,"다루었던"]],"textEdited":"그래서 이 두 가지 방법은 모두 정답이 있는 것은 아니고 각 피처가 가진 특징을 적합하게 고려하여서 선택하시면 됩니다. 그래서 논문의 최종 결과입니다. 이 논문에서는 우리가 다루었던"},{"start":2091900,"end":2099700,"text":"4가지 모델을 모두 비교하고 있습니다. 이 LM이 바로 로지스틱 디렉션 기본적인 선형 모델이었고요. 이 폴리 2가","confidence":0.886,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2092230,2092660,"4가지"],[2092710,2093160,"모델을"],[2093230,2093480,"모두"],[2093590,2093967,"비교하고"],[2093967,2094360,"있습니다."],[2094850,2095000,"이"],[2095130,2095540,"LM이"],[2095650,2095840,"바로"],[2095850,2096280,"로지스틱"],[2096290,2096660,"디렉션"],[2096950,2097360,"기본적인"],[2097370,2097600,"선형"],[2097600,2098100,"모델이었고요."],[2098270,2098420,"이"],[2098470,2098760,"폴리"],[2098770,2099040,"2가"]],"textEdited":"4가지 모델을 모두 비교하고 있습니다. 이 LM이 바로 로지스틱 디렉션 기본적인 선형 모델이었고요. 이 폴리 2가"},{"start":2099700,"end":2113400,"text":"두 개의 변수에 대한 상호작용을 강제로 카테시안 프로덕트 형태로 나타내는 것이고 이 뒤에 있는 FM과 FFM은 방금 전에 우리가 배웠던 모델들이죠. 그래서 데이터셋에 따라서 조금씩 다르고 표현형에 따라서 조금 다르긴 하지만","confidence":0.9035,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2099930,2100080,"두"],[2100090,2100400,"개의"],[2100470,2100847,"변수에"],[2100847,2101060,"대한"],[2101350,2101920,"상호작용을"],[2102110,2102500,"강제로"],[2102570,2103060,"카테시안"],[2103060,2103440,"프로덕트"],[2103470,2103800,"형태로"],[2103800,2104147,"나타내는"],[2104147,2104480,"것이고"],[2104810,2104960,"이"],[2104960,2105114,"뒤에"],[2105114,2105260,"있는"],[2105370,2105720,"FM과"],[2106430,2106900,"FFM은"],[2106990,2107167,"방금"],[2107167,2107367,"전에"],[2107367,2107560,"우리가"],[2107560,2107920,"배웠던"],[2108030,2108560,"모델들이죠."],[2109050,2109260,"그래서"],[2109260,2109840,"데이터셋에"],[2110170,2110460,"따라서"],[2110470,2110780,"조금씩"],[2110810,2111220,"다르고"],[2111750,2112100,"표현형에"],[2112100,2112307,"따라서"],[2112307,2112500,"조금"],[2112530,2112840,"다르긴"],[2112850,2113160,"하지만"]],"textEdited":"두 개의 변수에 대한 상호작용을 강제로 카테시안 프로덕트 형태로 나타내는 것이고 이 뒤에 있는 FM과 FFM은 방금 전에 우리가 배웠던 모델들이죠. 그래서 데이터셋에 따라서 조금씩 다르고 표현형에 따라서 조금 다르긴 하지만"},{"start":2113400,"end":2123200,"text":"이제 FM과 FM이 당연히 이 두 모델보다는 좋은 성능을 보이고요. 어떤 데이터셋에 대해서는 FFM이 좋은 성능을 보이지만 그렇지 않은","confidence":0.7134,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2113930,2114120,"이제"],[2114670,2115280,"FM과"],[2115370,2115700,"FM이"],[2115810,2116120,"당연히"],[2116150,2116300,"이"],[2116310,2116460,"두"],[2116510,2116960,"모델보다는"],[2116960,2117120,"좋은"],[2117270,2117620,"성능을"],[2117650,2118060,"보이고요."],[2118870,2119100,"어떤"],[2119150,2119607,"데이터셋에"],[2119607,2119980,"대해서는"],[2120090,2120600,"FFM이"],[2120600,2120760,"좋은"],[2120830,2121100,"성능을"],[2121100,2121460,"보이지만"],[2121750,2122180,"그렇지"],[2122310,2122520,"않은"]],"textEdited":"이제 FM과 FM이 당연히 이 두 모델보다는 좋은 성능을 보이고요. 어떤 데이터셋에 대해서는 FFM이 좋은 성능을 보이지만 그렇지 않은"},{"start":2123200,"end":2135200,"text":"데이터 셋도 있습니다. 이제 그 이유는 어떤 데이터셋은 필드를 사용하여서 명시적으로 피처를 구분하는 것이 별로 도움이 되지 않았을 수 있기 때문입니다. 그래서 FFM은 필드 개수만큼","confidence":0.9532,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2123470,2123727,"데이터"],[2123727,2124000,"셋도"],[2124000,2124360,"있습니다."],[2125270,2125440,"이제"],[2125450,2125600,"그"],[2125610,2125920,"이유는"],[2126470,2126700,"어떤"],[2126710,2127240,"데이터셋은"],[2127490,2127920,"필드를"],[2127930,2128440,"사용하여서"],[2128490,2129000,"명시적으로"],[2129030,2129360,"피처를"],[2129360,2129760,"구분하는"],[2129760,2129980,"것이"],[2129990,2130280,"별로"],[2130710,2131000,"도움이"],[2131000,2131240,"되지"],[2131250,2131640,"않았을"],[2131710,2131860,"수"],[2131970,2132147,"있기"],[2132147,2132660,"때문입니다."],[2133130,2133320,"그래서"],[2133370,2133860,"FFM은"],[2133990,2134260,"필드"],[2134290,2134960,"개수만큼"]],"textEdited":"데이터 셋도 있습니다. 이제 그 이유는 어떤 데이터셋은 필드를 사용하여서 명시적으로 피처를 구분하는 것이 별로 도움이 되지 않았을 수 있기 때문입니다. 그래서 FFM은 필드 개수만큼"},{"start":2135200,"end":2145800,"text":"팩토라이제이션 파라미터가 늘어나기 때문에 필드를 사용하는 것이 적절하지 않을 경우에는 프프엠을 사용했을 때 오히려 오버피팅이나 반대로 언더 피팅이 발생할 수도 있기 때문입니다.","confidence":0.9289,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2135490,2136120,"팩토라이제이션"],[2136120,2136800,"파라미터가"],[2136810,2137207,"늘어나기"],[2137207,2137560,"때문에"],[2138210,2138580,"필드를"],[2138580,2138914,"사용하는"],[2138914,2139140,"것이"],[2139150,2139520,"적절하지"],[2139520,2139740,"않을"],[2139770,2140180,"경우에는"],[2140510,2140980,"프프엠을"],[2140980,2141380,"사용했을"],[2141380,2141520,"때"],[2142350,2142640,"오히려"],[2142690,2143360,"오버피팅이나"],[2143530,2143820,"반대로"],[2143820,2144060,"언더"],[2144070,2144420,"피팅이"],[2144450,2144780,"발생할"],[2144780,2144960,"수도"],[2144960,2145107,"있기"],[2145107,2145660,"때문입니다."]],"textEdited":"팩토라이제이션 파라미터가 늘어나기 때문에 필드를 사용하는 것이 적절하지 않을 경우에는 프프엠을 사용했을 때 오히려 오버피팅이나 반대로 언더 피팅이 발생할 수도 있기 때문입니다."},{"start":2145800,"end":2160400,"text":"그래서 데이터셋에 따라서 FFM이 좋을 때도 있고 FM이 좋을 때도 있다는 점 현업에서 사용하실 때 기억해 두시면 좋을 것 같습니다. 아무튼 결과적으로는 lme 리니어 리그레션 죄송합니다. 로지스틱 리그레션 그리고 폴리 2","confidence":0.9469,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2146250,2146480,"그래서"],[2146480,2146947,"데이터셋에"],[2146947,2147260,"따라서"],[2147850,2148380,"FFM이"],[2148510,2148700,"좋을"],[2148710,2148907,"때도"],[2148907,2149160,"있고"],[2149450,2149760,"FM이"],[2149770,2149960,"좋을"],[2149960,2150180,"때도"],[2150180,2150700,"있다는"],[2150700,2150840,"점"],[2151310,2151720,"현업에서"],[2151720,2152140,"사용하실"],[2152150,2152300,"때"],[2152550,2152827,"기억해"],[2152827,2153100,"두시면"],[2153100,2153280,"좋을"],[2153280,2153400,"것"],[2153400,2153760,"같습니다."],[2154210,2154520,"아무튼"],[2154590,2155200,"결과적으로는"],[2155530,2156460,"lme"],[2156570,2156900,"리니어"],[2156900,2157280,"리그레션"],[2157590,2158000,"죄송합니다."],[2158150,2158520,"로지스틱"],[2158520,2158900,"리그레션"],[2159330,2159580,"그리고"],[2159670,2159900,"폴리"],[2159950,2160100,"2"]],"textEdited":"그래서 데이터셋에 따라서 FFM이 좋을 때도 있고 FM이 좋을 때도 있다는 점 현업에서 사용하실 때 기억해 두시면 좋을 것 같습니다. 아무튼 결과적으로는 lme 리니어 리그레션 죄송합니다. 로지스틱 리그레션 그리고 폴리 2"},{"start":2160400,"end":2171000,"text":"모델보다 FM이나 FM이 좋은 성능을 보이고 있고 특히 CTR 예측 데이터셋 같은 스퍼스 한 데이터셋에서 이런 팩토라이제이션 머신 계열의 모델이","confidence":0.7694,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2160650,2161120,"모델보다"],[2161870,2162280,"FM이나"],[2162350,2162880,"FM이"],[2162890,2163060,"좋은"],[2163170,2163460,"성능을"],[2163460,2163727,"보이고"],[2163727,2164000,"있고"],[2164350,2164620,"특히"],[2165410,2165820,"CTR"],[2165820,2166040,"예측"],[2166040,2166500,"데이터셋"],[2166590,2166880,"같은"],[2167030,2167460,"스퍼스"],[2167460,2167580,"한"],[2167590,2168200,"데이터셋에서"],[2168570,2168740,"이런"],[2168830,2169540,"팩토라이제이션"],[2169570,2169860,"머신"],[2169950,2170340,"계열의"],[2170370,2170760,"모델이"]],"textEdited":"모델보다 FM이나 FM이 좋은 성능을 보이고 있고 특히 CTR 예측 데이터셋 같은 스퍼스 한 데이터셋에서 이런 팩토라이제이션 머신 계열의 모델이"},{"start":2171000,"end":2182000,"text":"굉장히 효율적이면서 뛰어난 예측력을 가지고 있다고 정리할 수 있습니다. 자 마지막 네 번째 파트는 그레디언트 포스팅 머신입니다. CTR 예측에 효과적이라고 알려진","confidence":0.8661,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2171290,2171580,"굉장히"],[2171590,2172300,"효율적이면서"],[2173010,2173360,"뛰어난"],[2173410,2173800,"예측력을"],[2173810,2174140,"가지고"],[2174140,2174520,"있다고"],[2174850,2175220,"정리할"],[2175220,2175360,"수"],[2175360,2175720,"있습니다."],[2176170,2176320,"자"],[2176350,2176640,"마지막"],[2176690,2176840,"네"],[2176840,2177120,"번째"],[2177170,2177520,"파트는"],[2178330,2178800,"그레디언트"],[2178800,2179100,"포스팅"],[2179110,2179680,"머신입니다."],[2180030,2180400,"CTR"],[2180400,2180680,"예측에"],[2180680,2181260,"효과적이라고"],[2181260,2181560,"알려진"]],"textEdited":"굉장히 효율적이면서 뛰어난 예측력을 가지고 있다고 정리할 수 있습니다. 자 마지막 네 번째 파트는 그레디언트 포스팅 머신입니다. CTR 예측에 효과적이라고 알려진"},{"start":2182000,"end":2188400,"text":"그레디언트 부스팅 기법의 원리를 이해하고 대표적인 지비엠 계열의 모델들에 대해서 간단히 리뷰해 보겠습니다.","confidence":0.8573,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2182230,2182700,"그레디언트"],[2182700,2183040,"부스팅"],[2183090,2183440,"기법의"],[2183440,2183720,"원리를"],[2183730,2184140,"이해하고"],[2184610,2185060,"대표적인"],[2185490,2185840,"지비엠"],[2185870,2186180,"계열의"],[2186190,2186667,"모델들에"],[2186667,2186960,"대해서"],[2187050,2187380,"간단히"],[2187410,2187687,"리뷰해"],[2187687,2188300,"보겠습니다."]],"textEdited":"그레디언트 부스팅 기법의 원리를 이해하고 대표적인 지비엠 계열의 모델들에 대해서 간단히 리뷰해 보겠습니다."},{"start":2188400,"end":2198800,"text":"최근에 케이글과 같은 컴퍼티션에도 많이 등장하는 이 그래디언트 부스팅 머신 모델은 다양한 오픈 씨티알 데이터셋에 대해서도 뛰어난 성능을 보이고 있습니다.","confidence":0.8366,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2188670,2189000,"최근에"],[2189170,2189580,"케이글과"],[2189580,2189840,"같은"],[2190190,2190787,"컴퍼티션에도"],[2190787,2190960,"많이"],[2191030,2191480,"등장하는"],[2191610,2191760,"이"],[2191760,2192180,"그래디언트"],[2192180,2192500,"부스팅"],[2192530,2192820,"머신"],[2193130,2193500,"모델은"],[2194190,2194540,"다양한"],[2194690,2194960,"오픈"],[2195450,2195800,"씨티알"],[2195830,2196347,"데이터셋에"],[2196347,2196760,"대해서도"],[2197130,2197500,"뛰어난"],[2197670,2197980,"성능을"],[2197980,2198227,"보이고"],[2198227,2198620,"있습니다."]],"textEdited":"최근에 케이글과 같은 컴퍼티션에도 많이 등장하는 이 그래디언트 부스팅 머신 모델은 다양한 오픈 씨티알 데이터셋에 대해서도 뛰어난 성능을 보이고 있습니다."},{"start":2198800,"end":2212500,"text":"이제 프엠이나 프프엠 같은 계열의 모델을 포함하여서 다른 추천 모델보다도 때로는 높은 예측력을 보이고 있으며 그래서 종종 지비엠을 사용해서 개인화된 추천 모델을 학습하고 사용하는 사례도 있습니다.","confidence":0.8024,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2199510,2199680,"이제"],[2199830,2200280,"프엠이나"],[2200370,2200780,"프프엠"],[2200780,2201020,"같은"],[2201020,2201320,"계열의"],[2201320,2201660,"모델을"],[2201690,2202220,"포함하여서"],[2202790,2203000,"다른"],[2203090,2203340,"추천"],[2203340,2203880,"모델보다도"],[2204270,2204620,"때로는"],[2204630,2204860,"높은"],[2204970,2205400,"예측력을"],[2205400,2205680,"보이고"],[2205680,2205980,"있으며"],[2206590,2206840,"그래서"],[2207070,2207400,"종종"],[2207590,2208140,"지비엠을"],[2208150,2208660,"사용해서"],[2209210,2209660,"개인화된"],[2209710,2209960,"추천"],[2209960,2210220,"모델을"],[2210220,2210620,"학습하고"],[2210690,2211100,"사용하는"],[2211190,2211540,"사례도"],[2211850,2212340,"있습니다."]],"textEdited":"이제 프엠이나 프프엠 같은 계열의 모델을 포함하여서 다른 추천 모델보다도 때로는 높은 예측력을 보이고 있으며 그래서 종종 지비엠을 사용해서 개인화된 추천 모델을 학습하고 사용하는 사례도 있습니다."},{"start":2212500,"end":2224800,"text":"이제 하나의 예시로 하이퍼커넥트의 서비스인 하쿠나 라이브의 사례를 들고 왔습니다. 하쿠나 라이브에서는 기존의 인기도 기반 혹은 휴리스틱 기반의 추천 시스템","confidence":0.9539,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2213790,2213980,"이제"],[2213980,2214240,"하나의"],[2214250,2214600,"예시로"],[2215310,2216140,"하이퍼커넥트의"],[2216170,2216660,"서비스인"],[2216750,2217120,"하쿠나"],[2217120,2217500,"라이브의"],[2217500,2217840,"사례를"],[2217950,2218167,"들고"],[2218167,2218560,"왔습니다."],[2219910,2220260,"하쿠나"],[2220260,2220860,"라이브에서는"],[2221490,2221840,"기존의"],[2222270,2222640,"인기도"],[2222640,2222840,"기반"],[2223050,2223240,"혹은"],[2223290,2223680,"휴리스틱"],[2223680,2224000,"기반의"],[2224030,2224280,"추천"],[2224310,2224640,"시스템"]],"textEdited":"이제 하나의 예시로 하이퍼커넥트의 서비스인 하쿠나 라이브의 사례를 들고 왔습니다. 하쿠나 라이브에서는 기존의 인기도 기반 혹은 휴리스틱 기반의 추천 시스템"},{"start":2224800,"end":2234700,"text":"에서 탈피하여서 이제 더 성능이 좋은 추천 모델을 사용하고자 다양한 모델을 테스트했습니다. 특히 실시간 서비스","confidence":0.9799,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2225010,2225240,"에서"],[2225270,2225840,"탈피하여서"],[2226450,2226620,"이제"],[2226620,2226760,"더"],[2227030,2227360,"성능이"],[2227360,2227540,"좋은"],[2227630,2227880,"추천"],[2227880,2228220,"모델을"],[2228220,2228700,"사용하고자"],[2229390,2229800,"다양한"],[2230250,2230600,"모델을"],[2230610,2231340,"테스트했습니다."],[2232990,2233280,"특히"],[2233650,2234020,"실시간"],[2234050,2234460,"서비스"]],"textEdited":"에서 탈피하여서 이제 더 성능이 좋은 추천 모델을 사용하고자 다양한 모델을 테스트했습니다. 특히 실시간 서비스"},{"start":2234700,"end":2246100,"text":"데이터의 경우 다양한 환경에 의해서 데이터의 특징이 자주 변하기 때문에 비교적 데이터의 특성에 관계없이 하이퍼 파라미터에 민감하지 않은 모델을 사용하고 싶었는데요.","confidence":0.9496,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2234910,2235340,"데이터의"],[2235340,2235580,"경우"],[2236190,2236580,"다양한"],[2236750,2237160,"환경에"],[2237160,2237460,"의해서"],[2237530,2237940,"데이터의"],[2238030,2238360,"특징이"],[2238360,2238560,"자주"],[2238560,2238847,"변하기"],[2238847,2239200,"때문에"],[2239830,2240220,"비교적"],[2240350,2240760,"데이터의"],[2240830,2241120,"특성에"],[2241190,2241800,"관계없이"],[2242710,2243020,"하이퍼"],[2243030,2243640,"파라미터에"],[2243730,2244280,"민감하지"],[2244290,2244500,"않은"],[2244590,2244980,"모델을"],[2245030,2245400,"사용하고"],[2245400,2245920,"싶었는데요."]],"textEdited":"데이터의 경우 다양한 환경에 의해서 데이터의 특징이 자주 변하기 때문에 비교적 데이터의 특성에 관계없이 하이퍼 파라미터에 민감하지 않은 모델을 사용하고 싶었는데요."},{"start":2246100,"end":2253600,"text":"그래서 이 추천 모델링을 위해서 다양한 시티형 예측 모델을 비교한 결과 우리가 잘 알려진 프엠이나 프프엠 계열의 모델","confidence":0.7235,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2246870,2247014,"그래서"],[2247014,2247140,"이"],[2247140,2247400,"추천"],[2247400,2247800,"모델링을"],[2247800,2248060,"위해서"],[2248110,2248460,"다양한"],[2248590,2248940,"시티형"],[2248940,2249200,"예측"],[2249210,2249600,"모델을"],[2249750,2250080,"비교한"],[2250090,2250380,"결과"],[2250990,2251240,"우리가"],[2251240,2251380,"잘"],[2251430,2251720,"알려진"],[2251850,2252240,"프엠이나"],[2252310,2252740,"프프엠"],[2252750,2253100,"계열의"],[2253100,2253340,"모델"]],"textEdited":"그래서 이 추천 모델링을 위해서 다양한 시티형 예측 모델을 비교한 결과 우리가 잘 알려진 프엠이나 프프엠 계열의 모델"},{"start":2253600,"end":2264500,"text":"보다도 그리고 기존에 사용하던 휴리스텍 모델보다도 이 GBM 계열의 모델을 사용했을 때 더 높은 예측 정확도를 보였다는 것을 논문을 통해 발표하였습니다.","confidence":0.9917,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2253870,2254260,"보다도"],[2254630,2254860,"그리고"],[2254870,2255180,"기존에"],[2255180,2255660,"사용하던"],[2255690,2256080,"휴리스텍"],[2256080,2256580,"모델보다도"],[2257090,2257240,"이"],[2257330,2257780,"GBM"],[2257850,2258180,"계열의"],[2258190,2258560,"모델을"],[2258570,2259000,"사용했을"],[2259030,2259180,"때"],[2259290,2259440,"더"],[2259490,2259740,"높은"],[2259850,2260140,"예측"],[2260170,2260620,"정확도를"],[2260620,2261047,"보였다는"],[2261047,2261360,"것을"],[2262890,2263280,"논문을"],[2263280,2263460,"통해"],[2263510,2264240,"발표하였습니다."]],"textEdited":"보다도 그리고 기존에 사용하던 휴리스텍 모델보다도 이 GBM 계열의 모델을 사용했을 때 더 높은 예측 정확도를 보였다는 것을 논문을 통해 발표하였습니다."},{"start":2264500,"end":2273500,"text":"자 그렇다면 그레디언트 부스팅 모델이 무엇인지 알아보기 전에 이 부스팅이라는 단어 이 부스팅이 무엇인지를 알아봅시다.","confidence":0.9342,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2265410,2265560,"자"],[2265560,2265940,"그렇다면"],[2265990,2266520,"그레디언트"],[2266520,2266860,"부스팅"],[2266890,2267220,"모델이"],[2267230,2267700,"무엇인지"],[2267750,2268200,"알아보기"],[2268210,2268600,"전에"],[2269070,2269220,"이"],[2269310,2270060,"부스팅이라는"],[2270090,2270360,"단어"],[2270550,2270700,"이"],[2270700,2271180,"부스팅이"],[2271190,2271780,"무엇인지를"],[2271830,2272360,"알아봅시다."]],"textEdited":"자 그렇다면 그레디언트 부스팅 모델이 무엇인지 알아보기 전에 이 부스팅이라는 단어 이 부스팅이 무엇인지를 알아봅시다."},{"start":2273500,"end":2286000,"text":"부스팅은 앙상블의 일종인데요. 먼저 앙상블이란 한 가지 모델만 사용할 경우 모델에 생기는 예측 오차를 줄이기 위해서 그 모델의 편향을 줄이기 위해서","confidence":0.962,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2274630,2275160,"부스팅은"],[2275290,2275900,"앙상블의"],[2275990,2276500,"일종인데요."],[2277250,2277480,"먼저"],[2277570,2278180,"앙상블이란"],[2278450,2278600,"한"],[2278600,2278880,"가지"],[2278910,2279300,"모델만"],[2279370,2279800,"사용할"],[2279850,2280100,"경우"],[2280790,2281240,"모델에"],[2281310,2281820,"생기는"],[2281990,2282280,"예측"],[2282350,2282760,"오차를"],[2282770,2283080,"줄이기"],[2283080,2283380,"위해서"],[2283650,2283800,"그"],[2283800,2284100,"모델의"],[2284130,2284840,"편향을"],[2284910,2285240,"줄이기"],[2285240,2285540,"위해서"]],"textEdited":"부스팅은 앙상블의 일종인데요. 먼저 앙상블이란 한 가지 모델만 사용할 경우 모델에 생기는 예측 오차를 줄이기 위해서 그 모델의 편향을 줄이기 위해서"},{"start":2286000,"end":2300900,"text":"2개 이상 여러 가지의 모델을 동시에 결합하여서 사용하는 기법입니다. 그래서 부스팅 기법은 다양한 앙상블 기법 중에 하나로 분류되는 것입니다. 그렇다면 어떻게 앙상블을 진행할까요?","confidence":0.898,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2286530,2286860,"2개"],[2286860,2287060,"이상"],[2287190,2287420,"여러"],[2287420,2287800,"가지의"],[2287850,2288300,"모델을"],[2288690,2289100,"동시에"],[2289110,2289740,"결합하여서"],[2289770,2290200,"사용하는"],[2290370,2290920,"기법입니다."],[2291950,2292140,"그래서"],[2292140,2293100,"부스팅"],[2293100,2293440,"기법은"],[2294030,2294340,"다양한"],[2294410,2294840,"앙상블"],[2294910,2295160,"기법"],[2295160,2295380,"중에"],[2295470,2295860,"하나로"],[2296130,2296540,"분류되는"],[2296540,2296940,"것입니다."],[2298170,2298500,"그렇다면"],[2298510,2298860,"어떻게"],[2298970,2299480,"앙상블을"],[2299480,2300000,"진행할까요?"]],"textEdited":"2개 이상 여러 가지의 모델을 동시에 결합하여서 사용하는 기법입니다. 그래서 부스팅 기법은 다양한 앙상블 기법 중에 하나로 분류되는 것입니다. 그렇다면 어떻게 앙상블을 진행할까요?"},{"start":2300900,"end":2311000,"text":"이 의사결정 나무 디시전 트리로 된 위크 러너들을 연속적으로 학습하여 이를 결합하는데요. 여기서 계속 등장하는 이 위크 러너라는 단어는","confidence":0.9625,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2301190,2301340,"이"],[2301350,2301860,"의사결정"],[2301860,2302040,"나무"],[2302150,2302520,"디시전"],[2302550,2302880,"트리로"],[2302880,2303000,"된"],[2304310,2304620,"위크"],[2304620,2305740,"러너들을"],[2305790,2306420,"연속적으로"],[2306470,2306920,"학습하여"],[2307010,2307220,"이를"],[2307230,2307860,"결합하는데요."],[2308590,2308840,"여기서"],[2308840,2309040,"계속"],[2309090,2309480,"등장하는"],[2309490,2309640,"이"],[2309650,2309920,"위크"],[2309930,2310320,"러너라는"],[2310350,2310740,"단어는"]],"textEdited":"이 의사결정 나무 디시전 트리로 된 위크 러너들을 연속적으로 학습하여 이를 결합하는데요. 여기서 계속 등장하는 이 위크 러너라는 단어는"},{"start":2311000,"end":2323700,"text":"정확도와 복잡도가 비교적 낮은 간단한 분류기를 의미합니다. 그래서 먼저 연속적으로 학습한다는 것은 이전 단계의 위클 러너","confidence":0.9375,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2311290,2311820,"정확도와"],[2311990,2312560,"복잡도가"],[2312990,2313380,"비교적"],[2313470,2313740,"낮은"],[2314070,2314540,"간단한"],[2314650,2315400,"분류기를"],[2315510,2316000,"의미합니다."],[2316850,2317040,"그래서"],[2317110,2317340,"먼저"],[2317430,2318160,"연속적으로"],[2319750,2320327,"학습한다는"],[2320327,2320600,"것은"],[2321690,2321940,"이전"],[2322070,2322480,"단계의"],[2322590,2322880,"위클"],[2322910,2323200,"러너"]],"textEdited":"정확도와 복잡도가 비교적 낮은 간단한 분류기를 의미합니다. 그래서 먼저 연속적으로 학습한다는 것은 이전 단계의 위클 러너"},{"start":2323700,"end":2336400,"text":"니가 취약했던 부분을 위주로 해당 데이터를 샘플링해서 다음 단계의 위클 언어를 학습한다는 것입니다. 그래서 이 과정을 계속해서 반복되면은 위클 언어가 한 개가 아니라 여러 개가 생성되겠죠.","confidence":0.9057,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2323910,2324100,"니가"],[2324350,2324840,"취약했던"],[2324890,2325200,"부분을"],[2325200,2325540,"위주로"],[2325930,2326180,"해당"],[2326190,2326600,"데이터를"],[2326630,2327240,"샘플링해서"],[2327690,2327940,"다음"],[2328110,2328600,"단계의"],[2328650,2328900,"위클"],[2328910,2329200,"언어를"],[2329200,2329614,"학습한다는"],[2329614,2330040,"것입니다."],[2330970,2331127,"그래서"],[2331127,2331260,"이"],[2331290,2331620,"과정을"],[2331620,2331940,"계속해서"],[2332010,2332680,"반복되면은"],[2333190,2333480,"위클"],[2333510,2333820,"언어가"],[2334130,2334280,"한"],[2334280,2334454,"개가"],[2334454,2334700,"아니라"],[2334770,2334947,"여러"],[2334947,2335180,"개가"],[2335190,2335760,"생성되겠죠."]],"textEdited":"니가 취약했던 부분을 위주로 해당 데이터를 샘플링해서 다음 단계의 위클 언어를 학습한다는 것입니다. 그래서 이 과정을 계속해서 반복되면은 위클 언어가 한 개가 아니라 여러 개가 생성되겠죠."},{"start":2336400,"end":2344400,"text":"그 여러 개의 위클 러너들에 대해서 인퍼런스를 진행하고 그 인퍼런스를 최종적으로 다 합쳐서 최종 예측 값을 구하게 됩니다.","confidence":0.9709,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2336630,2336780,"그"],[2336790,2337040,"여러"],[2337040,2337260,"개의"],[2337270,2337520,"위클"],[2337520,2337854,"러너들에"],[2337854,2338120,"대해서"],[2338390,2338920,"인퍼런스를"],[2338930,2339380,"진행하고"],[2339910,2340060,"그"],[2340070,2340560,"인퍼런스를"],[2340590,2341020,"최종적으로"],[2341020,2341160,"다"],[2341330,2341820,"합쳐서"],[2342350,2342600,"최종"],[2342650,2342940,"예측"],[2342940,2343280,"값을"],[2343610,2343927,"구하게"],[2343927,2344340,"됩니다."]],"textEdited":"그 여러 개의 위클 러너들에 대해서 인퍼런스를 진행하고 그 인퍼런스를 최종적으로 다 합쳐서 최종 예측 값을 구하게 됩니다."},{"start":2344400,"end":2358300,"text":"그래서 이렇게 여러 개의 위클 러너들을 동시에 한꺼번에 사용해서 예측하는 기법이나 예측하는 모델을 부스팅이라고 합니다. 그래서 부스팅을 기반으로 하는 대표적인 모델은 아다부스트","confidence":0.9637,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2345270,2345467,"그래서"],[2345467,2345700,"이렇게"],[2345730,2345960,"여러"],[2345960,2346180,"개의"],[2346250,2346500,"위클"],[2346500,2346920,"러너들을"],[2346970,2347340,"동시에"],[2347340,2347740,"한꺼번에"],[2347750,2348220,"사용해서"],[2348790,2349260,"예측하는"],[2349330,2349820,"기법이나"],[2349830,2350220,"예측하는"],[2350220,2350580,"모델을"],[2351130,2352400,"부스팅이라고"],[2352450,2352740,"합니다."],[2354530,2354740,"그래서"],[2354750,2355260,"부스팅을"],[2355260,2355680,"기반으로"],[2355680,2355860,"하는"],[2355930,2356360,"대표적인"],[2356370,2356720,"모델은"],[2357330,2358000,"아다부스트"]],"textEdited":"그래서 이렇게 여러 개의 위클 러너들을 동시에 한꺼번에 사용해서 예측하는 기법이나 예측하는 모델을 부스팅이라고 합니다. 그래서 부스팅을 기반으로 하는 대표적인 모델은 아다부스트"},{"start":2358300,"end":2370700,"text":"우리가 배우고 있는 지금 그레디언트 부스팅 머신이 있는데요. 이제 이 그레디언트 부스팅 머신을 발전시킨 모델인 xg 부스트나 라이트 GBM 캣 부스트 같은","confidence":0.945,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2359590,2359840,"우리가"],[2359850,2360087,"배우고"],[2360087,2360240,"있는"],[2360240,2360400,"지금"],[2360490,2361100,"그레디언트"],[2361150,2361480,"부스팅"],[2361480,2362300,"머신이"],[2362300,2362680,"있는데요."],[2363870,2364040,"이제"],[2364040,2364180,"이"],[2364180,2364660,"그레디언트"],[2364690,2365040,"부스팅"],[2365130,2366380,"머신을"],[2366490,2367100,"발전시킨"],[2367550,2367880,"모델인"],[2368150,2368380,"xg"],[2368380,2368760,"부스트나"],[2368760,2369080,"라이트"],[2369090,2369480,"GBM"],[2369710,2369860,"캣"],[2369930,2370260,"부스트"],[2370270,2370520,"같은"]],"textEdited":"우리가 배우고 있는 지금 그레디언트 부스팅 머신이 있는데요. 이제 이 그레디언트 부스팅 머신을 발전시킨 모델인 xg 부스트나 라이트 GBM 캣 부스트 같은"},{"start":2370700,"end":2379400,"text":"것도 많이 있지만 이번 시간에는 주로 그레디언트 부스팅 머신을 위주로 살펴보겠습니다. 그레디언트 부스팅을 살펴봅시다.","confidence":0.9815,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2370950,2371260,"것도"],[2371330,2371540,"많이"],[2371550,2371880,"있지만"],[2372130,2372340,"이번"],[2372370,2372760,"시간에는"],[2373210,2373420,"주로"],[2373430,2373880,"그레디언트"],[2373880,2374160,"부스팅"],[2374170,2374860,"머신을"],[2374890,2375260,"위주로"],[2375730,2376500,"살펴보겠습니다."],[2377730,2378160,"그레디언트"],[2378160,2378700,"부스팅을"],[2378730,2379240,"살펴봅시다."]],"textEdited":"것도 많이 있지만 이번 시간에는 주로 그레디언트 부스팅 머신을 위주로 살펴보겠습니다. 그레디언트 부스팅을 살펴봅시다."},{"start":2379400,"end":2389900,"text":"그레디언트 부스팅이랑 그레디언트 디센트를 사용하여서 노스 펑션이 줄어드는 방향으로 위크 러너드를 반복적으로 결합하는 방법입니다.","confidence":0.954,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2380310,2380760,"그레디언트"],[2380760,2381260,"부스팅이랑"],[2382110,2382620,"그레디언트"],[2382650,2383280,"디센트를"],[2383450,2383980,"사용하여서"],[2384490,2384800,"노스"],[2384830,2385180,"펑션이"],[2385180,2385560,"줄어드는"],[2385610,2386040,"방향으로"],[2387150,2387480,"위크"],[2387530,2388080,"러너드를"],[2388150,2388700,"반복적으로"],[2388730,2389180,"결합하는"],[2389230,2389800,"방법입니다."]],"textEdited":"그레디언트 부스팅이랑 그레디언트 디센트를 사용하여서 노스 펑션이 줄어드는 방향으로 위크 러너드를 반복적으로 결합하는 방법입니다."},{"start":2389900,"end":2404200,"text":"이 로스 펑션이 줄어드는 방향이 바로 negative 그래디언트 방향인데요. 보통 우리가 그래디언트 디센트라는 말을 어디서 많이 들었냐면은 스토캐스트 그레디언트 디센트라는 것을 사용하여서 모델의 학습 파라미터를 업데이트","confidence":0.9608,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2390510,2390660,"이"],[2391010,2391320,"로스"],[2391350,2391660,"펑션이"],[2391660,2392000,"줄어드는"],[2392030,2392320,"방향이"],[2392320,2392560,"바로"],[2392890,2393420,"negative"],[2393430,2394020,"그래디언트"],[2394190,2394680,"방향인데요."],[2395570,2395900,"보통"],[2396130,2396340,"우리가"],[2396350,2396800,"그래디언트"],[2396800,2397340,"디센트라는"],[2397340,2397547,"말을"],[2397547,2397820,"어디서"],[2397820,2397960,"많이"],[2397960,2398500,"들었냐면은"],[2399130,2399780,"스토캐스트"],[2399790,2400200,"그레디언트"],[2400200,2401160,"디센트라는"],[2401160,2401380,"것을"],[2401380,2401880,"사용하여서"],[2402430,2402760,"모델의"],[2402760,2402960,"학습"],[2402960,2403420,"파라미터를"],[2403430,2403880,"업데이트"]],"textEdited":"이 로스 펑션이 줄어드는 방향이 바로 negative 그래디언트 방향인데요. 보통 우리가 그래디언트 디센트라는 말을 어디서 많이 들었냐면은 스토캐스트 그레디언트 디센트라는 것을 사용하여서 모델의 학습 파라미터를 업데이트"},{"start":2404200,"end":2415800,"text":"할 때 배웠던 개념입니다. 근데 이 그레디언트 부스팅은 그레디언트 디센트를 이용해서 학습 파라미터를 업데이트하는 것이 아니라 로스 펑션이 줄어드는 방향","confidence":0.9539,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2404490,2404640,"할"],[2404640,2404780,"때"],[2404780,2405120,"배웠던"],[2405130,2405600,"개념입니다."],[2406730,2406960,"근데"],[2406970,2407120,"이"],[2407120,2407520,"그레디언트"],[2407520,2407960,"부스팅은"],[2408750,2409260,"그레디언트"],[2409270,2409800,"디센트를"],[2409800,2410160,"이용해서"],[2410270,2410520,"학습"],[2410530,2411080,"파라미터를"],[2411090,2411647,"업데이트하는"],[2411647,2411847,"것이"],[2411847,2412120,"아니라"],[2413050,2413360,"로스"],[2413390,2413687,"펑션이"],[2413687,2414060,"줄어드는"],[2414590,2414820,"방향"]],"textEdited":"할 때 배웠던 개념입니다. 근데 이 그레디언트 부스팅은 그레디언트 디센트를 이용해서 학습 파라미터를 업데이트하는 것이 아니라 로스 펑션이 줄어드는 방향"},{"start":2415800,"end":2428300,"text":"으로 위크 러원을 추가한다라는 점에서 완전히 다릅니다. 이 아래 수도 코드를 보시면은 이 세 번째 라인이 그래디언트를 계산하는 수식인데요.","confidence":0.9081,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2417270,2417540,"으로"],[2418070,2418380,"위크"],[2418410,2418720,"러원을"],[2418770,2420080,"추가한다라는"],[2420080,2420400,"점에서"],[2420430,2420760,"완전히"],[2420760,2421140,"다릅니다."],[2422230,2422380,"이"],[2422380,2422560,"아래"],[2422570,2422840,"수도"],[2422840,2423120,"코드를"],[2423120,2423600,"보시면은"],[2424430,2424580,"이"],[2424630,2424780,"세"],[2424790,2425080,"번째"],[2425110,2425500,"라인이"],[2426010,2426620,"그래디언트를"],[2426620,2426980,"계산하는"],[2427090,2427600,"수식인데요."]],"textEdited":"으로 위크 러원을 추가한다라는 점에서 완전히 다릅니다. 이 아래 수도 코드를 보시면은 이 세 번째 라인이 그래디언트를 계산하는 수식인데요."},{"start":2428300,"end":2441600,"text":"스토캐스트 그레디언티티 센터와 다른 점은 이 그레디언트의 분모를 보시면 알 수 있습니다. 이 분모에 파라미터가 아니라 그 학습하는 러너 그 자체 FX가 들어가 있습니다. 즉 FX로","confidence":0.8979,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2428510,2429060,"스토캐스트"],[2429060,2429620,"그레디언티티"],[2429630,2429980,"센터와"],[2429980,2430200,"다른"],[2430200,2430440,"점은"],[2430930,2431080,"이"],[2431080,2431660,"그레디언트의"],[2431710,2432240,"분모를"],[2432930,2433260,"보시면"],[2433260,2433400,"알"],[2433400,2433460,"수"],[2433460,2433800,"있습니다."],[2434250,2434400,"이"],[2434410,2434840,"분모에"],[2434990,2435554,"파라미터가"],[2435554,2435800,"아니라"],[2436490,2436640,"그"],[2436770,2437240,"학습하는"],[2437270,2437580,"러너"],[2438050,2438200,"그"],[2438230,2438520,"자체"],[2438770,2439300,"FX가"],[2439300,2439520,"들어가"],[2439520,2439840,"있습니다."],[2439950,2440100,"즉"],[2440270,2441020,"FX로"]],"textEdited":"스토캐스트 그레디언티티 센터와 다른 점은 이 그레디언트의 분모를 보시면 알 수 있습니다. 이 분모에 파라미터가 아니라 그 학습하는 러너 그 자체 FX가 들어가 있습니다. 즉 FX로"},{"start":2441600,"end":2452000,"text":"이 로스를 미분한 그레디언트를 구하는 것이죠. 그리고 이 그래디언트의 음수를 취한 negative 그래디언트가 새로운 예측값 y 틸드가 되고요.","confidence":0.9186,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2441950,2442100,"이"],[2442100,2442480,"로스를"],[2442480,2442800,"미분한"],[2443030,2443547,"그레디언트를"],[2443547,2443827,"구하는"],[2443827,2444140,"것이죠."],[2445090,2445300,"그리고"],[2445300,2445420,"이"],[2445420,2445960,"그래디언트의"],[2446030,2446520,"음수를"],[2446520,2446760,"취한"],[2446810,2447240,"negative"],[2447240,2448420,"그래디언트가"],[2449790,2450100,"새로운"],[2450170,2450600,"예측값"],[2450750,2450900,"y"],[2451090,2451427,"틸드가"],[2451427,2451760,"되고요."]],"textEdited":"이 로스를 미분한 그레디언트를 구하는 것이죠. 그리고 이 그래디언트의 음수를 취한 negative 그래디언트가 새로운 예측값 y 틸드가 되고요."},{"start":2452000,"end":2461800,"text":"이 와 틸드을 다시 예측하는 새로운 위클러너 치를 학습하게 됩니다. 그래서 이 치가 그다음 위클 러너가 되는 것이죠.","confidence":0.7714,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2452250,2452400,"이"],[2452450,2452600,"와"],[2452890,2453500,"틸드을"],[2453830,2454100,"다시"],[2454130,2454660,"예측하는"],[2454950,2455260,"새로운"],[2456130,2456660,"위클러너"],[2457070,2457920,"치를"],[2458470,2458834,"학습하게"],[2458834,2459120,"됩니다."],[2459230,2459387,"그래서"],[2459387,2459520,"이"],[2459690,2459960,"치가"],[2460190,2460600,"그다음"],[2460710,2460960,"위클"],[2460960,2461220,"러너가"],[2461220,2461420,"되는"],[2461420,2461720,"것이죠."]],"textEdited":"이 와 틸드을 다시 예측하는 새로운 위클러너 치를 학습하게 됩니다. 그래서 이 치가 그다음 위클 러너가 되는 것이죠."},{"start":2461800,"end":2475100,"text":"그래서 그래디언트 포스팅은 로스 펑션이 줄어드는 방향인 negative 그래디언트를 예측해서 위클 언어를 생성한다고 했는데요. 사실 이 말 자체가 굉장히 이해하기 어렵기 때문에 좀 더 쉽게 이해할 수 있도록 설명해 보겠습니다.","confidence":0.9282,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2462490,2462720,"그래서"],[2462720,2463120,"그래디언트"],[2463120,2463500,"포스팅은"],[2463570,2463840,"로스"],[2463850,2464180,"펑션이"],[2464180,2464560,"줄어드는"],[2464560,2464840,"방향인"],[2465330,2465800,"negative"],[2465800,2466380,"그래디언트를"],[2466410,2466920,"예측해서"],[2467570,2467820,"위클"],[2467820,2468080,"언어를"],[2468080,2468527,"생성한다고"],[2468527,2468880,"했는데요."],[2469090,2469300,"사실"],[2469330,2469480,"이"],[2469480,2469620,"말"],[2469710,2470020,"자체가"],[2470070,2470360,"굉장히"],[2470390,2470720,"이해하기"],[2470790,2471140,"어렵기"],[2471140,2471480,"때문에"],[2472170,2472320,"좀"],[2472370,2472520,"더"],[2472770,2473160,"쉽게"],[2473210,2473540,"이해할"],[2473570,2473687,"수"],[2473687,2473980,"있도록"],[2474050,2474367,"설명해"],[2474367,2474900,"보겠습니다."]],"textEdited":"그래서 그래디언트 포스팅은 로스 펑션이 줄어드는 방향인 negative 그래디언트를 예측해서 위클 언어를 생성한다고 했는데요. 사실 이 말 자체가 굉장히 이해하기 어렵기 때문에 좀 더 쉽게 이해할 수 있도록 설명해 보겠습니다."},{"start":2475100,"end":2489100,"text":"통계학적인 관점에서 negative 그래디언트는 실제 값과 예측값의 차이인 레지듀얼이라고 볼 수 있습니다. 즉 그레디언트 부스팅에서 이 윌크 러너가 학습되는 과정은","confidence":0.948,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2476350,2476900,"통계학적인"],[2476970,2477400,"관점에서"],[2478410,2478860,"negative"],[2478860,2479480,"그래디언트는"],[2480270,2480620,"실제"],[2480620,2480940,"값과"],[2480970,2481500,"예측값의"],[2481530,2481860,"차이인"],[2482150,2482940,"레지듀얼이라고"],[2482940,2483080,"볼"],[2483090,2483194,"수"],[2483194,2483580,"있습니다."],[2485030,2485180,"즉"],[2485310,2485880,"그레디언트"],[2485880,2486420,"부스팅에서"],[2486870,2487020,"이"],[2487050,2487360,"윌크"],[2487410,2487740,"러너가"],[2487810,2488220,"학습되는"],[2488270,2488620,"과정은"]],"textEdited":"통계학적인 관점에서 negative 그래디언트는 실제 값과 예측값의 차이인 레지듀얼이라고 볼 수 있습니다. 즉 그레디언트 부스팅에서 이 윌크 러너가 학습되는 과정은"},{"start":2489100,"end":2503500,"text":"바로 이전까지의 레지 듀어를 계산하고 이 레지 듀엣을 예측하는 다음 단계의 위클 러너를 학습하여서 기존 모델에 이를 결합하는 것입니다. 그림을 통해 원리를 쉽게 이해해 봅시다.","confidence":0.9078,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2489410,2489680,"바로"],[2489710,2490420,"이전까지의"],[2490490,2490760,"레지"],[2490760,2492280,"듀어를"],[2492310,2492760,"계산하고"],[2492910,2493060,"이"],[2493070,2493340,"레지"],[2493340,2493740,"듀엣을"],[2493990,2494540,"예측하는"],[2495210,2495440,"다음"],[2495610,2496680,"단계의"],[2496750,2497020,"위클"],[2497020,2497360,"러너를"],[2497870,2498400,"학습하여서"],[2498590,2498820,"기존"],[2498850,2499180,"모델에"],[2499210,2499420,"이를"],[2499470,2499960,"결합하는"],[2499960,2500360,"것입니다."],[2500970,2501320,"그림을"],[2501350,2501600,"통해"],[2501870,2502240,"원리를"],[2502370,2502660,"쉽게"],[2502670,2502887,"이해해"],[2502887,2503220,"봅시다."]],"textEdited":"바로 이전까지의 레지 듀어를 계산하고 이 레지 듀엣을 예측하는 다음 단계의 위클 러너를 학습하여서 기존 모델에 이를 결합하는 것입니다. 그림을 통해 원리를 쉽게 이해해 봅시다."},{"start":2503500,"end":2513600,"text":"좌측에 스와 와이의 학습 데이터가 있고요. 이를 표현하는 큐 펑션이 녹색 곡선처럼 생겼다고 가정합시다.","confidence":0.7446,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2504090,2504580,"좌측에"],[2505350,2505640,"스와"],[2505710,2506080,"와이의"],[2506250,2506500,"학습"],[2506530,2506960,"데이터가"],[2506960,2507240,"있고요."],[2507410,2507660,"이를"],[2507770,2508220,"표현하는"],[2509070,2509220,"큐"],[2509350,2509960,"펑션이"],[2511550,2511860,"녹색"],[2511910,2512460,"곡선처럼"],[2512570,2512960,"생겼다고"],[2512960,2513420,"가정합시다."]],"textEdited":"좌측에 스와 와이의 학습 데이터가 있고요. 이를 표현하는 큐 펑션이 녹색 곡선처럼 생겼다고 가정합시다."},{"start":2513600,"end":2527800,"text":"그럼 우리는 예측 모델을 학습하여서 이 녹색 곡선과 최대한 비슷하게 만들어야 합니다. 먼저 첫 번째 위클 언어인 트리 1을 학습하여서 해당 모델과의 실제 값의 차이인 레지 듀어를 구합니다.","confidence":0.9217,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2513990,2514160,"그럼"],[2514170,2514460,"우리는"],[2514710,2515020,"예측"],[2515030,2515340,"모델을"],[2515350,2515920,"학습하여서"],[2516330,2516480,"이"],[2516490,2516820,"녹색"],[2516870,2517260,"곡선과"],[2517330,2517640,"최대한"],[2517730,2518240,"비슷하게"],[2518310,2518720,"만들어야"],[2518720,2518980,"합니다."],[2519570,2519840,"먼저"],[2519990,2520140,"첫"],[2520150,2520400,"번째"],[2520490,2520800,"위클"],[2520810,2521220,"언어인"],[2521350,2521620,"트리"],[2521620,2521960,"1을"],[2522550,2523140,"학습하여서"],[2523810,2524080,"해당"],[2524130,2524640,"모델과의"],[2524730,2525040,"실제"],[2525590,2526200,"값의"],[2526270,2526640,"차이인"],[2526870,2527087,"레지"],[2527087,2527387,"듀어를"],[2527387,2527780,"구합니다."]],"textEdited":"그럼 우리는 예측 모델을 학습하여서 이 녹색 곡선과 최대한 비슷하게 만들어야 합니다. 먼저 첫 번째 위클 언어인 트리 1을 학습하여서 해당 모델과의 실제 값의 차이인 레지 듀어를 구합니다."},{"start":2527800,"end":2541900,"text":"그래서 이 차이는 레지듀얼이 이렇게 되겠죠. 이제 이 값들을 다음 번 위크 러너에 사용하는데요. 이 레지듀얼을 예측하는 두 번째 트리를 학습하는 것입니다. 그리고 이 차이의 레지듀얼을 다시 구해줍니다.","confidence":0.8975,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2527990,2528154,"그래서"],[2528154,2528280,"이"],[2528330,2528640,"차이는"],[2528640,2529127,"레지듀얼이"],[2529127,2529347,"이렇게"],[2529347,2529680,"되겠죠."],[2530290,2530460,"이제"],[2530470,2530620,"이"],[2530650,2531220,"값들을"],[2532710,2533020,"다음"],[2533090,2533240,"번"],[2533310,2533560,"위크"],[2533590,2534040,"러너에"],[2534190,2534840,"사용하는데요."],[2535510,2535660,"이"],[2535670,2536187,"레지듀얼을"],[2536187,2536600,"예측하는"],[2536770,2536920,"두"],[2536920,2537180,"번째"],[2537230,2537680,"트리를"],[2537770,2538147,"학습하는"],[2538147,2538560,"것입니다."],[2539350,2539560,"그리고"],[2539560,2539680,"이"],[2539750,2540140,"차이의"],[2540370,2540920,"레지듀얼을"],[2540950,2541240,"다시"],[2541240,2541740,"구해줍니다."]],"textEdited":"그래서 이 차이는 레지듀얼이 이렇게 되겠죠. 이제 이 값들을 다음 번 위크 러너에 사용하는데요. 이 레지듀얼을 예측하는 두 번째 트리를 학습하는 것입니다. 그리고 이 차이의 레지듀얼을 다시 구해줍니다."},{"start":2541900,"end":2556500,"text":"그리고 이 레지듀얼을 다시 예측하는 세 번째 위클 러너 트리를 학습합니다. 이렇게 해서 계속해서 반복되면서 트리가 추가되고 레지듀얼은 점점 작아지면서 최종적으로 실제 출 펑션과 굉장히 비슷한","confidence":0.9517,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2542630,2542880,"그리고"],[2542880,2543000,"이"],[2543000,2543580,"레지듀얼을"],[2543650,2543900,"다시"],[2543900,2544300,"예측하는"],[2544390,2544540,"세"],[2544550,2544800,"번째"],[2544830,2545100,"위클"],[2545100,2545280,"러너"],[2545310,2545600,"트리를"],[2545610,2546120,"학습합니다."],[2546730,2546947,"이렇게"],[2546947,2547140,"해서"],[2547150,2547540,"계속해서"],[2547650,2548380,"반복되면서"],[2548910,2549260,"트리가"],[2549290,2549800,"추가되고"],[2550310,2550880,"레지듀얼은"],[2550890,2551140,"점점"],[2551170,2551780,"작아지면서"],[2552410,2552940,"최종적으로"],[2553110,2553620,"실제"],[2554550,2554700,"출"],[2554810,2555200,"펑션과"],[2555250,2555520,"굉장히"],[2555650,2556080,"비슷한"]],"textEdited":"그리고 이 레지듀얼을 다시 예측하는 세 번째 위클 러너 트리를 학습합니다. 이렇게 해서 계속해서 반복되면서 트리가 추가되고 레지듀얼은 점점 작아지면서 최종적으로 실제 출 펑션과 굉장히 비슷한"},{"start":2556500,"end":2571100,"text":"예측 모델이 학습될 것입니다. 그래서 그레디언트 부스팅을 사용하여서 이 리그레션 테스크 즉 회귀 테스크를 수행할 경우에는 방금 설명했던 것처럼 이 위클런의 예측 값으로 레지듀얼을 그대로 활용하고요. 이 레지듀얼이라고 하는 것은","confidence":0.9047,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2556810,2557100,"예측"],[2557110,2557440,"모델이"],[2558130,2558480,"학습될"],[2558480,2558880,"것입니다."],[2559510,2559720,"그래서"],[2559720,2560140,"그레디언트"],[2560140,2560520,"부스팅을"],[2560520,2561040,"사용하여서"],[2561750,2561900,"이"],[2561910,2562340,"리그레션"],[2562370,2562740,"테스크"],[2562910,2563060,"즉"],[2563190,2563440,"회귀"],[2563490,2564000,"테스크를"],[2564070,2564380,"수행할"],[2564390,2564820,"경우에는"],[2565130,2565320,"방금"],[2565350,2565787,"설명했던"],[2565787,2566100,"것처럼"],[2566610,2566760,"이"],[2566810,2567320,"위클런의"],[2567320,2567560,"예측"],[2567560,2567920,"값으로"],[2568190,2568800,"레지듀얼을"],[2568810,2569100,"그대로"],[2569100,2569580,"활용하고요."],[2569790,2569940,"이"],[2569940,2570507,"레지듀얼이라고"],[2570507,2570647,"하는"],[2570647,2570880,"것은"]],"textEdited":"예측 모델이 학습될 것입니다. 그래서 그레디언트 부스팅을 사용하여서 이 리그레션 테스크 즉 회귀 테스크를 수행할 경우에는 방금 설명했던 것처럼 이 위클런의 예측 값으로 레지듀얼을 그대로 활용하고요. 이 레지듀얼이라고 하는 것은"},{"start":2571100,"end":2582500,"text":"실측값에서 예측 값을 뺀 차이를 말하는 것이죠. 그리고 분류 문제 클래시피케이션 테스크에서는 0과 1 사이로 예측하는 것을 어떤 실수로 표현하기 어렵기 때문에","confidence":0.9453,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2571390,2572040,"실측값에서"],[2572050,2572227,"예측"],[2572227,2572460,"값을"],[2572460,2572580,"뺀"],[2572710,2573060,"차이를"],[2573330,2573627,"말하는"],[2573627,2573940,"것이죠."],[2574970,2575180,"그리고"],[2575230,2575520,"분류"],[2575530,2575760,"문제"],[2575830,2576640,"클래시피케이션"],[2576670,2577320,"테스크에서는"],[2578010,2578380,"0과"],[2578430,2578580,"1"],[2578650,2579140,"사이로"],[2579610,2580060,"예측하는"],[2580060,2580300,"것을"],[2580550,2580720,"어떤"],[2580790,2581100,"실수로"],[2581100,2581400,"표현하기"],[2581530,2581847,"어렵기"],[2581847,2582220,"때문에"]],"textEdited":"실측값에서 예측 값을 뺀 차이를 말하는 것이죠. 그리고 분류 문제 클래시피케이션 테스크에서는 0과 1 사이로 예측하는 것을 어떤 실수로 표현하기 어렵기 때문에"},{"start":2582500,"end":2594400,"text":"로그 오즈 값을 사용하여서 레지듀어를 계산합니다. 자 다음의 예제를 통해서 그레디언트 부스팅 모델이 학습되는 과정을 좀 더 잘 이해해 봅시다. 이제 본 문제는","confidence":0.945,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2582850,2583160,"로그"],[2583210,2583520,"오즈"],[2583570,2583940,"값을"],[2584010,2584580,"사용하여서"],[2585370,2585940,"레지듀어를"],[2585940,2586460,"계산합니다."],[2587410,2587560,"자"],[2587610,2588000,"다음의"],[2588010,2588320,"예제를"],[2588320,2588620,"통해서"],[2589490,2589940,"그레디언트"],[2589940,2590240,"부스팅"],[2590240,2590520,"모델이"],[2590520,2590880,"학습되는"],[2590890,2591240,"과정을"],[2591550,2591700,"좀"],[2591700,2591820,"더"],[2591850,2592000,"잘"],[2592050,2592274,"이해해"],[2592274,2592620,"봅시다."],[2593170,2593340,"이제"],[2593350,2593500,"본"],[2593590,2593980,"문제는"]],"textEdited":"로그 오즈 값을 사용하여서 레지듀어를 계산합니다. 자 다음의 예제를 통해서 그레디언트 부스팅 모델이 학습되는 과정을 좀 더 잘 이해해 봅시다. 이제 본 문제는"},{"start":2594400,"end":2608200,"text":"리그레션 테스크를 가정하고 이 리그레션 테스크 문제를 푸는 과정을 설명하였습니다. 그래서 먼저 주어진 데이터가 이렇게 3개 주어진 피처가 3개가 있겠죠.","confidence":0.9227,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2594850,2595320,"리그레션"],[2595350,2596980,"테스크를"],[2597010,2597500,"가정하고"],[2598290,2598440,"이"],[2598440,2598840,"리그레션"],[2598870,2599180,"테스크"],[2599190,2599540,"문제를"],[2599770,2600040,"푸는"],[2600370,2600760,"과정을"],[2600890,2601600,"설명하였습니다."],[2602470,2602680,"그래서"],[2602690,2602960,"먼저"],[2603030,2603400,"주어진"],[2603490,2603960,"데이터가"],[2604030,2604300,"이렇게"],[2604850,2605120,"3개"],[2605750,2606060,"주어진"],[2606130,2606540,"피처가"],[2606690,2607040,"3개가"],[2607050,2607400,"있겠죠."]],"textEdited":"리그레션 테스크를 가정하고 이 리그레션 테스크 문제를 푸는 과정을 설명하였습니다. 그래서 먼저 주어진 데이터가 이렇게 3개 주어진 피처가 3개가 있겠죠."},{"start":2608200,"end":2618600,"text":"이 입력 변수 3개에 대해서 우리는 이 웨이트 값을 예측하는 리그레션 모델을 학습해야 합니다. 첫 번째 스텝 제로 즉 아무런 트리도 없을 때는","confidence":0.9658,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2608570,2608720,"이"],[2608720,2608920,"입력"],[2608950,2609180,"변수"],[2609190,2609540,"3개에"],[2609540,2609900,"대해서"],[2610190,2610460,"우리는"],[2610550,2610700,"이"],[2610730,2611180,"웨이트"],[2611210,2611520,"값을"],[2611520,2611980,"예측하는"],[2612590,2613000,"리그레션"],[2613010,2613360,"모델을"],[2613410,2613820,"학습해야"],[2613820,2614080,"합니다."],[2614970,2615120,"첫"],[2615170,2615440,"번째"],[2615510,2615760,"스텝"],[2615830,2616120,"제로"],[2616630,2616780,"즉"],[2617110,2617400,"아무런"],[2617450,2617760,"트리도"],[2617760,2617960,"없을"],[2617970,2618240,"때는"]],"textEdited":"이 입력 변수 3개에 대해서 우리는 이 웨이트 값을 예측하는 리그레션 모델을 학습해야 합니다. 첫 번째 스텝 제로 즉 아무런 트리도 없을 때는"},{"start":2618600,"end":2630100,"text":"전체 웨이트의 평균값으로 초기 예측 값을 설정합니다. 이것이 트리 제로가 되는데요. 이제 이 트리 제로와 실제 값의 차이가 바로 레지듀얼리입니다.","confidence":0.8399,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2618930,2619400,"전체"],[2619550,2620200,"웨이트의"],[2620350,2621120,"평균값으로"],[2621330,2621580,"초기"],[2621610,2621880,"예측"],[2621890,2622220,"값을"],[2622350,2623000,"설정합니다."],[2623190,2623480,"이것이"],[2623490,2623720,"트리"],[2623730,2624320,"제로가"],[2624320,2624760,"되는데요."],[2625710,2625880,"이제"],[2625880,2626000,"이"],[2626010,2626260,"트리"],[2626290,2626740,"제로와"],[2627570,2627940,"실제"],[2627950,2628240,"값의"],[2628330,2628700,"차이가"],[2628710,2628920,"바로"],[2628950,2629760,"레지듀얼리입니다."]],"textEdited":"전체 웨이트의 평균값으로 초기 예측 값을 설정합니다. 이것이 트리 제로가 되는데요. 이제 이 트리 제로와 실제 값의 차이가 바로 레지듀얼리입니다."},{"start":2630100,"end":2641500,"text":"그래서 이 첫 번째 트리 첫 번째 위클 러너는 이 레지듀얼을 예측하게 되고요. 그래서 그 레지듀얼의 예측 값이 오른쪽에 있습니다. 그래서 이 첫 번째 트리는","confidence":0.9429,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2630730,2631000,"그래서"],[2631410,2631560,"이"],[2631590,2631740,"첫"],[2631750,2632020,"번째"],[2632090,2632360,"트리"],[2632910,2633060,"첫"],[2633060,2633280,"번째"],[2633280,2633467,"위클"],[2633467,2633780,"러너는"],[2633890,2634040,"이"],[2634050,2635320,"레지듀얼을"],[2635320,2635687,"예측하게"],[2635687,2636000,"되고요."],[2636330,2636520,"그래서"],[2636550,2636700,"그"],[2636700,2637180,"레지듀얼의"],[2637180,2637440,"예측"],[2637440,2637800,"값이"],[2638110,2638580,"오른쪽에"],[2638580,2638980,"있습니다."],[2639590,2639780,"그래서"],[2639830,2639980,"이"],[2640150,2640300,"첫"],[2640300,2640520,"번째"],[2640530,2640880,"트리는"]],"textEdited":"그래서 이 첫 번째 트리 첫 번째 위클 러너는 이 레지듀얼을 예측하게 되고요. 그래서 그 레지듀얼의 예측 값이 오른쪽에 있습니다. 그래서 이 첫 번째 트리는"},{"start":2641500,"end":2654800,"text":"실제 레지듀얼 값을 예측할 수 있도록 각각의 트리의 노드에 예측 레지듀얼 값이 적히게 됩니다. 그다음에 이 트리 제로와 트리 1을 합쳐","confidence":0.9392,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2641890,2642160,"실제"],[2642690,2643120,"레지듀얼"],[2643150,2643420,"값을"],[2643420,2643760,"예측할"],[2643790,2643894,"수"],[2643894,2644200,"있도록"],[2644350,2644640,"각각의"],[2644670,2644947,"트리의"],[2644947,2645320,"노드에"],[2645790,2646140,"예측"],[2646290,2646760,"레지듀얼"],[2646830,2647200,"값이"],[2649670,2650027,"적히게"],[2650027,2650320,"됩니다."],[2651890,2652360,"그다음에"],[2652710,2652860,"이"],[2652890,2653160,"트리"],[2653250,2653600,"제로와"],[2653610,2653840,"트리"],[2653840,2654100,"1을"],[2654100,2654380,"합쳐"]],"textEdited":"실제 레지듀얼 값을 예측할 수 있도록 각각의 트리의 노드에 예측 레지듀얼 값이 적히게 됩니다. 그다음에 이 트리 제로와 트리 1을 합쳐"},{"start":2654800,"end":2665900,"text":"합치게 되면은 최종 예측 값이 나오게 되고요. 이 최종 예측값과 원래 실측값을 다시 빼면은 또 다른 레지듀얼 두 번째 레지듀얼이 나오겠죠.","confidence":0.938,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2655230,2655554,"합치게"],[2655554,2655900,"되면은"],[2656690,2656960,"최종"],[2656970,2657240,"예측"],[2657240,2657487,"값이"],[2657487,2657727,"나오게"],[2657727,2658060,"되고요."],[2658870,2659020,"이"],[2659020,2659260,"최종"],[2659260,2659920,"예측값과"],[2660350,2660620,"원래"],[2660670,2661280,"실측값을"],[2661410,2661700,"다시"],[2661730,2662160,"빼면은"],[2662850,2663000,"또"],[2663000,2663200,"다른"],[2663250,2663660,"레지듀얼"],[2663970,2664120,"두"],[2664120,2664340,"번째"],[2664340,2664727,"레지듀얼이"],[2664727,2665180,"나오겠죠."]],"textEdited":"합치게 되면은 최종 예측 값이 나오게 되고요. 이 최종 예측값과 원래 실측값을 다시 빼면은 또 다른 레지듀얼 두 번째 레지듀얼이 나오겠죠."},{"start":2665900,"end":2680300,"text":"이 레지 듀얼을 다시 학습하는 두 번째 트리를 또 학습합니다. 그래서 이 두 번째 레지듀얼이 학습되면은 또 그 차이를 계산해서 세 번째 레지듀얼을 구할 수 있겠죠. 그래서 이 세 번째 레지듀얼이 바로 이 부분이죠.","confidence":0.9285,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2666170,2666320,"이"],[2666330,2666547,"레지"],[2666547,2666960,"듀얼을"],[2667170,2667440,"다시"],[2667490,2667960,"학습하는"],[2668110,2668260,"두"],[2668270,2668540,"번째"],[2668590,2668960,"트리를"],[2669270,2669420,"또"],[2669430,2669920,"학습합니다."],[2671170,2671327,"그래서"],[2671327,2671427,"이"],[2671427,2671560,"두"],[2671560,2671780,"번째"],[2671810,2673300,"레지듀얼이"],[2673300,2673800,"학습되면은"],[2674110,2674260,"또"],[2674270,2674420,"그"],[2674490,2674860,"차이를"],[2675030,2675440,"계산해서"],[2675550,2675700,"세"],[2675700,2675900,"번째"],[2675910,2676360,"레지듀얼을"],[2676360,2676560,"구할"],[2676560,2676634,"수"],[2676634,2676940,"있겠죠."],[2678050,2678194,"그래서"],[2678194,2678287,"이"],[2678287,2678374,"세"],[2678374,2678580,"번째"],[2678580,2679047,"레지듀얼이"],[2679047,2679300,"바로"],[2679350,2679500,"이"],[2679500,2679880,"부분이죠."]],"textEdited":"이 레지 듀얼을 다시 학습하는 두 번째 트리를 또 학습합니다. 그래서 이 두 번째 레지듀얼이 학습되면은 또 그 차이를 계산해서 세 번째 레지듀얼을 구할 수 있겠죠. 그래서 이 세 번째 레지듀얼이 바로 이 부분이죠."},{"start":2680300,"end":2689000,"text":"그래서 이렇게 해서 계속해서 트리를 하나씩 하나씩 학습해서 이 레지듀얼 값을 줄여 나가게 되면은 최종적으로 정확한","confidence":0.9264,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2680990,2681200,"그래서"],[2681200,2681420,"이렇게"],[2681420,2681600,"해서"],[2681630,2682120,"계속해서"],[2682690,2683000,"트리를"],[2683000,2683280,"하나씩"],[2683290,2683560,"하나씩"],[2683570,2683980,"학습해서"],[2684210,2684360,"이"],[2684360,2684780,"레지듀얼"],[2684790,2685100,"값을"],[2685170,2685400,"줄여"],[2685490,2685767,"나가게"],[2685767,2686120,"되면은"],[2686670,2687260,"최종적으로"],[2687850,2688240,"정확한"]],"textEdited":"그래서 이렇게 해서 계속해서 트리를 하나씩 하나씩 학습해서 이 레지듀얼 값을 줄여 나가게 되면은 최종적으로 정확한"},{"start":2689000,"end":2700200,"text":"예측 부스팅 모델을 학습할 수 있습니다. 그래서 n 번째 트리까지 학습한 이후에 언제 멈추냐 손실 함수 즉 로스 펑션 값이 일정 수준 이하이거나","confidence":0.9295,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2689490,2689820,"예측"],[2691030,2691400,"부스팅"],[2691400,2691720,"모델을"],[2691790,2692120,"학습할"],[2692120,2692214,"수"],[2692214,2692540,"있습니다."],[2692630,2692820,"그래서"],[2692850,2693000,"n"],[2693000,2693260,"번째"],[2693260,2693680,"트리까지"],[2693850,2694220,"학습한"],[2694230,2694520,"이후에"],[2695090,2695360,"언제"],[2695430,2695840,"멈추냐"],[2696890,2697160,"손실"],[2697160,2697400,"함수"],[2697450,2697600,"즉"],[2697610,2697880,"로스"],[2697890,2698160,"펑션"],[2698170,2698460,"값이"],[2698530,2698780,"일정"],[2698780,2699000,"수준"],[2699070,2699740,"이하이거나"]],"textEdited":"예측 부스팅 모델을 학습할 수 있습니다. 그래서 n 번째 트리까지 학습한 이후에 언제 멈추냐 손실 함수 즉 로스 펑션 값이 일정 수준 이하이거나"},{"start":2700200,"end":2714100,"text":"마지막 리프 노드 즉 마지막에 위클 러너에 학습했던 그 노드에 속한 데이터 수가 굉장히 적어질 때 멈추게 됩니다. 그래서 몇 번의 학습을 통해서 굉장히 예측 값이 정확해졌음을 확인해 볼 수 있습니다.","confidence":0.9471,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2700450,2700800,"마지막"],[2700910,2701160,"리프"],[2701170,2701420,"노드"],[2701550,2701700,"즉"],[2702050,2702600,"마지막에"],[2702710,2702980,"위클"],[2702980,2703300,"러너에"],[2703310,2703740,"학습했던"],[2704550,2704700,"그"],[2704700,2705100,"노드에"],[2705250,2705520,"속한"],[2705550,2705860,"데이터"],[2705860,2706120,"수가"],[2706370,2706660,"굉장히"],[2706710,2707080,"적어질"],[2707170,2707320,"때"],[2707890,2708307,"멈추게"],[2708307,2708620,"됩니다."],[2709030,2709220,"그래서"],[2709250,2709400,"몇"],[2709400,2709620,"번의"],[2709630,2709940,"학습을"],[2710010,2710300,"통해서"],[2710890,2711220,"굉장히"],[2711290,2711540,"예측"],[2711540,2711860,"값이"],[2712330,2713080,"정확해졌음을"],[2713190,2713454,"확인해"],[2713454,2713580,"볼"],[2713580,2713674,"수"],[2713674,2714020,"있습니다."]],"textEdited":"마지막 리프 노드 즉 마지막에 위클 러너에 학습했던 그 노드에 속한 데이터 수가 굉장히 적어질 때 멈추게 됩니다. 그래서 몇 번의 학습을 통해서 굉장히 예측 값이 정확해졌음을 확인해 볼 수 있습니다."},{"start":2714100,"end":2724900,"text":"레즈 듀얼이 거의 0에 가깝기 때문에 이 정도 학습한 이후에는 이제 더 이상 트리를 생성하지 않고 부스팅이 멈추게 됩니다. 그래서 이 GBM","confidence":0.9241,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2714590,2714814,"레즈"],[2714814,2715140,"듀얼이"],[2715150,2715400,"거의"],[2715400,2715620,"0에"],[2715620,2715927,"가깝기"],[2715927,2716260,"때문에"],[2716710,2716827,"이"],[2716827,2717040,"정도"],[2717040,2717340,"학습한"],[2717340,2717720,"이후에는"],[2717770,2717940,"이제"],[2718210,2718360,"더"],[2718360,2718540,"이상"],[2718550,2718840,"트리를"],[2718840,2719220,"생성하지"],[2719230,2719540,"않고"],[2720190,2720720,"부스팅이"],[2721190,2721587,"멈추게"],[2721587,2721880,"됩니다."],[2723050,2723320,"그래서"],[2723630,2723780,"이"],[2723810,2724200,"GBM"]],"textEdited":"레즈 듀얼이 거의 0에 가깝기 때문에 이 정도 학습한 이후에는 이제 더 이상 트리를 생성하지 않고 부스팅이 멈추게 됩니다. 그래서 이 GBM"},{"start":2724900,"end":2731900,"text":"은 다른 트리 계열의 앙상블 모델 대표적인 랜덤 포레스트가 있는데요. 그 랜덤 포레스트보다 대체적으로 좋은 성능을 보입니다.","confidence":0.9808,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2725190,2725340,"은"],[2725510,2725800,"다른"],[2725870,2726140,"트리"],[2726140,2726440,"계열의"],[2726510,2726900,"앙상블"],[2726910,2727140,"모델"],[2727450,2727800,"대표적인"],[2727870,2728140,"랜덤"],[2728150,2728547,"포레스트가"],[2728547,2728880,"있는데요."],[2729270,2729420,"그"],[2729420,2729660,"랜덤"],[2729660,2730160,"포레스트보다"],[2730290,2730720,"대체적으로"],[2730730,2730900,"좋은"],[2731050,2731360,"성능을"],[2731360,2731720,"보입니다."]],"textEdited":"은 다른 트리 계열의 앙상블 모델 대표적인 랜덤 포레스트가 있는데요. 그 랜덤 포레스트보다 대체적으로 좋은 성능을 보입니다."},{"start":2731900,"end":2744100,"text":"랜덤 포레스트는 앙상블 중에 배깅을 활용한 방법인데요. 같은 디시전 트리 같은 위클 러너를 배깅하는 것보다는 부스팅하는 것이 더 예측 정확도가 뛰어나다고 알려져 있습니다.","confidence":0.8909,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2732190,2732440,"랜덤"],[2732440,2732940,"포레스트는"],[2733250,2733720,"앙상블"],[2733770,2733980,"중에"],[2734050,2734480,"배깅을"],[2734510,2734820,"활용한"],[2734830,2735340,"방법인데요."],[2736150,2736460,"같은"],[2736770,2737140,"디시전"],[2737170,2737420,"트리"],[2737650,2737900,"같은"],[2737970,2738240,"위클"],[2738240,2738540,"러너를"],[2738610,2739027,"배깅하는"],[2739027,2739480,"것보다는"],[2740470,2741060,"부스팅하는"],[2741060,2741300,"것이"],[2741300,2741440,"더"],[2741510,2741820,"예측"],[2741970,2742420,"정확도가"],[2742470,2743000,"뛰어나다고"],[2743000,2743260,"알려져"],[2743260,2743640,"있습니다."]],"textEdited":"랜덤 포레스트는 앙상블 중에 배깅을 활용한 방법인데요. 같은 디시전 트리 같은 위클 러너를 배깅하는 것보다는 부스팅하는 것이 더 예측 정확도가 뛰어나다고 알려져 있습니다."},{"start":2744100,"end":2755600,"text":"하지만 이 그래디언트 부스팅 모델의 문제는 학습 속도가 굉장히 느리다는 것입니다. 순차적으로 계속해서 위클 언어를 학습하기 때문에 학습 속도가 랜덤 프로젝트보다 훨씬 느리게 되고요.","confidence":0.9054,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2744330,2744660,"하지만"],[2744830,2744980,"이"],[2744980,2745380,"그래디언트"],[2745380,2745740,"부스팅"],[2745950,2746260,"모델의"],[2746510,2746920,"문제는"],[2747530,2747800,"학습"],[2747800,2748060,"속도가"],[2748070,2748320,"굉장히"],[2748320,2748647,"느리다는"],[2748647,2749060,"것입니다."],[2749730,2750220,"순차적으로"],[2750270,2750660,"계속해서"],[2750670,2750907,"위클"],[2750907,2751180,"언어를"],[2751180,2751560,"학습하기"],[2751560,2751900,"때문에"],[2752570,2752800,"학습"],[2752810,2753120,"속도가"],[2753770,2754020,"랜덤"],[2754020,2754420,"프로젝트보다"],[2754420,2754680,"훨씬"],[2754680,2754967,"느리게"],[2754967,2755300,"되고요."]],"textEdited":"하지만 이 그래디언트 부스팅 모델의 문제는 학습 속도가 굉장히 느리다는 것입니다. 순차적으로 계속해서 위클 언어를 학습하기 때문에 학습 속도가 랜덤 프로젝트보다 훨씬 느리게 되고요."},{"start":2755600,"end":2768000,"text":"또한 모델이 계속해서 레지 듀얼에 맞게 계속 학습하게 되면은 이제 트레이닝 데이터 즉 학습 데이터에 대해서는 굉장히 잘 피팅하지만 반대로 테스트 데이터에 대해선","confidence":0.9609,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2756450,2756700,"또한"],[2756850,2757220,"모델이"],[2757250,2757700,"계속해서"],[2757770,2758007,"레지"],[2758007,2758400,"듀얼에"],[2758450,2758780,"맞게"],[2759130,2759360,"계속"],[2759430,2759807,"학습하게"],[2759807,2760180,"되면은"],[2760970,2761140,"이제"],[2761750,2762180,"트레이닝"],[2762190,2762480,"데이터"],[2762550,2762700,"즉"],[2762810,2763060,"학습"],[2763070,2763540,"데이터에"],[2763540,2763860,"대해서는"],[2763910,2764240,"굉장히"],[2764270,2764420,"잘"],[2764510,2765060,"피팅하지만"],[2765610,2765960,"반대로"],[2766390,2766740,"테스트"],[2766740,2767220,"데이터에"],[2767220,2767520,"대해선"]],"textEdited":"또한 모델이 계속해서 레지 듀얼에 맞게 계속 학습하게 되면은 이제 트레이닝 데이터 즉 학습 데이터에 대해서는 굉장히 잘 피팅하지만 반대로 테스트 데이터에 대해선"},{"start":2768000,"end":2780800,"text":"취약한 제너럴라이제이션에서는 취약한 모델로 학습될 위험이 있습니다. 즉 오버피팅이 된다는 것이죠. 그래서 이 GBM의 두 가지 문제 오버피팅이 쉽게 되고 학습 속도가 느리다는","confidence":0.9023,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2768310,2768680,"취약한"],[2769250,2770760,"제너럴라이제이션에서는"],[2770790,2771140,"취약한"],[2771150,2771520,"모델로"],[2771590,2771920,"학습될"],[2771930,2772187,"위험이"],[2772187,2772540,"있습니다."],[2772810,2772960,"즉"],[2773030,2773514,"오버피팅이"],[2773514,2773827,"된다는"],[2773827,2774140,"것이죠."],[2775210,2775460,"그래서"],[2775930,2776080,"이"],[2776130,2776620,"GBM의"],[2776650,2776800,"두"],[2776800,2777120,"가지"],[2777550,2777860,"문제"],[2778350,2778940,"오버피팅이"],[2778970,2779187,"쉽게"],[2779187,2779440,"되고"],[2779570,2779800,"학습"],[2779800,2780047,"속도가"],[2780047,2780440,"느리다는"]],"textEdited":"취약한 제너럴라이제이션에서는 취약한 모델로 학습될 위험이 있습니다. 즉 오버피팅이 된다는 것이죠. 그래서 이 GBM의 두 가지 문제 오버피팅이 쉽게 되고 학습 속도가 느리다는"},{"start":2780800,"end":2793700,"text":"단점을 보완한 다른 모델과 라이브러리들이 등장하였습니다. 그래서 이 다음과 같은 세 가지 모델이자 라이브러리가 제일 기본적인 그레디언트 부스팅의 문제점을 해결하였습니다.","confidence":0.9499,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2781090,2781580,"단점을"],[2781630,2782000,"보완한"],[2782330,2782540,"다른"],[2782590,2782960,"모델과"],[2782990,2783680,"라이브러리들이"],[2784330,2785060,"등장하였습니다."],[2786230,2786460,"그래서"],[2786490,2786640,"이"],[2786710,2787080,"다음과"],[2787080,2787280,"같은"],[2787350,2787500,"세"],[2787500,2787720,"가지"],[2787730,2788120,"모델이자"],[2788150,2788780,"라이브러리가"],[2790290,2790520,"제일"],[2790590,2791060,"기본적인"],[2791090,2791520,"그레디언트"],[2791530,2792020,"부스팅의"],[2792030,2792540,"문제점을"],[2792810,2793520,"해결하였습니다."]],"textEdited":"단점을 보완한 다른 모델과 라이브러리들이 등장하였습니다. 그래서 이 다음과 같은 세 가지 모델이자 라이브러리가 제일 기본적인 그레디언트 부스팅의 문제점을 해결하였습니다."},{"start":2793700,"end":2802300,"text":"사실 이 세 가지 모델을 제대로 이해하기에는 각각의 모델의 구현과 난이도가 다소 높기 때문에 지금 당장은","confidence":0.9842,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2794570,2794800,"사실"],[2794810,2794960,"이"],[2794990,2795140,"세"],[2795140,2795380,"가지"],[2795430,2795800,"모델을"],[2795830,2796120,"제대로"],[2796210,2796900,"이해하기에는"],[2797650,2798000,"각각의"],[2798010,2798380,"모델의"],[2798510,2799020,"구현과"],[2799230,2799700,"난이도가"],[2799730,2799960,"다소"],[2799960,2800220,"높기"],[2800220,2800560,"때문에"],[2801050,2801240,"지금"],[2801330,2801720,"당장은"]],"textEdited":"사실 이 세 가지 모델을 제대로 이해하기에는 각각의 모델의 구현과 난이도가 다소 높기 때문에 지금 당장은"},{"start":2802300,"end":2816500,"text":"이런 기법들이 있다 정도로 기억해 주시고, 나중에 이 모델을 직접 사용하게 될 때 해당 모델과 관련 논문에 대해서 자세히 학습드리길 추천드립니다. 그래서 엑스지 부스트 같은 경우에는 익스트 그레디언트 부스팅의 약자로서","confidence":0.9062,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2802610,2802800,"이런"],[2802930,2803400,"기법들이"],[2803450,2803700,"있다"],[2803750,2804080,"정도로"],[2804080,2804367,"기억해"],[2804367,2804700,"주시고,"],[2805190,2805540,"나중에"],[2805570,2805720,"이"],[2805750,2806100,"모델을"],[2806150,2806400,"직접"],[2806410,2806827,"사용하게"],[2806827,2806960,"될"],[2807030,2807180,"때"],[2807390,2807640,"해당"],[2807690,2808080,"모델과"],[2808130,2808340,"관련"],[2808390,2808694,"논문에"],[2808694,2808980,"대해서"],[2809090,2809440,"자세히"],[2809830,2810320,"학습드리길"],[2810330,2810900,"추천드립니다."],[2812270,2812460,"그래서"],[2812460,2812760,"엑스지"],[2812760,2813020,"부스트"],[2813020,2813214,"같은"],[2813214,2813580,"경우에는"],[2814150,2814560,"익스트"],[2814770,2815160,"그레디언트"],[2815160,2815560,"부스팅의"],[2815570,2816140,"약자로서"]],"textEdited":"이런 기법들이 있다 정도로 기억해 주시고, 나중에 이 모델을 직접 사용하게 될 때 해당 모델과 관련 논문에 대해서 자세히 학습드리길 추천드립니다. 그래서 엑스지 부스트 같은 경우에는 익스트 그레디언트 부스팅의 약자로서"},{"start":2816500,"end":2829500,"text":"학습 과정에서의 병렬 처리와 근사 알고리즘을 통해 속도를 굉장히 빠르게 한 라이브러리입니다. 그리고 라이트 GBM 같은 경우에는 마이크로소프트에서 제안한 가벼운 그래디언트 부스팅 머신이고요. 그리고 캡 푸스트 같은 경우에는","confidence":0.9234,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2816830,2817120,"학습"],[2817130,2817580,"과정에서의"],[2817670,2817940,"병렬"],[2818030,2818340,"처리와"],[2818410,2818660,"근사"],[2818690,2819160,"알고리즘을"],[2819160,2819360,"통해"],[2819530,2819860,"속도를"],[2819860,2820120,"굉장히"],[2820150,2820480,"빠르게"],[2820480,2820620,"한"],[2821190,2821840,"라이브러리입니다."],[2822310,2822540,"그리고"],[2822570,2822900,"라이트"],[2822900,2823240,"GBM"],[2823270,2823474,"같은"],[2823474,2823760,"경우에는"],[2823760,2824480,"마이크로소프트에서"],[2824480,2824820,"제안한"],[2825370,2825720,"가벼운"],[2825850,2826260,"그래디언트"],[2826260,2826580,"부스팅"],[2826630,2827200,"머신이고요."],[2827870,2828060,"그리고"],[2828110,2828260,"캡"],[2828310,2828587,"푸스트"],[2828587,2828767,"같은"],[2828767,2829200,"경우에는"]],"textEdited":"학습 과정에서의 병렬 처리와 근사 알고리즘을 통해 속도를 굉장히 빠르게 한 라이브러리입니다. 그리고 라이트 GBM 같은 경우에는 마이크로소프트에서 제안한 가벼운 그래디언트 부스팅 머신이고요. 그리고 캡 푸스트 같은 경우에는"},{"start":2829500,"end":2841500,"text":"이제 피처들 가운데 특히 카테고리컬 피처가 많을 때 이 카테고리컬 피처의 효과적인 알고리즘을 구현하여서 예측 정확도를 높이고 과적합을 방지한 모델입니다.","confidence":0.9244,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2829650,2829820,"이제"],[2829890,2830300,"피처들"],[2830300,2830700,"가운데"],[2830970,2831300,"특히"],[2831590,2832140,"카테고리컬"],[2832170,2832500,"피처가"],[2832500,2832740,"많을"],[2832790,2832940,"때"],[2833270,2833420,"이"],[2833510,2834040,"카테고리컬"],[2834070,2834880,"피처의"],[2834880,2835300,"효과적인"],[2835330,2835860,"알고리즘을"],[2836330,2836900,"구현하여서"],[2837770,2838120,"예측"],[2838390,2838820,"정확도를"],[2838820,2839200,"높이고"],[2839330,2839940,"과적합을"],[2840110,2840520,"방지한"],[2840890,2841500,"모델입니다."]],"textEdited":"이제 피처들 가운데 특히 카테고리컬 피처가 많을 때 이 카테고리컬 피처의 효과적인 알고리즘을 구현하여서 예측 정확도를 높이고 과적합을 방지한 모델입니다."},{"start":2841500,"end":2856405,"text":"네 이상 GBM에 대한 강의까지 모두 마쳤고 여덟 번째 강의를 모두 마무리하였습니다. 모두 수고하셨습니다.","confidence":0.7667,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[2842070,2842220,"네"],[2842220,2842460,"이상"],[2842690,2843207,"GBM에"],[2843207,2843400,"대한"],[2843490,2843920,"강의까지"],[2843920,2844100,"모두"],[2844110,2844560,"마쳤고"],[2844930,2845200,"여덟"],[2845200,2845440,"번째"],[2845450,2845760,"강의를"],[2845950,2846200,"모두"],[2846310,2847100,"마무리하였습니다."],[2847830,2848060,"모두"],[2848110,2848780,"수고하셨습니다."]],"textEdited":"네 이상 GBM에 대한 강의까지 모두 마쳤고 여덟 번째 강의를 모두 마무리하였습니다. 모두 수고하셨습니다."}],"text":"안녕하세요. 추천 시스템 강의를 맡고 있는 강사 이준원입니다. 이번 시간은 여덟 번째 강의 컨텍스트의 레코멘데이션이라는 이름으로 진행하겠습니다. 기본적으로 추천 시스템 분야는 유저와 아이템 사이의 상호 작용을 모델링하는 컬라버레이트 필터링으로부터 시작한 모델들이 주를 이룹니다. 하지만 이번 시간에는 유저 아이템, 아이디 피처 외에 다양한 부가 정보 즉 컨텍스트 정보를 풍부하게 활용하여 추천을 제공하는 모델들을 위주로 살펴보겠습니다. 네 먼저 컨텍스트 어여 레코멘데이션 문제가 무엇이고 어떤 분야에 활용되는지 주로 어떤 데이터를 사용하여서 모델링을 하는지 살펴봅시다. 다음으로 콘텍스트 어여 레코멘데이션 가운데 대표적인 문제인 CTR 프리딕션 문제 사용되는 이 FM 팩토라이제이션이 머신과 필드어의 팩토라이제이션 머신 FFM의 모델에 대해서 학습합니다. 이 FM과 FFM 모델은 딥러닝이 등장하기 전에 이 분야에서 가장 뛰어난 성능을 보인 머신러닝 모델이고요. 지금 현재도 현업에서 활발하게 사용되고 있습니다. 마지막으로 CTR 예측 문제를 포함하여서 그 외에 다양한 컴퍼티션에서 다양한 캐글 컴퍼티션에서 좋은 성능을 내고 있는 그레디언트 부스팅 머신에 대해서 다뤄보겠습니다. 첫 번째 컨텍스트의 레코멘데이션이 무엇인지 앞에서 다룬 컬래버이트 필터링과 어떻게 다른지를 이해하고 이 테스크가 어떠한 양상으로 발전해 왔는지를 간단하게 살펴보겠습니다. 컨텍스트와 레코멘데이션 문제를 정의하기 이전에 우리가 지금까지 추천 시스템에서 사용했던 데이터는 크게 세 가지로 분류할 수 있습니다. 유저 정보와 아이템 정보 그리고 유저와 아이템의 상호작용 정보 있죠? 우리가 지난 7강까지 학습했던 모델들은 주로 유저의 아이디와 아이템 아이디 정보를 사용하고 그 외에 유저와 아이템의 상호작용 정보를 주로 잘 사용해서 이 모델에 반영하는 컬라버레이트 필터링 기반의 모델이었습니다. 그래서 유저와 아이템의 고유한 아이디 외에 다른 이런 성별이나 연령이라든지 혹은 아이템의 적혀 있는 카테고리나 출시 연도 같은 유저 아이템의 메타 데이터 정보는 사용하지 않거나 혹은 사용하기 어려운 모델들이 주로 많았습니다. 가장 대표적인 CF 컬라버레이트 필터링 모델인 MF 매트리스 팩토라이제이션 모델이죠. 이것을 학습하기 위한 학습 데이터를 기억해 봅시다. 이 유저의 데모 그래픽 혹은 아이템의 카테고리와 같은 정보들 풍부한 정보들이 존재함에도 불구하고 이러한 특성들을 사용할 수 없었습니다. 왜냐하면 매트릭스 팩토라이제이션은 유저와 아이템으로 이루어진 유저 아이템 매트릭스 데이터를 가지고 학습 데이터를 활용했기 때문에 그 외에 다른 정보들은 사용할 수가 없는 모델이었죠. 이와 같이 이 MF의 학습 데이터는 오로지 유저가 어떤 아이템을 소비했다라는 상호작용 데이터만으로 구성되는데요. 이 경우에 상호 작용 정보가 아직 부족하거나 혹은 아예 데이터가 없는 유저 아이템에 대해서 이 엠프 추천 모델을 사용할 경우 좋은 추천을 제공하기가 어렵습니다. 그래서 이러한 문제를 콜드 스타트라고 하는데요. 이제 이 엠프와 같은 모델들은 콜드 스타트에 대한 대처가 어려운 부분이 있죠. 그래서 컨텍스트 어어 레코멘데이션은 유저 아이디 혹은 아이템 아이디 말고 그 유저가 가지고 있는 혹은 아이템이 가지고 있는 다양한 특성들을 추천 시스템에 오히려 반영할 수 있게 발전돼 왔습니다. 컨텍스트 기반 추천 시스템의 경우 유저와 아이템의 상호작용 정보는 가장 중요하기 때문에 당연히 필수적으로 사용하지만 그뿐만이 아니라 해당 상호작용이 일어났던 맥락적 정보 컨텍스트 정보를 함께 사용합니다. 여기서 이 컨텍스트라는 단어 안에는 유저의 부가 정보와 아이템의 부가 정보도 들어가고요. 유저와 아이템 정보 외에 그 추천이 일어났던 그 아이템의 소비가 일어났던 당시의 시간이나 공간적 정보 같은 다양한 정보들이 다 컨텍스트라는 단어로 표현됩니다. 그래서 이 컨텍스트 정보는 서비스와 데이터마다 모두 형태와 사용되는 종류가 다르기 때문에 그러한 피처들을 모두 담을 수 있는 제너럴한 모델이 설계되어야 합니다. 따라서 기존의 CF 기반의 추천 모델이 해결하는 문제와 접근 방법이 달라지고 그에 따라서 데이터를 구성하는 방법도 달라지게 됩니다. 가장 큰 차이점은 유저 아이템 매트릭스의 빈 공간을 채우는 게 아니라 다음과 같이 주어진 x에 대해서 y 값을 추론하는 우리가 보통 일반적인 예측 문제를 접근할 때 어떤 x가 주어지고 그 x에 대한 y 값을 예측하는 문제로 풀게 되죠. 그래서 이런 식의 데이터로 구성을 해야 한다는 것입니다. 이제 아래 데이터가 방금 전 슬라이드의 유저와 아이템 매트릭스의 데이터와 같은 데이터인데요. 이 하나의 로우가 하나의 데이터 포인트가 됩니다. 즉 유저 3이라는 사람이 아이템 1을 소비하고 그 외에 다른 컨텍스트 피처들이 있을 때 그때의 선호도는 3점 이다. 즉 x는 유저와 아이템과 컨텍스트로 이루어져 있고 y는 레이팅을 예측하는 것이죠. 그래서 이러한 형태는 보통 제너럴한 프리딕터의 모델 구조 가 됩니다. 그래서 원하는 만큼 유저 아이템 컨텍스트 그 컨텍스트가 하나가 아니라 되게 다양한 피쳐들이 있을 수 있겠죠. 내가 원하는 만큼 모델을 만드는 사람이 원하는 만큼 컨텍스트 피처를 옆으로 붙일 수 있고요. 그래서 이러한 피쳐를 통해서 결국에 최종 예측하는 값은 유저의 상호작용 정보인 웨이팅이 됩니다. 네 이제 이러한 컨텍스터 레코멘데이션 줄여서 car 이라고 불리는 테스크의 대표적인 분야는 CTR 예측 도메인입니다. 이 CTR 예측 문제는 유저가 해당 아이템이 주어졌을 때 그 아이템을 클릭할 확률을 예측하는 문제입니다. 추천 시스템에서 이제 온라인 에이비 테스트를 한다고 했을 때 가장 많이 사용되는 지표가 매출 혹은 CTR이라고 첫 번째 강의에서 언급했었습니다. 사실 매출이라는 지표는 추천 외에도 다른 요인이 굉장히 많기 때문에 보통 추천 시스템을 적용했을 때 좋아졌다 좋아지지 않았다라는 것을 평가하기 위한 지표는 CTR을 많이 사용합니다. 그 말은 추천 후보 아이템의 예측 CTR이 높은 것을 잘 추천해 준다면은 그에 따른 CTR이 상승할 수 있다는 것이죠. 따라서 추천 시스템에서는 CF 기반의 모델도 사용하지만 CTR 예측 모델을 사용한 추천 시스템도 굉장히 많이 사용하고 있습니다. 그래서 CTR 예측 문제는 예측해야 하는 y 값이 클릭을 했냐 안 했냐 0과 1이기 때문에 바이너리 클래시피케이션 문제라고 볼 수 있습니다. 근데 우리가 원하는 값은 0이냐 1이냐가 아니라 클릭할 확률이기 때문에 0과 1 사이의 확률로 아이템의 CTR이 출력되어야 합니다. 그래서 예측 모델을 다 만든 이후에 그 출력 값을 최종적으로 시그모이드 함수에 통과시켜서 0과 1 사이의 값으로 출력되게 하고요. 그 값이 곧 예측 CTR 값이 됩니다. 이 CTR 예측은 주로 광고 추천에서 가장 많이 사용되는데요. 광고 추천을 잘하면 광고주로부터 돈을 많이 받기 때문에 바로 돈이 됩니다. 그래서 광고 추천이 굉장히 많이 연구되었고 또 중요한 분야 중에 하나가 되었습니다. 이제 광고가 노출된 상황에 다양한 유저 광고 컨텍스트 피처가 존재하고 이 다양한 피처들을 위치하게 사용하여서 씨티알 예측의 정확도를 높이는 테스크가 많이 이루어지고 있습니다. 어떠한 데이터 같은 경우에는 유저 아이디가 아예 존재하지 않는 데이터도 있는데요. 우리가 지금 콜라보레이트 필터링 문제를 푸는 것이 아니기 때문에 유저 아이디가 존재하지 않더라도 다른 유저 피처나 컨텍스트 피처를 사용하여서 해당 아이템의 씨티알을 예측할 수 있습니다. 현업에서는 실제로 유저 아이디를 피처로 사용하지 않는 경우가 광고 추천에서는 굉장히 잦은 일입니다. 네 다음은 가장 기본적인 CTR 예측 모델인 로지스틱 리그레션을 간단하게 언급하고 넘어가겠습니다. 기본적인 선형 모델에다가 시그모이드를 씌운 모델인데요. 이제 우리가 정의한 유저 아이템 컨텍스트 피처들은 이 x아라는 입력 변수로 사용되게 되고 이제 입력 변수에 대한 선형 모델링을 통해서 클릭 예측 확률을 예측하는 가장 기본적인 로지스틱 리액션 모델이 있습니다. 이제 앞으로 배울 다양한 CTR 예측 모델 앞으로 FM이나 FFM 그리고 이 다음 아홉 번째 강의인 딥 CTR 모델 들이 다 이 로지스틱 리그레션으로부터 발전된 것을 기억해 두시기 바랍니다. 이 수식을 보면 로지스틱 리그레션은 어떤 변수 간의 상호 작용을 전혀 모델링 할 수 없습니다. 즉 유저 정보와 아이템 정보 간의 다양한 상호 작용 이 모델에 반영되지 않는다는 것인데요. 추천 모델에서는 그 피처들 간의 상호작용을 모델에서 반영하는 것이 사실 추천 모델뿐만이 아니라 모든 머신 러닝 모델에 대해서는 피처 간의 상호작용을 반영하는 것이 굉장히 중요하기 때문에 단순하게 이렇게 선형 모델 즉 로지스틱 리그레션만 사용하게 된다면은 예측 성능이 굉장히 떨어지게 됩니다. 따라서 아래와 같이 강제로 두 개의 변수를 상호작용을 만들어서 이 상호작용을 카테시안 프로덕트라고 하는데요. 카테시안 프로덕트를 만들어 가지고 강제로 두 개의 변수 상호작용을 w아제라는 파라미터로 학습하게 합니다. 이것을 폴리노미얼 모델이라고 하는데요. 즉 1차 항 말고 2차 이상의 항이 존재한다는 것을 의미합니다. 가장 큰 이 모델의 취약점은 파라미터 수가 급격하게 증가한다는 점입니다. 세컨오더 폴리노미얼 모델만 확인해도 파라미터 수가 엔 곱하기 n 즉 n의 제곱 배로 증가하게 되는데요. 그래서 이러한 상호작용을 단순하게 카테시안 프로덕트로 표현하는 것은 한계가 있습니다. 그래서 이 한계를 극복한 모델이 우리가 이후에 배울 프엠과 프프엠이고 이 프엠과 프엠의 모델에 대한 자세한 내용은 이 뒤에 있는 파트에서 다루겠습니다. 자 그렇다면 씨티알 예측 모델에는 다양한 유저 아이템 컨텍스트 피처 등을 사용할 수가 있는데요. 이제 이러한 피처들은 보통 두 가지 분류로 나눌 수가 있습니다. 첫 번째는 댄스 피처인데요. 벡터로 표현했을 때 비교적 작은 공간에 밀집되어 분포하는 수치형 변수를 의미합니다. 유저가 아이템에 매긴 절대 평점 1점부터 5점까지 있는 평점을 피처로 사용한다면 댄스한 피처가 될 수 있고요. 그리고 어떤 수치로 나타날 수 있는 다른 기온이나 시간과 같은 정보도 수치형 벡터 댄스한 피처가 되겠죠. 그와 그의 반대로 스파스한 피처 벡터로 표현했을 때 비교적 넓은 공간에 분포하는 피처가 스퍼스 피처입니다. 사실 이 두 개념은 여러분들이 앞선 강의에서도 충분히 많이 배웠을 텐데요. 유저의 아이템의 아이디 같은 경우라든지 혹은 요일이나 뭐 키워드 태그 같은 정보들이 다 스프레스한 피처입니다. 요일과 같은 경우에는 월요일부터 일요일까지 총 7개의 공간이 있기 때문에 수요일 금요일이 다음과 같이 원핫 인코딩으로 표현될 수가 있고요. 이제 키워드나 태그 같은 경우에는 아이템 하나가 1개가 아닌 2개 이상의 키워드나 태그를 가질 수도 있죠. 따라서 이 경우에는 멀티샷 인코딩으로 표현되긴 하지만 여전히 그 그 피처는 스퍼스 한 피처입니다. 이제 이 두 개의 피처를 봤을 때 씨티알 예측 문제에서 가장 많이 사용되는 피처는 이 위에 댄스 피처가 아니라 대부분 스퍼스 피처입니다. 다음 공개되어 있는 씨티알 예측 모델링을 위한 데이터를 살펴봅시다. 이제 이 데이터를 살펴보면 대부분의 피처가 스퍼스 한 피처라는 것을 알 수 있는데요. 이 하나하나의 컬럼이 피처를 의미합니다. 이제 공개 데이터 셋이기 때문에 모두 암호화가 된 해시 값으로 이루어져 있긴 하지만 이 전체 데이터 가운데 전체 피처 가운데 파란색으로 씌워져 있는 모든 피처들은 다 카테고리컬 데이터 즉 스파스한 피처로 나타나야 한다는 것입니다. 뭐 사이트의 아이디라든지 광고가 노출된 도메인 같은 것들은 다 스트링 값이고 이 스트링 값을 모델의 입력 변수를 사용하기 위해서는 보통 원핫 인코딩으로 표현해야 하기 때문에 각각의 피처들은 다 스프레스 한 피처로 표현되게 됩니다. 그래서 CTR 예측 문제의 데이터를 모두 다 원핫 인코딩만으로 표현하여서 모델링을 할 경우에는 학습 파라미터 수가 그 차원의 개수만큼 생기기 때문에 아주 많아질 수 있고, 학습 데이터에 등장하는 빈도에 따라서 특정 카테고리나 특정 피처는 과적합되거나 즉 오버 피팅 되거나 언더피팅 될 수 있습니다. 이를 막기 위해서 원아 인코딩을 보통 그대로 사용하지 않고 피처 인베딩을 합니다. 이 인베딩도 사실 이전 시간에 굉장히 많이 배웠죠. 우리가 5강에서 배웠던 아이템 투 백이나 혹은 자연어 처리에 사용되는 LDA와 같은 토픽 모델링이나 혹은 이제 버트와 같은 프리트 랭귀지 모델의 인베딩도 다 피처를 임베딩하는 기법이고 이 인베딩을 CTR 예측 모델의 피처 데이터로 사용할 수 있습니다. 그래서 우리가 앞으로 배울 CTR 모델 공통점이 있는데요. 첫째로는 스퍼스 한 피쳐를 인베딩을 통해 잘 표현하는 것 인베딩, 둘째로는 이 스프레스 한 피처들 간의 상호작용을 모델 설계에서 고려한다는 점입니다. 상호작용은 인터랙션이 되겠죠. 그래서 이 두 가지를 어떻게 모델에서 잘 표현할 것인가를 생각하시면서 이 이후의 내용들을 배우시면 크게 도움이 될 것입니다. 그래서 간단하게 컨텍스트 레코멘데이션 추천 알고리즘의 변천사를 살펴보면은 먼저 딥러닝 이전 AI에서는 로지스틱 리그레션과 SVM 모델이 등장하였고요. 그 이후에 매트리스 팩토라이제이션과 함께 추천 시스템 연구 분야가 크게 발전하였습니다. 그다음에 이제 컨텍스트의 레코멘데이션이라는 개념이 등장하고 전통적인 머신 러닝 모델들과 인베딩을 결합한 기법들이 많이 사용되었습니다. 이제 그 이후에 우리가 배울 팩토라이제이션 머신과 필드 어이어 팩토라이제이션 머신이 출연하였고 이 두 가지 모델에 대해서 자세히 살펴보겠습니다. 네 이번 파트는 팩토라이제이션 머신 모델과 해당 논문에 대해서 리뷰하겠습니다. 이 FM 모델의 등장 배경과 장점을 이해하고 그 원리가 어떻게 작동하는지 살펴보겠습니다. 팩토라이제이션 머신은 2010년에 동일한 이름의 논문을 통해 발표된 모델입니다. 당시 ML 모델 가운데 가장 많이 사용되었던 이 SVM과 MF와 같은 팩토라이제이션 모델의 장점을 결합한 논문입니다. 이 팩토라이제이션 모델의 대표적인 모델이 바로 아까 4강에서 배웠던 지난 4강에서 배웠던 MF입니다. 먼저 FM의 등장 배경입니다. 이 딥러닝이 등장하기 전에는 서포트 벡터 머신이 가장 ML 분야에서 많이 사용되는 모델 중에 하나였습니다. 커널 공간을 사용한 논 리니어 데이터셋에 대해서 이 SVM이 가장 높은 성능을 보였습니다. 모델링을 하기에 가장 어려운 게 이런 비선형 데이터 셋이었는데요. 랜덤 플러스 같은 모델도 괜찮은 성능을 그 당시에 냈지만 SVM 즉 커너를 사용한 SVM이 당시에 가장 좋은 성능을 보였습니다. 이제 그럼에도 불구하고 콜라버레이트 필터링 환경에서는 MF 계열의 모델이 SVM보다 더 좋은 성능을 내왔습니다. 이 CF 문제 CF 환경이라는 것은 앞에서 많이 다루었는데요. 유저 아이템에 대한 평점을 예측하는 것입니다. 이 CF 환경은 유저 아이템이 굉장히 개수가 많기 때문에 굉장히 스퍼스한 데이터로 이루어져 있고 이런 스파이스한 데이터는 SVM이 좋은 성능을 내지 못하는 분야였습니다. 하지만 MF 모델은 여러분들이 잘 아시다시피 특별한 환경과 특별한 데이터에 대해서만 적용할 수 있는데요. 그 특별한 환경이랑 아 아래와 같이 주어진 스가 유저 아이템일 때 예측해야 되는 것이 레이팅 이렇게 구성된 데이터를 말하고요. 이 데이터에 대해서만 엠프 모델링이 가능했습니다. 그래서 본 논문 팩토라이제이션 머신이라는 논문은 SVM과 MF 모델의 장점을 결합할 수 없을까라는 아이디어에서 시작했습니다. 자 그래서 다음은 FM 모델의 수식을 나타냈습니다. 먼저 입력 변수는 x1부터 xn 총 n개의 변수가 존재하고요. 이 FM에서 학습하는 파라미터는 먼저 글로벌 바이어스가 있고요. 그리고 각각의 변수마다 대응되는 1차 파라미터 WI가 존재합니다. 그리고 제일 중요한 부분이 바로 이 두 번째 텀 팩토라이제이션 텀입니다. 여기서 학습하는 파라미터는 VI와 VJ이고 이 VI와 VJ는 스칼라 값이 아니라 k 차원의 벡터로 이루어진 파라미터입니다. 그래서 XI와 xj가 상호작용을 할 때 그 XI에 해당되는 VI x 제에 해당되는 VJ가 각각 곱해져서 상호작용 즉 피처 간의 상호작용을 모델링하고 있습니다. 이 둘의 곱은 스칼라 곱 즉 내적을 의미합니다. 이제 이 수식과 앞서 다루었던 로지스틱 리그레션을 비교해 보도록 하겠습니다. 이 아래에 있는 수식이 로지스틱 리그레션의 수식인데요. 앞에 있는 이 부분이 로지스틱 리그레션과 동일함을 알 수 있습니다. 그런데 팩토라이제이션 머신은 뒤에 두 피처의 상호작용을 표현할 수 있는 팩토라이제이션 텀이 추가된 것이죠. 로지스틱 리그레션은 아까 설명한 대로 두 피처의 상호 작용을 모델링 할 수 없다고 말씀드렸습니다. 자 그리고 두 피처의 상호 작용을 강제로 카테시안 프로덕트를 만들어 가지고 이 wij라는 파라미터를 정의한 모델이 바로 이 폴리노미얼 모델이었습니다. 이제 이 두 수식을 비교해 보면은 이 앞에 있는 글로벌 바이어스와 1차 텀은 동일하지만 두 상호작용을 모델링하는 텀이 달라짐을 알 수 있습니다. 이 폴리노미 모델은 XI와 xj의 상호작용을 wij라는 하나의 파라미터로 표현했다면은 FM 같은 경우에는 XI와 xj의 상호작용을 각각 VI와 v제 즉 k 차원의 팩토라이제이션 파라미터로 표현하여서 좀 더 일반화시켰습니다. 자 그렇다면 이 FM 모델을 가지고 스파스한 데이터를 직접 예측해 보겠습니다. 우리가 제일 많이 다루었던 제일 익숙한 데이터는 바로 컬래버레이트 필터링에서 다루었던 유저와 영화 아이템에 대한 평점 데이터입니다. 이 유저 아이템 매트릭스에서 다루던 평점 데이터는 대표적인 하이 스프레시티 스프레시티가 굉장히 높은 데이터라는 것입니다. 그 데이터를 한번 보시면 이 아래 데이터가 여러분들이 잘 아시는 유저와 아이템 아이디에 대해서 평점이 주어져 있는 데이터입니다. 일반적인 CF 문제 입력 데이터와 같죠 이제 우리는 이 데이터를 일반적인 제너럴 프리딕터 가 소화할 수 있는 스와로 바꿔서 이 아래와 같이 표현해 보도록 하겠습니다. 일반적인 입력 데이터로 바꾸면 여기 있는 유저 원의 영화 2가 5점 평점을 갖는다는 것을 이렇게 표현할 수 있습니다. 그래서 이 처음에 있는 앞에 유의 차원이 유저 전체가 되고요. 뒤에 있는 이 m이 영화 전체의 차원이 됩니다. 그래서 유저 1이 영화 2를 봤을 때 5점을 매겼다는 것은 유저 1에 해당하는 원 핫 인코딩이 1 유저 2에 해당하는 원화 인코딩이 1이고 최종 예측값은 5다. 마찬가지로 유저 3은 세 번째 차원이 1이고 영화 1은 첫 번째 차원이 1인 이것이 x가 되겠고요. 얘가 y가 되겠죠. 그래서 입력 값의 차원이 전체 유저와 아이템 수만큼 증가한다는 것입니다. 그런데 이 데이터셋을 보시면 아주 적은 변수만 1이고 나머지 모두 다 0이죠. 이제 이러한 데이터가 바로 하이 스프레시티 데이터라는 것입니다. 네 그렇다면 프엠에서 가장 중요한 것은 이 스파스한 피처들의 인터랙션이 어떻게 학습되느냐입니다. 다음 예시를 통해 살펴보겠습니다. 먼저 유저 a를 기준으로 유저 a가 이미 봤던 영화들은 여기 데이터 3개에 표현되어 있습니다. 이 유저 a에 해당하는 영화 하나 둘 세 개 즉 이 유저 a는 ti와 NHSW 총 3개의 영화에 대해 평가를 5점 3점 1점으로 진행했지만 ST에 대한 영화 ST 영화에 대한 평가는 내리지 않았습니다. 그래서 우리는 이 모델을 통해서 유저 a의 ST에 대한 평점을 예측하고 싶은데요. 어떻게 예측값을 구할 수 있는지 보겠습니다. 자 이 둘의 상호 작용을 구하기 위해서는 여기 있는 데이터를 가지고 a라는 유저와 에스티라는 영화에 대한 학습 파라미터가 학습될 텐데요. 그 파라미터 가운데 제일 중요한 것이 바로 이 팩토라이제이션 파라미터입니다. 그래서 이 a에 대한 팩토라이제이션 파라미터와 ST에 대한 팩토라이제이션 파라미터가 어떻게 학습되는지를 살펴보면 이 둘이 상호 작용을 했을 때 예측 값이 정확하게 나올 것이다라는 것을 확인할 수 있겠죠. 먼저 이 VST 영화 ST에 대한 팩토라이제이션 학습 파라미터 같은 경우에는 이 ST라는 영화가 유저 b와 유저 c가 이미 평가를 했음을 알 수 있습니다. 그리고 또 유저 b와 c는 동시에 스블라는 영화를 같이 평가했습니다. 그래서 유저 b씨가 동시에 스티와 스블 영화를 보았기 때문에 이 스티라는 영화가 sw에 비해서 상대적으로 어떤 특징을 가졌는지가 학습될 것이고요. 그 학습을 통해서 이 VST가 적절하게 학습이 되겠죠. 반대로 이 vaa에 대한 팩토라이제션 파라미터의 경우에도 보시면은 유저 a가 평가했으면서 동시에 유저 BC도 같이 평가한 영화가 존재합니다. 바로 이 sw라는 영화인데요. 이 sw라는 영화는 유저 a b c가 동시에 같이 평가했죠. 그래서 이 데이터를 학습하게 되면은 유저 b c와는 또 다른 유저 a의 특징이 이 VA라는 팩토라이제이션 파라미터에 학습이 될 것입니다. 그래서 이 둘의 인터랙션 데이터는 없지만 여기에 있는 다른 데이터를 통해서 각각의 팩토라이제이션 파라미터가 학습이 잘될 것이고 그 파라미터를 통해서 최종적으로 유저 a의 아직 보지 않은 영화 ST에 대한 평점 예측이 정확하게 구해집니다. 여기서는 유저와 아이템의 예시만을 들었지만 또 다른 장점은 이 뒤에 있는 부분인데요. 유저 아이템 아이디 외에 뒤에 있는 다양한 콘텍스트 정보를 계속 붙일 수 있다는 점입니다. 그리고 이 서로 서로의 인터랙션들 이 둘의 인터랙션 말고도 이들의 인터랙션 그리고 이 안에서의 인터랙션들도 다 FM에서 모델링이 된다는 것이죠. 그래서 이렇게 스프레스 한 데이터셋에 대해서 FM은 효율적으로 피처 간의 인터랙션을 표현하고 좋은 예측 성능을 보입니다. 마지막으로 2개 모델 SVM과 MF의 장점을 결합한 모델이 FM이라고 했는데요. 각각의 모델에 비해서 에프엠이 어떤 것이 좋은지 어떤 장점을 가지고 있는지 정리하면서 프엠 모델의 설명을 마치도록 합니다. 먼저 에브엠 같은 경우에는 어 스파스한 데이터에 대해서 예측 성능이 나쁘다고 했는데요. 그에 비해서 에프엠은 굉장히 스파스한 피처를 가지고도 높은 예측 성능을 보이고 있습니다. 또한 자세히 설명하진 않았지만 sv엠에 비해서 FM은 학습할 때 선형 복잡도를 가지기 때문에 학습 데이터가 굉장히 많더라도 이 모델은 빠르게 학습이 됩니다. 반면에 에브엠 같은 경우에는 학습 데이터가 굉장히 많이 늘어날수록 학습 시간은 이 5m보다 더 많이 증가하기 때문에 학습 데이터가 아주 많은 데이터에 대해서는 에비엠 학습을 하기가 어렵습니다. 굉장히 오래 걸리기 때문이죠. 그다음에 매트리스 팩터라이제이션과도 비교해 보면 이제 매트리스 팩터라이제이션은 오로지 콜라버레이트 필터링 환경으로 구성된 데이터만 소화할 수 있었는데요. 이 FM 같은 경우에는 콜라버트 필터링 형태의 모양이 아닌 다양한 예측 문제에도 활용 가능한 일반적인 제너럴 프리딕터임을 아까 설명드렸습니다. 그래서 엠프와 비교했을 때 유저 아이디와 아이템 아이디만 피처로 사용하는 것이 아니라 그 외에 다른 부가 정보들 즉 컨텍스트 정보들을 입력 값으로 사용하고 더 정확한 예측을 할 수 있습니다. 네 그래서 여기까지가 에프엠 모델에 대한 내용이었고요. 다음은 프프엠 필드 어웨어 팩토라이제이션 머신입니다. 이 모델의 원리를 이해하고 방금 전에 배웠던 프엠 모델과의 차이점을 살펴보도록 하겠습니다. 네 본 논문은 FM을 변형시킨 모델인 FFM을 제안하였고 이 FFM 모델은 CTR 예측 데이터셋 즉 컨텍스트어 레코멘데이션에서 가장 활발하게 풀리고 있는 그 문제에 대해서 높은 성능을 보였다고 이야기하고 있습니다. 먼저 앞서 설명했듯이 FM은 예측 문제 두루두루 적용 가능한 제너럴한 프리딕터 모델이라고 말씀드렸고요. 특히 스파스한 데이터에 아주 강력하다고 했는데요. 우리가 처음에 CTR 예측 모델 문제를 이야기할 때 CTR 예측 문제의 피처들은 대부분 스파스하다고 했죠. 따라서 이 CTR 예측 문제에서 FM은 굉장히 좋은 성능을 내고 있었습니다. 이제 여기서 필드 어웨어라는 말이 FM 앞에 붙었고요. 이게 FFM인데요. FFM은 FM을 발전시킨 모델로서 이 pitf라는 모델에서 아이디어를 얻었습니다. 그래서 이 pitf 모델에 대해서 간단히 설명을 드릴 텐데요. pitf 모델은 매트리스 팩토라이제이션 모델을 발전시킨 모델인데요. 어떻게 발전시켰냐면은 매트리스 팩토라이제이션 같은 경우에는 2차원 매트릭스로 유저 아이디와 아이템 아이디로 구성되어 있지만 이 pitf는 텐서 팩토라이제이션 즉 3차원으로 엠프를 확장시킨 모델입니다. 그래서 pitf에는 유저 아이디와 아이템 아이디에다가 태그 아이디까지 총 3개의 필드로 구성되어 있습니다. 그래서 이 pitf는 유저와 아이템 인베딩 외에 태그의 인베딩까지 총 3개의 인베딩을 학습하게 됩니다. 3차원 텐서이기 때문에 원래 MF는 이 둘의 곱으로만 이루어져 있지만 3차원 텐서 같은 경우에는 유저와 아이템 아이템과 태그 태그와 유저 각각의 인터랙션이 모두 가능한데요. 이제 여기서 pitf의 핵심적인 아이디어는 유저가 아이템이랑 곱해질 때의 레이턴트 팩터와 유저가 태그와 곱해질 때 레이턴트 팩터를 서로 다른 레이턴트 팩터 즉 서로 다른 인베딩을 정의하여서 구했다는 것입니다. 하나의 인베딩만을 사용해서는 서로 다른 필드와의 인터랙션을 표현하기에는 그 인베딩의 표현력이 부족했기 때문에 곱해지는 반대편의 필드가 무엇인지에 따라서 서로 다른 인베딩을 사용하는 것입니다. 그리고 프프엠은 방금 얘기했던 이 pitf에 서로 다른 레이턴트 팩터 즉 서로 다른 인베딩을 사용하는 그 아이디어를 일반화하여서 여러 개의 필드에 대해서 이 레이턴트 팩터를 정의한 것입니다. pitf는 필드가 3개지만 FFM은 사용자가 정의하는 개수만큼 필드를 늘려서 인베딩에 인터랙션을 시킬 수 있다는 것입니다. 앞서 말한 대로 FFM은 주어진 입력 변수에 이 필드라는 속성을 추가합니다. 그리고 필드별로 서로 다른 레이턴트 팩터를 가지도록 하고 그렇게 해서 팩토라이즈를 합니다. 기존의 FM은 하나의 변수 x1에 대해서 k g로 팩토라이즈 하는 vk라는 하나의 팩토라이제이션 파라미터만을 가졌지만 FFM은 필드가 총 2개 있다고 했을 때 프개의 팩토라이제이션 파라미터를 갖습니다. 자 그렇다면 필드를 보통 어떻게 정의하고 어떻게 나눌까요? 이제 필드는 모델을 설계할 때 사용자가 정의하는 것입니다. 이 모델이 알아서 정해주는 것이 아니라 사용자가 어떤 변수를 같은 필드로 묶을지를 정해야 하는데요. 보통 이제 유저나 아이템이나 콘텍스트 피처를 사용할 때 보통 우리가 시멘틱하게 성별이나 디바이스 같은 피처를 사용한다고 하지만 이 성별은 사실 남자 여자 그리고 디바이스 같은 경우에는 뭐 안드로이드 아이폰 같이 2개 이상의 피처 공간으로 표현하게 되겠죠. 그러면 그 두 개 이상의 변수가 하나의 필드가 되는 거죠. 그래서 성별 필드 디바이스 필드 운영 체제 필드 될 수 있고요. 아이템 같은 경우에는 카테고리 필드 등이 존재할 수 있는 거죠. 카테고리가 하나가 아니라 10개가 있으면은 그 카테고리는 10개의 원핫 인코딩으로 표현돼야 되기 때문에 10개의 변수로 표현되고요. 그 10개의 변수가 하나의 카테고리 필드에 포함되는 것이죠. 그래서 이 외에도 CTR 예측에는 훨씬 더 다양한 피처가 사용되는데요. 보통 피처의 개수만큼 필드를 정의하여서 사용하게 됩니다. 자 다음은 FFM의 수식을 다음과 같이 표현하였는데요. 보시면 이 앞에 있는 이 부분은 이제 리니어한 부분 로직스 리그레션 부분이고요. 이제 가장 큰 차이는 FM과 비교했을 때 여기 팩토라이제이션 더이 가장 큰 차이가 됩니다. 기존의 FM은 2개의 xixj 즉 2개의 변수가 인터랙션 할 때 각각에 해당하는 k 차원 내 파라미터를 내적이 되는 형태로 이 모델에서는 그 인터랙션을 표현하였는데요. 이제 보시면은 FFM 같은 경우에는 단순히 XI에 해당하는 VI가 아니라 이 뒤에 f제가 포함되어 있습니다. 이것은 무엇이냐 XI 그러니까 곱해지는 반대편인 xj의 필드에 해당하는 팩토라이제이션 파라미터를 사용한다는 것이죠. 그래서 이 하나의 변수는 총 2개의 필드를 갖고 각 필드별로 팩토라이제이션 파라미터가 정의되는 것입니다. 수식이 좀 복잡할 수 있으니 다음 슬라이드에서 예시를 통해 좀 더 쉽게 이해해 보겠습니다. 다음과 같은 광고 클릭 데이터가 존재하고 이제 이 데이터를 FM과 FM FFM 모델을 사용하여서 각각 표현해 보겠습니다. 먼저 좌측에 있는 FM인데요. FM은 필드가 존재하지 않기 때문에 각각 하나의 변수에 대해서 하나의 팩토라이제이션 파라미터만 존재합니다. 그래서 이 왼쪽에 이 수식을 표현해 보면은 글로벌 바이오스가 있고요. 각각의 변수가 하나씩 있기 때문에 ESPN 블크 블메일 이 부분은 1차 항이죠. 이제 이 뒤에 있는 부분이 팩토라이제이션 텀인데요. 각각의 변수에 해당하는 팩토라이제이션 파라미터가 선택돼서 이 둘이 내적으로 곱해지게 됩니다. 반면에 프프엠은 이 앞에 있는 글로벌 바이어스와 1차 텀은 똑같지만 이 뒤에 있는 팩토라이제이션 텀이 다소 복잡하게 되어 있습니다. 자 요 텀과 이 텀만을 비교해 보도록 하겠습니다. 이제 FM에서는 이 ESPN이라는 변수에 해당되는 파라미터가 단순히 vesp엔 하나였고 그 ESPN이 반대편인 나이키와 곱해지게 됐는데요. 이 에프엠에서는 먼저 확인해야 될 게 이 ESPN이라는 피처 변수는 퍼블리셔 필드에 속해 있고 나이키라는 변수는 광고주 에드벌 타이스 필드에 속해 있고 이 메일은 성별 필드에 속해 있음을 사용자가 지정을 했습니다. 자 그 상황에서 이 ESPN과 나이키의 인터랙션은 ESPN의 반대편 곱해지는 나이키가 바로 에드벌 타이스 필드이기 때문에 브이피엔 콤마 에 즉 2스피엔 변수면서 에드벌 타이즈 필드가 곱해진다는 의미인 이 파라미터를 사용하게 됩니다. 반대로 이 나이키 같은 경우에는 반대편 곱해지는 ESPN이 바로 퍼블리셔 필드에 속해 있기 때문에 브나이키 콤마 피라는 파라미터를 사용하여서 팩토라이제이션을 합니다. 그래서 이렇게 곱해지는 반대편 즉 인터랙션이 일어나는 반대편 변수의 필드를 고려하여서 팩토라이제이션을 수행하기 때문에 그래서 이름이 바로 필드 어웨어 팩토라이제이션 머신인 것입니다. 그래서 에프엠 모델은 주로 CTR 예측 문제에 많이 사용되고 이 문제 데이터의 대부분은 카테고리컬 피처라고 언급하였습니다. 그래서 카테고리컬 피처는 보통 같은 피처 그룹을 같은 필드로 묶어서 정의한다고 했습니다. 그래서 에프엠 같은 경우에는 필드가 필요 없지만 이 아래에 있는 에프엠은 각각의 변수가 속한 피처 그룹을 필드로 정의합니다. 그래서 이스피에는 이 피처가 퍼블리셔 피처였기 때문에 퍼블리셔 필드라고 정의하였고요. 이 뒤에 있는 것도 마찬가지로 각각의 피처가 속해 있는 필드를 사용하였습니다. 문제는 뉴메릭 피처인데요. FFM은 모든 변수가 반드시 어떤 필드에 속해야 하는데요. 실수 피처 같은 경우에는 필드에 할당하기가 다소 부족합니다. 하나의 피처가 0 콤마 1 같은 원 핫 인코딩으로 표현되는 것이 아니라 그냥 하나의 변수의 실수 값을 갖기 때문에 첫 번째 방법은 더미 필드를 사용하는 것입니다. 이 오른쪽에 있는 각각의 피처와 이 값들이 모두 예측 모델에 사용돼야 되는 입력 변수인데요. 더미 필드 같은 경우에는 그냥 하나의 변수에 하나의 필드만을 할당하고 그 외에 다른 변수는 이 에알이라는 필드를 사용하지 않습니다. 즉 피처 1개당 하나의 필드만을 할당하기 때문에 실제로 이 필드는 큰 의미를 가지진 않죠. 그렇기 때문에 더미 필드라고 명명을 하였고요. 두 번째 방법은 이 각각의 실수 피처를 어떤 n 개의 구간으로 나누는 디스크리타이즈 방법입니다. 그러면 이제 이 실수 값이 n 개의 구간으로 나눠지기 때문에 n 차원의 원핫 인코딩으로 표현될 것이고 그 n 차원의 원핫 인코딩은 총 n개의 입력 변수가 되겠죠. 그래서 그 값을 하나의 AR 필드 hidx라는 필드로 매핑하고 그 n개의 변수를 하나의 필드로 사용하여서 FFM 모델링을 수행합니다. 그래서 이 두 가지 방법은 모두 정답이 있는 것은 아니고 각 피처가 가진 특징을 적합하게 고려하여서 선택하시면 됩니다. 그래서 논문의 최종 결과입니다. 이 논문에서는 우리가 다루었던 4가지 모델을 모두 비교하고 있습니다. 이 LM이 바로 로지스틱 디렉션 기본적인 선형 모델이었고요. 이 폴리 2가 두 개의 변수에 대한 상호작용을 강제로 카테시안 프로덕트 형태로 나타내는 것이고 이 뒤에 있는 FM과 FFM은 방금 전에 우리가 배웠던 모델들이죠. 그래서 데이터셋에 따라서 조금씩 다르고 표현형에 따라서 조금 다르긴 하지만 이제 FM과 FM이 당연히 이 두 모델보다는 좋은 성능을 보이고요. 어떤 데이터셋에 대해서는 FFM이 좋은 성능을 보이지만 그렇지 않은 데이터 셋도 있습니다. 이제 그 이유는 어떤 데이터셋은 필드를 사용하여서 명시적으로 피처를 구분하는 것이 별로 도움이 되지 않았을 수 있기 때문입니다. 그래서 FFM은 필드 개수만큼 팩토라이제이션 파라미터가 늘어나기 때문에 필드를 사용하는 것이 적절하지 않을 경우에는 프프엠을 사용했을 때 오히려 오버피팅이나 반대로 언더 피팅이 발생할 수도 있기 때문입니다. 그래서 데이터셋에 따라서 FFM이 좋을 때도 있고 FM이 좋을 때도 있다는 점 현업에서 사용하실 때 기억해 두시면 좋을 것 같습니다. 아무튼 결과적으로는 lme 리니어 리그레션 죄송합니다. 로지스틱 리그레션 그리고 폴리 2 모델보다 FM이나 FM이 좋은 성능을 보이고 있고 특히 CTR 예측 데이터셋 같은 스퍼스 한 데이터셋에서 이런 팩토라이제이션 머신 계열의 모델이 굉장히 효율적이면서 뛰어난 예측력을 가지고 있다고 정리할 수 있습니다. 자 마지막 네 번째 파트는 그레디언트 포스팅 머신입니다. CTR 예측에 효과적이라고 알려진 그레디언트 부스팅 기법의 원리를 이해하고 대표적인 지비엠 계열의 모델들에 대해서 간단히 리뷰해 보겠습니다. 최근에 케이글과 같은 컴퍼티션에도 많이 등장하는 이 그래디언트 부스팅 머신 모델은 다양한 오픈 씨티알 데이터셋에 대해서도 뛰어난 성능을 보이고 있습니다. 이제 프엠이나 프프엠 같은 계열의 모델을 포함하여서 다른 추천 모델보다도 때로는 높은 예측력을 보이고 있으며 그래서 종종 지비엠을 사용해서 개인화된 추천 모델을 학습하고 사용하는 사례도 있습니다. 이제 하나의 예시로 하이퍼커넥트의 서비스인 하쿠나 라이브의 사례를 들고 왔습니다. 하쿠나 라이브에서는 기존의 인기도 기반 혹은 휴리스틱 기반의 추천 시스템 에서 탈피하여서 이제 더 성능이 좋은 추천 모델을 사용하고자 다양한 모델을 테스트했습니다. 특히 실시간 서비스 데이터의 경우 다양한 환경에 의해서 데이터의 특징이 자주 변하기 때문에 비교적 데이터의 특성에 관계없이 하이퍼 파라미터에 민감하지 않은 모델을 사용하고 싶었는데요. 그래서 이 추천 모델링을 위해서 다양한 시티형 예측 모델을 비교한 결과 우리가 잘 알려진 프엠이나 프프엠 계열의 모델 보다도 그리고 기존에 사용하던 휴리스텍 모델보다도 이 GBM 계열의 모델을 사용했을 때 더 높은 예측 정확도를 보였다는 것을 논문을 통해 발표하였습니다. 자 그렇다면 그레디언트 부스팅 모델이 무엇인지 알아보기 전에 이 부스팅이라는 단어 이 부스팅이 무엇인지를 알아봅시다. 부스팅은 앙상블의 일종인데요. 먼저 앙상블이란 한 가지 모델만 사용할 경우 모델에 생기는 예측 오차를 줄이기 위해서 그 모델의 편향을 줄이기 위해서 2개 이상 여러 가지의 모델을 동시에 결합하여서 사용하는 기법입니다. 그래서 부스팅 기법은 다양한 앙상블 기법 중에 하나로 분류되는 것입니다. 그렇다면 어떻게 앙상블을 진행할까요? 이 의사결정 나무 디시전 트리로 된 위크 러너들을 연속적으로 학습하여 이를 결합하는데요. 여기서 계속 등장하는 이 위크 러너라는 단어는 정확도와 복잡도가 비교적 낮은 간단한 분류기를 의미합니다. 그래서 먼저 연속적으로 학습한다는 것은 이전 단계의 위클 러너 니가 취약했던 부분을 위주로 해당 데이터를 샘플링해서 다음 단계의 위클 언어를 학습한다는 것입니다. 그래서 이 과정을 계속해서 반복되면은 위클 언어가 한 개가 아니라 여러 개가 생성되겠죠. 그 여러 개의 위클 러너들에 대해서 인퍼런스를 진행하고 그 인퍼런스를 최종적으로 다 합쳐서 최종 예측 값을 구하게 됩니다. 그래서 이렇게 여러 개의 위클 러너들을 동시에 한꺼번에 사용해서 예측하는 기법이나 예측하는 모델을 부스팅이라고 합니다. 그래서 부스팅을 기반으로 하는 대표적인 모델은 아다부스트 우리가 배우고 있는 지금 그레디언트 부스팅 머신이 있는데요. 이제 이 그레디언트 부스팅 머신을 발전시킨 모델인 xg 부스트나 라이트 GBM 캣 부스트 같은 것도 많이 있지만 이번 시간에는 주로 그레디언트 부스팅 머신을 위주로 살펴보겠습니다. 그레디언트 부스팅을 살펴봅시다. 그레디언트 부스팅이랑 그레디언트 디센트를 사용하여서 노스 펑션이 줄어드는 방향으로 위크 러너드를 반복적으로 결합하는 방법입니다. 이 로스 펑션이 줄어드는 방향이 바로 negative 그래디언트 방향인데요. 보통 우리가 그래디언트 디센트라는 말을 어디서 많이 들었냐면은 스토캐스트 그레디언트 디센트라는 것을 사용하여서 모델의 학습 파라미터를 업데이트 할 때 배웠던 개념입니다. 근데 이 그레디언트 부스팅은 그레디언트 디센트를 이용해서 학습 파라미터를 업데이트하는 것이 아니라 로스 펑션이 줄어드는 방향 으로 위크 러원을 추가한다라는 점에서 완전히 다릅니다. 이 아래 수도 코드를 보시면은 이 세 번째 라인이 그래디언트를 계산하는 수식인데요. 스토캐스트 그레디언티티 센터와 다른 점은 이 그레디언트의 분모를 보시면 알 수 있습니다. 이 분모에 파라미터가 아니라 그 학습하는 러너 그 자체 FX가 들어가 있습니다. 즉 FX로 이 로스를 미분한 그레디언트를 구하는 것이죠. 그리고 이 그래디언트의 음수를 취한 negative 그래디언트가 새로운 예측값 y 틸드가 되고요. 이 와 틸드을 다시 예측하는 새로운 위클러너 치를 학습하게 됩니다. 그래서 이 치가 그다음 위클 러너가 되는 것이죠. 그래서 그래디언트 포스팅은 로스 펑션이 줄어드는 방향인 negative 그래디언트를 예측해서 위클 언어를 생성한다고 했는데요. 사실 이 말 자체가 굉장히 이해하기 어렵기 때문에 좀 더 쉽게 이해할 수 있도록 설명해 보겠습니다. 통계학적인 관점에서 negative 그래디언트는 실제 값과 예측값의 차이인 레지듀얼이라고 볼 수 있습니다. 즉 그레디언트 부스팅에서 이 윌크 러너가 학습되는 과정은 바로 이전까지의 레지 듀어를 계산하고 이 레지 듀엣을 예측하는 다음 단계의 위클 러너를 학습하여서 기존 모델에 이를 결합하는 것입니다. 그림을 통해 원리를 쉽게 이해해 봅시다. 좌측에 스와 와이의 학습 데이터가 있고요. 이를 표현하는 큐 펑션이 녹색 곡선처럼 생겼다고 가정합시다. 그럼 우리는 예측 모델을 학습하여서 이 녹색 곡선과 최대한 비슷하게 만들어야 합니다. 먼저 첫 번째 위클 언어인 트리 1을 학습하여서 해당 모델과의 실제 값의 차이인 레지 듀어를 구합니다. 그래서 이 차이는 레지듀얼이 이렇게 되겠죠. 이제 이 값들을 다음 번 위크 러너에 사용하는데요. 이 레지듀얼을 예측하는 두 번째 트리를 학습하는 것입니다. 그리고 이 차이의 레지듀얼을 다시 구해줍니다. 그리고 이 레지듀얼을 다시 예측하는 세 번째 위클 러너 트리를 학습합니다. 이렇게 해서 계속해서 반복되면서 트리가 추가되고 레지듀얼은 점점 작아지면서 최종적으로 실제 출 펑션과 굉장히 비슷한 예측 모델이 학습될 것입니다. 그래서 그레디언트 부스팅을 사용하여서 이 리그레션 테스크 즉 회귀 테스크를 수행할 경우에는 방금 설명했던 것처럼 이 위클런의 예측 값으로 레지듀얼을 그대로 활용하고요. 이 레지듀얼이라고 하는 것은 실측값에서 예측 값을 뺀 차이를 말하는 것이죠. 그리고 분류 문제 클래시피케이션 테스크에서는 0과 1 사이로 예측하는 것을 어떤 실수로 표현하기 어렵기 때문에 로그 오즈 값을 사용하여서 레지듀어를 계산합니다. 자 다음의 예제를 통해서 그레디언트 부스팅 모델이 학습되는 과정을 좀 더 잘 이해해 봅시다. 이제 본 문제는 리그레션 테스크를 가정하고 이 리그레션 테스크 문제를 푸는 과정을 설명하였습니다. 그래서 먼저 주어진 데이터가 이렇게 3개 주어진 피처가 3개가 있겠죠. 이 입력 변수 3개에 대해서 우리는 이 웨이트 값을 예측하는 리그레션 모델을 학습해야 합니다. 첫 번째 스텝 제로 즉 아무런 트리도 없을 때는 전체 웨이트의 평균값으로 초기 예측 값을 설정합니다. 이것이 트리 제로가 되는데요. 이제 이 트리 제로와 실제 값의 차이가 바로 레지듀얼리입니다. 그래서 이 첫 번째 트리 첫 번째 위클 러너는 이 레지듀얼을 예측하게 되고요. 그래서 그 레지듀얼의 예측 값이 오른쪽에 있습니다. 그래서 이 첫 번째 트리는 실제 레지듀얼 값을 예측할 수 있도록 각각의 트리의 노드에 예측 레지듀얼 값이 적히게 됩니다. 그다음에 이 트리 제로와 트리 1을 합쳐 합치게 되면은 최종 예측 값이 나오게 되고요. 이 최종 예측값과 원래 실측값을 다시 빼면은 또 다른 레지듀얼 두 번째 레지듀얼이 나오겠죠. 이 레지 듀얼을 다시 학습하는 두 번째 트리를 또 학습합니다. 그래서 이 두 번째 레지듀얼이 학습되면은 또 그 차이를 계산해서 세 번째 레지듀얼을 구할 수 있겠죠. 그래서 이 세 번째 레지듀얼이 바로 이 부분이죠. 그래서 이렇게 해서 계속해서 트리를 하나씩 하나씩 학습해서 이 레지듀얼 값을 줄여 나가게 되면은 최종적으로 정확한 예측 부스팅 모델을 학습할 수 있습니다. 그래서 n 번째 트리까지 학습한 이후에 언제 멈추냐 손실 함수 즉 로스 펑션 값이 일정 수준 이하이거나 마지막 리프 노드 즉 마지막에 위클 러너에 학습했던 그 노드에 속한 데이터 수가 굉장히 적어질 때 멈추게 됩니다. 그래서 몇 번의 학습을 통해서 굉장히 예측 값이 정확해졌음을 확인해 볼 수 있습니다. 레즈 듀얼이 거의 0에 가깝기 때문에 이 정도 학습한 이후에는 이제 더 이상 트리를 생성하지 않고 부스팅이 멈추게 됩니다. 그래서 이 GBM 은 다른 트리 계열의 앙상블 모델 대표적인 랜덤 포레스트가 있는데요. 그 랜덤 포레스트보다 대체적으로 좋은 성능을 보입니다. 랜덤 포레스트는 앙상블 중에 배깅을 활용한 방법인데요. 같은 디시전 트리 같은 위클 러너를 배깅하는 것보다는 부스팅하는 것이 더 예측 정확도가 뛰어나다고 알려져 있습니다. 하지만 이 그래디언트 부스팅 모델의 문제는 학습 속도가 굉장히 느리다는 것입니다. 순차적으로 계속해서 위클 언어를 학습하기 때문에 학습 속도가 랜덤 프로젝트보다 훨씬 느리게 되고요. 또한 모델이 계속해서 레지 듀얼에 맞게 계속 학습하게 되면은 이제 트레이닝 데이터 즉 학습 데이터에 대해서는 굉장히 잘 피팅하지만 반대로 테스트 데이터에 대해선 취약한 제너럴라이제이션에서는 취약한 모델로 학습될 위험이 있습니다. 즉 오버피팅이 된다는 것이죠. 그래서 이 GBM의 두 가지 문제 오버피팅이 쉽게 되고 학습 속도가 느리다는 단점을 보완한 다른 모델과 라이브러리들이 등장하였습니다. 그래서 이 다음과 같은 세 가지 모델이자 라이브러리가 제일 기본적인 그레디언트 부스팅의 문제점을 해결하였습니다. 사실 이 세 가지 모델을 제대로 이해하기에는 각각의 모델의 구현과 난이도가 다소 높기 때문에 지금 당장은 이런 기법들이 있다 정도로 기억해 주시고, 나중에 이 모델을 직접 사용하게 될 때 해당 모델과 관련 논문에 대해서 자세히 학습드리길 추천드립니다. 그래서 엑스지 부스트 같은 경우에는 익스트 그레디언트 부스팅의 약자로서 학습 과정에서의 병렬 처리와 근사 알고리즘을 통해 속도를 굉장히 빠르게 한 라이브러리입니다. 그리고 라이트 GBM 같은 경우에는 마이크로소프트에서 제안한 가벼운 그래디언트 부스팅 머신이고요. 그리고 캡 푸스트 같은 경우에는 이제 피처들 가운데 특히 카테고리컬 피처가 많을 때 이 카테고리컬 피처의 효과적인 알고리즘을 구현하여서 예측 정확도를 높이고 과적합을 방지한 모델입니다. 네 이상 GBM에 대한 강의까지 모두 마쳤고 여덟 번째 강의를 모두 마무리하였습니다. 모두 수고하셨습니다.","confidence":0.90646243,"speakers":[{"label":"","name":"","edited":false}],"events":[],"eventTypes":[]}