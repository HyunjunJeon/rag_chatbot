{"result":"SUCCEEDED","message":"Succeeded","token":"719302f002ea47ba9597daa077158984","version":"ncp_v2_v2.4.6-c00dd1b-20250528__v4.2.20.1_ko_firedepartment_20250923_","params":{"service":"ncp","domain":"general","lang":"ko","completion":"sync","callback":"","diarization":{"enable":false,"speakerCountMin":-1,"speakerCountMax":-1},"sed":{"enable":false},"boostings":[],"forbiddens":"","wordAlignment":true,"fullText":true,"noiseFiltering":true,"priority":0,"userdata":{"_ncp_DomainCode":"tpc-boostcamp","_ncp_DomainId":13807,"_ncp_TaskId":42975707,"_ncp_TraceId":"c0ac684dcc30429c9024ec1ea53c09cc"}},"progress":100,"keywords":{},"segments":[{"start":0,"end":14900,"text":"안녕하세요. 도메인 공통 프로젝트 8강 더 좋은 성능을 위한 기법 두 번째 하이퍼 파라미터 튜닝 시작하겠습니다. 이번 강의에서는","confidence":0.9685,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[6030,6480,"안녕하세요."],[7110,7420,"도메인"],[7420,7620,"공통"],[7620,8000,"프로젝트"],[8270,8560,"8강"],[9070,9220,"더"],[9290,9460,"좋은"],[9550,9840,"성능을"],[9840,10020,"위한"],[10130,10400,"기법"],[10450,10600,"두"],[10600,10860,"번째"],[11350,11640,"하이퍼"],[11640,11980,"파라미터"],[11980,12240,"튜닝"],[12510,13140,"시작하겠습니다."],[13910,14120,"이번"],[14170,14620,"강의에서는"]],"textEdited":"안녕하세요. 도메인 공통 프로젝트 8강 더 좋은 성능을 위한 기법 두 번째 하이퍼 파라미터 튜닝 시작하겠습니다. 이번 강의에서는"},{"start":14900,"end":22500,"text":"모델에 설정해야 하는 각 하이퍼 파라미터들을 튜닝하는 방법인 하이퍼 파라미터 튜닝에 대해서 이해해 보겠습니다.","confidence":0.9697,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[15190,15600,"모델에"],[15970,16387,"설정해야"],[16387,16580,"하는"],[17290,17440,"각"],[17530,17820,"하이퍼"],[17820,18460,"파라미터들을"],[18590,19020,"튜닝하는"],[19090,19420,"방법인"],[20010,20280,"하이퍼"],[20280,20640,"파라미터"],[20690,21027,"튜닝에"],[21027,21340,"대해서"],[21530,21827,"이해해"],[21827,22420,"보겠습니다."]],"textEdited":"모델에 설정해야 하는 각 하이퍼 파라미터들을 튜닝하는 방법인 하이퍼 파라미터 튜닝에 대해서 이해해 보겠습니다."},{"start":22500,"end":30800,"text":"두 번째로는 실제 하이퍼 파라미터를 튜닝하기 위해 여러분들이 사용할 수 있는 하이퍼 파라미터 옵티마이제이션 툴에 대해서 소개하도록 하겠습니다.","confidence":0.9728,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[23010,23160,"두"],[23160,23600,"번째로는"],[24270,24560,"실제"],[24570,24800,"하이퍼"],[24800,25220,"파라미터를"],[25220,25647,"튜닝하기"],[25647,25820,"위해"],[26070,26520,"여러분들이"],[26520,26840,"사용할"],[26850,27000,"수"],[27000,27180,"있는"],[27570,27820,"하이퍼"],[27820,28200,"파라미터"],[28270,28840,"옵티마이제이션"],[28910,29167,"툴에"],[29167,29480,"대해서"],[29750,30240,"소개하도록"],[30250,30780,"하겠습니다."]],"textEdited":"두 번째로는 실제 하이퍼 파라미터를 튜닝하기 위해 여러분들이 사용할 수 있는 하이퍼 파라미터 옵티마이제이션 툴에 대해서 소개하도록 하겠습니다."},{"start":30800,"end":45200,"text":"먼저 하이퍼 파라미터 튜닝 이해하기입니다. 하이퍼 파라미터란 모델 학습 과정의 디자인에 반영되는 값입니다. 학습 시작 전에 미리 설정하게 되는 값입니다. 예시로는 러닝 레이트, 손실 함수, 배치, 사이즈,","confidence":0.967,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[31190,31460,"먼저"],[31590,31840,"하이퍼"],[31840,32220,"파라미터"],[32270,32580,"튜닝"],[32690,33360,"이해하기입니다."],[33910,34200,"하이퍼"],[34210,34680,"파라미터란"],[35310,35580,"모델"],[35650,35880,"학습"],[35930,36280,"과정의"],[36350,36820,"디자인에"],[37010,37420,"반영되는"],[37490,37960,"값입니다."],[38530,38760,"학습"],[38770,38947,"시작"],[38947,39200,"전에"],[39390,39620,"미리"],[39730,40147,"설정하게"],[40147,40340,"되는"],[40340,40760,"값입니다."],[41410,41900,"예시로는"],[42230,42500,"러닝"],[42500,42780,"레이트,"],[43390,43700,"손실"],[43710,43980,"함수,"],[44530,44800,"배치,"],[44810,45120,"사이즈,"]],"textEdited":"먼저 하이퍼 파라미터 튜닝 이해하기입니다. 하이퍼 파라미터란 모델 학습 과정의 디자인에 반영되는 값입니다. 학습 시작 전에 미리 설정하게 되는 값입니다. 예시로는 러닝 레이트, 손실 함수, 배치, 사이즈,"},{"start":45200,"end":58400,"text":"신경망의 레이어 수가 있습니다. 여러분들이 직접 조정 가능한 값들의 형태입니다. 다음으로는 파라미터가 있습니다. 파라미터는 모델 내부에서 결정되는 변수로 데이터로부터 학습","confidence":0.9862,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[45690,46160,"신경망의"],[46170,46440,"레이어"],[46440,46720,"수가"],[46720,47060,"있습니다."],[47770,48240,"여러분들이"],[48270,48500,"직접"],[48500,48760,"조정"],[48790,49120,"가능한"],[49890,50280,"값들의"],[50280,50720,"형태입니다."],[51690,52180,"다음으로는"],[52350,52840,"파라미터가"],[52840,53160,"있습니다."],[53890,54420,"파라미터는"],[54790,55060,"모델"],[55090,55480,"내부에서"],[55550,55980,"결정되는"],[55990,56320,"변수로"],[56970,57640,"데이터로부터"],[57890,58140,"학습"]],"textEdited":"신경망의 레이어 수가 있습니다. 여러분들이 직접 조정 가능한 값들의 형태입니다. 다음으로는 파라미터가 있습니다. 파라미터는 모델 내부에서 결정되는 변수로 데이터로부터 학습"},{"start":58400,"end":67400,"text":"또는 조정되는 값들입니다. 예시로는 선형 회귀 모델의 개수, 신경망의 가중치 혹은 편향 등을 말합니다.","confidence":0.9547,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[58630,58920,"또는"],[59030,59460,"조정되는"],[59490,60040,"값들입니다."],[60710,61220,"예시로는"],[61830,62100,"선형"],[62100,62300,"회귀"],[62300,62600,"모델의"],[62630,62920,"개수,"],[63870,64320,"신경망의"],[64320,64680,"가중치"],[65170,65380,"혹은"],[65630,65920,"편향"],[66290,66560,"등을"],[66810,67220,"말합니다."]],"textEdited":"또는 조정되는 값들입니다. 예시로는 선형 회귀 모델의 개수, 신경망의 가중치 혹은 편향 등을 말합니다."},{"start":67400,"end":81500,"text":"이러한 값들은 학습 과정에서 자연스럽게 조정되는 값이기 때문에 개발자가 직접 조정하지 않습니다. 정리해 보면 하이퍼 파라미터는 학습 과정이 시작되기 전에 설정되는 구성 변수라고도 이야기할 수 있습니다.","confidence":0.9816,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[67830,68120,"이러한"],[68130,68500,"값들은"],[68950,69220,"학습"],[69230,69620,"과정에서"],[69830,70460,"자연스럽게"],[70790,71220,"조정되는"],[71220,71527,"값이기"],[71527,71860,"때문에"],[72310,72800,"개발자가"],[73070,73340,"직접"],[73350,73740,"조정하지"],[73810,74220,"않습니다."],[74950,75227,"정리해"],[75227,75440,"보면"],[75670,75940,"하이퍼"],[75940,76400,"파라미터는"],[76970,77220,"학습"],[77230,77540,"과정이"],[77540,77907,"시작되기"],[77907,78200,"전에"],[78630,79140,"설정되는"],[79510,79800,"구성"],[79800,80400,"변수라고도"],[80530,80920,"이야기할"],[80950,81100,"수"],[81100,81500,"있습니다."]],"textEdited":"이러한 값들은 학습 과정에서 자연스럽게 조정되는 값이기 때문에 개발자가 직접 조정하지 않습니다. 정리해 보면 하이퍼 파라미터는 학습 과정이 시작되기 전에 설정되는 구성 변수라고도 이야기할 수 있습니다."},{"start":81500,"end":93300,"text":"다음은 모델 파라미터와 하이퍼 파라미터에 대한 예시 그림입니다. 모델 파라미터의 경우 보시는 것과 같이 웨이트와 같은 값들이 존재합니다. w0, w1, w2","confidence":0.9384,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[81990,82320,"다음은"],[82650,82900,"모델"],[82950,83400,"파라미터와"],[83650,83940,"하이퍼"],[83970,84540,"파라미터에"],[84540,84740,"대한"],[84950,85240,"예시"],[85240,85680,"그림입니다."],[86230,86460,"모델"],[86490,86907,"파라미터의"],[86907,87100,"경우"],[87490,87780,"보시는"],[87780,87980,"것과"],[87980,88220,"같이"],[88750,89220,"웨이트와"],[89230,89500,"같은"],[89710,90080,"값들이"],[90130,90600,"존재합니다."],[91070,91420,"w0,"],[91870,92200,"w1,"],[92690,93080,"w2"]],"textEdited":"다음은 모델 파라미터와 하이퍼 파라미터에 대한 예시 그림입니다. 모델 파라미터의 경우 보시는 것과 같이 웨이트와 같은 값들이 존재합니다. w0, w1, w2"},{"start":93300,"end":107000,"text":"그리고 wm 이러한 값들은 모델이 가지고 있는 가중치 값들이며 모델을 학습시키는 과정에서 로스를 최적화하는 동안 조정되는 값입니다. 오른쪽에 있는 하이퍼 파라미터들을 보겠습니다. an it","confidence":0.8999,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[93590,93820,"그리고"],[93910,94300,"wm"],[94730,95020,"이러한"],[95050,95400,"값들은"],[95910,96260,"모델이"],[96290,96580,"가지고"],[96580,96720,"있는"],[96810,97160,"가중치"],[97190,97600,"값들이며"],[98130,98500,"모델을"],[98670,99180,"학습시키는"],[99230,99660,"과정에서"],[100150,100520,"로스를"],[100520,100960,"최적화하는"],[100960,101160,"동안"],[101570,102020,"조정되는"],[102030,102440,"값입니다."],[103230,103667,"오른쪽에"],[103667,103820,"있는"],[103820,104060,"하이퍼"],[104060,104547,"파라미터들을"],[104547,105000,"보겠습니다."],[105690,105900,"an"],[105900,106140,"it"]],"textEdited":"그리고 wm 이러한 값들은 모델이 가지고 있는 가중치 값들이며 모델을 학습시키는 과정에서 로스를 최적화하는 동안 조정되는 값입니다. 오른쪽에 있는 하이퍼 파라미터들을 보겠습니다. an it"},{"start":107000,"end":119100,"text":"테스트 사이즈 랜덤 스테이트 알파 시 이러한 값들은 모델을 학습할 때 얼마나 여러 번 학습할 것인지, 테스트 사이즈는 어떻게 되는지, 랜덤 시드 값은 어떻게 되는지,","confidence":0.9069,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[107210,107507,"테스트"],[107507,107820,"사이즈"],[108330,108580,"랜덤"],[108580,108920,"스테이트"],[109430,109720,"알파"],[110290,110440,"시"],[111110,111400,"이러한"],[111430,111800,"값들은"],[112250,112600,"모델을"],[112600,112920,"학습할"],[112950,113100,"때"],[113490,113860,"얼마나"],[114210,114427,"여러"],[114427,114560,"번"],[114970,115300,"학습할"],[115300,115640,"것인지,"],[116130,116460,"테스트"],[116460,116807,"사이즈는"],[116807,116974,"어떻게"],[116974,117320,"되는지,"],[117690,117960,"랜덤"],[117990,118240,"시드"],[118240,118460,"값은"],[118460,118614,"어떻게"],[118614,118940,"되는지,"]],"textEdited":"테스트 사이즈 랜덤 스테이트 알파 시 이러한 값들은 모델을 학습할 때 얼마나 여러 번 학습할 것인지, 테스트 사이즈는 어떻게 되는지, 랜덤 시드 값은 어떻게 되는지,"},{"start":119100,"end":133900,"text":"우리가 모델의 오버피팅을 방지하기 위해 정교화를 적용할 때 얼마나 그 정교화의 강도를 강하게 설정할지 이러한 값들을 하이퍼 파라미터라고 부릅니다. 각 모델마다 가지고 있는 하이퍼 파라미터는 다르지만 하이퍼 파라미터가 많을수록","confidence":0.9684,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[119390,119700,"우리가"],[120030,120367,"모델의"],[120367,120900,"오버피팅을"],[120930,121320,"방지하기"],[121320,121500,"위해"],[121910,122420,"정교화를"],[122420,122760,"적용할"],[122760,122880,"때"],[123470,123860,"얼마나"],[123990,124140,"그"],[124190,124580,"정교화의"],[124630,125020,"강도를"],[125430,125740,"강하게"],[125750,126260,"설정할지"],[126890,127180,"이러한"],[127230,127620,"값들을"],[127930,128220,"하이퍼"],[128230,128707,"파라미터라고"],[128707,129040,"부릅니다."],[129650,129800,"각"],[129890,130380,"모델마다"],[130530,130880,"가지고"],[130880,131020,"있는"],[131050,131300,"하이퍼"],[131300,131760,"파라미터는"],[131760,132140,"다르지만"],[132650,132920,"하이퍼"],[132920,133320,"파라미터가"],[133320,133720,"많을수록"]],"textEdited":"우리가 모델의 오버피팅을 방지하기 위해 정교화를 적용할 때 얼마나 그 정교화의 강도를 강하게 설정할지 이러한 값들을 하이퍼 파라미터라고 부릅니다. 각 모델마다 가지고 있는 하이퍼 파라미터는 다르지만 하이퍼 파라미터가 많을수록"},{"start":133900,"end":147200,"text":"모델 학습에 고려할 디자인 요소가 많다는 의미입니다. 하이퍼 파라미터 옵티마이제이션이 필요한 이유에 대해서 살펴보겠습니다. 예시를 하나하나 확인해 보면서 따라가겠습니다. 첫 번째 예시를 보면 레이어는 3개","confidence":0.9802,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[134250,134500,"모델"],[134510,134820,"학습에"],[134890,135200,"고려할"],[135210,135480,"디자인"],[135480,135760,"요소가"],[136210,136600,"많다는"],[136630,137080,"의미입니다."],[137990,138280,"하이퍼"],[138280,138640,"파라미터"],[138640,139260,"옵티마이제이션이"],[139260,139520,"필요한"],[139550,139814,"이유에"],[139814,140040,"대해서"],[140040,140660,"살펴보겠습니다."],[141470,141840,"예시를"],[141970,142380,"하나하나"],[142710,142974,"확인해"],[142974,143280,"보면서"],[143370,144020,"따라가겠습니다."],[144710,144860,"첫"],[144870,145120,"번째"],[145120,145367,"예시를"],[145367,145580,"보면"],[146130,146620,"레이어는"],[146750,147000,"3개"]],"textEdited":"모델 학습에 고려할 디자인 요소가 많다는 의미입니다. 하이퍼 파라미터 옵티마이제이션이 필요한 이유에 대해서 살펴보겠습니다. 예시를 하나하나 확인해 보면서 따라가겠습니다. 첫 번째 예시를 보면 레이어는 3개"},{"start":147200,"end":159200,"text":"그리고 각 레이어에 할당되는 뉴런의 수는 512개, 러닝 웨이트는 0.1입니다. 이 하이퍼 파라미터를 가지고 모델을 학습한 결과는 85%의 스코어를 가지게 됩니다.","confidence":0.9542,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[147750,148020,"그리고"],[148070,148220,"각"],[148310,148720,"레이어에"],[148750,149160,"할당되는"],[149170,149507,"뉴런의"],[149507,149800,"수는"],[150090,150660,"512개,"],[151330,151600,"러닝"],[151600,151960,"웨이트는"],[151970,152600,"0.1입니다."],[153310,153460,"이"],[153490,153740,"하이퍼"],[153750,154240,"파라미터를"],[154240,154560,"가지고"],[155070,155400,"모델을"],[155410,155720,"학습한"],[155770,156200,"결과는"],[156750,157560,"85%의"],[157790,158300,"스코어를"],[158530,158794,"가지게"],[158794,159160,"됩니다."]],"textEdited":"그리고 각 레이어에 할당되는 뉴런의 수는 512개, 러닝 웨이트는 0.1입니다. 이 하이퍼 파라미터를 가지고 모델을 학습한 결과는 85%의 스코어를 가지게 됩니다."},{"start":159200,"end":171200,"text":"두 번째 예시를 보겠습니다. 동일하게 3개의 레이어를 가지고 있고 뉴런의 수는 2배 늘어난 숫자인 1024를 가지고 있습니다. 러닝 레이트는 0.01로 설정되었고","confidence":0.9721,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[159790,159940,"두"],[159940,160180,"번째"],[160180,160407,"예시를"],[160407,160860,"보겠습니다."],[161830,162300,"동일하게"],[162330,162640,"3개의"],[162640,162947,"레이어를"],[162947,163147,"가지고"],[163147,163380,"있고"],[164090,164414,"뉴런의"],[164414,164680,"수는"],[165030,165280,"2배"],[165310,165600,"늘어난"],[165650,165980,"숫자인"],[166310,166980,"1024를"],[167210,167434,"가지고"],[167434,167740,"있습니다."],[168470,168740,"러닝"],[168740,169120,"레이트는"],[169470,170220,"0.01로"],[170410,171000,"설정되었고"]],"textEdited":"두 번째 예시를 보겠습니다. 동일하게 3개의 레이어를 가지고 있고 뉴런의 수는 2배 늘어난 숫자인 1024를 가지고 있습니다. 러닝 레이트는 0.01로 설정되었고"},{"start":171200,"end":182700,"text":"동일하게 스코어는 85%를 보여주고 있습니다. 마지막 예시를 보겠습니다. 마지막 예시는 3개의 레이어를 가지고 있고 각 레이어별로 256개의 뉴런을 가지고 있습니다.","confidence":0.945,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[171750,172180,"동일하게"],[172190,172640,"스코어는"],[173070,173720,"85%를"],[173720,174047,"보여주고"],[174047,174400,"있습니다."],[174890,175220,"마지막"],[175230,175467,"예시를"],[175467,175900,"보겠습니다."],[176570,176900,"마지막"],[176910,177220,"예시는"],[177870,178200,"3개의"],[178200,178540,"레이어를"],[178540,178820,"가지고"],[178820,179060,"있고"],[179870,180020,"각"],[180090,180600,"레이어별로"],[180930,181740,"256개의"],[181740,182080,"뉴런을"],[182080,182320,"가지고"],[182320,182620,"있습니다."]],"textEdited":"동일하게 스코어는 85%를 보여주고 있습니다. 마지막 예시를 보겠습니다. 마지막 예시는 3개의 레이어를 가지고 있고 각 레이어별로 256개의 뉴런을 가지고 있습니다."},{"start":182700,"end":190300,"text":"러닝 레이트는 첫 번째 예시와 동일한 0.1입니다. 세 번째 예시의 스코어는 92%를 보여주고 있습니다.","confidence":0.9704,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[183310,183560,"러닝"],[183560,183960,"레이트는"],[184290,184440,"첫"],[184440,184680,"번째"],[184680,184940,"예시와"],[184950,185260,"동일한"],[185530,186200,"0.1입니다."],[186850,187000,"세"],[187000,187260,"번째"],[187290,187680,"예시의"],[187830,188240,"스코어는"],[188810,189480,"92%를"],[189480,189774,"보여주고"],[189774,190200,"있습니다."]],"textEdited":"러닝 레이트는 첫 번째 예시와 동일한 0.1입니다. 세 번째 예시의 스코어는 92%를 보여주고 있습니다."},{"start":190300,"end":204700,"text":"사실 이 예시는 매우 단순한 예시일 뿐입니다. 실제로 여러분들이 하이퍼 파라미터를 설정할 때는 이것보다 훨씬 더 많고 훨씬 더 넓은 영역의 하이퍼 파라미터를 탐색을 해야 되는데요. 예시에서 볼 수 있듯이","confidence":0.9763,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[190950,191200,"사실"],[191250,191400,"이"],[191430,191820,"예시는"],[192050,192260,"매우"],[192410,192800,"단순한"],[193010,193400,"예시일"],[193410,193820,"뿐입니다."],[194330,194720,"실제로"],[194870,195400,"여러분들이"],[195690,195980,"하이퍼"],[196010,196480,"파라미터를"],[196490,196860,"설정할"],[196860,197080,"때는"],[197650,198120,"이것보다"],[198250,198560,"훨씬"],[198560,198680,"더"],[198750,199120,"많고"],[199470,199727,"훨씬"],[199727,199860,"더"],[199930,200280,"넓은"],[200430,200800,"영역의"],[201050,201300,"하이퍼"],[201300,201800,"파라미터를"],[202170,202520,"탐색을"],[202520,202680,"해야"],[202680,203060,"되는데요."],[203730,204100,"예시에서"],[204100,204240,"볼"],[204240,204300,"수"],[204300,204560,"있듯이"]],"textEdited":"사실 이 예시는 매우 단순한 예시일 뿐입니다. 실제로 여러분들이 하이퍼 파라미터를 설정할 때는 이것보다 훨씬 더 많고 훨씬 더 넓은 영역의 하이퍼 파라미터를 탐색을 해야 되는데요. 예시에서 볼 수 있듯이"},{"start":204700,"end":218000,"text":"어떤 하이퍼파라미터를 설정하느냐에 따라 스코어가 달라질 수 있습니다. 하이퍼파라미터 옵티마이제이션의 장점에 대해서 이야기해 보겠습니다. 먼저 모델 성능입니다. 하이퍼파라미터 선택은 모델 성능에 큰 영향을 미치며","confidence":0.965,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[205190,205440,"어떤"],[205450,206220,"하이퍼파라미터를"],[206230,206674,"설정하느냐에"],[206674,206900,"따라"],[207530,207940,"스코어가"],[207940,208200,"달라질"],[208200,208274,"수"],[208274,208580,"있습니다."],[209190,209860,"하이퍼파라미터"],[209870,210760,"옵티마이제이션의"],[211010,211420,"장점에"],[211420,211700,"대해서"],[211930,212247,"이야기해"],[212247,212720,"보겠습니다."],[213310,213560,"먼저"],[213610,213840,"모델"],[213910,214380,"성능입니다."],[215030,215680,"하이퍼파라미터"],[215730,216100,"선택은"],[216330,216600,"모델"],[216670,216960,"성능에"],[217030,217180,"큰"],[217230,217520,"영향을"],[217520,217860,"미치며"]],"textEdited":"어떤 하이퍼파라미터를 설정하느냐에 따라 스코어가 달라질 수 있습니다. 하이퍼파라미터 옵티마이제이션의 장점에 대해서 이야기해 보겠습니다. 먼저 모델 성능입니다. 하이퍼파라미터 선택은 모델 성능에 큰 영향을 미치며"},{"start":218000,"end":231200,"text":"적절히 조정된 하이퍼 파라미터는 모델의 정확도 일반화 능력 효율성을 향상시킬 수 있습니다. 다음은 학습 시간입니다. 효율적인 하이퍼 파라미터 조정은 학습 시간과 계산 자원을 감소시킬 수 있습니다.","confidence":0.9211,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[218410,218774,"적절히"],[218774,219060,"조정된"],[219070,219340,"하이퍼"],[219340,219800,"파라미터는"],[220290,220660,"모델의"],[220670,221080,"정확도"],[221610,221960,"일반화"],[221990,222240,"능력"],[222730,223180,"효율성을"],[223190,223580,"향상시킬"],[223580,223654,"수"],[223654,223980,"있습니다."],[224770,225080,"다음은"],[225150,225380,"학습"],[225380,225820,"시간입니다."],[226210,226680,"효율적인"],[226680,226940,"하이퍼"],[226940,227260,"파라미터"],[227260,227560,"조정은"],[228050,228320,"학습"],[228320,228700,"시간과"],[228990,229280,"계산"],[229290,229680,"자원을"],[229710,230180,"감소시킬"],[230190,230307,"수"],[230307,230660,"있습니다."]],"textEdited":"적절히 조정된 하이퍼 파라미터는 모델의 정확도 일반화 능력 효율성을 향상시킬 수 있습니다. 다음은 학습 시간입니다. 효율적인 하이퍼 파라미터 조정은 학습 시간과 계산 자원을 감소시킬 수 있습니다."},{"start":231200,"end":243400,"text":"마지막으로는 모델 일반화입니다. 잘 최적화된 하이퍼 파라미터는 모델이 실제 데이터에 대해 더 잘 일반화되도록 도와 과적합과 과소적합을 줄일 수 있습니다. 하지만 하이퍼파라미터 옵티마이제이션에","confidence":0.9685,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[231590,232240,"마지막으로는"],[232350,232600,"모델"],[232630,233200,"일반화입니다."],[233770,233920,"잘"],[234010,234400,"최적화된"],[234400,234587,"하이퍼"],[234587,235060,"파라미터는"],[235510,235860,"모델이"],[235950,236240,"실제"],[236240,236547,"데이터에"],[236547,236740,"대해"],[236950,237100,"더"],[237230,237380,"잘"],[237530,238100,"일반화되도록"],[238130,238340,"도와"],[238710,239260,"과적합과"],[239770,240340,"과소적합을"],[240340,240560,"줄일"],[240560,240667,"수"],[240667,241020,"있습니다."],[241490,241780,"하지만"],[241970,242540,"하이퍼파라미터"],[242540,243220,"옵티마이제이션에"]],"textEdited":"마지막으로는 모델 일반화입니다. 잘 최적화된 하이퍼 파라미터는 모델이 실제 데이터에 대해 더 잘 일반화되도록 도와 과적합과 과소적합을 줄일 수 있습니다. 하지만 하이퍼파라미터 옵티마이제이션에"},{"start":243400,"end":253200,"text":"큰 단점이 있는데요. 이러한 하이퍼 파라미터를 찾기 위해 조정 비용이 많이 발생할 수 있습니다. 어떤 하이퍼 파라미터가 최적인지는 직접 학습을 시키고","confidence":0.9679,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[243850,244000,"큰"],[244170,244560,"단점이"],[244570,244960,"있는데요."],[245590,245880,"이러한"],[245930,246180,"하이퍼"],[246180,246660,"파라미터를"],[246710,247020,"찾기"],[247020,247200,"위해"],[247670,247980,"조정"],[247980,248260,"비용이"],[248290,248500,"많이"],[248590,248940,"발생할"],[248940,249047,"수"],[249047,249380,"있습니다."],[249950,250180,"어떤"],[250210,250460,"하이퍼"],[250460,250900,"파라미터가"],[250910,251420,"최적인지는"],[251890,252180,"직접"],[252250,252600,"학습을"],[252650,252980,"시키고"]],"textEdited":"큰 단점이 있는데요. 이러한 하이퍼 파라미터를 찾기 위해 조정 비용이 많이 발생할 수 있습니다. 어떤 하이퍼 파라미터가 최적인지는 직접 학습을 시키고"},{"start":253200,"end":266500,"text":"그 모델의 성능을 어느 정도 확인할 수 있을 정도로 학습을 시켜야 하기 때문에 그만큼 시간과 계산 비용, 인프라 비용이 발생할 수 있습니다. 다음은 허깅페이스 사전 학습 모델에서 볼 수 있는 하이퍼 파라미터들입니다.","confidence":0.9461,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[253470,253620,"그"],[253670,254040,"모델의"],[254410,254740,"성능을"],[254910,255120,"어느"],[255120,255440,"정도"],[255970,256300,"확인할"],[256300,256374,"수"],[256374,256560,"있을"],[256570,256880,"정도로"],[256970,257240,"학습을"],[257240,257474,"시켜야"],[257474,257594,"하기"],[257594,257920,"때문에"],[258330,258760,"그만큼"],[258850,259240,"시간과"],[259730,260020,"계산"],[260020,260200,"비용,"],[260670,260980,"인프라"],[260980,261240,"비용이"],[261240,261507,"발생할"],[261507,261594,"수"],[261594,261940,"있습니다."],[262750,263060,"다음은"],[263130,263607,"허깅페이스"],[263607,263767,"사전"],[263767,264000,"학습"],[264000,264360,"모델에서"],[264410,264560,"볼"],[264610,264760,"수"],[264760,264960,"있는"],[265370,265660,"하이퍼"],[265690,266400,"파라미터들입니다."]],"textEdited":"그 모델의 성능을 어느 정도 확인할 수 있을 정도로 학습을 시켜야 하기 때문에 그만큼 시간과 계산 비용, 인프라 비용이 발생할 수 있습니다. 다음은 허깅페이스 사전 학습 모델에서 볼 수 있는 하이퍼 파라미터들입니다."},{"start":266500,"end":280500,"text":"nom 레이어스 트랜스포머의 인코더 층 수를 나타냅니다. 벌트 베이스의 경우 12개, BT 미니의 경우 4개를 가지고 있습니다. 다음은 히든 사이즈입니다. 히든 상태 벡터 차원입니다. 벌트 베이스는 768,","confidence":0.8489,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[267070,267280,"nom"],[267290,267760,"레이어스"],[268110,268760,"트랜스포머의"],[268790,269160,"인코더"],[269230,269380,"층"],[269410,269674,"수를"],[269674,270080,"나타냅니다."],[270670,270960,"벌트"],[270960,271380,"베이스의"],[271380,271600,"경우"],[271830,272320,"12개,"],[272710,272954,"BT"],[272954,273280,"미니의"],[273280,273520,"경우"],[273830,274180,"4개를"],[274180,274374,"가지고"],[274374,274680,"있습니다."],[275790,276060,"다음은"],[276090,276320,"히든"],[276320,276780,"사이즈입니다."],[277070,277340,"히든"],[277390,277607,"상태"],[277607,277840,"벡터"],[277840,278280,"차원입니다."],[278730,278954,"벌트"],[278954,279400,"베이스는"],[279730,280280,"768,"]],"textEdited":"nom 레이어스 트랜스포머의 인코더 층 수를 나타냅니다. 벌트 베이스의 경우 12개, BT 미니의 경우 4개를 가지고 있습니다. 다음은 히든 사이즈입니다. 히든 상태 벡터 차원입니다. 벌트 베이스는 768,"},{"start":280500,"end":295400,"text":"펄, 미니는 256을 가지고 있습니다. 다음은 어텐션, 헤드, 셀프 어텐션의 머리 수입니다. 12개 4개를 가지고 있습니다. 인터미디어트 사이즈, 로켓 사이즈, 맥스, 포지션, 임베링스, 액티베이션, 펑션, 드롭아웃 등","confidence":0.8651,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[280710,280860,"펄,"],[280910,281280,"미니는"],[281510,282147,"256을"],[282147,282314,"가지고"],[282314,282640,"있습니다."],[283010,283320,"다음은"],[283470,283860,"어텐션,"],[283870,284080,"헤드,"],[284570,284814,"셀프"],[284814,285180,"어텐션의"],[285180,285400,"머리"],[285400,285840,"수입니다."],[286430,286900,"12개"],[287390,287740,"4개를"],[287740,287934,"가지고"],[287934,288240,"있습니다."],[289010,289680,"인터미디어트"],[289810,290180,"사이즈,"],[290650,290940,"로켓"],[290950,291320,"사이즈,"],[291810,292080,"맥스,"],[292080,292420,"포지션,"],[292550,293080,"임베링스,"],[293490,293920,"액티베이션,"],[293970,294240,"펑션,"],[294610,295020,"드롭아웃"],[295070,295220,"등"]],"textEdited":"펄, 미니는 256을 가지고 있습니다. 다음은 어텐션, 헤드, 셀프 어텐션의 머리 수입니다. 12개 4개를 가지고 있습니다. 인터미디어트 사이즈, 로켓 사이즈, 맥스, 포지션, 임베링스, 액티베이션, 펑션, 드롭아웃 등"},{"start":295400,"end":307700,"text":"여러분들이 어떤 하이퍼 파라미터를 설정하냐에 따라 가장 아래에서 보여지는 전체 모델의 파라미터 개수가 5배까지 혹은 그 이상까지 차이 날 수 있습니다. 다음은 훈련 파라미터입니다.","confidence":0.9655,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[295830,296340,"여러분들이"],[296670,296940,"어떤"],[296990,297240,"하이퍼"],[297250,297660,"파라미터를"],[297660,297940,"설정하냐에"],[297940,298160,"따라"],[298850,299100,"가장"],[299130,299520,"아래에서"],[299520,299880,"보여지는"],[300290,300620,"전체"],[300630,300960,"모델의"],[300960,301360,"파라미터"],[301410,301780,"개수가"],[302370,302900,"5배까지"],[303230,303460,"혹은"],[303850,304000,"그"],[304070,304560,"이상까지"],[304690,304867,"차이"],[304867,305000,"날"],[305000,305074,"수"],[305074,305400,"있습니다."],[305990,306300,"다음은"],[306370,306580,"훈련"],[306590,307300,"파라미터입니다."]],"textEdited":"여러분들이 어떤 하이퍼 파라미터를 설정하냐에 따라 가장 아래에서 보여지는 전체 모델의 파라미터 개수가 5배까지 혹은 그 이상까지 차이 날 수 있습니다. 다음은 훈련 파라미터입니다."},{"start":307700,"end":320900,"text":"이는 훈련을 진행하는 동안 여러분들이 설정할 수 있는 하이퍼 파라미터를 뜻합니다. 첫 번째로 넘 에폭스입니다. 여러분들이 모델에게 데이터셋 전체를 얼마나 많이 보여줄지 결정하는 수치입니다.","confidence":0.9301,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[308030,308300,"이는"],[308710,309100,"훈련을"],[309110,309520,"진행하는"],[309520,309740,"동안"],[310030,310540,"여러분들이"],[310570,310980,"설정할"],[310990,311107,"수"],[311107,311280,"있는"],[311330,311600,"하이퍼"],[311600,312080,"파라미터를"],[312080,312440,"뜻합니다."],[313170,313320,"첫"],[313320,313640,"번째로"],[313640,313780,"넘"],[313810,314360,"에폭스입니다."],[315110,315580,"여러분들이"],[315990,316460,"모델에게"],[316930,317420,"데이터셋"],[317470,317860,"전체를"],[318150,318500,"얼마나"],[318650,318840,"많이"],[318930,319440,"보여줄지"],[319670,320140,"결정하는"],[320190,320660,"수치입니다."]],"textEdited":"이는 훈련을 진행하는 동안 여러분들이 설정할 수 있는 하이퍼 파라미터를 뜻합니다. 첫 번째로 넘 에폭스입니다. 여러분들이 모델에게 데이터셋 전체를 얼마나 많이 보여줄지 결정하는 수치입니다."},{"start":320900,"end":334400,"text":"예시에서는 50회로 설정되어 있습니다. 그다음은 얼리스타핑 페이션스입니다. 이 값은 여러분들이 설정한 검증 데이터에 대한 검증 스코어가 해당 횟수만큼 개선되지 않으면 얼리스탑","confidence":0.9253,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[321390,321920,"예시에서는"],[321970,322800,"50회로"],[322810,323140,"설정되어"],[323140,323420,"있습니다."],[324190,324560,"그다음은"],[324630,325180,"얼리스타핑"],[325210,325780,"페이션스입니다."],[326390,326540,"이"],[326590,326920,"값은"],[327450,327960,"여러분들이"],[327960,328320,"설정한"],[328710,329020,"검증"],[329070,329447,"데이터에"],[329447,329640,"대한"],[329810,330080,"검증"],[330150,330620,"스코어가"],[331170,331440,"해당"],[331490,332080,"횟수만큼"],[332450,332920,"개선되지"],[332920,333200,"않으면"],[333850,334260,"얼리스탑"]],"textEdited":"예시에서는 50회로 설정되어 있습니다. 그다음은 얼리스타핑 페이션스입니다. 이 값은 여러분들이 설정한 검증 데이터에 대한 검증 스코어가 해당 횟수만큼 개선되지 않으면 얼리스탑"},{"start":334400,"end":346700,"text":"모델 학습을 일찍 멈추게 도와주는 하이퍼 파라미터입니다. 예시의 경우 5로 설정되어 있고 5회 이상 에폭에 대해 검증 스코어가 개선되지 않으면 학습을 중단합니다. 다음은 배치 사이즈입니다.","confidence":0.9639,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[334730,334980,"모델"],[334990,335300,"학습을"],[335410,335700,"일찍"],[335710,336100,"멈추게"],[336130,336600,"도와주는"],[336830,337120,"하이퍼"],[337130,337700,"파라미터입니다."],[338330,338647,"예시의"],[338647,338880,"경우"],[339230,339520,"5로"],[339530,339880,"설정되어"],[339880,340100,"있고"],[340590,340880,"5회"],[340880,341080,"이상"],[341110,341434,"에폭에"],[341434,341640,"대해"],[342210,342480,"검증"],[342510,342920,"스코어가"],[342950,343400,"개선되지"],[343400,343680,"않으면"],[344190,344520,"학습을"],[344530,344980,"중단합니다."],[345330,345620,"다음은"],[345650,345900,"배치"],[345900,346480,"사이즈입니다."]],"textEdited":"모델 학습을 일찍 멈추게 도와주는 하이퍼 파라미터입니다. 예시의 경우 5로 설정되어 있고 5회 이상 에폭에 대해 검증 스코어가 개선되지 않으면 학습을 중단합니다. 다음은 배치 사이즈입니다."},{"start":346700,"end":361300,"text":"배치 사이즈는 딥러닝 모델을 학습할 때 미니 배치 사이즈의 크기를 결정합니다. 현재 예시의 경우 16개로 되어 있고 그렇다라는 거는 16개의 샘플이 모델에 한 번에 학습된다라는 의미입니다. 오른쪽에서는 로스를 볼 수 있습니다.","confidence":0.9322,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[347070,347340,"배치"],[347340,347760,"사이즈는"],[348370,348780,"딥러닝"],[348780,349047,"모델을"],[349047,349360,"학습할"],[349360,349500,"때"],[349890,350120,"미니"],[350130,350380,"배치"],[350380,350760,"사이즈의"],[350790,351100,"크기를"],[351150,351580,"결정합니다."],[352210,352480,"현재"],[352480,352747,"예시의"],[352747,352960,"경우"],[353290,353854,"16개로"],[353854,354040,"되어"],[354040,354260,"있고"],[354630,355034,"그렇다라는"],[355034,355240,"거는"],[355410,356080,"16개의"],[356130,356520,"샘플이"],[356790,357160,"모델에"],[357470,357574,"한"],[357574,357800,"번에"],[357890,358460,"학습된다라는"],[358550,359020,"의미입니다."],[359650,360220,"오른쪽에서는"],[360230,360587,"로스를"],[360587,360687,"볼"],[360687,360774,"수"],[360774,361080,"있습니다."]],"textEdited":"배치 사이즈는 딥러닝 모델을 학습할 때 미니 배치 사이즈의 크기를 결정합니다. 현재 예시의 경우 16개로 되어 있고 그렇다라는 거는 16개의 샘플이 모델에 한 번에 학습된다라는 의미입니다. 오른쪽에서는 로스를 볼 수 있습니다."},{"start":361300,"end":376300,"text":"우리가 일반적으로 우리가 일반적으로 분류에서는 바이너리 크로스, 엔트로피 회귀에서는 엠스 혹은 엠에이와 같은 로스를 사용을 하는데요. 여러분들이 푸는 테스크에 따라 사용할 수 있는 로스가 여러 개일 수 있습니다.","confidence":0.8685,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[361610,361900,"우리가"],[361930,362420,"일반적으로"],[362790,363080,"우리가"],[363130,363680,"일반적으로"],[363970,364580,"분류에서는"],[365070,365440,"바이너리"],[365440,365634,"크로스,"],[365634,365980,"엔트로피"],[366510,367020,"회귀에서는"],[367190,367600,"엠스"],[368170,368400,"혹은"],[368810,369840,"엠에이와"],[369870,370120,"같은"],[370130,370460,"로스를"],[370460,370680,"사용을"],[370690,371080,"하는데요."],[371930,372440,"여러분들이"],[372450,372700,"푸는"],[372750,373167,"테스크에"],[373167,373420,"따라"],[373750,374160,"사용할"],[374170,374260,"수"],[374260,374420,"있는"],[374510,374960,"로스가"],[375270,375507,"여러"],[375507,375740,"개일"],[375740,375814,"수"],[375814,376180,"있습니다."]],"textEdited":"우리가 일반적으로 우리가 일반적으로 분류에서는 바이너리 크로스, 엔트로피 회귀에서는 엠스 혹은 엠에이와 같은 로스를 사용을 하는데요. 여러분들이 푸는 테스크에 따라 사용할 수 있는 로스가 여러 개일 수 있습니다."},{"start":376300,"end":390600,"text":"이런 경우일 땐 여러분들이 사용하는 로스 그 자체도 하이퍼 파라미터로 간주할 수 있습니다. 이어서 옵티마이저입니다. 예시에서는 아담블를 예시로 들었고요. 아담더블유가 아닌 다른 옵티마이저를 고려하고 싶다면","confidence":0.9298,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[376770,376960,"이런"],[377050,377347,"경우일"],[377347,377480,"땐"],[377850,378300,"여러분들이"],[378300,378680,"사용하는"],[378750,379040,"로스"],[379040,379160,"그"],[379160,379520,"자체도"],[379670,379940,"하이퍼"],[379950,380460,"파라미터로"],[380890,381227,"간주할"],[381227,381314,"수"],[381314,381620,"있습니다."],[382270,382620,"이어서"],[382870,383620,"옵티마이저입니다."],[384390,384880,"예시에서는"],[384950,385680,"아담블를"],[385910,386167,"예시로"],[386167,386540,"들었고요."],[387130,387754,"아담더블유가"],[387754,387920,"아닌"],[388350,388560,"다른"],[388610,389320,"옵티마이저를"],[389590,390020,"고려하고"],[390020,390400,"싶다면"]],"textEdited":"이런 경우일 땐 여러분들이 사용하는 로스 그 자체도 하이퍼 파라미터로 간주할 수 있습니다. 이어서 옵티마이저입니다. 예시에서는 아담블를 예시로 들었고요. 아담더블유가 아닌 다른 옵티마이저를 고려하고 싶다면"},{"start":390600,"end":402900,"text":"이 또한 하이퍼 파라미터로 쓸 수 있습니다. 러닝 레이트, 맥스, 시퀀스 랭스 등 학습 단계에서 고려할 수 있는 다른 하이퍼 파라미터들도 많이 있습니다. 그래서 여러분들이 모델의 디자인을 결정한 뒤에","confidence":0.9456,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[390910,391060,"이"],[391110,391340,"또한"],[391370,391600,"하이퍼"],[391610,391987,"파라미터로"],[391987,392120,"쓸"],[392120,392194,"수"],[392194,392520,"있습니다."],[393110,393400,"러닝"],[393400,393700,"레이트,"],[394330,394600,"맥스,"],[394600,394960,"시퀀스"],[394960,395220,"랭스"],[395220,395360,"등"],[396030,396280,"학습"],[396310,396660,"단계에서"],[396710,397060,"고려할"],[397070,397174,"수"],[397174,397360,"있는"],[397750,397940,"다른"],[397990,398260,"하이퍼"],[398260,398800,"파라미터들도"],[399050,399280,"많이"],[399290,399640,"있습니다."],[400270,400500,"그래서"],[400500,401020,"여러분들이"],[401250,401660,"모델의"],[401660,402080,"디자인을"],[402090,402460,"결정한"],[402470,402700,"뒤에"]],"textEdited":"이 또한 하이퍼 파라미터로 쓸 수 있습니다. 러닝 레이트, 맥스, 시퀀스 랭스 등 학습 단계에서 고려할 수 있는 다른 하이퍼 파라미터들도 많이 있습니다. 그래서 여러분들이 모델의 디자인을 결정한 뒤에"},{"start":402900,"end":413400,"text":"훈련하는 파이프라인에 대한 하이퍼 파라미터도 반드시 고려해야 합니다. 하이퍼 파라미터 튜닝이란 사실은 하이퍼 파라미터를 찾는 하이퍼 파라미터 설치라고 할 수 있습니다.","confidence":0.9497,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[403270,403660,"훈련하는"],[403690,404194,"파이프라인에"],[404194,404360,"대한"],[404430,404700,"하이퍼"],[404710,405180,"파라미터도"],[405510,405860,"반드시"],[405910,406280,"고려해야"],[406280,406520,"합니다."],[407370,407660,"하이퍼"],[407660,408020,"파라미터"],[408050,408520,"튜닝이란"],[409310,409640,"사실은"],[409690,409960,"하이퍼"],[409970,410520,"파라미터를"],[410830,411080,"찾는"],[411370,411620,"하이퍼"],[411620,411940,"파라미터"],[411970,412660,"설치라고"],[412660,412800,"할"],[412800,412860,"수"],[412860,413280,"있습니다."]],"textEdited":"훈련하는 파이프라인에 대한 하이퍼 파라미터도 반드시 고려해야 합니다. 하이퍼 파라미터 튜닝이란 사실은 하이퍼 파라미터를 찾는 하이퍼 파라미터 설치라고 할 수 있습니다."},{"start":413400,"end":424600,"text":"여러분들이 가지고 있는 주어진 데이터에 대해 어떤 하이퍼 파라미터 조합에서 내가 가진 모델이 가장 성능이 좋은지는 직접 실험을 통해 찾아내어야 합니다.","confidence":0.9864,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[413870,414340,"여러분들이"],[414370,414660,"가지고"],[414660,414820,"있는"],[415330,415660,"주어진"],[415670,416060,"데이터에"],[416060,416240,"대해"],[416910,417220,"어떤"],[417310,417580,"하이퍼"],[417590,417920,"파라미터"],[417920,418340,"조합에서"],[419250,419480,"내가"],[419510,419720,"가진"],[419730,420080,"모델이"],[420490,420780,"가장"],[420910,421220,"성능이"],[421220,421660,"좋은지는"],[422410,422720,"직접"],[422810,423100,"실험을"],[423100,423300,"통해"],[423650,424140,"찾아내어야"],[424140,424460,"합니다."]],"textEdited":"여러분들이 가지고 있는 주어진 데이터에 대해 어떤 하이퍼 파라미터 조합에서 내가 가진 모델이 가장 성능이 좋은지는 직접 실험을 통해 찾아내어야 합니다."},{"start":424600,"end":433800,"text":"그림은 학습률 러닝레이트를 조정했을 때 모델 성능 양상을 보여주는 그래프입니다. 매우 극단적인 예시일 수는 있지만","confidence":0.9685,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[425150,425480,"그림은"],[426090,426460,"학습률"],[426930,427600,"러닝레이트를"],[427600,428040,"조정했을"],[428070,428220,"때"],[428470,428740,"모델"],[428890,429180,"성능"],[429290,429680,"양상을"],[429710,430100,"보여주는"],[430230,430760,"그래프입니다."],[431190,431440,"매우"],[432130,432620,"극단적인"],[432670,433040,"예시일"],[433040,433260,"수는"],[433260,433540,"있지만"]],"textEdited":"그림은 학습률 러닝레이트를 조정했을 때 모델 성능 양상을 보여주는 그래프입니다. 매우 극단적인 예시일 수는 있지만"},{"start":433800,"end":445300,"text":"다음과 같이 학습률이 올라감에 따라 모델의 성능이 올라갈 수도 혹은 내려갈 수도 있습니다. 그렇기 때문에 어느 지점에서 최적인지는 실험을 통해 알아낼 수밖에 없습니다.","confidence":0.9755,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[434270,434660,"다음과"],[434660,434940,"같이"],[435590,436040,"학습률이"],[436070,436467,"올라감에"],[436467,436720,"따라"],[437110,437480,"모델의"],[437490,437820,"성능이"],[438030,438420,"올라갈"],[438450,438700,"수도"],[439050,439280,"혹은"],[439510,439880,"내려갈"],[439880,439994,"수도"],[439994,440340,"있습니다."],[440910,441134,"그렇기"],[441134,441440,"때문에"],[441830,442080,"어느"],[442170,442580,"지점에서"],[442630,443200,"최적인지는"],[443770,444080,"실험을"],[444080,444280,"통해"],[444280,444560,"알아낼"],[444560,444880,"수밖에"],[444880,445300,"없습니다."]],"textEdited":"다음과 같이 학습률이 올라감에 따라 모델의 성능이 올라갈 수도 혹은 내려갈 수도 있습니다. 그렇기 때문에 어느 지점에서 최적인지는 실험을 통해 알아낼 수밖에 없습니다."},{"start":445300,"end":456700,"text":"대표적인 하이퍼 파라미터 튜닝 방법으로는 그리드 서치가 있습니다. 그리드 서치는 말 그대로 내가 최적화하고 싶은 하이퍼 파라미터들의 값을 그리드로","confidence":0.9703,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[445750,446180,"대표적인"],[446230,446560,"하이퍼"],[446560,446920,"파라미터"],[446990,447320,"튜닝"],[447430,447940,"방법으로는"],[448450,448740,"그리드"],[448740,449027,"서치가"],[449027,449340,"있습니다."],[449970,450187,"그리드"],[450187,450540,"서치는"],[450990,451140,"말"],[451270,451620,"그대로"],[452190,452440,"내가"],[452790,453300,"최적화하고"],[453300,453480,"싶은"],[453550,453840,"하이퍼"],[453870,454540,"파라미터들의"],[455230,455600,"값을"],[456070,456520,"그리드로"]],"textEdited":"대표적인 하이퍼 파라미터 튜닝 방법으로는 그리드 서치가 있습니다. 그리드 서치는 말 그대로 내가 최적화하고 싶은 하이퍼 파라미터들의 값을 그리드로"},{"start":456700,"end":471300,"text":"설정을 하고 가능한 모든 경우의 수를 탐색하는 방법입니다. 그리 서치는 하이퍼 파라미터의 수 그리고 각 하이퍼 파라미터에 설정한 그리드의 수만큼으로 실험 횟수가 정해집니다.","confidence":0.9574,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[456970,457340,"설정을"],[457340,457540,"하고"],[458130,458480,"가능한"],[458610,458880,"모든"],[458990,459320,"경우의"],[459320,459640,"수를"],[460150,460640,"탐색하는"],[460710,461200,"방법입니다."],[461710,461920,"그리"],[461920,462300,"서치는"],[462750,463060,"하이퍼"],[463090,463620,"파라미터의"],[463620,463760,"수"],[464410,464740,"그리고"],[465110,465260,"각"],[465450,465760,"하이퍼"],[465810,466340,"파라미터에"],[466370,466720,"설정한"],[467190,467620,"그리드의"],[467670,468920,"수만큼으로"],[469810,470060,"실험"],[470110,470480,"횟수가"],[470690,471280,"정해집니다."]],"textEdited":"설정을 하고 가능한 모든 경우의 수를 탐색하는 방법입니다. 그리 서치는 하이퍼 파라미터의 수 그리고 각 하이퍼 파라미터에 설정한 그리드의 수만큼으로 실험 횟수가 정해집니다."},{"start":471300,"end":485700,"text":"하지만 여기에 생길 수 있는 단점은 실제 우리가 사용하는 하이퍼 파라미터 중 정수인 경우에도 문제가 있겠지만 실수인 경우에서는 훨씬 더 큰 문제가 발생합니다. 왜냐하면 여러분들이 손쉽게 볼 수 있는 하이퍼 파라미터들","confidence":0.9786,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[471790,472100,"하지만"],[472170,472460,"여기에"],[472460,472640,"생길"],[472640,472720,"수"],[472720,472880,"있는"],[472990,473420,"단점은"],[474010,474320,"실제"],[474350,474620,"우리가"],[474730,475180,"사용하는"],[475610,475920,"하이퍼"],[475920,476260,"파라미터"],[476270,476420,"중"],[477290,477720,"정수인"],[477720,478040,"경우에도"],[478050,478340,"문제가"],[478340,478720,"있겠지만"],[479350,479780,"실수인"],[479780,480180,"경우에서는"],[480210,480434,"훨씬"],[480434,480560,"더"],[480610,480760,"큰"],[480830,481160,"문제가"],[481170,481580,"발생합니다."],[482070,482500,"왜냐하면"],[482850,483400,"여러분들이"],[483610,484100,"손쉽게"],[484110,484260,"볼"],[484290,484380,"수"],[484380,484540,"있는"],[484650,484960,"하이퍼"],[484960,485440,"파라미터들"]],"textEdited":"하지만 여기에 생길 수 있는 단점은 실제 우리가 사용하는 하이퍼 파라미터 중 정수인 경우에도 문제가 있겠지만 실수인 경우에서는 훨씬 더 큰 문제가 발생합니다. 왜냐하면 여러분들이 손쉽게 볼 수 있는 하이퍼 파라미터들"},{"start":485700,"end":500700,"text":"혹은 다른 경진대회 혹은 현업에서 볼 수 있는 하이퍼 파라미터들을 보시면 인간이 추론할 수 있는 어떤 수치의 값이 아닙니다. 실제로 어떤 실수 값으로 매우 낮은 소수점까지 튜닝을 하게 됩니다.","confidence":0.9368,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[486050,486260,"혹은"],[486490,486720,"다른"],[486830,487360,"경진대회"],[487870,488080,"혹은"],[488390,488800,"현업에서"],[488800,488907,"볼"],[488907,488980,"수"],[488980,489087,"있는"],[489087,489320,"하이퍼"],[489320,489820,"파라미터들을"],[489830,490200,"보시면"],[490950,491300,"인간이"],[491330,491660,"추론할"],[491670,491820,"수"],[491820,492040,"있는"],[492590,492840,"어떤"],[492930,493380,"수치의"],[493430,493780,"값이"],[493850,494280,"아닙니다."],[494990,495340,"실제로"],[495410,495660,"어떤"],[496290,496740,"실수"],[497070,497540,"값으로"],[497950,498200,"매우"],[498530,498780,"낮은"],[498870,499480,"소수점까지"],[499830,500180,"튜닝을"],[500180,500314,"하게"],[500314,500580,"됩니다."]],"textEdited":"혹은 다른 경진대회 혹은 현업에서 볼 수 있는 하이퍼 파라미터들을 보시면 인간이 추론할 수 있는 어떤 수치의 값이 아닙니다. 실제로 어떤 실수 값으로 매우 낮은 소수점까지 튜닝을 하게 됩니다."},{"start":500700,"end":508700,"text":"그렇기 때문에 그리스 워치는 가장 쉬우면서도 직관적인 방법이지만 실제로는 최적의 점을 찾기는 사실상 어렵습니다.","confidence":0.969,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[501130,501374,"그렇기"],[501374,501680,"때문에"],[502010,502294,"그리스"],[502294,502660,"워치는"],[503090,503320,"가장"],[503390,503900,"쉬우면서도"],[504190,504660,"직관적인"],[504690,505180,"방법이지만"],[505690,506180,"실제로는"],[506210,506540,"최적의"],[506540,506760,"점을"],[506790,507160,"찾기는"],[507690,508020,"사실상"],[508020,508560,"어렵습니다."]],"textEdited":"그렇기 때문에 그리스 워치는 가장 쉬우면서도 직관적인 방법이지만 실제로는 최적의 점을 찾기는 사실상 어렵습니다."},{"start":508700,"end":517400,"text":"다음은 랜덤 서치입니다. 그리 설치에서 그리드를 만들어서 정해진 구간을 탐색하는 거였다면 랜덤 서치는 튜닝할 하이퍼 파라미터와","confidence":0.9308,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[509090,509420,"다음은"],[509450,509700,"랜덤"],[509710,510160,"서치입니다."],[510470,510660,"그리"],[510670,511160,"설치에서"],[511490,511940,"그리드를"],[511950,512400,"만들어서"],[512750,513140,"정해진"],[513430,513800,"구간을"],[513810,514260,"탐색하는"],[514260,514700,"거였다면"],[515150,515380,"랜덤"],[515380,515740,"서치는"],[516130,516500,"튜닝할"],[516550,516800,"하이퍼"],[516800,517200,"파라미터와"]],"textEdited":"다음은 랜덤 서치입니다. 그리 설치에서 그리드를 만들어서 정해진 구간을 탐색하는 거였다면 랜덤 서치는 튜닝할 하이퍼 파라미터와"},{"start":517400,"end":529300,"text":"그리고 탐색할 하이퍼 파라미터의 값의 범위를 지정합니다. 이 과정에서 랜덤하게 하이퍼 파라미터의 실제 값들을 설정을 하고 학습을 진행한 뒤에 탐색을 진행합니다.","confidence":0.9656,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[517630,517960,"그리고"],[518370,518780,"탐색할"],[518950,519240,"하이퍼"],[519250,519740,"파라미터의"],[519740,520040,"값의"],[520250,520640,"범위를"],[520670,521100,"지정합니다."],[521430,521580,"이"],[521630,522060,"과정에서"],[522390,522880,"랜덤하게"],[523090,523380,"하이퍼"],[523410,523960,"파라미터의"],[524510,524820,"실제"],[524890,525400,"값들을"],[525890,526220,"설정을"],[526220,526460,"하고"],[527030,527380,"학습을"],[527430,527780,"진행한"],[527780,528000,"뒤에"],[528310,528660,"탐색을"],[528660,529160,"진행합니다."]],"textEdited":"그리고 탐색할 하이퍼 파라미터의 값의 범위를 지정합니다. 이 과정에서 랜덤하게 하이퍼 파라미터의 실제 값들을 설정을 하고 학습을 진행한 뒤에 탐색을 진행합니다."},{"start":529300,"end":538800,"text":"사실 탐색이라고 설명을 했지만 탐색이라고 말하기는 약간 어렵습니다. 왜냐하면 모든 하이퍼 파라미터는 랜덤하게 임의로 선택되기 때문입니다.","confidence":0.9657,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[529730,529980,"사실"],[530110,530640,"탐색이라고"],[530650,530874,"설명을"],[530874,531180,"했지만"],[531790,532360,"탐색이라고"],[532360,532860,"말하기는"],[533370,533620,"약간"],[533630,534100,"어렵습니다."],[534650,535060,"왜냐하면"],[535150,535380,"모든"],[535390,535607,"하이퍼"],[535607,536060,"파라미터는"],[536610,537100,"랜덤하게"],[537630,537940,"임의로"],[537940,538287,"선택되기"],[538287,538800,"때문입니다."]],"textEdited":"사실 탐색이라고 설명을 했지만 탐색이라고 말하기는 약간 어렵습니다. 왜냐하면 모든 하이퍼 파라미터는 랜덤하게 임의로 선택되기 때문입니다."},{"start":538800,"end":552800,"text":"그래서 그리드 서치에서 있었던 실수 혹은 인간이 인지하기 어려운 실수 범위 혹은 인간이 먼저 그리드를 설정해야 된다라는 단점은 해결할 수 있지만 여전히 비효율적일 수 있습니다.","confidence":0.9921,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[539110,539380,"그래서"],[539810,540120,"그리드"],[540120,540580,"서치에서"],[540610,540940,"있었던"],[541530,541940,"실수"],[542190,542440,"혹은"],[543090,543520,"인간이"],[543790,544220,"인지하기"],[544220,544440,"어려운"],[544610,545000,"실수"],[545000,545220,"범위"],[545530,545780,"혹은"],[546310,546720,"인간이"],[546850,547120,"먼저"],[547390,547800,"그리드를"],[547830,548187,"설정해야"],[548187,548620,"된다라는"],[549050,549480,"단점은"],[549610,549960,"해결할"],[549960,550034,"수"],[550034,550340,"있지만"],[550750,551120,"여전히"],[551310,551940,"비효율적일"],[552010,552160,"수"],[552230,552680,"있습니다."]],"textEdited":"그래서 그리드 서치에서 있었던 실수 혹은 인간이 인지하기 어려운 실수 범위 혹은 인간이 먼저 그리드를 설정해야 된다라는 단점은 해결할 수 있지만 여전히 비효율적일 수 있습니다."},{"start":552800,"end":564500,"text":"다음 하이퍼 파라미터 튜닝 방법론은 베이지안 서치입니다. 베이지안 서치는 선택된 하이퍼 파라미터와 모델 성능 사이의 관계성이 있을 것을 고려하여 최적의 하이퍼 파라미터 조합을 찾는 것입니다.","confidence":0.9163,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[553470,553700,"다음"],[553730,553980,"하이퍼"],[553980,554320,"파라미터"],[554320,554580,"튜닝"],[554630,555080,"방법론은"],[555670,556080,"베이지안"],[556090,556580,"서치입니다."],[557110,557520,"베이지안"],[557520,557860,"서치는"],[558270,558640,"선택된"],[558710,558960,"하이퍼"],[558960,559440,"파라미터와"],[559890,560160,"모델"],[560290,560540,"성능"],[560550,560840,"사이의"],[560910,561380,"관계성이"],[561380,561560,"있을"],[561570,561820,"것을"],[561830,562220,"고려하여"],[562610,562874,"최적의"],[562874,563100,"하이퍼"],[563100,563380,"파라미터"],[563380,563660,"조합을"],[563660,563900,"찾는"],[563900,564260,"것입니다."]],"textEdited":"다음 하이퍼 파라미터 튜닝 방법론은 베이지안 서치입니다. 베이지안 서치는 선택된 하이퍼 파라미터와 모델 성능 사이의 관계성이 있을 것을 고려하여 최적의 하이퍼 파라미터 조합을 찾는 것입니다."},{"start":564500,"end":575000,"text":"예시를 보겠습니다. 가장 왼쪽에 있는 랜덤 서치의 경우 약 10번의 시도에 걸쳐 글로벌 미니멈 최적점에 도달한 것을 확인하실 수 있습니다. 다음은 그리 설치입니다.","confidence":0.9469,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[564990,565327,"예시를"],[565327,565780,"보겠습니다."],[566450,566700,"가장"],[566770,567120,"왼쪽에"],[567120,567260,"있는"],[567350,567580,"랜덤"],[567580,567887,"서치의"],[567887,568140,"경우"],[568530,568680,"약"],[568850,569320,"10번의"],[569350,569660,"시도에"],[569710,570020,"걸쳐"],[570550,570820,"글로벌"],[570830,571120,"미니멈"],[571490,571940,"최적점에"],[571940,572240,"도달한"],[572240,572480,"것을"],[572610,572980,"확인하실"],[572980,573054,"수"],[573054,573360,"있습니다."],[573670,574000,"다음은"],[574090,574280,"그리"],[574290,574840,"설치입니다."]],"textEdited":"예시를 보겠습니다. 가장 왼쪽에 있는 랜덤 서치의 경우 약 10번의 시도에 걸쳐 글로벌 미니멈 최적점에 도달한 것을 확인하실 수 있습니다. 다음은 그리 설치입니다."},{"start":575000,"end":588600,"text":"그릴 서치는 개발자가 설정한 각 하이퍼 파라미터들의 그리드를 기반으로 가능한 모든 경우의 수를 탐색합니다. 결과에서 보시면 아시겠지만 그리 서치는 글로벌 미니멈에 도달하지 못했습니다.","confidence":0.9489,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[575270,575480,"그릴"],[575490,575860,"서치는"],[576470,577060,"개발자가"],[577390,577760,"설정한"],[578210,578360,"각"],[578450,578740,"하이퍼"],[578770,579380,"파라미터들의"],[579730,580140,"그리드를"],[580140,580540,"기반으로"],[581050,581400,"가능한"],[581510,581720,"모든"],[581830,582140,"경우의"],[582150,582460,"수를"],[582810,583320,"탐색합니다."],[583790,584240,"결과에서"],[584250,584560,"보시면"],[584560,585060,"아시겠지만"],[585550,585760,"그리"],[585770,586160,"서치는"],[586610,586920,"글로벌"],[586930,587340,"미니멈에"],[587510,587960,"도달하지"],[587960,588540,"못했습니다."]],"textEdited":"그릴 서치는 개발자가 설정한 각 하이퍼 파라미터들의 그리드를 기반으로 가능한 모든 경우의 수를 탐색합니다. 결과에서 보시면 아시겠지만 그리 서치는 글로벌 미니멈에 도달하지 못했습니다."},{"start":588600,"end":602600,"text":"다음은 베이지안 서치입니다. 베이지안 서치는 약 다섯 번 만의 시도 끝에 글로벌 미니멈에 가까이 도달한 것을 확인할 수 있습니다. 그래서 여러분들이 현업에서 하이퍼 파라미터 튜닝을 수행하신다면","confidence":0.9075,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[589050,589360,"다음은"],[589410,589780,"베이지안"],[589780,590180,"서치입니다."],[590570,590920,"베이지안"],[590920,591240,"서치는"],[591650,591800,"약"],[592190,592460,"다섯"],[592470,592620,"번"],[592630,592920,"만의"],[593110,593360,"시도"],[593360,593620,"끝에"],[594050,594340,"글로벌"],[594370,594780,"미니멈에"],[595210,595640,"가까이"],[595990,596380,"도달한"],[596380,596660,"것을"],[596910,597220,"확인할"],[597220,597314,"수"],[597314,597660,"있습니다."],[598610,598840,"그래서"],[598850,599420,"여러분들이"],[599670,600160,"현업에서"],[600170,600400,"하이퍼"],[600400,600700,"파라미터"],[600700,601080,"튜닝을"],[601650,602420,"수행하신다면"]],"textEdited":"다음은 베이지안 서치입니다. 베이지안 서치는 약 다섯 번 만의 시도 끝에 글로벌 미니멈에 가까이 도달한 것을 확인할 수 있습니다. 그래서 여러분들이 현업에서 하이퍼 파라미터 튜닝을 수행하신다면"},{"start":602600,"end":616300,"text":"일반적으로 처음 수행하는 것은 베이지안 옵티마이션 설치일 것입니다. 이외에도 데이터의 특성 혹은 도메인의 특성에 따라 베이지안 옵티마이제이션을 기반으로 한 다른 튜닝 방법론을 사용하실 수도 있습니다.","confidence":0.977,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[602970,603620,"일반적으로"],[603730,603960,"처음"],[604290,604740,"수행하는"],[604740,605000,"것은"],[605290,605700,"베이지안"],[605710,606240,"옵티마이션"],[606250,606660,"설치일"],[606660,607020,"것입니다."],[607550,608060,"이외에도"],[608550,608980,"데이터의"],[609050,609340,"특성"],[609770,610000,"혹은"],[610130,610520,"도메인의"],[610550,610880,"특성에"],[610880,611100,"따라"],[611670,612080,"베이지안"],[612080,612780,"옵티마이제이션을"],[612780,613160,"기반으로"],[613160,613280,"한"],[613750,613940,"다른"],[614030,614260,"튜닝"],[614310,614740,"방법론을"],[615070,615460,"사용하실"],[615460,615640,"수도"],[615640,616060,"있습니다."]],"textEdited":"일반적으로 처음 수행하는 것은 베이지안 옵티마이션 설치일 것입니다. 이외에도 데이터의 특성 혹은 도메인의 특성에 따라 베이지안 옵티마이제이션을 기반으로 한 다른 튜닝 방법론을 사용하실 수도 있습니다."},{"start":616300,"end":631300,"text":"베이지안 서치를 조금 더 쉽게 이해해 보도록 하겠습니다. 먼저 우리가 풀고자 하는 문제를 정리해 보겠습니다. 여러분들이 낚시를 하러 갔다고 생각해 보겠습니다. 가장 큰 물고기를 낚을 수 있는 하이퍼 파라미터 여기에서는 배의 위치","confidence":0.9577,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[616770,617160,"베이지안"],[617160,617540,"서치를"],[617710,617940,"조금"],[617940,618080,"더"],[618130,618440,"쉽게"],[618630,618867,"이해해"],[618867,619160,"보도록"],[619160,619580,"하겠습니다."],[620230,620480,"먼저"],[620710,621000,"우리가"],[621070,621387,"풀고자"],[621387,621560,"하는"],[621610,621940,"문제를"],[621950,622214,"정리해"],[622214,622620,"보겠습니다."],[623190,623680,"여러분들이"],[623730,624160,"낚시를"],[624160,624360,"하러"],[624360,624740,"갔다고"],[625190,625414,"생각해"],[625414,625840,"보겠습니다."],[626490,626740,"가장"],[626850,627000,"큰"],[627110,627487,"물고기를"],[627487,627720,"낚을"],[627720,627794,"수"],[627794,627960,"있는"],[628110,628380,"하이퍼"],[628380,628780,"파라미터"],[629290,629820,"여기에서는"],[630230,630500,"배의"],[630530,630800,"위치"]],"textEdited":"베이지안 서치를 조금 더 쉽게 이해해 보도록 하겠습니다. 먼저 우리가 풀고자 하는 문제를 정리해 보겠습니다. 여러분들이 낚시를 하러 갔다고 생각해 보겠습니다. 가장 큰 물고기를 낚을 수 있는 하이퍼 파라미터 여기에서는 배의 위치"},{"start":631300,"end":639200,"text":"그리고 낚싯대의 깊이를 찾는다고 가정해 보겠습니다. 첫 번째는 초기 탐색입니다. 무작위로 몇 군데 낚시를 시도합니다.","confidence":0.9141,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[631550,631860,"그리고"],[632330,632920,"낚싯대의"],[633090,633760,"깊이를"],[633850,634320,"찾는다고"],[634430,634727,"가정해"],[634727,635200,"보겠습니다."],[635710,635860,"첫"],[635870,636220,"번째는"],[636250,636480,"초기"],[636510,637040,"탐색입니다."],[637370,637840,"무작위로"],[637870,638020,"몇"],[638070,638300,"군데"],[638330,638700,"낚시를"],[638710,639120,"시도합니다."]],"textEdited":"그리고 낚싯대의 깊이를 찾는다고 가정해 보겠습니다. 첫 번째는 초기 탐색입니다. 무작위로 몇 군데 낚시를 시도합니다."},{"start":639200,"end":652200,"text":"랜덤 하이퍼 파라미터 조합을 가지고 일단 모델 학습을 몇 개 정도 수행해 봅니다. 여기에서 얻은 정보는 낚시를 했던 위치, 낚싯대의 깊이와 같은 세팅, 그리고 실제로 내가 잡은 물고기의 크기","confidence":0.9817,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[639550,639840,"랜덤"],[639850,640100,"하이퍼"],[640100,640347,"파라미터"],[640347,640660,"조합을"],[640660,641000,"가지고"],[641330,641600,"일단"],[641750,642020,"모델"],[642050,642380,"학습을"],[642650,642800,"몇"],[642810,642960,"개"],[642960,643240,"정도"],[643490,643767,"수행해"],[643767,644060,"봅니다."],[644470,644860,"여기에서"],[644860,645060,"얻은"],[645110,645480,"정보는"],[645850,646167,"낚시를"],[646167,646360,"했던"],[646410,646660,"위치,"],[647230,647700,"낚싯대의"],[647730,648060,"깊이와"],[648070,648320,"같은"],[648710,648980,"세팅,"],[649450,649680,"그리고"],[649750,650140,"실제로"],[650350,650580,"내가"],[650710,650960,"잡은"],[651230,651680,"물고기의"],[651730,651960,"크기"]],"textEdited":"랜덤 하이퍼 파라미터 조합을 가지고 일단 모델 학습을 몇 개 정도 수행해 봅니다. 여기에서 얻은 정보는 낚시를 했던 위치, 낚싯대의 깊이와 같은 세팅, 그리고 실제로 내가 잡은 물고기의 크기"},{"start":652200,"end":667200,"text":"이런 것들입니다. 다음으로는 얻은 정보를 기반으로 물고기 지도를 만들겠습니다. 우리가 방금 이전 페이지에서 봤던 어떤 그래프 같은 걸 만든다 정도로 이해하시면 되겠습니다. 지금까지의 결과로 물고기 밀도 지도를 생성합니다.","confidence":0.9841,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[652510,652740,"이런"],[652740,653200,"것들입니다."],[653610,654180,"다음으로는"],[654530,654780,"얻은"],[654870,655260,"정보를"],[655270,655700,"기반으로"],[656330,656740,"물고기"],[656740,657100,"지도를"],[657450,658040,"만들겠습니다."],[658510,658760,"우리가"],[658850,659080,"방금"],[659110,659340,"이전"],[659410,659760,"페이지에서"],[659760,660020,"봤던"],[660350,660560,"어떤"],[660630,660960,"그래프"],[660960,661187,"같은"],[661187,661320,"걸"],[661450,661820,"만든다"],[662050,662380,"정도로"],[662390,662787,"이해하시면"],[662787,663220,"되겠습니다."],[663870,664480,"지금까지의"],[664490,664880,"결과로"],[665390,665860,"물고기"],[665930,666280,"밀도"],[666290,666620,"지도를"],[666630,667040,"생성합니다."]],"textEdited":"이런 것들입니다. 다음으로는 얻은 정보를 기반으로 물고기 지도를 만들겠습니다. 우리가 방금 이전 페이지에서 봤던 어떤 그래프 같은 걸 만든다 정도로 이해하시면 되겠습니다. 지금까지의 결과로 물고기 밀도 지도를 생성합니다."},{"start":667200,"end":679500,"text":"이는 가우시안 프로세스를 통해 등고선을 그린다 정도로 이해하시면 되겠습니다. 지도로부터 알 수 있는 정보는 예상된 물고기의 크기 그리고 정보가 부족한 불확실성이 있는 지역들이 나타납니다.","confidence":0.9339,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[667450,667720,"이는"],[667950,668360,"가우시안"],[668360,668860,"프로세스를"],[668860,669080,"통해"],[669370,669880,"등고선을"],[669880,670180,"그린다"],[670470,670820,"정도로"],[670830,671207,"이해하시면"],[671207,671660,"되겠습니다."],[671970,672480,"지도로부터"],[672490,672640,"알"],[672640,672700,"수"],[672700,672860,"있는"],[672950,673320,"정보는"],[673690,674080,"예상된"],[674150,674580,"물고기의"],[674630,674840,"크기"],[675350,675620,"그리고"],[676050,676440,"정보가"],[676510,676860,"부족한"],[677350,677920,"불확실성이"],[677920,678060,"있는"],[678190,678700,"지역들이"],[678870,679340,"나타납니다."]],"textEdited":"이는 가우시안 프로세스를 통해 등고선을 그린다 정도로 이해하시면 되겠습니다. 지도로부터 알 수 있는 정보는 예상된 물고기의 크기 그리고 정보가 부족한 불확실성이 있는 지역들이 나타납니다."},{"start":679500,"end":693000,"text":"다음 단계에서는 다음 낚시 지점을 선정합니다. 물고기가 잡힐 것 같은 곳 이는 모델 성능이 높을 것으로 예상되는 지점을 이야기합니다. 다음은 아직 탐색이 많이 되지 않은 곳을 선정합니다.","confidence":0.9358,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[680030,680260,"다음"],[680350,680840,"단계에서는"],[681410,681680,"다음"],[681830,682087,"낚시"],[682087,682400,"지점을"],[682590,683080,"선정합니다."],[683730,684220,"물고기가"],[684230,684480,"잡힐"],[684480,684620,"것"],[684630,684880,"같은"],[684880,685020,"곳"],[685290,685580,"이는"],[685930,686220,"모델"],[686310,686600,"성능이"],[686600,686860,"높을"],[686890,687260,"것으로"],[687430,687900,"예상되는"],[687990,688320,"지점을"],[688330,688780,"이야기합니다."],[689370,689680,"다음은"],[690230,690460,"아직"],[690630,690980,"탐색이"],[690990,691220,"많이"],[691230,691480,"되지"],[691510,691720,"않은"],[691770,692060,"곳을"],[692290,692760,"선정합니다."]],"textEdited":"다음 단계에서는 다음 낚시 지점을 선정합니다. 물고기가 잡힐 것 같은 곳 이는 모델 성능이 높을 것으로 예상되는 지점을 이야기합니다. 다음은 아직 탐색이 많이 되지 않은 곳을 선정합니다."},{"start":693000,"end":705200,"text":"이는 우리가 작성한 물고기 지도에서 불확실성이 높은 곳을 의미합니다. 두 요소를 조합하여 점수를 매겨서 우선순위를 설정합니다. 그다음 다시 한 번 더 실제 낚시를","confidence":0.99,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[693330,693600,"이는"],[694170,694500,"우리가"],[694950,695320,"작성한"],[695910,696360,"물고기"],[696390,696860,"지도에서"],[697270,697747,"불확실성이"],[697747,698000,"높은"],[698030,698300,"곳을"],[698630,699100,"의미합니다."],[699530,699680,"두"],[699710,700007,"요소를"],[700007,700440,"조합하여"],[700670,701120,"점수를"],[701120,701420,"매겨서"],[701810,702267,"우선순위를"],[702267,702680,"설정합니다."],[703230,703560,"그다음"],[703870,704120,"다시"],[704120,704207,"한"],[704207,704340,"번"],[704340,704460,"더"],[704530,704760,"실제"],[704770,705120,"낚시를"]],"textEdited":"이는 우리가 작성한 물고기 지도에서 불확실성이 높은 곳을 의미합니다. 두 요소를 조합하여 점수를 매겨서 우선순위를 설정합니다. 그다음 다시 한 번 더 실제 낚시를"},{"start":705200,"end":718500,"text":"진행합니다. 우선순위가 높은 지점에서 낚시를 한다는 것은 새로운 하이퍼 파라미터 조합으로 실험을 진행한다는 것입니다. 실험을 진행했으면 실제 성능을 확인합니다. 잡힌 물고기의 크기를 확인해 보는 것이죠.","confidence":0.9625,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[705450,705900,"진행합니다."],[706310,706840,"우선순위가"],[706840,707040,"높은"],[707090,707460,"지점에서"],[707850,708240,"낚시를"],[708250,708600,"한다는"],[708600,708840,"것은"],[709290,709600,"새로운"],[709670,709940,"하이퍼"],[709940,710220,"파라미터"],[710220,710620,"조합으로"],[710990,711320,"실험을"],[711430,711867,"진행한다는"],[711867,712240,"것입니다."],[713150,713480,"실험을"],[713490,714040,"진행했으면"],[714650,714980,"실제"],[715070,715380,"성능을"],[715430,715840,"확인합니다."],[716290,716540,"잡힌"],[716590,717060,"물고기의"],[717090,717440,"크기를"],[717590,717867,"확인해"],[717867,718047,"보는"],[718047,718340,"것이죠."]],"textEdited":"진행합니다. 우선순위가 높은 지점에서 낚시를 한다는 것은 새로운 하이퍼 파라미터 조합으로 실험을 진행한다는 것입니다. 실험을 진행했으면 실제 성능을 확인합니다. 잡힌 물고기의 크기를 확인해 보는 것이죠."},{"start":718500,"end":731500,"text":"이를 통해 우리가 가진 물고기 지도를 다시 한 번 더 갱신합니다. 그런 다음 이를 반복합니다. 보시는 예시와 같이 이터레이션을 돌면서 하이퍼 파라미터에 따른","confidence":0.9774,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[718930,719200,"이를"],[719230,719480,"통해"],[720050,720380,"우리가"],[720470,720700,"가진"],[721110,721500,"물고기"],[721500,721840,"지도를"],[722210,722500,"다시"],[722530,722647,"한"],[722647,722780,"번"],[722780,722900,"더"],[723310,723780,"갱신합니다."],[724530,724720,"그런"],[724730,724940,"다음"],[725290,725540,"이를"],[725770,726340,"반복합니다."],[726830,727180,"보시는"],[727190,727520,"예시와"],[727530,727820,"같이"],[728310,728847,"이터레이션을"],[728847,729220,"돌면서"],[729850,730160,"하이퍼"],[730190,731000,"파라미터에"],[731000,731260,"따른"]],"textEdited":"이를 통해 우리가 가진 물고기 지도를 다시 한 번 더 갱신합니다. 그런 다음 이를 반복합니다. 보시는 예시와 같이 이터레이션을 돌면서 하이퍼 파라미터에 따른"},{"start":731500,"end":742500,"text":"모델 성능에 대한 함수를 추정하여 최적의 하이퍼 파라미터를 탐색하는 것이 베이지안 옵티마이제이션 방법론입니다. 그림에서 보시면 아실 수 있듯이 인터레이션이 진행됨에 따라","confidence":0.9501,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[731770,732040,"모델"],[732130,732420,"성능에"],[732420,732600,"대한"],[732870,733240,"함수를"],[733240,733620,"추정하여"],[734050,734380,"최적의"],[734380,734640,"하이퍼"],[734640,735040,"파라미터를"],[735040,735480,"탐색하는"],[735480,735740,"것이"],[736050,736460,"베이지안"],[736460,737080,"옵티마이제이션"],[737410,738020,"방법론입니다."],[738930,739300,"그림에서"],[739310,739640,"보시면"],[739670,739880,"아실"],[739880,739954,"수"],[739954,740300,"있듯이"],[740850,741540,"인터레이션이"],[741590,742040,"진행됨에"],[742050,742320,"따라"]],"textEdited":"모델 성능에 대한 함수를 추정하여 최적의 하이퍼 파라미터를 탐색하는 것이 베이지안 옵티마이제이션 방법론입니다. 그림에서 보시면 아실 수 있듯이 인터레이션이 진행됨에 따라"},{"start":742500,"end":755100,"text":"최적화된 그 스코어에 탐색 범위가 가까워지는 것을 볼 수 있습니다. 하이퍼 파라미터 튜닝 방법론에 대해 정리를 한번 해보겠습니다. 하이퍼 파라미터 튜닝은 여러 가지 방법을 사용할 수 있고 정답이 정해져 있는 것은 아닙니다.","confidence":0.936,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[742870,743360,"최적화된"],[743490,743640,"그"],[743710,744140,"스코어에"],[744530,744800,"탐색"],[744810,745120,"범위가"],[745370,745914,"가까워지는"],[745914,746160,"것을"],[746310,746460,"볼"],[746490,746594,"수"],[746594,746900,"있습니다."],[747450,747780,"하이퍼"],[747830,748240,"파라미터"],[748290,748600,"튜닝"],[748690,749107,"방법론에"],[749107,749280,"대해"],[749350,749614,"정리를"],[749614,749780,"한번"],[749780,750340,"해보겠습니다."],[750730,751000,"하이퍼"],[751000,751360,"파라미터"],[751370,751740,"튜닝은"],[751910,752147,"여러"],[752147,752360,"가지"],[752370,752640,"방법을"],[752640,752880,"사용할"],[752880,752974,"수"],[752974,753220,"있고"],[753630,754000,"정답이"],[754000,754260,"정해져"],[754260,754420,"있는"],[754420,754607,"것은"],[754607,754920,"아닙니다."]],"textEdited":"최적화된 그 스코어에 탐색 범위가 가까워지는 것을 볼 수 있습니다. 하이퍼 파라미터 튜닝 방법론에 대해 정리를 한번 해보겠습니다. 하이퍼 파라미터 튜닝은 여러 가지 방법을 사용할 수 있고 정답이 정해져 있는 것은 아닙니다."},{"start":755100,"end":761900,"text":"하이퍼 파라미터 옵티마이션을 통해 모델의 성능을 최적화할 수는 있지만 항상 주어진 계산 자원과 시간이 무한하지 않기 때문에","confidence":0.9708,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[755430,755720,"하이퍼"],[755720,756060,"파라미터"],[756060,756620,"옵티마이션을"],[756620,756840,"통해"],[757250,757560,"모델의"],[757560,757800,"성능을"],[757800,758220,"최적화할"],[758220,758420,"수는"],[758420,758700,"있지만"],[759030,759280,"항상"],[759330,759660,"주어진"],[759710,759960,"계산"],[759960,760300,"자원과"],[760590,760920,"시간이"],[760920,761280,"무한하지"],[761280,761480,"않기"],[761480,761800,"때문에"]],"textEdited":"하이퍼 파라미터 옵티마이션을 통해 모델의 성능을 최적화할 수는 있지만 항상 주어진 계산 자원과 시간이 무한하지 않기 때문에"},{"start":761900,"end":776700,"text":"사용자가 적절한 선에서 하이퍼 파라미터 서치를 진행해야 됩니다. 예를 들어 48시간 동안 그리 설치를 진행해서 나온 결과에서 가장 좋은 하이퍼 파라미터를 쓰겠다. 또는 우리 팀에서 서비스하는 모델의 재학습 주기가 엔 시간인데","confidence":0.9374,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[762370,762800,"사용자가"],[762910,763207,"적절한"],[763207,763500,"선에서"],[763500,763720,"하이퍼"],[763720,764040,"파라미터"],[764040,764420,"서치를"],[764550,764894,"진행해야"],[764894,765160,"됩니다."],[765410,765647,"예를"],[765647,765820,"들어"],[766150,766700,"48시간"],[766700,766920,"동안"],[767190,767380,"그리"],[767390,767820,"설치를"],[767830,768240,"진행해서"],[768270,768440,"나온"],[768530,769000,"결과에서"],[769330,769580,"가장"],[769630,769800,"좋은"],[769850,770080,"하이퍼"],[770080,770387,"파라미터를"],[770387,770680,"쓰겠다."],[771030,771320,"또는"],[771790,771980,"우리"],[772010,772380,"팀에서"],[772690,773280,"서비스하는"],[773650,774040,"모델의"],[774430,774920,"재학습"],[774970,775320,"주기가"],[775770,775920,"엔"],[776010,776480,"시간인데"]],"textEdited":"사용자가 적절한 선에서 하이퍼 파라미터 서치를 진행해야 됩니다. 예를 들어 48시간 동안 그리 설치를 진행해서 나온 결과에서 가장 좋은 하이퍼 파라미터를 쓰겠다. 또는 우리 팀에서 서비스하는 모델의 재학습 주기가 엔 시간인데"},{"start":776700,"end":787900,"text":"그 엔 시간 동안 가장 최대한으로 최적화된 하이퍼 파라미터를 찾고 싶다 라고 한다면 그 n 시간 안에 끝날 수 있는 하이퍼 파라미터 설치 횟수가","confidence":0.9261,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[777190,777340,"그"],[777510,777660,"엔"],[777670,777920,"시간"],[778030,778260,"동안"],[778850,779100,"가장"],[779530,780040,"최대한으로"],[780050,780500,"최적화된"],[780670,780940,"하이퍼"],[780940,781340,"파라미터를"],[781340,781620,"찾고"],[781620,781880,"싶다"],[782210,782480,"라고"],[782480,782820,"한다면"],[783270,783420,"그"],[783550,783700,"n"],[783730,784000,"시간"],[784230,784520,"안에"],[785050,785340,"끝날"],[785350,785454,"수"],[785454,785620,"있는"],[785710,785960,"하이퍼"],[785960,786420,"파라미터"],[786910,787280,"설치"],[787310,787720,"횟수가"]],"textEdited":"그 엔 시간 동안 가장 최대한으로 최적화된 하이퍼 파라미터를 찾고 싶다 라고 한다면 그 n 시간 안에 끝날 수 있는 하이퍼 파라미터 설치 횟수가"},{"start":787900,"end":800700,"text":"최대한 상한이라고 생각하시면 됩니다. 혹은 우리 팀은 이런 하이퍼 파라미터를 튜닝하는 혹은 모델을 학습하는 비용이 매우 민감하기 때문에 최소한으로 해야 한다라는 제약 조건이 있다면","confidence":0.9772,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[788230,788560,"최대한"],[788950,789480,"상한이라고"],[789480,789814,"생각하시면"],[789814,790060,"됩니다."],[790310,790560,"혹은"],[790910,791120,"우리"],[791150,791440,"팀은"],[791790,791960,"이런"],[792030,792300,"하이퍼"],[792300,792760,"파라미터를"],[792760,793160,"튜닝하는"],[793490,793700,"혹은"],[793930,794280,"모델을"],[794280,794660,"학습하는"],[794790,795180,"비용이"],[795670,795940,"매우"],[796370,796900,"민감하기"],[796900,797240,"때문에"],[797650,798140,"최소한으로"],[798150,798400,"해야"],[798410,799360,"한다라는"],[799490,799720,"제약"],[799770,800127,"조건이"],[800127,800460,"있다면"]],"textEdited":"최대한 상한이라고 생각하시면 됩니다. 혹은 우리 팀은 이런 하이퍼 파라미터를 튜닝하는 혹은 모델을 학습하는 비용이 매우 민감하기 때문에 최소한으로 해야 한다라는 제약 조건이 있다면"},{"start":800700,"end":815100,"text":"그 최소한의 제약 조건에 맞춰 횟수를 결정하시면 됩니다. 또한 모델끼리 성능을 비교할 때는 각 모델별로 하이퍼 파라미터 최적화를 진행시켜 주셔야 됩니다. 다음은 하이퍼 파라미터 최적화 툴에 대해서 다뤄보겠습니다.","confidence":0.9388,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[801170,801320,"그"],[801390,801880,"최소한의"],[802030,802260,"제약"],[802310,802680,"조건에"],[802690,803000,"맞춰"],[803290,803720,"횟수를"],[803950,804540,"결정하시면"],[804540,804800,"됩니다."],[805170,805400,"또한"],[805810,806420,"모델끼리"],[806490,806780,"성능을"],[806790,807107,"비교할"],[807107,807320,"때는"],[807530,807680,"각"],[807750,808300,"모델별로"],[808730,809000,"하이퍼"],[809000,809280,"파라미터"],[809280,809740,"최적화를"],[809950,810400,"진행시켜"],[810400,810680,"주셔야"],[810680,810940,"됩니다."],[811690,812020,"다음은"],[812310,812560,"하이퍼"],[812560,812880,"파라미터"],[812910,813260,"최적화"],[813390,813627,"툴에"],[813627,813920,"대해서"],[814170,814840,"다뤄보겠습니다."]],"textEdited":"그 최소한의 제약 조건에 맞춰 횟수를 결정하시면 됩니다. 또한 모델끼리 성능을 비교할 때는 각 모델별로 하이퍼 파라미터 최적화를 진행시켜 주셔야 됩니다. 다음은 하이퍼 파라미터 최적화 툴에 대해서 다뤄보겠습니다."},{"start":815100,"end":828400,"text":"첫 번째로는 우리가 6강에서 다루었던 웨이렌 바이어스입니다. 웨이렌 바이어스의 스윕이라는 기능을 통해 하이퍼 파라미터를 튜닝하고 다음과 같이 결과를 시각화할 수 있습니다. 예시에서 보면 알 수 있듯이","confidence":0.9383,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[815550,815700,"첫"],[815730,816220,"번째로는"],[816490,816780,"우리가"],[816990,817500,"6강에서"],[817510,817940,"다루었던"],[818330,818660,"웨이렌"],[818750,819360,"바이어스입니다."],[820010,820300,"웨이렌"],[820310,820740,"바이어스의"],[820740,821300,"스윕이라는"],[821330,821640,"기능을"],[821650,821860,"통해"],[822190,822480,"하이퍼"],[822480,822920,"파라미터를"],[822920,823360,"튜닝하고"],[823890,824240,"다음과"],[824240,824440,"같이"],[824510,824900,"결과를"],[824930,825380,"시각화할"],[825390,825540,"수"],[825570,825940,"있습니다."],[826810,827240,"예시에서"],[827250,827480,"보면"],[827530,827680,"알"],[827680,827754,"수"],[827754,828040,"있듯이"]],"textEdited":"첫 번째로는 우리가 6강에서 다루었던 웨이렌 바이어스입니다. 웨이렌 바이어스의 스윕이라는 기능을 통해 하이퍼 파라미터를 튜닝하고 다음과 같이 결과를 시각화할 수 있습니다. 예시에서 보면 알 수 있듯이"},{"start":828400,"end":839700,"text":"하이퍼 파라미터의 중요도를 플롯 형태로 시각화할 수도 있고요. 오른쪽에서의 예시와 같이 내가 각 실험에서 선택한 하이퍼 파라미터의 조합에 따라 로스","confidence":0.9642,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[828690,828980,"하이퍼"],[828990,829580,"파라미터의"],[829930,830400,"중요도를"],[830790,830980,"플롯"],[831090,831440,"형태로"],[831730,832260,"시각화할"],[832260,832460,"수도"],[832460,832760,"있고요."],[833490,834120,"오른쪽에서의"],[834120,834420,"예시와"],[834420,834660,"같이"],[835350,835600,"내가"],[835930,836080,"각"],[836210,836640,"실험에서"],[836690,837040,"선택한"],[837050,837300,"하이퍼"],[837300,837680,"파라미터의"],[837690,838060,"조합에"],[838060,838300,"따라"],[839130,839460,"로스"]],"textEdited":"하이퍼 파라미터의 중요도를 플롯 형태로 시각화할 수도 있고요. 오른쪽에서의 예시와 같이 내가 각 실험에서 선택한 하이퍼 파라미터의 조합에 따라 로스"},{"start":839700,"end":853000,"text":"혹은 매트릭이 어느 양상으로 학습되는지를 볼 수 있는 시각화도 제공합니다. 하이퍼 파라미터 스윕을 준비하는 예시를 보겠습니다. 스윗 컨피그라고 하는 어떤 딕셔너리를 준비해 주시면 됩니다.","confidence":0.9178,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[839930,840160,"혹은"],[840670,841220,"매트릭이"],[841630,841840,"어느"],[841950,842380,"양상으로"],[842390,843040,"학습되는지를"],[843070,843220,"볼"],[843230,843334,"수"],[843334,843520,"있는"],[843970,844440,"시각화도"],[844650,845100,"제공합니다."],[845830,846100,"하이퍼"],[846100,846460,"파라미터"],[846490,846840,"스윕을"],[847250,847700,"준비하는"],[848030,848420,"예시를"],[848530,849020,"보겠습니다."],[849750,849980,"스윗"],[850090,850860,"컨피그라고"],[850870,851080,"하는"],[851210,851420,"어떤"],[851530,852080,"딕셔너리를"],[852170,852414,"준비해"],[852414,852647,"주시면"],[852647,852900,"됩니다."]],"textEdited":"혹은 매트릭이 어느 양상으로 학습되는지를 볼 수 있는 시각화도 제공합니다. 하이퍼 파라미터 스윕을 준비하는 예시를 보겠습니다. 스윗 컨피그라고 하는 어떤 딕셔너리를 준비해 주시면 됩니다."},{"start":853000,"end":866300,"text":"여기에서 메소드라고 하는 항목에는 베이즈라고 작성이 되어 있는데요. 베이즈는 베이지 안 설치를 뜻합니다. 이 부분에 여러분들이 랜덤을 넣게 되면 VR 설치나 랜덤 서치가 진행되게 됩니다.","confidence":0.8849,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[853470,853940,"여기에서"],[854270,855100,"메소드라고"],[855100,855280,"하는"],[855330,855760,"항목에는"],[856250,857160,"베이즈라고"],[857310,857594,"작성이"],[857594,857780,"되어"],[857790,858160,"있는데요."],[858690,859100,"베이즈는"],[859410,859727,"베이지"],[859727,859860,"안"],[859990,860420,"설치를"],[860570,860980,"뜻합니다."],[861510,861627,"이"],[861627,861900,"부분에"],[861900,862360,"여러분들이"],[862770,863180,"랜덤을"],[863180,863427,"넣게"],[863427,863640,"되면"],[863850,864060,"VR"],[864070,864440,"설치나"],[864830,865080,"랜덤"],[865080,865440,"서치가"],[865710,866020,"진행되게"],[866020,866280,"됩니다."]],"textEdited":"여기에서 메소드라고 하는 항목에는 베이즈라고 작성이 되어 있는데요. 베이즈는 베이지 안 설치를 뜻합니다. 이 부분에 여러분들이 랜덤을 넣게 되면 VR 설치나 랜덤 서치가 진행되게 됩니다."},{"start":866300,"end":880000,"text":"다음은 하이퍼 파라미터였습니다. 이곳에는 여러분들이 탐색하고 싶은 하이퍼 파라미터들을 정의하고 그 하이퍼 파라미터들에 넣을 어떤 값들 이런 필드들을 정의합니다. 예시에서는 러닝 레이트","confidence":0.9699,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[866570,866920,"다음은"],[867210,867500,"하이퍼"],[867500,868140,"파라미터였습니다."],[868470,868920,"이곳에는"],[869210,869740,"여러분들이"],[870210,870687,"탐색하고"],[870687,870880,"싶은"],[871070,871340,"하이퍼"],[871340,872020,"파라미터들을"],[872110,872580,"정의하고"],[872990,873140,"그"],[873170,873420,"하이퍼"],[873420,873980,"파라미터들에"],[874310,874540,"넣을"],[874810,875040,"어떤"],[875270,875660,"값들"],[876250,876440,"이런"],[876690,877140,"필드들을"],[877410,877860,"정의합니다."],[878370,878840,"예시에서는"],[878990,879260,"러닝"],[879260,879520,"레이트"]],"textEdited":"다음은 하이퍼 파라미터였습니다. 이곳에는 여러분들이 탐색하고 싶은 하이퍼 파라미터들을 정의하고 그 하이퍼 파라미터들에 넣을 어떤 값들 이런 필드들을 정의합니다. 예시에서는 러닝 레이트"},{"start":880000,"end":894300,"text":"배치 사이즈, 드롭바웃 레이트 디 모델이 존재합니다. 러닝 레이트 배치 사이즈 디 모델의 경우 그리드 설치 형태의 값들을 전달을 했고요. 드롭아웃의 경우 최소 최댓값과 함께 어떤 분포에서","confidence":0.8823,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[880210,880480,"배치"],[880480,880780,"사이즈,"],[881210,881580,"드롭바웃"],[881580,881860,"레이트"],[882190,882340,"디"],[882390,882900,"모델이"],[882930,883400,"존재합니다."],[884170,884440,"러닝"],[884440,884740,"레이트"],[884870,885140,"배치"],[885140,885460,"사이즈"],[885870,886020,"디"],[886070,886460,"모델의"],[886460,886700,"경우"],[887230,887540,"그리드"],[887540,887820,"설치"],[887820,888180,"형태의"],[888530,888940,"값들을"],[888950,889247,"전달을"],[889247,889560,"했고요."],[890110,890680,"드롭아웃의"],[890680,890900,"경우"],[891370,891660,"최소"],[891910,892440,"최댓값과"],[892440,892660,"함께"],[893250,893540,"어떤"],[893650,894120,"분포에서"]],"textEdited":"배치 사이즈, 드롭바웃 레이트 디 모델이 존재합니다. 러닝 레이트 배치 사이즈 디 모델의 경우 그리드 설치 형태의 값들을 전달을 했고요. 드롭아웃의 경우 최소 최댓값과 함께 어떤 분포에서"},{"start":894300,"end":908900,"text":"추출할지에 대한 값을 설정했습니다. 이렇게 되면 드라바웃 레이트의 설정을 기준으로 설명을 드리면 0.1부터 0.5까지 균등 분포에서 값을 추출하게 됩니다. 마지막은 매트입니다. 여기에 설정된 매트릭의 네임은","confidence":0.9184,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[894630,895234,"추출할지에"],[895234,895420,"대한"],[895790,896120,"값을"],[896150,896680,"설정했습니다."],[897410,897707,"이렇게"],[897707,897940,"되면"],[898370,898760,"드라바웃"],[898760,899180,"레이트의"],[899210,899540,"설정을"],[899550,899880,"기준으로"],[899890,900160,"설명을"],[900160,900420,"드리면"],[900770,901400,"0.1부터"],[901810,902500,"0.5까지"],[902850,903180,"균등"],[903210,903680,"분포에서"],[903970,904260,"값을"],[904260,904534,"추출하게"],[904534,904780,"됩니다."],[905310,905760,"마지막은"],[905760,906200,"매트입니다."],[906790,907100,"여기에"],[907100,907460,"설정된"],[907510,907960,"매트릭의"],[908330,908720,"네임은"]],"textEdited":"추출할지에 대한 값을 설정했습니다. 이렇게 되면 드라바웃 레이트의 설정을 기준으로 설명을 드리면 0.1부터 0.5까지 균등 분포에서 값을 추출하게 됩니다. 마지막은 매트입니다. 여기에 설정된 매트릭의 네임은"},{"start":908900,"end":919800,"text":"우리가 추후 기록할 로스의 이름을 동일하게 넣어주시면 됩니다. 여기에서 골은 맥시마이즈로 되어 있는데요. 우리가 전달한 매트릭의 수치가","confidence":0.9232,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[909190,909500,"우리가"],[909990,910260,"추후"],[910470,910900,"기록할"],[911370,911840,"로스의"],[911990,912360,"이름을"],[912690,913100,"동일하게"],[913100,913494,"넣어주시면"],[913494,913760,"됩니다."],[914250,914620,"여기에서"],[914650,914920,"골은"],[915210,915767,"맥시마이즈로"],[915767,915940,"되어"],[915940,916300,"있는데요."],[916730,917020,"우리가"],[917630,918060,"전달한"],[918330,918860,"매트릭의"],[919250,919640,"수치가"]],"textEdited":"우리가 추후 기록할 로스의 이름을 동일하게 넣어주시면 됩니다. 여기에서 골은 맥시마이즈로 되어 있는데요. 우리가 전달한 매트릭의 수치가"},{"start":919800,"end":929900,"text":"높을수록 좋다면 맥시마이즈 로스와 같이 낮을수록 좋다면 미니마이즈라고 전달하시면 됩니다. 다음은 1db 로그인 및 수입 아이디 생성입니다.","confidence":0.9138,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[920050,920560,"높을수록"],[920750,921160,"좋다면"],[921430,921940,"맥시마이즈"],[922410,922880,"로스와"],[922890,923180,"같이"],[923530,923920,"낮을수록"],[923920,924240,"좋다면"],[924530,925640,"미니마이즈라고"],[925670,926147,"전달하시면"],[926147,926400,"됩니다."],[926810,927120,"다음은"],[927270,927620,"1db"],[927650,928000,"로그인"],[928000,928140,"및"],[928490,928740,"수입"],[928750,929060,"아이디"],[929350,929820,"생성입니다."]],"textEdited":"높을수록 좋다면 맥시마이즈 로스와 같이 낮을수록 좋다면 미니마이즈라고 전달하시면 됩니다. 다음은 1db 로그인 및 수입 아이디 생성입니다."},{"start":929900,"end":937900,"text":"이전 예시에서는 커맨드 라인에서 완디비 로그인이라고 하는 어떤 명령어를 사용했었는데요. 이번 예시에서는 코드","confidence":0.9422,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[930550,930800,"이전"],[930870,931400,"예시에서는"],[931830,932167,"커맨드"],[932167,932560,"라인에서"],[932670,933080,"완디비"],[933310,934080,"로그인이라고"],[934080,934240,"하는"],[934240,934400,"어떤"],[934450,934787,"명령어를"],[934787,935400,"사용했었는데요."],[936050,936260,"이번"],[936350,936860,"예시에서는"],[937350,937640,"코드"]],"textEdited":"이전 예시에서는 커맨드 라인에서 완디비 로그인이라고 하는 어떤 명령어를 사용했었는데요. 이번 예시에서는 코드"},{"start":937900,"end":950100,"text":"혹은 노트북에서 1db 수입이라는 명령어를 호출했을 때 자동으로 로그인 및 수입 아이디가 생성되는 예시를 보여줍니다. 완디비 데모라고 하는 프로젝트에","confidence":0.8863,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[938190,938420,"혹은"],[938690,939280,"노트북에서"],[940070,940440,"1db"],[940470,941220,"수입이라는"],[941270,941640,"명령어를"],[941640,942120,"호출했을"],[942170,942320,"때"],[942730,943140,"자동으로"],[943390,943780,"로그인"],[943830,943980,"및"],[944410,944640,"수입"],[944710,945100,"아이디가"],[945130,945520,"생성되는"],[945550,945940,"예시를"],[946070,946580,"보여줍니다."],[947570,948060,"완디비"],[948130,948880,"데모라고"],[948880,949060,"하는"],[949110,949680,"프로젝트에"]],"textEdited":"혹은 노트북에서 1db 수입이라는 명령어를 호출했을 때 자동으로 로그인 및 수입 아이디가 생성되는 예시를 보여줍니다. 완디비 데모라고 하는 프로젝트에"},{"start":950100,"end":965000,"text":"스윕이 생성이 되었고 생성된 스윗 아이디가 보여집니다. 뿐만 아니라 스윕 URL이 같이 출력이 되는데요. 해당 URL을 클릭하여 오른쪽 예시와 같이 하이퍼 파라미터 튜닝 기록이 저장될 대시보드로 이동할 수 있습니다.","confidence":0.7994,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[950390,950760,"스윕이"],[950760,951014,"생성이"],[951014,951400,"되었고"],[951970,952320,"생성된"],[952390,952580,"스윗"],[952580,952980,"아이디가"],[953330,953820,"보여집니다."],[954450,954700,"뿐만"],[954710,954980,"아니라"],[955330,955560,"스윕"],[955570,956040,"URL이"],[956250,956520,"같이"],[956550,956787,"출력이"],[956787,957180,"되는데요."],[957790,958040,"해당"],[958090,958500,"URL을"],[958530,958980,"클릭하여"],[959570,959940,"오른쪽"],[959970,960300,"예시와"],[960330,960600,"같이"],[961470,961720,"하이퍼"],[961730,962100,"파라미터"],[962170,962480,"튜닝"],[962510,962860,"기록이"],[962860,963220,"저장될"],[963650,964220,"대시보드로"],[964220,964500,"이동할"],[964500,964574,"수"],[964574,964920,"있습니다."]],"textEdited":"스윕이 생성이 되었고 생성된 스윗 아이디가 보여집니다. 뿐만 아니라 스윕 URL이 같이 출력이 되는데요. 해당 URL을 클릭하여 오른쪽 예시와 같이 하이퍼 파라미터 튜닝 기록이 저장될 대시보드로 이동할 수 있습니다."},{"start":965000,"end":979200,"text":"이 대시보드에서 튜닝이 되는 과정을 실시간으로 확인할 수 있습니다. 이제 실제로 하이퍼 파라미터 튜닝을 해보도록 하겠습니다. 위드 문으로 구성된 1디비 이닛이 실행되면 이후 실행되는 실험이","confidence":0.9506,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[965410,965560,"이"],[965590,966260,"대시보드에서"],[967070,967447,"튜닝이"],[967447,967660,"되는"],[967710,968060,"과정을"],[968490,969040,"실시간으로"],[969390,969720,"확인할"],[969720,969807,"수"],[969807,970140,"있습니다."],[970950,971140,"이제"],[971450,971840,"실제로"],[971910,972140,"하이퍼"],[972140,972460,"파라미터"],[972460,972840,"튜닝을"],[973210,973660,"해보도록"],[973890,974380,"하겠습니다."],[974910,975147,"위드"],[975147,975460,"문으로"],[975460,975760,"구성된"],[975990,976460,"1디비"],[976590,976980,"이닛이"],[977110,977520,"실행되면"],[977950,978160,"이후"],[978250,978620,"실행되는"],[978670,979000,"실험이"]],"textEdited":"이 대시보드에서 튜닝이 되는 과정을 실시간으로 확인할 수 있습니다. 이제 실제로 하이퍼 파라미터 튜닝을 해보도록 하겠습니다. 위드 문으로 구성된 1디비 이닛이 실행되면 이후 실행되는 실험이"},{"start":979200,"end":986200,"text":"완디비 웹상에서 로깅되기 시작합니다. 두 번째 줄에서 실행되는 완디비 컨피그에서 반환받은 파람즈가","confidence":0.9205,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[979570,979920,"완디비"],[980250,980840,"웹상에서"],[980950,981460,"로깅되기"],[981490,981960,"시작합니다."],[982450,982600,"두"],[982600,982847,"번째"],[982847,983120,"줄에서"],[983120,983480,"실행되는"],[983650,983980,"완디비"],[984070,984740,"컨피그에서"],[984990,985480,"반환받은"],[985590,986060,"파람즈가"]],"textEdited":"완디비 웹상에서 로깅되기 시작합니다. 두 번째 줄에서 실행되는 완디비 컨피그에서 반환받은 파람즈가"},{"start":986200,"end":998500,"text":"우리가 앞서 설정한 스윗 컨피그에 정의되어 있는 하이퍼 파라미터들 중 선택된 하이퍼 파라미터들의 값들을 반환받게 됩니다. 해당 값은 딕셔너리 형태로 반환이 됩니다.","confidence":0.9529,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[986630,986940,"우리가"],[987030,987280,"앞서"],[987330,987680,"설정한"],[988170,988420,"스윗"],[988650,989180,"컨피그에"],[989310,989720,"정의되어"],[989720,989920,"있는"],[990350,990640,"하이퍼"],[990690,991240,"파라미터들"],[991270,991420,"중"],[991910,992360,"선택된"],[992470,992720,"하이퍼"],[992720,993340,"파라미터들의"],[993930,994420,"값들을"],[994670,995054,"반환받게"],[995054,995320,"됩니다."],[995870,996140,"해당"],[996170,996480,"값은"],[996810,997240,"딕셔너리"],[997240,997540,"형태로"],[997830,998094,"반환이"],[998094,998500,"됩니다."]],"textEdited":"우리가 앞서 설정한 스윗 컨피그에 정의되어 있는 하이퍼 파라미터들 중 선택된 하이퍼 파라미터들의 값들을 반환받게 됩니다. 해당 값은 딕셔너리 형태로 반환이 됩니다."},{"start":998500,"end":1009300,"text":"밑에 부분에서 보시면 알 수 있듯이 파람스에서 맥스트랭스 배치 사이즈와 같은 선택된 값들을 꺼내어서 학습 단계에서 사용할 수 있습니다.","confidence":0.9449,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[999070,999360,"밑에"],[999360,999700,"부분에서"],[999710,1000060,"보시면"],[1000130,1000280,"알"],[1000280,1000420,"수"],[1000420,1000760,"있듯이"],[1001250,1001860,"파람스에서"],[1002410,1003000,"맥스트랭스"],[1003430,1003700,"배치"],[1003700,1004100,"사이즈와"],[1004110,1004380,"같은"],[1004890,1005340,"선택된"],[1005450,1005900,"값들을"],[1006270,1006760,"꺼내어서"],[1007190,1007480,"학습"],[1007510,1007920,"단계에서"],[1008130,1008480,"사용할"],[1008510,1008660,"수"],[1008770,1009220,"있습니다."]],"textEdited":"밑에 부분에서 보시면 알 수 있듯이 파람스에서 맥스트랭스 배치 사이즈와 같은 선택된 값들을 꺼내어서 학습 단계에서 사용할 수 있습니다."},{"start":1009300,"end":1018600,"text":"다음은 이전 단계에서 전달받은 모델의 이름을 기반으로 허깅페이스로부터 사전 학습 모델을 불러오는 코드입니다.","confidence":0.9625,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1009630,1010020,"다음은"],[1010530,1010780,"이전"],[1010890,1011360,"단계에서"],[1011770,1012320,"전달받은"],[1012410,1012820,"모델의"],[1012970,1013320,"이름을"],[1013530,1014000,"기반으로"],[1014670,1015700,"허깅페이스로부터"],[1016270,1016540,"사전"],[1016540,1016780,"학습"],[1016780,1017080,"모델을"],[1017130,1017580,"불러오는"],[1017890,1018500,"코드입니다."]],"textEdited":"다음은 이전 단계에서 전달받은 모델의 이름을 기반으로 허깅페이스로부터 사전 학습 모델을 불러오는 코드입니다."},{"start":1018600,"end":1029900,"text":"이를 통해 사전 학습 모델을 불러와서 우리의 태스크에 맞도록 파인튜닝을 진행하게 됩니다. 일반적으로 사전 학습 모델들은 모델의 인베딩 크기, 레이어 수 등이 미리 정해져 있습니다.","confidence":0.9189,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1018930,1019180,"이를"],[1019190,1019400,"통해"],[1019750,1020020,"사전"],[1020020,1020240,"학습"],[1020250,1020580,"모델을"],[1020590,1021040,"불러와서"],[1021690,1021960,"우리의"],[1021990,1022380,"태스크에"],[1022380,1022780,"맞도록"],[1023110,1023680,"파인튜닝을"],[1023770,1024127,"진행하게"],[1024127,1024400,"됩니다."],[1024890,1025480,"일반적으로"],[1025490,1025687,"사전"],[1025687,1025900,"학습"],[1025900,1026320,"모델들은"],[1026690,1027020,"모델의"],[1027030,1027340,"인베딩"],[1027390,1027600,"크기,"],[1028050,1028380,"레이어"],[1028430,1028580,"수"],[1028650,1028900,"등이"],[1028900,1029120,"미리"],[1029130,1029407,"정해져"],[1029407,1029740,"있습니다."]],"textEdited":"이를 통해 사전 학습 모델을 불러와서 우리의 태스크에 맞도록 파인튜닝을 진행하게 됩니다. 일반적으로 사전 학습 모델들은 모델의 인베딩 크기, 레이어 수 등이 미리 정해져 있습니다."},{"start":1029900,"end":1040800,"text":"그렇기 때문에 우리 예제에서는 드라바웃 레이트 정도만 조정해 봅니다. 다음은 모델 네임이 존재하지 않는 경우 랜덤하게 모델 파라미터가 초기화된 트랜스포머를 학습하게 됩니다.","confidence":0.9649,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1030190,1030427,"그렇기"],[1030427,1030740,"때문에"],[1030740,1030900,"우리"],[1030930,1031440,"예제에서는"],[1031750,1032140,"드라바웃"],[1032140,1032380,"레이트"],[1032380,1032680,"정도만"],[1032990,1033294,"조정해"],[1033294,1033580,"봅니다."],[1034270,1034600,"다음은"],[1035090,1035380,"모델"],[1035410,1035720,"네임이"],[1035730,1036180,"존재하지"],[1036190,1036400,"않는"],[1036430,1036680,"경우"],[1037150,1037660,"랜덤하게"],[1037890,1038160,"모델"],[1038210,1038660,"파라미터가"],[1038670,1039060,"초기화된"],[1039390,1040020,"트랜스포머를"],[1040020,1040354,"학습하게"],[1040354,1040700,"됩니다."]],"textEdited":"그렇기 때문에 우리 예제에서는 드라바웃 레이트 정도만 조정해 봅니다. 다음은 모델 네임이 존재하지 않는 경우 랜덤하게 모델 파라미터가 초기화된 트랜스포머를 학습하게 됩니다."},{"start":1040800,"end":1054400,"text":"이때는 디 모델을 조정하여 모델의 인베딩 사이즈를 다양하게 바꿔가며 성능 변화를 확인해 봅니다. 모델을 초기부터 스크래치로 학습하는 경우와 사전 학습 모델을 불러와 파인 튜닝으로 학습하는 경우를 비교할 수 있는 예제입니다.","confidence":0.9573,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1041130,1041480,"이때는"],[1041730,1041880,"디"],[1041990,1042380,"모델을"],[1042470,1042920,"조정하여"],[1043150,1043500,"모델의"],[1043500,1043800,"인베딩"],[1043810,1044200,"사이즈를"],[1044200,1044480,"다양하게"],[1044480,1044860,"바꿔가며"],[1045210,1045480,"성능"],[1045490,1045780,"변화를"],[1045810,1046020,"확인해"],[1046020,1046300,"봅니다."],[1046710,1047100,"모델을"],[1047110,1047480,"초기부터"],[1047480,1047940,"스크래치로"],[1047940,1048300,"학습하는"],[1048300,1048600,"경우와"],[1049470,1049700,"사전"],[1049700,1049900,"학습"],[1049900,1050160,"모델을"],[1050170,1050460,"불러와"],[1050810,1051060,"파인"],[1051090,1051540,"튜닝으로"],[1051690,1052140,"학습하는"],[1052170,1052500,"경우를"],[1052670,1053060,"비교할"],[1053070,1053187,"수"],[1053187,1053380,"있는"],[1053730,1054260,"예제입니다."]],"textEdited":"이때는 디 모델을 조정하여 모델의 인베딩 사이즈를 다양하게 바꿔가며 성능 변화를 확인해 봅니다. 모델을 초기부터 스크래치로 학습하는 경우와 사전 학습 모델을 불러와 파인 튜닝으로 학습하는 경우를 비교할 수 있는 예제입니다."},{"start":1054400,"end":1063800,"text":"다음은 미리 정의해 둔 트레인 모델 함수를 통해서 모델을 학습하도록 합니다. 이때 학습 하이퍼 파라미터로 최대 에폭스와 러닝 레이트를 사용합니다.","confidence":0.9443,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1054970,1055300,"다음은"],[1055830,1056100,"미리"],[1056210,1056534,"정의해"],[1056534,1056660,"둔"],[1056990,1057300,"트레인"],[1057310,1057540,"모델"],[1057550,1057847,"함수를"],[1057847,1058100,"통해서"],[1058250,1058600,"모델을"],[1058600,1059040,"학습하도록"],[1059040,1059280,"합니다."],[1059790,1060040,"이때"],[1060070,1060300,"학습"],[1060300,1060540,"하이퍼"],[1060540,1060920,"파라미터로"],[1061250,1061487,"최대"],[1061487,1061960,"에폭스와"],[1062250,1062500,"러닝"],[1062500,1062920,"레이트를"],[1063130,1063640,"사용합니다."]],"textEdited":"다음은 미리 정의해 둔 트레인 모델 함수를 통해서 모델을 학습하도록 합니다. 이때 학습 하이퍼 파라미터로 최대 에폭스와 러닝 레이트를 사용합니다."},{"start":1063800,"end":1072400,"text":"학습이 완료되었다면 모델 성능을 추적할 수 있도록 매트릭으로 AU PRC를 계산을 하고요. 마지막으로 1db 로그","confidence":0.8582,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1064330,1064607,"학습이"],[1064607,1065180,"완료되었다면"],[1065630,1065900,"모델"],[1065990,1066300,"성능을"],[1066330,1066680,"추적할"],[1066680,1066787,"수"],[1066787,1067100,"있도록"],[1067330,1067880,"매트릭으로"],[1068290,1068620,"AU"],[1068770,1069420,"PRC를"],[1069570,1069920,"계산을"],[1069920,1070220,"하고요."],[1070710,1071260,"마지막으로"],[1071630,1071980,"1db"],[1072010,1072280,"로그"]],"textEdited":"학습이 완료되었다면 모델 성능을 추적할 수 있도록 매트릭으로 AU PRC를 계산을 하고요. 마지막으로 1db 로그"},{"start":1072400,"end":1085100,"text":"라고 하는 메소드를 통해서 1db 상에 필요한 매트릭 그리고 추가적인 어떤 값들을 기록을 합니다. 예시에서는 베스트 auprc 스코어 파이널 트레인, auprc","confidence":0.9153,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1072710,1073000,"라고"],[1073000,1073220,"하는"],[1073650,1074080,"메소드를"],[1074080,1074380,"통해서"],[1074810,1075200,"1db"],[1075200,1075440,"상에"],[1075750,1076080,"필요한"],[1076250,1076580,"매트릭"],[1076790,1077020,"그리고"],[1077510,1077920,"추가적인"],[1077920,1078120,"어떤"],[1078470,1078960,"값들을"],[1079370,1079647,"기록을"],[1079647,1079900,"합니다."],[1080550,1081060,"예시에서는"],[1081570,1081920,"베스트"],[1081970,1082720,"auprc"],[1082950,1083280,"스코어"],[1083690,1083980,"파이널"],[1083990,1084240,"트레인,"],[1084310,1084940,"auprc"]],"textEdited":"라고 하는 메소드를 통해서 1db 상에 필요한 매트릭 그리고 추가적인 어떤 값들을 기록을 합니다. 예시에서는 베스트 auprc 스코어 파이널 트레인, auprc"},{"start":1085100,"end":1099800,"text":"파이널 밸리데이션, 에유피알3 토탈 파람즈를 기록했습니다. 이렇게 설정을 해 둔 상태로 실제로 완디비 에이전트에게 해당 펑션과 그리고 해당 컨피그를 기반으로 수행하도록 명령을 보내 보겠습니다.","confidence":0.8376,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1085410,1085740,"파이널"],[1086090,1086640,"밸리데이션,"],[1086930,1087520,"에유피알3"],[1088150,1088440,"토탈"],[1088450,1089080,"파람즈를"],[1089170,1089740,"기록했습니다."],[1090350,1090640,"이렇게"],[1090710,1091080,"설정을"],[1091110,1091260,"해"],[1091260,1091400,"둔"],[1091490,1091840,"상태로"],[1092470,1092840,"실제로"],[1092910,1093280,"완디비"],[1093280,1093900,"에이전트에게"],[1094470,1094720,"해당"],[1094890,1095380,"펑션과"],[1095790,1096080,"그리고"],[1096470,1096700,"해당"],[1096810,1097187,"컨피그를"],[1097187,1097580,"기반으로"],[1097830,1098360,"수행하도록"],[1098610,1098960,"명령을"],[1098970,1099180,"보내"],[1099180,1099720,"보겠습니다."]],"textEdited":"파이널 밸리데이션, 에유피알3 토탈 파람즈를 기록했습니다. 이렇게 설정을 해 둔 상태로 실제로 완디비 에이전트에게 해당 펑션과 그리고 해당 컨피그를 기반으로 수행하도록 명령을 보내 보겠습니다."},{"start":1099800,"end":1110500,"text":"이때는 완디비 에이전트라고 하는 메서드에 앞서 전달받은 수입 아이디, 그리고 우리가 학습에 사용할 원디비 트레이닝 펑션을 전달합니다. 몇 번 최적화를 진행할지에 대한 값은","confidence":0.9261,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1100190,1100540,"이때는"],[1100670,1101020,"완디비"],[1101020,1101660,"에이전트라고"],[1101660,1101820,"하는"],[1101850,1102280,"메서드에"],[1102650,1102960,"앞서"],[1103030,1103460,"전달받은"],[1103460,1103647,"수입"],[1103647,1103920,"아이디,"],[1104230,1104520,"그리고"],[1104530,1104780,"우리가"],[1105170,1105500,"학습에"],[1105500,1105780,"사용할"],[1106090,1106440,"원디비"],[1106440,1106720,"트레이닝"],[1106770,1107160,"펑션을"],[1107370,1107840,"전달합니다."],[1108110,1108260,"몇"],[1108330,1108480,"번"],[1108710,1109180,"최적화를"],[1109180,1109734,"진행할지에"],[1109734,1109920,"대한"],[1110010,1110320,"값은"]],"textEdited":"이때는 완디비 에이전트라고 하는 메서드에 앞서 전달받은 수입 아이디, 그리고 우리가 학습에 사용할 원디비 트레이닝 펑션을 전달합니다. 몇 번 최적화를 진행할지에 대한 값은"},{"start":1110500,"end":1125500,"text":"카운트라고 하는 값으로 설정합니다. 만약 내가 가진 서버가 혹은 GPU가 여러 개라면 여러 서버에서 같은 수입 아이디를 연동하여 여러 에이전트로 동시에 수입을 진행할 수도 있습니다. 이후 출력되는 결과에서","confidence":0.8934,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1110790,1111620,"카운트라고"],[1111620,1111800,"하는"],[1111810,1112180,"값으로"],[1112630,1113100,"설정합니다."],[1113570,1113800,"만약"],[1113850,1114060,"내가"],[1114090,1114300,"가진"],[1114350,1114740,"서버가"],[1115330,1115560,"혹은"],[1115950,1116440,"GPU가"],[1116550,1116787,"여러"],[1116787,1117140,"개라면"],[1117690,1117920,"여러"],[1117930,1118320,"서버에서"],[1118630,1118900,"같은"],[1118930,1119140,"수입"],[1119140,1119540,"아이디를"],[1119550,1120060,"연동하여"],[1120430,1120660,"여러"],[1120670,1121080,"에이전트로"],[1121110,1121420,"동시에"],[1121420,1121740,"수입을"],[1122010,1122380,"진행할"],[1122380,1122600,"수도"],[1122750,1123120,"있습니다."],[1123730,1123960,"이후"],[1124090,1124520,"출력되는"],[1124610,1125180,"결과에서"]],"textEdited":"카운트라고 하는 값으로 설정합니다. 만약 내가 가진 서버가 혹은 GPU가 여러 개라면 여러 서버에서 같은 수입 아이디를 연동하여 여러 에이전트로 동시에 수입을 진행할 수도 있습니다. 이후 출력되는 결과에서"},{"start":1125500,"end":1139400,"text":"이번 이터레이션에서 어떤 하이퍼 파라미터를 사용하는지 결과를 보실 수가 있습니다. 뿐만 아니라 완디비 학습 함수 안에서 프린트 문을 통해 하이퍼 파라미터 서치 중에 학습이 잘 되는지를 로깅할 수도 있습니다.","confidence":0.9367,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1125990,1126220,"이번"],[1126270,1126940,"이터레이션에서"],[1127530,1127820,"어떤"],[1127870,1128120,"하이퍼"],[1128120,1128620,"파라미터를"],[1128730,1129300,"사용하는지"],[1129730,1130100,"결과를"],[1130100,1130360,"보실"],[1130360,1130507,"수가"],[1130507,1130840,"있습니다."],[1131610,1131860,"뿐만"],[1131860,1132100,"아니라"],[1132450,1132840,"완디비"],[1132930,1133180,"학습"],[1133190,1133440,"함수"],[1133450,1133760,"안에서"],[1134010,1134307,"프린트"],[1134307,1134580,"문을"],[1134580,1134800,"통해"],[1135230,1135520,"하이퍼"],[1135530,1135880,"파라미터"],[1135880,1136107,"서치"],[1136107,1136320,"중에"],[1136730,1137020,"학습이"],[1137020,1137140,"잘"],[1137170,1137680,"되는지를"],[1138050,1138420,"로깅할"],[1138420,1138660,"수도"],[1138750,1139200,"있습니다."]],"textEdited":"이번 이터레이션에서 어떤 하이퍼 파라미터를 사용하는지 결과를 보실 수가 있습니다. 뿐만 아니라 완디비 학습 함수 안에서 프린트 문을 통해 하이퍼 파라미터 서치 중에 학습이 잘 되는지를 로깅할 수도 있습니다."},{"start":1139400,"end":1151300,"text":"에이전트에게 전달한 실험이 완료가 되면 최종 성능을 완디비에서 자동으로 웹 서버에 기록을 하게 됩니다. 수입이 실행되고 있는 상황을 웹에서 확인할 수 있다라는 뜻입니다.","confidence":0.8967,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1139730,1140320,"에이전트에게"],[1140370,1140740,"전달한"],[1140910,1141240,"실험이"],[1141450,1141860,"완료가"],[1141860,1142100,"되면"],[1142790,1143060,"최종"],[1143190,1143520,"성능을"],[1143870,1144480,"완디비에서"],[1144730,1145160,"자동으로"],[1145470,1145620,"웹"],[1145650,1146000,"서버에"],[1146150,1146427,"기록을"],[1146427,1146560,"하게"],[1146560,1146820,"됩니다."],[1147530,1147880,"수입이"],[1147950,1148287,"실행되고"],[1148287,1148440,"있는"],[1148450,1148780,"상황을"],[1149170,1149520,"웹에서"],[1149650,1149927,"확인할"],[1149927,1150014,"수"],[1150014,1150400,"있다라는"],[1150550,1150960,"뜻입니다."]],"textEdited":"에이전트에게 전달한 실험이 완료가 되면 최종 성능을 완디비에서 자동으로 웹 서버에 기록을 하게 됩니다. 수입이 실행되고 있는 상황을 웹에서 확인할 수 있다라는 뜻입니다."},{"start":1151300,"end":1165600,"text":"웹상에서 각 하이퍼 파라미터 튜닝이 끝날 때마다 다음과 같이 어떤 하이퍼 파라미터가 중요한지, 그리고 우리가 최적화하고자 하는 매트릭 혹은 로스와 어떤 코릴레이션이 있는지를 보여줍니다.","confidence":0.9688,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1151610,1152160,"웹상에서"],[1152710,1152860,"각"],[1153190,1153440,"하이퍼"],[1153450,1153820,"파라미터"],[1153830,1154240,"튜닝이"],[1154470,1154720,"끝날"],[1154730,1155060,"때마다"],[1155610,1156000,"다음과"],[1156010,1156260,"같이"],[1156810,1157060,"어떤"],[1157070,1157320,"하이퍼"],[1157320,1157800,"파라미터가"],[1158270,1158780,"중요한지,"],[1159330,1159660,"그리고"],[1160130,1160420,"우리가"],[1160490,1161054,"최적화하고자"],[1161054,1161200,"하는"],[1161230,1161600,"매트릭"],[1161950,1162180,"혹은"],[1162430,1162840,"로스와"],[1163390,1163660,"어떤"],[1163790,1164267,"코릴레이션이"],[1164267,1164680,"있는지를"],[1164930,1165600,"보여줍니다."]],"textEdited":"웹상에서 각 하이퍼 파라미터 튜닝이 끝날 때마다 다음과 같이 어떤 하이퍼 파라미터가 중요한지, 그리고 우리가 최적화하고자 하는 매트릭 혹은 로스와 어떤 코릴레이션이 있는지를 보여줍니다."},{"start":1165600,"end":1177300,"text":"오른쪽에서는 각 실험에 대해 출력된 매트릭 스코어를 확인하실 수 있습니다. 앞서 설명드렸던 것처럼 어떤 하이퍼 파라미터에 어떤 값을 설정했느냐에 따라 다음과 같이","confidence":0.9745,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1165930,1166560,"오른쪽에서는"],[1166830,1166980,"각"],[1167070,1167400,"실험에"],[1167400,1167620,"대해"],[1168130,1168520,"출력된"],[1168810,1169160,"매트릭"],[1169250,1169720,"스코어를"],[1169990,1170400,"확인하실"],[1170430,1170580,"수"],[1170710,1171080,"있습니다."],[1171710,1171980,"앞서"],[1172050,1172520,"설명드렸던"],[1172520,1172800,"것처럼"],[1173330,1173560,"어떤"],[1173590,1173840,"하이퍼"],[1173840,1174320,"파라미터에"],[1174810,1175060,"어떤"],[1175110,1175380,"값을"],[1175380,1175927,"설정했느냐에"],[1175927,1176140,"따라"],[1176390,1176780,"다음과"],[1176780,1177060,"같이"]],"textEdited":"오른쪽에서는 각 실험에 대해 출력된 매트릭 스코어를 확인하실 수 있습니다. 앞서 설명드렸던 것처럼 어떤 하이퍼 파라미터에 어떤 값을 설정했느냐에 따라 다음과 같이"},{"start":1177300,"end":1187500,"text":"가장 오른쪽에 있는 우리가 타겟하는 로스 혹은 어떤 매트릭이 어떤 양상을 보이는지 한눈으로 볼 수 있도록 시각화를 해주는 기능도 존재합니다.","confidence":0.9825,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1177630,1177860,"가장"],[1177910,1178360,"오른쪽에"],[1178360,1178540,"있는"],[1178850,1179160,"우리가"],[1179450,1179900,"타겟하는"],[1180250,1180580,"로스"],[1181050,1181260,"혹은"],[1181290,1181460,"어떤"],[1181490,1181940,"매트릭이"],[1182430,1182660,"어떤"],[1182690,1183000,"양상을"],[1183000,1183460,"보이는지"],[1184150,1184500,"한눈으로"],[1184500,1184640,"볼"],[1184640,1184720,"수"],[1184720,1185020,"있도록"],[1185250,1185780,"시각화를"],[1185780,1186100,"해주는"],[1186230,1186600,"기능도"],[1186850,1187440,"존재합니다."]],"textEdited":"가장 오른쪽에 있는 우리가 타겟하는 로스 혹은 어떤 매트릭이 어떤 양상을 보이는지 한눈으로 볼 수 있도록 시각화를 해주는 기능도 존재합니다."},{"start":1187500,"end":1196800,"text":"이를 통해 우리가 직관적으로 어떤 하이퍼 파라미터에 어느 정도의 값을 설정했을 때 최적의 값에 가까워지는구나를 직관적으로 이해할 수 있게 됩니다.","confidence":0.9854,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1187810,1188040,"이를"],[1188040,1188240,"통해"],[1188240,1188440,"우리가"],[1188530,1189140,"직관적으로"],[1189610,1189880,"어떤"],[1189890,1190120,"하이퍼"],[1190120,1190580,"파라미터에"],[1191030,1191260,"어느"],[1191270,1191560,"정도의"],[1191560,1191860,"값을"],[1191860,1192320,"설정했을"],[1192370,1192520,"때"],[1193050,1193480,"최적의"],[1193830,1194160,"값에"],[1194210,1195160,"가까워지는구나를"],[1195410,1195880,"직관적으로"],[1195880,1196160,"이해할"],[1196160,1196234,"수"],[1196234,1196367,"있게"],[1196367,1196720,"됩니다."]],"textEdited":"이를 통해 우리가 직관적으로 어떤 하이퍼 파라미터에 어느 정도의 값을 설정했을 때 최적의 값에 가까워지는구나를 직관적으로 이해할 수 있게 됩니다."},{"start":1196800,"end":1208300,"text":"다음은 옵튜나입니다. 옵튜나는 머신 러닝 모델의 하이퍼 파라미터 최적화를 위해 만들어진 오픈소스 프레임워크입니다. 웨이레인 바이어스의 기능 중 하나인 수입과 거의 같은 기능을 제공하고요.","confidence":0.9095,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1197170,1197500,"다음은"],[1197550,1198220,"옵튜나입니다."],[1198850,1199360,"옵튜나는"],[1199610,1199874,"머신"],[1199874,1200120,"러닝"],[1200150,1200480,"모델의"],[1200490,1200720,"하이퍼"],[1200720,1201000,"파라미터"],[1201000,1201347,"최적화를"],[1201347,1201520,"위해"],[1201750,1202220,"만들어진"],[1202690,1203180,"오픈소스"],[1203180,1203800,"프레임워크입니다."],[1204210,1204547,"웨이레인"],[1204547,1204940,"바이어스의"],[1204940,1205140,"기능"],[1205140,1205280,"중"],[1205290,1205600,"하나인"],[1205870,1206300,"수입과"],[1206650,1206940,"거의"],[1206990,1207260,"같은"],[1207330,1207640,"기능을"],[1207750,1208220,"제공하고요."]],"textEdited":"다음은 옵튜나입니다. 옵튜나는 머신 러닝 모델의 하이퍼 파라미터 최적화를 위해 만들어진 오픈소스 프레임워크입니다. 웨이레인 바이어스의 기능 중 하나인 수입과 거의 같은 기능을 제공하고요."},{"start":1208300,"end":1214600,"text":"옵튜나의 경우 웹보다는 노트북 상에서 비주얼라이제이션 하는 데 초점이 맞춰져 있습니다. 옵튜나의 경우","confidence":0.9472,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1208630,1209120,"옵튜나의"],[1209120,1209300,"경우"],[1209450,1210000,"웹보다는"],[1210330,1210700,"노트북"],[1210700,1211020,"상에서"],[1211310,1212000,"비주얼라이제이션"],[1212030,1212227,"하는"],[1212227,1212360,"데"],[1212550,1212814,"초점이"],[1212814,1213074,"맞춰져"],[1213074,1213380,"있습니다."],[1213710,1214187,"옵튜나의"],[1214187,1214400,"경우"]],"textEdited":"옵튜나의 경우 웹보다는 노트북 상에서 비주얼라이제이션 하는 데 초점이 맞춰져 있습니다. 옵튜나의 경우"},{"start":1214600,"end":1226900,"text":"하이퍼 파라미터뿐만 아니라 모델도 같이 옵티마이제이션 대상으로 설정할 수 있습니다. 예를 들어서 랜덤 포레스트, 에브엠, 엑스지부스트 케엔에서 각 모델별 하이퍼 파라미터 셋으로 최적화를 진행할 수 있습니다.","confidence":0.7982,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1214870,1215107,"하이퍼"],[1215107,1215620,"파라미터뿐만"],[1215620,1215860,"아니라"],[1216190,1216600,"모델도"],[1216610,1216880,"같이"],[1217210,1217860,"옵티마이제이션"],[1217910,1218280,"대상으로"],[1218290,1218600,"설정할"],[1218600,1218674,"수"],[1218674,1218960,"있습니다."],[1219230,1219427,"예를"],[1219427,1219700,"들어서"],[1220110,1220320,"랜덤"],[1220320,1220660,"포레스트,"],[1220930,1221360,"에브엠,"],[1221670,1222200,"엑스지부스트"],[1222410,1223000,"케엔에서"],[1223290,1223440,"각"],[1223570,1223980,"모델별"],[1224150,1224440,"하이퍼"],[1224440,1224740,"파라미터"],[1224750,1225140,"셋으로"],[1225550,1226020,"최적화를"],[1226070,1226380,"진행할"],[1226380,1226454,"수"],[1226454,1226840,"있습니다."]],"textEdited":"하이퍼 파라미터뿐만 아니라 모델도 같이 옵티마이제이션 대상으로 설정할 수 있습니다. 예를 들어서 랜덤 포레스트, 에브엠, 엑스지부스트 케엔에서 각 모델별 하이퍼 파라미터 셋으로 최적화를 진행할 수 있습니다."},{"start":1226900,"end":1231200,"text":"옵튜나에서 하이퍼 파라미터 컨피그를 준비하는 세팅입니다.","confidence":0.9691,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1227230,1227780,"옵튜나에서"],[1227990,1228300,"하이퍼"],[1228330,1228820,"파라미터"],[1229250,1229760,"컨피그를"],[1229830,1230260,"준비하는"],[1230550,1231160,"세팅입니다."]],"textEdited":"옵튜나에서 하이퍼 파라미터 컨피그를 준비하는 세팅입니다."},{"start":1231200,"end":1245600,"text":"우리가 이전 웨이앤 바이어스에서는 스윗 컨피그라고 하는 딕셔너리를 설정을 했었는데요. 옵튜나에서는 다음과 같이 트라이얼 닷 서제스트 카테고리 컬 혹은 서제스트 플러 혹은 서제스트 인트와 같은 인터페이스를 사용을 해서","confidence":0.8988,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1231550,1231840,"우리가"],[1231840,1232020,"이전"],[1232070,1232340,"웨이앤"],[1232370,1233020,"바이어스에서는"],[1233370,1233600,"스윗"],[1233750,1234700,"컨피그라고"],[1234700,1234900,"하는"],[1235030,1235507,"딕셔너리를"],[1235507,1235694,"설정을"],[1235694,1236120,"했었는데요."],[1236630,1237260,"옵튜나에서는"],[1237530,1237900,"다음과"],[1237900,1238120,"같이"],[1238290,1238700,"트라이얼"],[1239070,1239220,"닷"],[1239290,1239700,"서제스트"],[1239700,1240047,"카테고리"],[1240047,1240180,"컬"],[1240550,1240760,"혹은"],[1241090,1241500,"서제스트"],[1241500,1241740,"플러"],[1241890,1242100,"혹은"],[1242410,1242800,"서제스트"],[1242810,1243240,"인트와"],[1243370,1243700,"같은"],[1244270,1244900,"인터페이스를"],[1244900,1245160,"사용을"],[1245160,1245360,"해서"]],"textEdited":"우리가 이전 웨이앤 바이어스에서는 스윗 컨피그라고 하는 딕셔너리를 설정을 했었는데요. 옵튜나에서는 다음과 같이 트라이얼 닷 서제스트 카테고리 컬 혹은 서제스트 플러 혹은 서제스트 인트와 같은 인터페이스를 사용을 해서"},{"start":1245600,"end":1260000,"text":"하이퍼 파라미터의 이름 그리고 하이퍼 파라미터를 탐색할 범위 등을 설정할 수 있습니다. 이를 동일하게 트레이닝 펑션에 전달을 하여 실행하게 됩니다. 다시 정리를 해보면 완디비에서는 스윗 컨픽으로","confidence":0.9367,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1246010,1246280,"하이퍼"],[1246280,1246660,"파라미터의"],[1246660,1246820,"이름"],[1247370,1247680,"그리고"],[1248070,1248360,"하이퍼"],[1248390,1249040,"파라미터를"],[1249130,1249540,"탐색할"],[1249990,1250240,"범위"],[1250550,1250800,"등을"],[1251010,1251340,"설정할"],[1251340,1251414,"수"],[1251414,1251740,"있습니다."],[1252410,1252660,"이를"],[1252750,1253200,"동일하게"],[1253810,1254160,"트레이닝"],[1254210,1254580,"펑션에"],[1254790,1255200,"전달을"],[1255250,1255480,"하여"],[1255910,1256360,"실행하게"],[1256490,1256800,"됩니다."],[1257290,1257540,"다시"],[1257550,1257780,"정리를"],[1257780,1258060,"해보면"],[1258450,1259120,"완디비에서는"],[1259170,1259380,"스윗"],[1259450,1259900,"컨픽으로"]],"textEdited":"하이퍼 파라미터의 이름 그리고 하이퍼 파라미터를 탐색할 범위 등을 설정할 수 있습니다. 이를 동일하게 트레이닝 펑션에 전달을 하여 실행하게 됩니다. 다시 정리를 해보면 완디비에서는 스윗 컨픽으로"},{"start":1260000,"end":1273400,"text":"하이퍼 파라미터를 설치할 범위를 지정하고 트레이닝 펑션에 한 실험이 돌아갈 때 작동하는 모델 학습과 평가에 대한 코드를 담았었습니다. 옵튜나에서는 실험 함수 안에 최적화할 컨피그와 트레이닝 펑션을 모두 넣어 줍니다.","confidence":0.9535,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1260110,1260360,"하이퍼"],[1260370,1260900,"파라미터를"],[1261050,1261480,"설치할"],[1261510,1261840,"범위를"],[1261930,1262380,"지정하고"],[1262970,1263300,"트레이닝"],[1263350,1263720,"펑션에"],[1263790,1263940,"한"],[1264030,1264280,"실험이"],[1264280,1264560,"돌아갈"],[1264560,1264700,"때"],[1264830,1265260,"작동하는"],[1265270,1265520,"모델"],[1265520,1265860,"학습과"],[1266130,1266487,"평가에"],[1266487,1266660,"대한"],[1266770,1267100,"코드를"],[1267130,1267740,"담았었습니다."],[1268110,1268760,"옵튜나에서는"],[1269190,1269440,"실험"],[1269550,1269820,"함수"],[1269820,1270060,"안에"],[1270390,1270900,"최적화할"],[1270970,1271460,"컨피그와"],[1271750,1272060,"트레이닝"],[1272110,1272460,"펑션을"],[1272490,1272740,"모두"],[1272750,1272960,"넣어"],[1272960,1273380,"줍니다."]],"textEdited":"하이퍼 파라미터를 설치할 범위를 지정하고 트레이닝 펑션에 한 실험이 돌아갈 때 작동하는 모델 학습과 평가에 대한 코드를 담았었습니다. 옵튜나에서는 실험 함수 안에 최적화할 컨피그와 트레이닝 펑션을 모두 넣어 줍니다."},{"start":1273400,"end":1287800,"text":"각 트라이얼에 최적화할 해퍼 파라미터들을 카테고리별 플롯별로 나누어서 지정을 해주고요. 다음 트라이얼 함수 안에서 완디비와 마찬가지로 데이터 셋, 데이터 로더, 트레인 모델 함수들을 차례로 넣어 학습 코드를 완성합니다.","confidence":0.9355,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1273850,1274000,"각"],[1274070,1274560,"트라이얼에"],[1274990,1275440,"최적화할"],[1275440,1275640,"해퍼"],[1275640,1276120,"파라미터들을"],[1276310,1276840,"카테고리별"],[1277550,1278020,"플롯별로"],[1278020,1278380,"나누어서"],[1278730,1279040,"지정을"],[1279040,1279400,"해주고요."],[1279890,1280100,"다음"],[1280150,1280460,"트라이얼"],[1280460,1280660,"함수"],[1280660,1280940,"안에서"],[1281650,1282120,"완디비와"],[1282130,1282720,"마찬가지로"],[1283050,1283320,"데이터"],[1283320,1283460,"셋,"],[1283910,1284200,"데이터"],[1284200,1284420,"로더,"],[1284730,1285000,"트레인"],[1285000,1285220,"모델"],[1285230,1285600,"함수들을"],[1285610,1285880,"차례로"],[1285880,1286060,"넣어"],[1286510,1286760,"학습"],[1286760,1287060,"코드를"],[1287170,1287760,"완성합니다."]],"textEdited":"각 트라이얼에 최적화할 해퍼 파라미터들을 카테고리별 플롯별로 나누어서 지정을 해주고요. 다음 트라이얼 함수 안에서 완디비와 마찬가지로 데이터 셋, 데이터 로더, 트레인 모델 함수들을 차례로 넣어 학습 코드를 완성합니다."},{"start":1287800,"end":1302400,"text":"앞서 우리가 최적화할 하이퍼 파라미터의 학습 함수를 이미 설정했다면 먼저 크리에이트 스터디라고 하는 인터페이스를 통해서 우리가 최적화할 실험을 생성해 냅니다. 디렉션에서 볼 수 있듯이 맥시마이즈","confidence":0.933,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1288310,1288600,"앞서"],[1288850,1289160,"우리가"],[1289290,1289700,"최적화할"],[1289710,1289920,"하이퍼"],[1289930,1290540,"파라미터의"],[1291250,1291500,"학습"],[1291510,1291880,"함수를"],[1292270,1292440,"이미"],[1292490,1293140,"설정했다면"],[1293670,1293940,"먼저"],[1294050,1294367,"크리에이트"],[1294367,1295140,"스터디라고"],[1295140,1295340,"하는"],[1295470,1296080,"인터페이스를"],[1296080,1296360,"통해서"],[1296790,1297060,"우리가"],[1297110,1297620,"최적화할"],[1298310,1298640,"실험을"],[1299090,1299334,"생성해"],[1299334,1299600,"냅니다."],[1299990,1300560,"디렉션에서"],[1300650,1300800,"볼"],[1300810,1300914,"수"],[1300914,1301220,"있듯이"],[1301710,1302240,"맥시마이즈"]],"textEdited":"앞서 우리가 최적화할 하이퍼 파라미터의 학습 함수를 이미 설정했다면 먼저 크리에이트 스터디라고 하는 인터페이스를 통해서 우리가 최적화할 실험을 생성해 냅니다. 디렉션에서 볼 수 있듯이 맥시마이즈"},{"start":1302400,"end":1314100,"text":"이 의미는 우리가 최적화할 매트릭을 최대화하는 방향으로 학습하라는 의미입니다. 다음에는 해당 스터디 객체에 우리가 최적화할 실험 함수를 전달합니다.","confidence":0.9863,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1302650,1302800,"이"],[1302850,1303200,"의미는"],[1303590,1303880,"우리가"],[1303950,1304480,"최적화할"],[1304950,1305440,"매트릭을"],[1305830,1306400,"최대화하는"],[1306650,1307060,"방향으로"],[1307330,1307820,"학습하라는"],[1307820,1308240,"의미입니다."],[1308810,1309240,"다음에는"],[1309510,1309760,"해당"],[1309790,1310080,"스터디"],[1310110,1310520,"객체에"],[1311130,1311460,"우리가"],[1311550,1312060,"최적화할"],[1312590,1312820,"실험"],[1312850,1313240,"함수를"],[1313270,1313900,"전달합니다."]],"textEdited":"이 의미는 우리가 최적화할 매트릭을 최대화하는 방향으로 학습하라는 의미입니다. 다음에는 해당 스터디 객체에 우리가 최적화할 실험 함수를 전달합니다."},{"start":1314100,"end":1323000,"text":"이때 앤 트라이얼즈 20회로 설정을 했고요. 이는 최대 20번 실험으로 하이퍼 파라미터 설치를 하라는 의미입니다.","confidence":0.8911,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1314630,1314900,"이때"],[1314970,1315120,"앤"],[1315130,1315640,"트라이얼즈"],[1316650,1317120,"20회로"],[1317120,1317314,"설정을"],[1317314,1317600,"했고요."],[1318270,1318560,"이는"],[1319130,1319380,"최대"],[1319450,1319780,"20번"],[1320270,1320680,"실험으로"],[1320730,1320980,"하이퍼"],[1320980,1321320,"파라미터"],[1321320,1321627,"설치를"],[1321627,1321900,"하라는"],[1322130,1322720,"의미입니다."]],"textEdited":"이때 앤 트라이얼즈 20회로 설정을 했고요. 이는 최대 20번 실험으로 하이퍼 파라미터 설치를 하라는 의미입니다."},{"start":1323000,"end":1334700,"text":"결과를 보겠습니다. 결과에서는 스터디 닷 베스트 트라이얼이라고 하는 어트리뷰트에 저장되어 있는 트라이얼 값을 가져옵니다. 해당 트라이얼의 밸류를 확인을 해보면","confidence":0.9295,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1323470,1323827,"결과를"],[1323827,1324280,"보겠습니다."],[1324670,1325280,"결과에서는"],[1325610,1325980,"스터디"],[1325990,1326140,"닷"],[1326550,1326827,"베스트"],[1326827,1327920,"트라이얼이라고"],[1327920,1328100,"하는"],[1328390,1328980,"어트리뷰트에"],[1329110,1329580,"저장되어"],[1329610,1329780,"있는"],[1329870,1330260,"트라이얼"],[1330430,1330740,"값을"],[1330740,1331140,"가져옵니다."],[1331870,1332100,"해당"],[1332150,1332540,"트라이얼의"],[1332670,1333140,"밸류를"],[1333490,1333787,"확인을"],[1333787,1334120,"해보면"]],"textEdited":"결과를 보겠습니다. 결과에서는 스터디 닷 베스트 트라이얼이라고 하는 어트리뷰트에 저장되어 있는 트라이얼 값을 가져옵니다. 해당 트라이얼의 밸류를 확인을 해보면"},{"start":1334700,"end":1347500,"text":"가장 높은 스코어를 확인할 수 있습니다. 맨 마지막으로는 트라이얼 닷 파람스라고 하는 딕셔너리에 저장되어 있는 베스트 트라이얼에서 사용했었던 하이퍼 파라미터의 종류와 값들을","confidence":0.9187,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1335070,1335340,"가장"],[1335470,1335740,"높은"],[1335990,1336440,"스코어를"],[1336450,1336740,"확인할"],[1336740,1336834,"수"],[1336834,1337140,"있습니다."],[1337690,1337840,"맨"],[1337890,1338540,"마지막으로는"],[1338930,1339300,"트라이얼"],[1339300,1339440,"닷"],[1339690,1340800,"파람스라고"],[1340800,1341000,"하는"],[1341110,1341574,"딕셔너리에"],[1341574,1341960,"저장되어"],[1341970,1342180,"있는"],[1342830,1343220,"베스트"],[1343270,1343960,"트라이얼에서"],[1344110,1344620,"사용했었던"],[1345030,1345300,"하이퍼"],[1345300,1345780,"파라미터의"],[1346310,1346620,"종류와"],[1346970,1347420,"값들을"]],"textEdited":"가장 높은 스코어를 확인할 수 있습니다. 맨 마지막으로는 트라이얼 닷 파람스라고 하는 딕셔너리에 저장되어 있는 베스트 트라이얼에서 사용했었던 하이퍼 파라미터의 종류와 값들을"},{"start":1347500,"end":1362000,"text":"확인할 수 있습니다. 옵튜나의 결과를 시각화하는 이런 기능도 제공합니다. 옵티나 비주얼라이제이션 플롯, 옵티마이션 히스토리 함수에 스터디 객체를 전달하시면 됩니다. 그럼 다음과 같이","confidence":0.93,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1347810,1348140,"확인할"],[1348140,1348234,"수"],[1348234,1348560,"있습니다."],[1349030,1349520,"옵튜나의"],[1349550,1349960,"결과를"],[1350670,1351260,"시각화하는"],[1351790,1351980,"이런"],[1352110,1352480,"기능도"],[1352650,1353080,"제공합니다."],[1353670,1354040,"옵티나"],[1354040,1354660,"비주얼라이제이션"],[1355330,1355540,"플롯,"],[1355630,1356100,"옵티마이션"],[1356170,1356560,"히스토리"],[1357250,1357620,"함수에"],[1358550,1358880,"스터디"],[1358880,1359200,"객체를"],[1359330,1359900,"전달하시면"],[1360010,1360320,"됩니다."],[1360930,1361100,"그럼"],[1361130,1361500,"다음과"],[1361500,1361740,"같이"]],"textEdited":"확인할 수 있습니다. 옵튜나의 결과를 시각화하는 이런 기능도 제공합니다. 옵티나 비주얼라이제이션 플롯, 옵티마이션 히스토리 함수에 스터디 객체를 전달하시면 됩니다. 그럼 다음과 같이"},{"start":1362000,"end":1375900,"text":"플롯이 생성되게 됩니다. 또 다른 시각화 방법도 있습니다. 플랫 슬라이스라고 하는 함수에 스터디를 전달하면 각 하이퍼 파라미터의 값에 따라 우리가 최적화하고자 했었던 오브젝티브 밸류의 수치가","confidence":0.9438,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1362330,1362740,"플롯이"],[1363010,1363354,"생성되게"],[1363354,1363620,"됩니다."],[1364410,1364560,"또"],[1364560,1364760,"다른"],[1364950,1365260,"시각화"],[1365260,1365494,"방법도"],[1365494,1365780,"있습니다."],[1366230,1366440,"플랫"],[1366650,1367640,"슬라이스라고"],[1367640,1367780,"하는"],[1367780,1368100,"함수에"],[1368430,1368800,"스터디를"],[1368800,1369180,"전달하면"],[1369530,1369680,"각"],[1369870,1370160,"하이퍼"],[1370160,1370720,"파라미터의"],[1370930,1371260,"값에"],[1371260,1371500,"따라"],[1372070,1372380,"우리가"],[1372570,1373200,"최적화하고자"],[1373200,1373520,"했었던"],[1373990,1374520,"오브젝티브"],[1374530,1374900,"밸류의"],[1375370,1375760,"수치가"]],"textEdited":"플롯이 생성되게 됩니다. 또 다른 시각화 방법도 있습니다. 플랫 슬라이스라고 하는 함수에 스터디를 전달하면 각 하이퍼 파라미터의 값에 따라 우리가 최적화하고자 했었던 오브젝티브 밸류의 수치가"},{"start":1375900,"end":1390700,"text":"어떻게 분포되는지를 보여줍니다. 마지막으로는 대시보드입니다. 옵튜나의 대시보드를 통해 다음과 같이 다양한 정보를 한눈에 확인할 수 있습니다. 마지막으로 요약하겠습니다. 이번 강의에서는 하이퍼 파라미터 튜닝에 대해 배웠습니다.","confidence":0.9445,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1376230,1376600,"어떻게"],[1376630,1377340,"분포되는지를"],[1377670,1378120,"보여줍니다."],[1378430,1379080,"마지막으로는"],[1379530,1380500,"대시보드입니다."],[1381290,1381667,"옵튜나의"],[1381667,1382180,"대시보드를"],[1382180,1382380,"통해"],[1382630,1382980,"다음과"],[1382980,1383220,"같이"],[1383570,1383880,"다양한"],[1383950,1384300,"정보를"],[1384490,1384820,"한눈에"],[1385010,1385320,"확인할"],[1385350,1385500,"수"],[1385670,1386040,"있습니다."],[1386390,1386800,"마지막으로"],[1386800,1387440,"요약하겠습니다."],[1387990,1388200,"이번"],[1388270,1388700,"강의에서는"],[1388700,1388960,"하이퍼"],[1388960,1389280,"파라미터"],[1389280,1389547,"튜닝에"],[1389547,1389720,"대해"],[1389850,1390300,"배웠습니다."]],"textEdited":"어떻게 분포되는지를 보여줍니다. 마지막으로는 대시보드입니다. 옵튜나의 대시보드를 통해 다음과 같이 다양한 정보를 한눈에 확인할 수 있습니다. 마지막으로 요약하겠습니다. 이번 강의에서는 하이퍼 파라미터 튜닝에 대해 배웠습니다."},{"start":1390700,"end":1402700,"text":"하이퍼 파라미터란 모델 학습의 디자인적인 요소로 학습 과정 전에 개발자가 미리 설정하는 값을 뜻합니다. 또한 세 가지 정도의 하이퍼 파라미터 튜닝 방법론에 대해서 배웠는데요.","confidence":0.953,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1391030,1391320,"하이퍼"],[1391320,1391740,"파라미터란"],[1392230,1392480,"모델"],[1392490,1392780,"학습의"],[1392810,1393260,"디자인적인"],[1393260,1393560,"요소로"],[1394030,1394320,"학습"],[1394370,1394640,"과정"],[1394640,1394920,"전에"],[1395650,1396140,"개발자가"],[1396190,1396400,"미리"],[1396450,1396840,"설정하는"],[1396870,1397200,"값을"],[1397390,1397800,"뜻합니다."],[1398270,1398500,"또한"],[1399050,1399200,"세"],[1399200,1399440,"가지"],[1399510,1399840,"정도의"],[1400030,1400280,"하이퍼"],[1400280,1400680,"파라미터"],[1400790,1401100,"튜닝"],[1401350,1401754,"방법론에"],[1401754,1402000,"대해서"],[1402070,1402620,"배웠는데요."]],"textEdited":"하이퍼 파라미터란 모델 학습의 디자인적인 요소로 학습 과정 전에 개발자가 미리 설정하는 값을 뜻합니다. 또한 세 가지 정도의 하이퍼 파라미터 튜닝 방법론에 대해서 배웠는데요."},{"start":1402700,"end":1415400,"text":"첫 번째 그리 서치는 정해진 그리드의 모든 하이퍼 파라미터의 조합을 시도합니다. 두 번째는 랜덤 서치입니다. 무작위로 정해진 범위 내에서 하이퍼 파라미터를 탐색합니다. 마지막으로 베이지안 서치입니다.","confidence":0.9324,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1403010,1403160,"첫"],[1403170,1403400,"번째"],[1403450,1403627,"그리"],[1403627,1404000,"서치는"],[1404550,1404900,"정해진"],[1404970,1405340,"그리드의"],[1405730,1405960,"모든"],[1406050,1406300,"하이퍼"],[1406300,1406700,"파라미터의"],[1406700,1407020,"조합을"],[1407070,1407500,"시도합니다."],[1408210,1408360,"두"],[1408360,1408680,"번째는"],[1408750,1409020,"랜덤"],[1409020,1409460,"서치입니다."],[1409850,1410280,"무작위로"],[1410280,1410560,"정해진"],[1410570,1410800,"범위"],[1410800,1411120,"내에서"],[1411570,1411820,"하이퍼"],[1411820,1412260,"파라미터를"],[1412270,1412780,"탐색합니다."],[1413550,1414100,"마지막으로"],[1414450,1414820,"베이지안"],[1414820,1415240,"서치입니다."]],"textEdited":"첫 번째 그리 서치는 정해진 그리드의 모든 하이퍼 파라미터의 조합을 시도합니다. 두 번째는 랜덤 서치입니다. 무작위로 정해진 범위 내에서 하이퍼 파라미터를 탐색합니다. 마지막으로 베이지안 서치입니다."},{"start":1415400,"end":1430000,"text":"이전 결과를 토대로 하이퍼 파라미터를 탐색하게 됩니다. 다음으로는 웨이렌 바이어스의 스윗 옵튜나에 대해서 다루었습니다. 웨이렌 바이어스의 스윕은 하이퍼 파라미터 튜닝을 자동화하는 툴로 원디비 웹사이트와 연동하여 사용할 수 있었습니다.","confidence":0.9017,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1415910,1416160,"이전"],[1416210,1416507,"결과를"],[1416507,1416780,"토대로"],[1417210,1417480,"하이퍼"],[1417480,1417860,"파라미터를"],[1417870,1418234,"탐색하게"],[1418234,1418480,"됩니다."],[1419350,1419860,"다음으로는"],[1420090,1420380,"웨이렌"],[1420390,1420820,"바이어스의"],[1420830,1421080,"스윗"],[1421530,1421987,"옵튜나에"],[1421987,1422260,"대해서"],[1422370,1422900,"다루었습니다."],[1423750,1424040,"웨이렌"],[1424050,1424387,"바이어스의"],[1424387,1424680,"스윕은"],[1425170,1425440,"하이퍼"],[1425440,1425760,"파라미터"],[1425760,1426060,"튜닝을"],[1426060,1426460,"자동화하는"],[1426470,1426780,"툴로"],[1427370,1427800,"원디비"],[1428130,1428720,"웹사이트와"],[1428720,1429100,"연동하여"],[1429100,1429307,"사용할"],[1429307,1429380,"수"],[1429380,1429760,"있었습니다."]],"textEdited":"이전 결과를 토대로 하이퍼 파라미터를 탐색하게 됩니다. 다음으로는 웨이렌 바이어스의 스윗 옵튜나에 대해서 다루었습니다. 웨이렌 바이어스의 스윕은 하이퍼 파라미터 튜닝을 자동화하는 툴로 원디비 웹사이트와 연동하여 사용할 수 있었습니다."},{"start":1430000,"end":1438100,"text":"s 컨피그라고 하는 값을 통해 튜닝한 해퍼 파라미터의 범위와 방법을 미리 설정했었고요. 옵튜나에서도 동일한 방법으로","confidence":0.8539,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1430410,1430560,"s"],[1430710,1431327,"컨피그라고"],[1431327,1431500,"하는"],[1431500,1431780,"값을"],[1431780,1432000,"통해"],[1432270,1432620,"튜닝한"],[1432630,1432840,"해퍼"],[1432840,1433200,"파라미터의"],[1433200,1433520,"범위와"],[1434230,1434540,"방법을"],[1434540,1434700,"미리"],[1434700,1435240,"설정했었고요."],[1435790,1436500,"옵튜나에서도"],[1436930,1437280,"동일한"],[1437370,1437780,"방법으로"]],"textEdited":"s 컨피그라고 하는 값을 통해 튜닝한 해퍼 파라미터의 범위와 방법을 미리 설정했었고요. 옵튜나에서도 동일한 방법으로"},{"start":1438100,"end":1451100,"text":"튜닝할 하이퍼 파라미터의 종류, 범위, 방법들을 설정을 하고 트레이닝 펑션을 정의하여 수행하는 방식으로 하이퍼 파라미터를 최적화했습니다. 옵튜나의 경우 별도 웹사이트가 존재하지 않기 때문에","confidence":0.9581,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1438310,1438680,"튜닝할"],[1438770,1439000,"하이퍼"],[1439000,1439400,"파라미터의"],[1439710,1440060,"종류,"],[1440490,1440760,"범위,"],[1441410,1441900,"방법들을"],[1441900,1442160,"설정을"],[1442160,1442360,"하고"],[1442750,1443140,"트레이닝"],[1443210,1443560,"펑션을"],[1443560,1444000,"정의하여"],[1444590,1444980,"수행하는"],[1445050,1445500,"방식으로"],[1445830,1446100,"하이퍼"],[1446100,1446580,"파라미터를"],[1446810,1447440,"최적화했습니다."],[1448090,1448580,"옵튜나의"],[1448580,1448780,"경우"],[1449010,1449480,"별도"],[1449650,1450120,"웹사이트가"],[1450120,1450460,"존재하지"],[1450460,1450607,"않기"],[1450607,1450920,"때문에"]],"textEdited":"튜닝할 하이퍼 파라미터의 종류, 범위, 방법들을 설정을 하고 트레이닝 펑션을 정의하여 수행하는 방식으로 하이퍼 파라미터를 최적화했습니다. 옵튜나의 경우 별도 웹사이트가 존재하지 않기 때문에"},{"start":1451100,"end":1463200,"text":"옵티나 비주얼라이제이션 패키지를 통해 튜닝 결과를 시각화하여 어떤 하이퍼 파라미터가 중요한지 분석하는 부분도 배웠습니다. 이번 강의는 여기까지입니다. 고생 많으셨습니다.","confidence":0.9603,"diarization":{"label":""},"speaker":{"label":"","name":"","edited":false},"words":[[1451450,1451860,"옵티나"],[1452010,1452660,"비주얼라이제이션"],[1453110,1453540,"패키지를"],[1453540,1453760,"통해"],[1454170,1454440,"튜닝"],[1454450,1454780,"결과를"],[1454790,1455280,"시각화하여"],[1455770,1456020,"어떤"],[1456050,1456280,"하이퍼"],[1456280,1456700,"파라미터가"],[1456750,1457160,"중요한지"],[1457190,1457640,"분석하는"],[1458010,1458380,"부분도"],[1458770,1459220,"배웠습니다."],[1459670,1459880,"이번"],[1459930,1460154,"강의는"],[1460154,1460640,"여기까지입니다."],[1461410,1461640,"고생"],[1461640,1462080,"많으셨습니다."]],"textEdited":"옵티나 비주얼라이제이션 패키지를 통해 튜닝 결과를 시각화하여 어떤 하이퍼 파라미터가 중요한지 분석하는 부분도 배웠습니다. 이번 강의는 여기까지입니다. 고생 많으셨습니다."}],"text":"안녕하세요. 도메인 공통 프로젝트 8강 더 좋은 성능을 위한 기법 두 번째 하이퍼 파라미터 튜닝 시작하겠습니다. 이번 강의에서는 모델에 설정해야 하는 각 하이퍼 파라미터들을 튜닝하는 방법인 하이퍼 파라미터 튜닝에 대해서 이해해 보겠습니다. 두 번째로는 실제 하이퍼 파라미터를 튜닝하기 위해 여러분들이 사용할 수 있는 하이퍼 파라미터 옵티마이제이션 툴에 대해서 소개하도록 하겠습니다. 먼저 하이퍼 파라미터 튜닝 이해하기입니다. 하이퍼 파라미터란 모델 학습 과정의 디자인에 반영되는 값입니다. 학습 시작 전에 미리 설정하게 되는 값입니다. 예시로는 러닝 레이트, 손실 함수, 배치, 사이즈, 신경망의 레이어 수가 있습니다. 여러분들이 직접 조정 가능한 값들의 형태입니다. 다음으로는 파라미터가 있습니다. 파라미터는 모델 내부에서 결정되는 변수로 데이터로부터 학습 또는 조정되는 값들입니다. 예시로는 선형 회귀 모델의 개수, 신경망의 가중치 혹은 편향 등을 말합니다. 이러한 값들은 학습 과정에서 자연스럽게 조정되는 값이기 때문에 개발자가 직접 조정하지 않습니다. 정리해 보면 하이퍼 파라미터는 학습 과정이 시작되기 전에 설정되는 구성 변수라고도 이야기할 수 있습니다. 다음은 모델 파라미터와 하이퍼 파라미터에 대한 예시 그림입니다. 모델 파라미터의 경우 보시는 것과 같이 웨이트와 같은 값들이 존재합니다. w0, w1, w2 그리고 wm 이러한 값들은 모델이 가지고 있는 가중치 값들이며 모델을 학습시키는 과정에서 로스를 최적화하는 동안 조정되는 값입니다. 오른쪽에 있는 하이퍼 파라미터들을 보겠습니다. an it 테스트 사이즈 랜덤 스테이트 알파 시 이러한 값들은 모델을 학습할 때 얼마나 여러 번 학습할 것인지, 테스트 사이즈는 어떻게 되는지, 랜덤 시드 값은 어떻게 되는지, 우리가 모델의 오버피팅을 방지하기 위해 정교화를 적용할 때 얼마나 그 정교화의 강도를 강하게 설정할지 이러한 값들을 하이퍼 파라미터라고 부릅니다. 각 모델마다 가지고 있는 하이퍼 파라미터는 다르지만 하이퍼 파라미터가 많을수록 모델 학습에 고려할 디자인 요소가 많다는 의미입니다. 하이퍼 파라미터 옵티마이제이션이 필요한 이유에 대해서 살펴보겠습니다. 예시를 하나하나 확인해 보면서 따라가겠습니다. 첫 번째 예시를 보면 레이어는 3개 그리고 각 레이어에 할당되는 뉴런의 수는 512개, 러닝 웨이트는 0.1입니다. 이 하이퍼 파라미터를 가지고 모델을 학습한 결과는 85%의 스코어를 가지게 됩니다. 두 번째 예시를 보겠습니다. 동일하게 3개의 레이어를 가지고 있고 뉴런의 수는 2배 늘어난 숫자인 1024를 가지고 있습니다. 러닝 레이트는 0.01로 설정되었고 동일하게 스코어는 85%를 보여주고 있습니다. 마지막 예시를 보겠습니다. 마지막 예시는 3개의 레이어를 가지고 있고 각 레이어별로 256개의 뉴런을 가지고 있습니다. 러닝 레이트는 첫 번째 예시와 동일한 0.1입니다. 세 번째 예시의 스코어는 92%를 보여주고 있습니다. 사실 이 예시는 매우 단순한 예시일 뿐입니다. 실제로 여러분들이 하이퍼 파라미터를 설정할 때는 이것보다 훨씬 더 많고 훨씬 더 넓은 영역의 하이퍼 파라미터를 탐색을 해야 되는데요. 예시에서 볼 수 있듯이 어떤 하이퍼파라미터를 설정하느냐에 따라 스코어가 달라질 수 있습니다. 하이퍼파라미터 옵티마이제이션의 장점에 대해서 이야기해 보겠습니다. 먼저 모델 성능입니다. 하이퍼파라미터 선택은 모델 성능에 큰 영향을 미치며 적절히 조정된 하이퍼 파라미터는 모델의 정확도 일반화 능력 효율성을 향상시킬 수 있습니다. 다음은 학습 시간입니다. 효율적인 하이퍼 파라미터 조정은 학습 시간과 계산 자원을 감소시킬 수 있습니다. 마지막으로는 모델 일반화입니다. 잘 최적화된 하이퍼 파라미터는 모델이 실제 데이터에 대해 더 잘 일반화되도록 도와 과적합과 과소적합을 줄일 수 있습니다. 하지만 하이퍼파라미터 옵티마이제이션에 큰 단점이 있는데요. 이러한 하이퍼 파라미터를 찾기 위해 조정 비용이 많이 발생할 수 있습니다. 어떤 하이퍼 파라미터가 최적인지는 직접 학습을 시키고 그 모델의 성능을 어느 정도 확인할 수 있을 정도로 학습을 시켜야 하기 때문에 그만큼 시간과 계산 비용, 인프라 비용이 발생할 수 있습니다. 다음은 허깅페이스 사전 학습 모델에서 볼 수 있는 하이퍼 파라미터들입니다. nom 레이어스 트랜스포머의 인코더 층 수를 나타냅니다. 벌트 베이스의 경우 12개, BT 미니의 경우 4개를 가지고 있습니다. 다음은 히든 사이즈입니다. 히든 상태 벡터 차원입니다. 벌트 베이스는 768, 펄, 미니는 256을 가지고 있습니다. 다음은 어텐션, 헤드, 셀프 어텐션의 머리 수입니다. 12개 4개를 가지고 있습니다. 인터미디어트 사이즈, 로켓 사이즈, 맥스, 포지션, 임베링스, 액티베이션, 펑션, 드롭아웃 등 여러분들이 어떤 하이퍼 파라미터를 설정하냐에 따라 가장 아래에서 보여지는 전체 모델의 파라미터 개수가 5배까지 혹은 그 이상까지 차이 날 수 있습니다. 다음은 훈련 파라미터입니다. 이는 훈련을 진행하는 동안 여러분들이 설정할 수 있는 하이퍼 파라미터를 뜻합니다. 첫 번째로 넘 에폭스입니다. 여러분들이 모델에게 데이터셋 전체를 얼마나 많이 보여줄지 결정하는 수치입니다. 예시에서는 50회로 설정되어 있습니다. 그다음은 얼리스타핑 페이션스입니다. 이 값은 여러분들이 설정한 검증 데이터에 대한 검증 스코어가 해당 횟수만큼 개선되지 않으면 얼리스탑 모델 학습을 일찍 멈추게 도와주는 하이퍼 파라미터입니다. 예시의 경우 5로 설정되어 있고 5회 이상 에폭에 대해 검증 스코어가 개선되지 않으면 학습을 중단합니다. 다음은 배치 사이즈입니다. 배치 사이즈는 딥러닝 모델을 학습할 때 미니 배치 사이즈의 크기를 결정합니다. 현재 예시의 경우 16개로 되어 있고 그렇다라는 거는 16개의 샘플이 모델에 한 번에 학습된다라는 의미입니다. 오른쪽에서는 로스를 볼 수 있습니다. 우리가 일반적으로 우리가 일반적으로 분류에서는 바이너리 크로스, 엔트로피 회귀에서는 엠스 혹은 엠에이와 같은 로스를 사용을 하는데요. 여러분들이 푸는 테스크에 따라 사용할 수 있는 로스가 여러 개일 수 있습니다. 이런 경우일 땐 여러분들이 사용하는 로스 그 자체도 하이퍼 파라미터로 간주할 수 있습니다. 이어서 옵티마이저입니다. 예시에서는 아담블를 예시로 들었고요. 아담더블유가 아닌 다른 옵티마이저를 고려하고 싶다면 이 또한 하이퍼 파라미터로 쓸 수 있습니다. 러닝 레이트, 맥스, 시퀀스 랭스 등 학습 단계에서 고려할 수 있는 다른 하이퍼 파라미터들도 많이 있습니다. 그래서 여러분들이 모델의 디자인을 결정한 뒤에 훈련하는 파이프라인에 대한 하이퍼 파라미터도 반드시 고려해야 합니다. 하이퍼 파라미터 튜닝이란 사실은 하이퍼 파라미터를 찾는 하이퍼 파라미터 설치라고 할 수 있습니다. 여러분들이 가지고 있는 주어진 데이터에 대해 어떤 하이퍼 파라미터 조합에서 내가 가진 모델이 가장 성능이 좋은지는 직접 실험을 통해 찾아내어야 합니다. 그림은 학습률 러닝레이트를 조정했을 때 모델 성능 양상을 보여주는 그래프입니다. 매우 극단적인 예시일 수는 있지만 다음과 같이 학습률이 올라감에 따라 모델의 성능이 올라갈 수도 혹은 내려갈 수도 있습니다. 그렇기 때문에 어느 지점에서 최적인지는 실험을 통해 알아낼 수밖에 없습니다. 대표적인 하이퍼 파라미터 튜닝 방법으로는 그리드 서치가 있습니다. 그리드 서치는 말 그대로 내가 최적화하고 싶은 하이퍼 파라미터들의 값을 그리드로 설정을 하고 가능한 모든 경우의 수를 탐색하는 방법입니다. 그리 서치는 하이퍼 파라미터의 수 그리고 각 하이퍼 파라미터에 설정한 그리드의 수만큼으로 실험 횟수가 정해집니다. 하지만 여기에 생길 수 있는 단점은 실제 우리가 사용하는 하이퍼 파라미터 중 정수인 경우에도 문제가 있겠지만 실수인 경우에서는 훨씬 더 큰 문제가 발생합니다. 왜냐하면 여러분들이 손쉽게 볼 수 있는 하이퍼 파라미터들 혹은 다른 경진대회 혹은 현업에서 볼 수 있는 하이퍼 파라미터들을 보시면 인간이 추론할 수 있는 어떤 수치의 값이 아닙니다. 실제로 어떤 실수 값으로 매우 낮은 소수점까지 튜닝을 하게 됩니다. 그렇기 때문에 그리스 워치는 가장 쉬우면서도 직관적인 방법이지만 실제로는 최적의 점을 찾기는 사실상 어렵습니다. 다음은 랜덤 서치입니다. 그리 설치에서 그리드를 만들어서 정해진 구간을 탐색하는 거였다면 랜덤 서치는 튜닝할 하이퍼 파라미터와 그리고 탐색할 하이퍼 파라미터의 값의 범위를 지정합니다. 이 과정에서 랜덤하게 하이퍼 파라미터의 실제 값들을 설정을 하고 학습을 진행한 뒤에 탐색을 진행합니다. 사실 탐색이라고 설명을 했지만 탐색이라고 말하기는 약간 어렵습니다. 왜냐하면 모든 하이퍼 파라미터는 랜덤하게 임의로 선택되기 때문입니다. 그래서 그리드 서치에서 있었던 실수 혹은 인간이 인지하기 어려운 실수 범위 혹은 인간이 먼저 그리드를 설정해야 된다라는 단점은 해결할 수 있지만 여전히 비효율적일 수 있습니다. 다음 하이퍼 파라미터 튜닝 방법론은 베이지안 서치입니다. 베이지안 서치는 선택된 하이퍼 파라미터와 모델 성능 사이의 관계성이 있을 것을 고려하여 최적의 하이퍼 파라미터 조합을 찾는 것입니다. 예시를 보겠습니다. 가장 왼쪽에 있는 랜덤 서치의 경우 약 10번의 시도에 걸쳐 글로벌 미니멈 최적점에 도달한 것을 확인하실 수 있습니다. 다음은 그리 설치입니다. 그릴 서치는 개발자가 설정한 각 하이퍼 파라미터들의 그리드를 기반으로 가능한 모든 경우의 수를 탐색합니다. 결과에서 보시면 아시겠지만 그리 서치는 글로벌 미니멈에 도달하지 못했습니다. 다음은 베이지안 서치입니다. 베이지안 서치는 약 다섯 번 만의 시도 끝에 글로벌 미니멈에 가까이 도달한 것을 확인할 수 있습니다. 그래서 여러분들이 현업에서 하이퍼 파라미터 튜닝을 수행하신다면 일반적으로 처음 수행하는 것은 베이지안 옵티마이션 설치일 것입니다. 이외에도 데이터의 특성 혹은 도메인의 특성에 따라 베이지안 옵티마이제이션을 기반으로 한 다른 튜닝 방법론을 사용하실 수도 있습니다. 베이지안 서치를 조금 더 쉽게 이해해 보도록 하겠습니다. 먼저 우리가 풀고자 하는 문제를 정리해 보겠습니다. 여러분들이 낚시를 하러 갔다고 생각해 보겠습니다. 가장 큰 물고기를 낚을 수 있는 하이퍼 파라미터 여기에서는 배의 위치 그리고 낚싯대의 깊이를 찾는다고 가정해 보겠습니다. 첫 번째는 초기 탐색입니다. 무작위로 몇 군데 낚시를 시도합니다. 랜덤 하이퍼 파라미터 조합을 가지고 일단 모델 학습을 몇 개 정도 수행해 봅니다. 여기에서 얻은 정보는 낚시를 했던 위치, 낚싯대의 깊이와 같은 세팅, 그리고 실제로 내가 잡은 물고기의 크기 이런 것들입니다. 다음으로는 얻은 정보를 기반으로 물고기 지도를 만들겠습니다. 우리가 방금 이전 페이지에서 봤던 어떤 그래프 같은 걸 만든다 정도로 이해하시면 되겠습니다. 지금까지의 결과로 물고기 밀도 지도를 생성합니다. 이는 가우시안 프로세스를 통해 등고선을 그린다 정도로 이해하시면 되겠습니다. 지도로부터 알 수 있는 정보는 예상된 물고기의 크기 그리고 정보가 부족한 불확실성이 있는 지역들이 나타납니다. 다음 단계에서는 다음 낚시 지점을 선정합니다. 물고기가 잡힐 것 같은 곳 이는 모델 성능이 높을 것으로 예상되는 지점을 이야기합니다. 다음은 아직 탐색이 많이 되지 않은 곳을 선정합니다. 이는 우리가 작성한 물고기 지도에서 불확실성이 높은 곳을 의미합니다. 두 요소를 조합하여 점수를 매겨서 우선순위를 설정합니다. 그다음 다시 한 번 더 실제 낚시를 진행합니다. 우선순위가 높은 지점에서 낚시를 한다는 것은 새로운 하이퍼 파라미터 조합으로 실험을 진행한다는 것입니다. 실험을 진행했으면 실제 성능을 확인합니다. 잡힌 물고기의 크기를 확인해 보는 것이죠. 이를 통해 우리가 가진 물고기 지도를 다시 한 번 더 갱신합니다. 그런 다음 이를 반복합니다. 보시는 예시와 같이 이터레이션을 돌면서 하이퍼 파라미터에 따른 모델 성능에 대한 함수를 추정하여 최적의 하이퍼 파라미터를 탐색하는 것이 베이지안 옵티마이제이션 방법론입니다. 그림에서 보시면 아실 수 있듯이 인터레이션이 진행됨에 따라 최적화된 그 스코어에 탐색 범위가 가까워지는 것을 볼 수 있습니다. 하이퍼 파라미터 튜닝 방법론에 대해 정리를 한번 해보겠습니다. 하이퍼 파라미터 튜닝은 여러 가지 방법을 사용할 수 있고 정답이 정해져 있는 것은 아닙니다. 하이퍼 파라미터 옵티마이션을 통해 모델의 성능을 최적화할 수는 있지만 항상 주어진 계산 자원과 시간이 무한하지 않기 때문에 사용자가 적절한 선에서 하이퍼 파라미터 서치를 진행해야 됩니다. 예를 들어 48시간 동안 그리 설치를 진행해서 나온 결과에서 가장 좋은 하이퍼 파라미터를 쓰겠다. 또는 우리 팀에서 서비스하는 모델의 재학습 주기가 엔 시간인데 그 엔 시간 동안 가장 최대한으로 최적화된 하이퍼 파라미터를 찾고 싶다 라고 한다면 그 n 시간 안에 끝날 수 있는 하이퍼 파라미터 설치 횟수가 최대한 상한이라고 생각하시면 됩니다. 혹은 우리 팀은 이런 하이퍼 파라미터를 튜닝하는 혹은 모델을 학습하는 비용이 매우 민감하기 때문에 최소한으로 해야 한다라는 제약 조건이 있다면 그 최소한의 제약 조건에 맞춰 횟수를 결정하시면 됩니다. 또한 모델끼리 성능을 비교할 때는 각 모델별로 하이퍼 파라미터 최적화를 진행시켜 주셔야 됩니다. 다음은 하이퍼 파라미터 최적화 툴에 대해서 다뤄보겠습니다. 첫 번째로는 우리가 6강에서 다루었던 웨이렌 바이어스입니다. 웨이렌 바이어스의 스윕이라는 기능을 통해 하이퍼 파라미터를 튜닝하고 다음과 같이 결과를 시각화할 수 있습니다. 예시에서 보면 알 수 있듯이 하이퍼 파라미터의 중요도를 플롯 형태로 시각화할 수도 있고요. 오른쪽에서의 예시와 같이 내가 각 실험에서 선택한 하이퍼 파라미터의 조합에 따라 로스 혹은 매트릭이 어느 양상으로 학습되는지를 볼 수 있는 시각화도 제공합니다. 하이퍼 파라미터 스윕을 준비하는 예시를 보겠습니다. 스윗 컨피그라고 하는 어떤 딕셔너리를 준비해 주시면 됩니다. 여기에서 메소드라고 하는 항목에는 베이즈라고 작성이 되어 있는데요. 베이즈는 베이지 안 설치를 뜻합니다. 이 부분에 여러분들이 랜덤을 넣게 되면 VR 설치나 랜덤 서치가 진행되게 됩니다. 다음은 하이퍼 파라미터였습니다. 이곳에는 여러분들이 탐색하고 싶은 하이퍼 파라미터들을 정의하고 그 하이퍼 파라미터들에 넣을 어떤 값들 이런 필드들을 정의합니다. 예시에서는 러닝 레이트 배치 사이즈, 드롭바웃 레이트 디 모델이 존재합니다. 러닝 레이트 배치 사이즈 디 모델의 경우 그리드 설치 형태의 값들을 전달을 했고요. 드롭아웃의 경우 최소 최댓값과 함께 어떤 분포에서 추출할지에 대한 값을 설정했습니다. 이렇게 되면 드라바웃 레이트의 설정을 기준으로 설명을 드리면 0.1부터 0.5까지 균등 분포에서 값을 추출하게 됩니다. 마지막은 매트입니다. 여기에 설정된 매트릭의 네임은 우리가 추후 기록할 로스의 이름을 동일하게 넣어주시면 됩니다. 여기에서 골은 맥시마이즈로 되어 있는데요. 우리가 전달한 매트릭의 수치가 높을수록 좋다면 맥시마이즈 로스와 같이 낮을수록 좋다면 미니마이즈라고 전달하시면 됩니다. 다음은 1db 로그인 및 수입 아이디 생성입니다. 이전 예시에서는 커맨드 라인에서 완디비 로그인이라고 하는 어떤 명령어를 사용했었는데요. 이번 예시에서는 코드 혹은 노트북에서 1db 수입이라는 명령어를 호출했을 때 자동으로 로그인 및 수입 아이디가 생성되는 예시를 보여줍니다. 완디비 데모라고 하는 프로젝트에 스윕이 생성이 되었고 생성된 스윗 아이디가 보여집니다. 뿐만 아니라 스윕 URL이 같이 출력이 되는데요. 해당 URL을 클릭하여 오른쪽 예시와 같이 하이퍼 파라미터 튜닝 기록이 저장될 대시보드로 이동할 수 있습니다. 이 대시보드에서 튜닝이 되는 과정을 실시간으로 확인할 수 있습니다. 이제 실제로 하이퍼 파라미터 튜닝을 해보도록 하겠습니다. 위드 문으로 구성된 1디비 이닛이 실행되면 이후 실행되는 실험이 완디비 웹상에서 로깅되기 시작합니다. 두 번째 줄에서 실행되는 완디비 컨피그에서 반환받은 파람즈가 우리가 앞서 설정한 스윗 컨피그에 정의되어 있는 하이퍼 파라미터들 중 선택된 하이퍼 파라미터들의 값들을 반환받게 됩니다. 해당 값은 딕셔너리 형태로 반환이 됩니다. 밑에 부분에서 보시면 알 수 있듯이 파람스에서 맥스트랭스 배치 사이즈와 같은 선택된 값들을 꺼내어서 학습 단계에서 사용할 수 있습니다. 다음은 이전 단계에서 전달받은 모델의 이름을 기반으로 허깅페이스로부터 사전 학습 모델을 불러오는 코드입니다. 이를 통해 사전 학습 모델을 불러와서 우리의 태스크에 맞도록 파인튜닝을 진행하게 됩니다. 일반적으로 사전 학습 모델들은 모델의 인베딩 크기, 레이어 수 등이 미리 정해져 있습니다. 그렇기 때문에 우리 예제에서는 드라바웃 레이트 정도만 조정해 봅니다. 다음은 모델 네임이 존재하지 않는 경우 랜덤하게 모델 파라미터가 초기화된 트랜스포머를 학습하게 됩니다. 이때는 디 모델을 조정하여 모델의 인베딩 사이즈를 다양하게 바꿔가며 성능 변화를 확인해 봅니다. 모델을 초기부터 스크래치로 학습하는 경우와 사전 학습 모델을 불러와 파인 튜닝으로 학습하는 경우를 비교할 수 있는 예제입니다. 다음은 미리 정의해 둔 트레인 모델 함수를 통해서 모델을 학습하도록 합니다. 이때 학습 하이퍼 파라미터로 최대 에폭스와 러닝 레이트를 사용합니다. 학습이 완료되었다면 모델 성능을 추적할 수 있도록 매트릭으로 AU PRC를 계산을 하고요. 마지막으로 1db 로그 라고 하는 메소드를 통해서 1db 상에 필요한 매트릭 그리고 추가적인 어떤 값들을 기록을 합니다. 예시에서는 베스트 auprc 스코어 파이널 트레인, auprc 파이널 밸리데이션, 에유피알3 토탈 파람즈를 기록했습니다. 이렇게 설정을 해 둔 상태로 실제로 완디비 에이전트에게 해당 펑션과 그리고 해당 컨피그를 기반으로 수행하도록 명령을 보내 보겠습니다. 이때는 완디비 에이전트라고 하는 메서드에 앞서 전달받은 수입 아이디, 그리고 우리가 학습에 사용할 원디비 트레이닝 펑션을 전달합니다. 몇 번 최적화를 진행할지에 대한 값은 카운트라고 하는 값으로 설정합니다. 만약 내가 가진 서버가 혹은 GPU가 여러 개라면 여러 서버에서 같은 수입 아이디를 연동하여 여러 에이전트로 동시에 수입을 진행할 수도 있습니다. 이후 출력되는 결과에서 이번 이터레이션에서 어떤 하이퍼 파라미터를 사용하는지 결과를 보실 수가 있습니다. 뿐만 아니라 완디비 학습 함수 안에서 프린트 문을 통해 하이퍼 파라미터 서치 중에 학습이 잘 되는지를 로깅할 수도 있습니다. 에이전트에게 전달한 실험이 완료가 되면 최종 성능을 완디비에서 자동으로 웹 서버에 기록을 하게 됩니다. 수입이 실행되고 있는 상황을 웹에서 확인할 수 있다라는 뜻입니다. 웹상에서 각 하이퍼 파라미터 튜닝이 끝날 때마다 다음과 같이 어떤 하이퍼 파라미터가 중요한지, 그리고 우리가 최적화하고자 하는 매트릭 혹은 로스와 어떤 코릴레이션이 있는지를 보여줍니다. 오른쪽에서는 각 실험에 대해 출력된 매트릭 스코어를 확인하실 수 있습니다. 앞서 설명드렸던 것처럼 어떤 하이퍼 파라미터에 어떤 값을 설정했느냐에 따라 다음과 같이 가장 오른쪽에 있는 우리가 타겟하는 로스 혹은 어떤 매트릭이 어떤 양상을 보이는지 한눈으로 볼 수 있도록 시각화를 해주는 기능도 존재합니다. 이를 통해 우리가 직관적으로 어떤 하이퍼 파라미터에 어느 정도의 값을 설정했을 때 최적의 값에 가까워지는구나를 직관적으로 이해할 수 있게 됩니다. 다음은 옵튜나입니다. 옵튜나는 머신 러닝 모델의 하이퍼 파라미터 최적화를 위해 만들어진 오픈소스 프레임워크입니다. 웨이레인 바이어스의 기능 중 하나인 수입과 거의 같은 기능을 제공하고요. 옵튜나의 경우 웹보다는 노트북 상에서 비주얼라이제이션 하는 데 초점이 맞춰져 있습니다. 옵튜나의 경우 하이퍼 파라미터뿐만 아니라 모델도 같이 옵티마이제이션 대상으로 설정할 수 있습니다. 예를 들어서 랜덤 포레스트, 에브엠, 엑스지부스트 케엔에서 각 모델별 하이퍼 파라미터 셋으로 최적화를 진행할 수 있습니다. 옵튜나에서 하이퍼 파라미터 컨피그를 준비하는 세팅입니다. 우리가 이전 웨이앤 바이어스에서는 스윗 컨피그라고 하는 딕셔너리를 설정을 했었는데요. 옵튜나에서는 다음과 같이 트라이얼 닷 서제스트 카테고리 컬 혹은 서제스트 플러 혹은 서제스트 인트와 같은 인터페이스를 사용을 해서 하이퍼 파라미터의 이름 그리고 하이퍼 파라미터를 탐색할 범위 등을 설정할 수 있습니다. 이를 동일하게 트레이닝 펑션에 전달을 하여 실행하게 됩니다. 다시 정리를 해보면 완디비에서는 스윗 컨픽으로 하이퍼 파라미터를 설치할 범위를 지정하고 트레이닝 펑션에 한 실험이 돌아갈 때 작동하는 모델 학습과 평가에 대한 코드를 담았었습니다. 옵튜나에서는 실험 함수 안에 최적화할 컨피그와 트레이닝 펑션을 모두 넣어 줍니다. 각 트라이얼에 최적화할 해퍼 파라미터들을 카테고리별 플롯별로 나누어서 지정을 해주고요. 다음 트라이얼 함수 안에서 완디비와 마찬가지로 데이터 셋, 데이터 로더, 트레인 모델 함수들을 차례로 넣어 학습 코드를 완성합니다. 앞서 우리가 최적화할 하이퍼 파라미터의 학습 함수를 이미 설정했다면 먼저 크리에이트 스터디라고 하는 인터페이스를 통해서 우리가 최적화할 실험을 생성해 냅니다. 디렉션에서 볼 수 있듯이 맥시마이즈 이 의미는 우리가 최적화할 매트릭을 최대화하는 방향으로 학습하라는 의미입니다. 다음에는 해당 스터디 객체에 우리가 최적화할 실험 함수를 전달합니다. 이때 앤 트라이얼즈 20회로 설정을 했고요. 이는 최대 20번 실험으로 하이퍼 파라미터 설치를 하라는 의미입니다. 결과를 보겠습니다. 결과에서는 스터디 닷 베스트 트라이얼이라고 하는 어트리뷰트에 저장되어 있는 트라이얼 값을 가져옵니다. 해당 트라이얼의 밸류를 확인을 해보면 가장 높은 스코어를 확인할 수 있습니다. 맨 마지막으로는 트라이얼 닷 파람스라고 하는 딕셔너리에 저장되어 있는 베스트 트라이얼에서 사용했었던 하이퍼 파라미터의 종류와 값들을 확인할 수 있습니다. 옵튜나의 결과를 시각화하는 이런 기능도 제공합니다. 옵티나 비주얼라이제이션 플롯, 옵티마이션 히스토리 함수에 스터디 객체를 전달하시면 됩니다. 그럼 다음과 같이 플롯이 생성되게 됩니다. 또 다른 시각화 방법도 있습니다. 플랫 슬라이스라고 하는 함수에 스터디를 전달하면 각 하이퍼 파라미터의 값에 따라 우리가 최적화하고자 했었던 오브젝티브 밸류의 수치가 어떻게 분포되는지를 보여줍니다. 마지막으로는 대시보드입니다. 옵튜나의 대시보드를 통해 다음과 같이 다양한 정보를 한눈에 확인할 수 있습니다. 마지막으로 요약하겠습니다. 이번 강의에서는 하이퍼 파라미터 튜닝에 대해 배웠습니다. 하이퍼 파라미터란 모델 학습의 디자인적인 요소로 학습 과정 전에 개발자가 미리 설정하는 값을 뜻합니다. 또한 세 가지 정도의 하이퍼 파라미터 튜닝 방법론에 대해서 배웠는데요. 첫 번째 그리 서치는 정해진 그리드의 모든 하이퍼 파라미터의 조합을 시도합니다. 두 번째는 랜덤 서치입니다. 무작위로 정해진 범위 내에서 하이퍼 파라미터를 탐색합니다. 마지막으로 베이지안 서치입니다. 이전 결과를 토대로 하이퍼 파라미터를 탐색하게 됩니다. 다음으로는 웨이렌 바이어스의 스윗 옵튜나에 대해서 다루었습니다. 웨이렌 바이어스의 스윕은 하이퍼 파라미터 튜닝을 자동화하는 툴로 원디비 웹사이트와 연동하여 사용할 수 있었습니다. s 컨피그라고 하는 값을 통해 튜닝한 해퍼 파라미터의 범위와 방법을 미리 설정했었고요. 옵튜나에서도 동일한 방법으로 튜닝할 하이퍼 파라미터의 종류, 범위, 방법들을 설정을 하고 트레이닝 펑션을 정의하여 수행하는 방식으로 하이퍼 파라미터를 최적화했습니다. 옵튜나의 경우 별도 웹사이트가 존재하지 않기 때문에 옵티나 비주얼라이제이션 패키지를 통해 튜닝 결과를 시각화하여 어떤 하이퍼 파라미터가 중요한지 분석하는 부분도 배웠습니다. 이번 강의는 여기까지입니다. 고생 많으셨습니다.","confidence":0.9390898,"speakers":[{"label":"","name":"","edited":false}],"events":[],"eventTypes":[]}