"""
ë²„ì „ ê´€ë¦¬ ìœ í‹¸ë¦¬í‹°.

ì²­í¬ ë°ì´í„°ì˜ ë²„ì „ ì¶”ì , íŒŒì¼ í•´ì‹œ ê³„ì‚°, ì¦ë¶„ ì—…ë°ì´íŠ¸ ì§€ì›ì„ ìœ„í•œ ìœ í‹¸ë¦¬í‹°ì…ë‹ˆë‹¤.

ì‚¬ìš© ì˜ˆ:
    ```python
    from document_processing.common.versioning import (
        compute_file_hash,
        get_current_timestamp,
        create_chunk_version_metadata,
        SCHEMA_VERSION,
        PIPELINE_VERSION,
    )

    # íŒŒì¼ í•´ì‹œ ê³„ì‚°
    file_hash = compute_file_hash(Path("notebook.ipynb"))

    # ì²­í¬ ë©”íƒ€ë°ì´í„°ì— ë²„ì „ ì •ë³´ ì¶”ê°€
    version_meta = create_chunk_version_metadata(
        source_file=Path("notebook.ipynb"),
    )
    chunk_metadata.update(version_meta)
    ```
"""

import hashlib
import json
from dataclasses import dataclass, field, asdict
from datetime import datetime, timezone
from pathlib import Path
from typing import Any


# =============================================================================
# ë²„ì „ ìƒìˆ˜
# =============================================================================

SCHEMA_VERSION = "2.0.0"
"""
ì²­í¬ ìŠ¤í‚¤ë§ˆ ë²„ì „.

ë³€ê²½ ì‹œì :
- ë©”íƒ€ë°ì´í„° í•„ë“œ ì¶”ê°€/ì œê±°/ë³€ê²½
- ì²­í¬ ID í˜•ì‹ ë³€ê²½
- ì½˜í…ì¸  êµ¬ì¡° ë³€ê²½

ë³€ê²½ ë¡œê·¸:
- 2.0.0: ë¼ì¸ë¦¬ì§€ í•„ë“œ ì¶”ê°€ (corpus_version, pipeline_trace), ìš”ì•½ í•„ë“œ ì¶”ê°€
- 1.0.0: ì´ˆê¸° ë²„ì „
"""

PIPELINE_VERSION = "2.0.0"
"""
ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ë²„ì „.

ë³€ê²½ ì‹œì :
- ì²­í‚¹ ë¡œì§ ë³€ê²½
- í•„í„°ë§ ê·œì¹™ ë³€ê²½
- í…ìŠ¤íŠ¸ ì •ì œ ë¡œì§ ë³€ê²½

ë³€ê²½ ë¡œê·¸:
- 2.0.0: ì†ŒìŠ¤ í´ë¦°ì—… ê·œì¹™ ì¶”ê°€, ë©”íƒ€ ë¼ìš°íŒ… ì§€ì›
- 1.0.0: ì´ˆê¸° ë²„ì „
"""

CORPUS_VERSION = "2025.11.27"
"""
ì½”í¼ìŠ¤ ì „ì²´ ë²„ì „ (ë‚ ì§œ ê¸°ë°˜).

ë³€ê²½ ì‹œì :
- ìƒˆë¡œìš´ ë°ì´í„° ì†ŒìŠ¤ ì¶”ê°€
- ëŒ€ê·œëª¨ ì¬ì¸ì œìŠ¤íŠ¸
- í•„í„°ë§/ì²­í‚¹ ë¡œì§ ë³€ê²½ìœ¼ë¡œ ì¸í•œ ì „ì²´ ì¬ì²˜ë¦¬

í˜•ì‹: YYYY.MM.DD (ë˜ëŠ” YYYY.MM.DD.N for ê°™ì€ ë‚  ì—¬ëŸ¬ ë²„ì „)
"""

# ìš”ì•½ ëª¨ë¸ ê¸°ë³¸ê°’
DEFAULT_SUMMARY_MODEL = "clova-hcx-003"
DEFAULT_SUMMARY_MAX_LENGTH = 200


# =============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# =============================================================================


def compute_file_hash(file_path: Path, algorithm: str = "sha256") -> str:
    """
    íŒŒì¼ì˜ í•´ì‹œê°’ì„ ê³„ì‚°í•©ë‹ˆë‹¤.

    Args:
        file_path: í•´ì‹œë¥¼ ê³„ì‚°í•  íŒŒì¼ ê²½ë¡œ
        algorithm: í•´ì‹œ ì•Œê³ ë¦¬ì¦˜ (ê¸°ë³¸: sha256)

    Returns:
        "algorithm:hash_value" í˜•ì‹ì˜ ë¬¸ìì—´

    ì˜ˆì‹œ:
        >>> compute_file_hash(Path("notebook.ipynb"))
        "sha256:abc123def456..."
    """
    hash_func = hashlib.new(algorithm)

    with open(file_path, "rb") as f:
        # í° íŒŒì¼ë„ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ì²­í¬ ë‹¨ìœ„ë¡œ ì½ê¸°
        for chunk in iter(lambda: f.read(8192), b""):
            hash_func.update(chunk)

    return f"{algorithm}:{hash_func.hexdigest()}"


def get_current_timestamp() -> str:
    """
    í˜„ì¬ ì‹œê°„ì„ ISO 8601 í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.

    Returns:
        ISO 8601 í˜•ì‹ì˜ UTC íƒ€ì„ìŠ¤íƒ¬í”„

    ì˜ˆì‹œ:
        >>> get_current_timestamp()
        "2025-11-27T00:00:00Z"
    """
    return datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")


def create_chunk_version_metadata(
    source_file: Path | None = None,
    include_hash: bool = True,
    pipeline_trace: list[str] | None = None,
) -> dict[str, Any]:
    """
    ì²­í¬ì— í¬í•¨í•  ë²„ì „ ë©”íƒ€ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        source_file: ì›ë³¸ íŒŒì¼ ê²½ë¡œ (í•´ì‹œ ê³„ì‚°ìš©)
        include_hash: íŒŒì¼ í•´ì‹œ í¬í•¨ ì—¬ë¶€
        pipeline_trace: íŒŒì´í”„ë¼ì¸ ì¶”ì  ì •ë³´ (ì˜ˆ: ["loaded", "filtered", "chunked"])

    Returns:
        ë²„ì „ ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬

    ì˜ˆì‹œ:
        >>> meta = create_chunk_version_metadata(
        ...     Path("notebook.ipynb"),
        ...     pipeline_trace=["loaded", "filtered_v2", "chunked"]
        ... )
        >>> meta
        {
            "schema_version": "2.0.0",
            "pipeline_version": "2.0.0",
            "corpus_version": "2025.11.27",
            "processed_at": "2025-11-27T00:00:00Z",
            "source_hash": "sha256:abc123...",
            "pipeline_trace": ["loaded", "filtered_v2", "chunked"]
        }
    """
    metadata: dict[str, Any] = {
        "schema_version": SCHEMA_VERSION,
        "pipeline_version": PIPELINE_VERSION,
        "corpus_version": CORPUS_VERSION,
        "processed_at": get_current_timestamp(),
    }

    if include_hash and source_file and source_file.exists():
        metadata["source_hash"] = compute_file_hash(source_file)

    if pipeline_trace:
        metadata["pipeline_trace"] = pipeline_trace

    return metadata


# =============================================================================
# ìš”ì•½ ìºì‹œ ìŠ¤í‚¤ë§ˆ
# =============================================================================


@dataclass
class SummaryMetadata:
    """
    ìš”ì•½ ìºì‹œ ë©”íƒ€ë°ì´í„°.

    ì²­í¬ì— ìš”ì•½ì´ ì¶”ê°€ë  ë•Œ í•¨ê»˜ ì €ì¥ë˜ëŠ” ë©”íƒ€ë°ì´í„°ì…ë‹ˆë‹¤.

    Attributes:
        summary: ìƒì„±ëœ ìš”ì•½ í…ìŠ¤íŠ¸
        summary_model: ìš”ì•½ ìƒì„±ì— ì‚¬ìš©ëœ ëª¨ë¸
        summary_model_version: ëª¨ë¸ ë²„ì „
        summary_created_at: ìš”ì•½ ìƒì„± ì‹œê°„
        summary_max_length: ìš”ì•½ ìµœëŒ€ ê¸¸ì´ ì œí•œ
        action_summary: (Slackìš©) í•µì‹¬ ì¡°ì¹˜/í•´ê²°ì±… ìš”ì•½
    """

    summary: str = ""
    summary_model: str = DEFAULT_SUMMARY_MODEL
    summary_model_version: str = "1.0"
    summary_created_at: str = field(default_factory=get_current_timestamp)
    summary_max_length: int = DEFAULT_SUMMARY_MAX_LENGTH
    action_summary: str | None = None  # Slack Q&Aìš©

    def to_dict(self) -> dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜."""
        result = {
            "summary": self.summary,
            "summary_model": self.summary_model,
            "summary_model_version": self.summary_model_version,
            "summary_created_at": self.summary_created_at,
            "summary_max_length": self.summary_max_length,
        }
        if self.action_summary:
            result["action_summary"] = self.action_summary
        return result

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "SummaryMetadata":
        """ë”•ì…”ë„ˆë¦¬ì—ì„œ ìƒì„±."""
        return cls(
            summary=data.get("summary", ""),
            summary_model=data.get("summary_model", DEFAULT_SUMMARY_MODEL),
            summary_model_version=data.get("summary_model_version", "1.0"),
            summary_created_at=data.get("summary_created_at", get_current_timestamp()),
            summary_max_length=data.get("summary_max_length", DEFAULT_SUMMARY_MAX_LENGTH),
            action_summary=data.get("action_summary"),
        )


def create_summary_metadata(
    summary: str,
    model: str = DEFAULT_SUMMARY_MODEL,
    action_summary: str | None = None,
) -> dict[str, Any]:
    """
    ìš”ì•½ ë©”íƒ€ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        summary: ìƒì„±ëœ ìš”ì•½ í…ìŠ¤íŠ¸
        model: ì‚¬ìš©ëœ ëª¨ë¸
        action_summary: (ì„ íƒ) í•µì‹¬ ì¡°ì¹˜ ìš”ì•½ (Slack Q&Aìš©)

    Returns:
        ìš”ì•½ ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬

    ì˜ˆì‹œ:
        >>> meta = create_summary_metadata(
        ...     summary="PyTorch í…ì„œ ìƒì„± ë° ê¸°ë³¸ ì—°ì‚° ì„¤ëª…",
        ...     model="clova-hcx-003",
        ... )
    """
    metadata = SummaryMetadata(
        summary=summary,
        summary_model=model,
        action_summary=action_summary,
    )
    return metadata.to_dict()


def has_valid_summary(chunk_metadata: dict[str, Any]) -> bool:
    """
    ì²­í¬ì— ìœ íš¨í•œ ìš”ì•½ì´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.

    ìºì‹œëœ ìš”ì•½ì´ ìˆê³ , í˜„ì¬ ìŠ¤í‚¤ë§ˆ ë²„ì „ê³¼ í˜¸í™˜ë˜ë©´ True.

    Args:
        chunk_metadata: ì²­í¬ ë©”íƒ€ë°ì´í„°

    Returns:
        ìœ íš¨í•œ ìš”ì•½ ì¡´ì¬ ì—¬ë¶€
    """
    if not chunk_metadata.get("summary"):
        return False

    # ìŠ¤í‚¤ë§ˆ ë²„ì „ í˜¸í™˜ì„± ì²´í¬
    chunk_schema = chunk_metadata.get("schema_version", "1.0.0")
    major_version = int(chunk_schema.split(".")[0])

    # í˜„ì¬ ë©”ì´ì € ë²„ì „ê³¼ ê°™ìœ¼ë©´ í˜¸í™˜
    current_major = int(SCHEMA_VERSION.split(".")[0])
    return major_version == current_major


# =============================================================================
# ë²„ì „ íŒŒì¼ ê´€ë¦¬
# =============================================================================


@dataclass
class SourceFileInfo:
    """ì›ë³¸ íŒŒì¼ ì •ë³´."""

    hash: str
    chunks: int
    processed_at: str

    def to_dict(self) -> dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜."""
        return asdict(self)


@dataclass
class VersionInfo:
    """
    ë²„ì „ ì •ë³´ (_version.json êµ¬ì¡°).

    Attributes:
        schema_version: ì²­í¬ ìŠ¤í‚¤ë§ˆ ë²„ì „
        pipeline_version: ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ë²„ì „
        created_at: ìµœì´ˆ ìƒì„± ì‹œê°„
        updated_at: ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ì‹œê°„
        total_chunks: ì „ì²´ ì²­í¬ ìˆ˜
        source_files: ì›ë³¸ íŒŒì¼ë³„ ì •ë³´
    """

    schema_version: str = SCHEMA_VERSION
    pipeline_version: str = PIPELINE_VERSION
    created_at: str = field(default_factory=get_current_timestamp)
    updated_at: str = field(default_factory=get_current_timestamp)
    total_chunks: int = 0
    source_files: dict[str, dict[str, Any]] = field(default_factory=dict)

    def to_dict(self) -> dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜."""
        return {
            "schema_version": self.schema_version,
            "pipeline_version": self.pipeline_version,
            "created_at": self.created_at,
            "updated_at": self.updated_at,
            "total_chunks": self.total_chunks,
            "source_files": self.source_files,
        }

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> "VersionInfo":
        """ë”•ì…”ë„ˆë¦¬ì—ì„œ ìƒì„±."""
        return cls(
            schema_version=data.get("schema_version", SCHEMA_VERSION),
            pipeline_version=data.get("pipeline_version", PIPELINE_VERSION),
            created_at=data.get("created_at", get_current_timestamp()),
            updated_at=data.get("updated_at", get_current_timestamp()),
            total_chunks=data.get("total_chunks", 0),
            source_files=data.get("source_files", {}),
        )

    def add_source_file(
        self,
        file_name: str,
        file_path: Path,
        chunk_count: int,
    ) -> None:
        """ì›ë³¸ íŒŒì¼ ì •ë³´ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤."""
        self.source_files[file_name] = {
            "hash": compute_file_hash(file_path) if file_path.exists() else "",
            "chunks": chunk_count,
            "processed_at": get_current_timestamp(),
        }
        self.updated_at = get_current_timestamp()

    def get_changed_files(
        self,
        current_files: dict[str, Path],
    ) -> tuple[list[str], list[str], list[str]]:
        """
        ë³€ê²½ëœ íŒŒì¼ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

        Args:
            current_files: í˜„ì¬ íŒŒì¼ ëª©ë¡ {íŒŒì¼ëª…: ê²½ë¡œ}

        Returns:
            (ìƒˆ íŒŒì¼, ë³€ê²½ëœ íŒŒì¼, ì‚­ì œëœ íŒŒì¼) íŠœí”Œ
        """
        new_files: list[str] = []
        changed_files: list[str] = []
        deleted_files: list[str] = []

        # ìƒˆ íŒŒì¼ ë° ë³€ê²½ëœ íŒŒì¼ í™•ì¸
        for file_name, file_path in current_files.items():
            if file_name not in self.source_files:
                new_files.append(file_name)
            else:
                current_hash = compute_file_hash(file_path)
                stored_hash = self.source_files[file_name].get("hash", "")
                if current_hash != stored_hash:
                    changed_files.append(file_name)

        # ì‚­ì œëœ íŒŒì¼ í™•ì¸
        for file_name in self.source_files:
            if file_name not in current_files:
                deleted_files.append(file_name)

        return new_files, changed_files, deleted_files


def load_version_file(version_path: Path) -> VersionInfo | None:
    """
    _version.json íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.

    Args:
        version_path: _version.json íŒŒì¼ ê²½ë¡œ

    Returns:
        VersionInfo ê°ì²´ ë˜ëŠ” íŒŒì¼ì´ ì—†ìœ¼ë©´ None
    """
    if not version_path.exists():
        return None

    try:
        with open(version_path, encoding="utf-8") as f:
            data = json.load(f)
        return VersionInfo.from_dict(data)
    except (json.JSONDecodeError, KeyError) as e:
        print(f"âš ï¸ ë²„ì „ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None


def save_version_file(version_path: Path, version_info: VersionInfo) -> None:
    """
    _version.json íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        version_path: ì €ì¥í•  ê²½ë¡œ
        version_info: ë²„ì „ ì •ë³´
    """
    version_info.updated_at = get_current_timestamp()

    with open(version_path, "w", encoding="utf-8") as f:
        json.dump(version_info.to_dict(), f, ensure_ascii=False, indent=2)


# =============================================================================
# CLI í…ŒìŠ¤íŠ¸
# =============================================================================

if __name__ == "__main__":
    import sys

    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python versioning.py <file_path>")
        print("\nì˜ˆì‹œ:")
        print("  python versioning.py notebook.ipynb")
        sys.exit(1)

    file_path = Path(sys.argv[1])

    if not file_path.exists():
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        sys.exit(1)

    print(f"ğŸ“„ íŒŒì¼: {file_path}")
    print(f"ğŸ”’ í•´ì‹œ: {compute_file_hash(file_path)}")
    print(f"ğŸ• ì‹œê°„: {get_current_timestamp()}")
    print(f"ğŸ“‹ ìŠ¤í‚¤ë§ˆ ë²„ì „: {SCHEMA_VERSION}")
    print(f"ğŸ”§ íŒŒì´í”„ë¼ì¸ ë²„ì „: {PIPELINE_VERSION}")
