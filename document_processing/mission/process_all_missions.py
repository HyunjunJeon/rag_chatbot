"""
ì „ì²´ ì£¼ê°„ ë¯¸ì…˜ ì¼ê´„ ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸.

weekly_mission/ í´ë”ì˜ ë¬¸ì œ íŒŒì¼ê³¼ ì±„ì  ê¸°ì¤€í‘œë¥¼ ì²˜ë¦¬í•˜ì—¬
document_chunks/mission_chunks/ ì— ì €ì¥í•©ë‹ˆë‹¤.

âš ï¸ ì •ë‹µ íŒŒì¼ì€ ìë™ìœ¼ë¡œ ì œì™¸ë©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    # ì¦ë¶„ ì—…ë°ì´íŠ¸ (ê¸°ë³¸)
    python process_all_missions.py

    # ì „ì²´ ì¬ì²˜ë¦¬
    python process_all_missions.py --recreate

    # ë³€ê²½ì‚¬í•­ë§Œ í™•ì¸ (dry-run)
    python process_all_missions.py --dry-run
"""

import argparse
import json
import sys
from collections import defaultdict
from datetime import datetime
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT / "document_processing"))

from mission.mission_loader import MissionLoader, MissionType
from mission.mission_chunker import MissionChunker
from common.versioning import VersionInfo, save_version_file, load_version_file


def process_all_missions(
    input_dir: Path,
    output_dir: Path,
    chunk_size: int = 1000,
    chunk_overlap: int = 100,
    verbose: bool = True,
    incremental: bool = True,
    dry_run: bool = False,
) -> dict:
    """
    ëª¨ë“  ë¯¸ì…˜ì„ ì²˜ë¦¬í•˜ê³  ì²­í¬ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        input_dir: ë¯¸ì…˜ íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬
        output_dir: ì²­í¬ ì €ì¥ ë””ë ‰í† ë¦¬
        chunk_size: ì²­í¬ ìµœëŒ€ í† í° ìˆ˜
        chunk_overlap: ì²­í¬ ê°„ ì˜¤ë²„ë© í† í° ìˆ˜
        verbose: ìƒì„¸ ë¡œê·¸ ì¶œë ¥
        incremental: Trueë©´ ë³€ê²½ëœ íŒŒì¼ë§Œ ì²˜ë¦¬
        dry_run: Trueë©´ ë³€ê²½ì‚¬í•­ë§Œ í™•ì¸ (ì‹¤ì œ ì²˜ë¦¬ ì•ˆí•¨)

    Returns:
        ì²˜ë¦¬ í†µê³„ ë”•ì…”ë„ˆë¦¬
    """
    print("=" * 60)
    print("ğŸ“‹ ì£¼ê°„ ë¯¸ì…˜ ì¼ê´„ ì²˜ë¦¬ ì‹œì‘")
    print("=" * 60)
    print(f"ğŸ“‚ ì…ë ¥: {input_dir}")
    print(f"ğŸ“ ì¶œë ¥: {output_dir}")
    print(f"ğŸ”§ ì²­í¬ í¬ê¸°: {chunk_size} tokens (overlap: {chunk_overlap})")
    print("âš ï¸  ì •ë‹µ íŒŒì¼ì€ ìë™ ì œì™¸ë©ë‹ˆë‹¤")
    mode_str = "ğŸ”„ ì¦ë¶„ ì—…ë°ì´íŠ¸" if incremental else "ğŸ” ì „ì²´ ì¬ì²˜ë¦¬"
    if dry_run:
        mode_str += " (DRY-RUN)"
    print(f"ğŸ“Œ ëª¨ë“œ: {mode_str}")
    print()

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir.mkdir(parents=True, exist_ok=True)

    # ê¸°ì¡´ ë²„ì „ ì •ë³´ ë¡œë“œ (ì¦ë¶„ ì—…ë°ì´íŠ¸ìš©)
    version_file = output_dir / "_version.json"
    existing_version = load_version_file(version_file) if incremental else None

    # ë¡œë” ë° ì²­ì»¤ ì´ˆê¸°í™”
    loader = MissionLoader(verbose=verbose)
    chunker = MissionChunker(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        include_code_hints=True,
    )

    # ë¯¸ì…˜ íŒŒì¼ ë¡œë“œ (ì •ë‹µ ì œì™¸)
    print("ğŸ“¥ ë¯¸ì…˜ íŒŒì¼ ë¡œë“œ ì¤‘...")
    all_missions = loader.load_from_directory(input_dir, include_solutions=False)

    # ì¦ë¶„ ì—…ë°ì´íŠ¸: ë³€ê²½ëœ íŒŒì¼ë§Œ í•„í„°ë§
    if existing_version and incremental:
        current_files = {m.file_path.name: m.file_path for m in all_missions}
        new_files, changed_files, deleted_files = existing_version.get_changed_files(current_files)

        print(f"\nğŸ“Š ë³€ê²½ ê°ì§€ ê²°ê³¼:")
        print(f"   ğŸ†• ìƒˆ íŒŒì¼: {len(new_files)}ê°œ")
        print(f"   âœï¸  ë³€ê²½ë¨: {len(changed_files)}ê°œ")
        print(f"   ğŸ—‘ï¸  ì‚­ì œë¨: {len(deleted_files)}ê°œ")

        if dry_run:
            if new_files:
                print(f"\n   ìƒˆ íŒŒì¼ ëª©ë¡: {new_files[:5]}{'...' if len(new_files) > 5 else ''}")
            if changed_files:
                print(
                    f"   ë³€ê²½ íŒŒì¼ ëª©ë¡: {changed_files[:5]}{'...' if len(changed_files) > 5 else ''}"
                )
            if deleted_files:
                print(
                    f"   ì‚­ì œ íŒŒì¼ ëª©ë¡: {deleted_files[:5]}{'...' if len(deleted_files) > 5 else ''}"
                )
            print("\nâœ… DRY-RUN ì™„ë£Œ. ì‹¤ì œ ì²˜ë¦¬ëŠ” ìˆ˜í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return {
                "mode": "dry_run",
                "new": len(new_files),
                "changed": len(changed_files),
                "deleted": len(deleted_files),
            }

        # ë³€ê²½ëœ íŒŒì¼ë§Œ ì²˜ë¦¬ ëŒ€ìƒìœ¼ë¡œ í•„í„°ë§
        files_to_process = set(new_files + changed_files)
        if not files_to_process:
            print("\nâœ… ë³€ê²½ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì²˜ë¦¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return {"mode": "incremental", "changes": 0}

        missions = [m for m in all_missions if m.file_path.name in files_to_process]
        print(f"\n   â†’ ì²˜ë¦¬ ëŒ€ìƒ: {len(missions)}ê°œ íŒŒì¼")
    else:
        missions = all_missions

    problems = [m for m in missions if m.mission_type == MissionType.PROBLEM]
    rubrics = [m for m in missions if m.mission_type == MissionType.RUBRIC]

    print(f"   ğŸ“ ë¬¸ì œ: {len(problems)}ê°œ")
    print(f"   ğŸ“‹ ì±„ì ê¸°ì¤€: {len(rubrics)}ê°œ")
    print()

    if not missions:
        print("âš ï¸ ì²˜ë¦¬í•  ë¯¸ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
        return {}

    # ê³¼ëª©ë³„ë¡œ ê·¸ë£¹í™”
    missions_by_course: dict[str, list] = defaultdict(list)
    for mission in missions:
        course = mission.course if mission.course else "Unknown"
        missions_by_course[course].append(mission)

    # í†µê³„
    stats = {
        "processed_at": datetime.now().isoformat(),
        "input_dir": str(input_dir),
        "output_dir": str(output_dir),
        "chunk_size": chunk_size,
        "chunk_overlap": chunk_overlap,
        "total_problems": len(problems),
        "total_rubrics": len(rubrics),
        "total_chunks": 0,
        "by_course": {},
    }

    all_chunks: list[dict] = []

    # ê³¼ëª©ë³„ ì²˜ë¦¬
    for course, course_missions in sorted(missions_by_course.items()):
        print(f"ğŸ“š {course} ({len(course_missions)}ê°œ íŒŒì¼)")

        course_chunks: list[dict] = []

        for mission in course_missions:
            # ì²­í‚¹
            chunks = chunker.chunk_mission(mission)
            chunk_dicts = [c.to_dict() for c in chunks]
            course_chunks.extend(chunk_dicts)

            if verbose:
                type_icon = "ğŸ“" if mission.is_problem else "ğŸ“‹"
                print(f"   {type_icon} {mission.mission_name}: {len(chunks)} chunks")

        # ê³¼ëª©ë³„ ì €ì¥
        course_slug = course.lower().replace(" ", "_").replace("-", "_")
        course_file = output_dir / f"{course_slug}_chunks.json"

        course_data = {
            "course": course,
            "mission_count": len(course_missions),
            "chunk_count": len(course_chunks),
            "chunks": course_chunks,
        }

        with open(course_file, "w", encoding="utf-8") as f:
            json.dump(course_data, f, ensure_ascii=False, indent=2)

        print(f"   âœ… ì €ì¥: {course_file.name} ({len(course_chunks)} chunks)")
        print()

        # í†µê³„ ì—…ë°ì´íŠ¸
        course_problems = [m for m in course_missions if m.is_problem]
        course_rubrics = [m for m in course_missions if m.is_rubric]

        stats["by_course"][course] = {
            "problem_count": len(course_problems),
            "rubric_count": len(course_rubrics),
            "chunk_count": len(course_chunks),
        }
        stats["total_chunks"] += len(course_chunks)
        all_chunks.extend(course_chunks)

    # ì „ì²´ ì²­í¬ ì €ì¥
    all_chunks_file = output_dir / "all_mission_chunks.json"
    with open(all_chunks_file, "w", encoding="utf-8") as f:
        json.dump(
            {
                "total_chunks": len(all_chunks),
                "chunks": all_chunks,
            },
            f,
            ensure_ascii=False,
            indent=2,
        )
    print(f"ğŸ“¦ ì „ì²´ ì €ì¥: {all_chunks_file.name} ({len(all_chunks)} chunks)")

    # ìš”ì•½ ì €ì¥
    summary_file = output_dir / "_summary.json"
    with open(summary_file, "w", encoding="utf-8") as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)

    # ë²„ì „ ì •ë³´ ì €ì¥
    save_version_info_mission(missions, all_chunks, output_dir)

    # ê²°ê³¼ ì¶œë ¥
    print()
    print("=" * 60)
    print("âœ… ì²˜ë¦¬ ì™„ë£Œ")
    print("=" * 60)
    print(f"ğŸ“ ë¬¸ì œ íŒŒì¼: {stats['total_problems']}ê°œ")
    print(f"ğŸ“‹ ì±„ì ê¸°ì¤€: {stats['total_rubrics']}ê°œ")
    print(f"ğŸ§© ì´ ì²­í¬: {stats['total_chunks']}ê°œ")
    print()
    print("ğŸ“Š ê³¼ëª©ë³„ í†µê³„:")
    for course, course_stats in stats["by_course"].items():
        print(
            f"   â€¢ {course}: "
            f"{course_stats['problem_count']}ë¬¸ì œ + {course_stats['rubric_count']}ì±„ì ê¸°ì¤€ "
            f"â†’ {course_stats['chunk_count']} chunks"
        )
    print()

    return stats


def save_version_info_mission(missions: list, all_chunks: list[dict], output_dir: Path) -> None:
    """
    ë²„ì „ ì •ë³´ë¥¼ _version.jsonì— ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        missions: ì²˜ë¦¬ëœ ë¯¸ì…˜ ë¦¬ìŠ¤íŠ¸
        all_chunks: ìƒì„±ëœ ì²­í¬ ë¦¬ìŠ¤íŠ¸ (dict)
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
    """
    version_info = VersionInfo(
        total_chunks=len(all_chunks),
    )

    # ê° ë¯¸ì…˜ì˜ ì²­í¬ ìˆ˜ ê³„ì‚°
    chunks_by_file: dict[str, int] = {}
    for chunk in all_chunks:
        source_file = chunk.get("metadata", {}).get("source_file", "")
        if source_file:
            file_name = Path(source_file).name
            chunks_by_file[file_name] = chunks_by_file.get(file_name, 0) + 1

    # ì›ë³¸ íŒŒì¼ ì •ë³´ ì¶”ê°€
    for mission in missions:
        file_name = mission.file_path.name
        chunk_count = chunks_by_file.get(file_name, 0)
        if chunk_count > 0:
            version_info.add_source_file(
                file_name=file_name,
                file_path=mission.file_path,
                chunk_count=chunk_count,
            )

    # ì €ì¥
    version_file = output_dir / "_version.json"
    save_version_file(version_file, version_info)
    print(f"\nğŸ“ ë²„ì „ ì •ë³´ ì €ì¥: {version_file.name}")


def main():
    """ë©”ì¸ í•¨ìˆ˜."""
    parser = argparse.ArgumentParser(
        description="ì£¼ê°„ ë¯¸ì…˜ì„ ì²­í‚¹í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤. (ì •ë‹µ íŒŒì¼ ì œì™¸)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    parser.add_argument(
        "--input-dir",
        type=Path,
        default=PROJECT_ROOT / "original_documents" / "weekly_mission",
        help="ë¯¸ì…˜ íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬",
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=PROJECT_ROOT / "document_chunks" / "mission_chunks",
        help="ì²­í¬ ì €ì¥ ë””ë ‰í† ë¦¬",
    )
    parser.add_argument(
        "--chunk-size",
        type=int,
        default=1000,
        help="ì²­í¬ ìµœëŒ€ í† í° ìˆ˜ (ê¸°ë³¸: 1000)",
    )
    parser.add_argument(
        "--chunk-overlap",
        type=int,
        default=100,
        help="ì²­í¬ ê°„ ì˜¤ë²„ë© í† í° ìˆ˜ (ê¸°ë³¸: 100)",
    )
    parser.add_argument(
        "-q",
        "--quiet",
        action="store_true",
        help="ê°„ëµí•œ ì¶œë ¥",
    )
    parser.add_argument(
        "--recreate",
        action="store_true",
        help="ì „ì²´ ì¬ì²˜ë¦¬ (ê¸°ì¡´ ì²­í¬ ë¬´ì‹œ)",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="ë³€ê²½ì‚¬í•­ë§Œ í™•ì¸ (ì‹¤ì œ ì²˜ë¦¬ ì•ˆí•¨)",
    )

    args = parser.parse_args()

    # ì…ë ¥ ë””ë ‰í† ë¦¬ í™•ì¸
    if not args.input_dir.exists():
        print(f"âŒ ì…ë ¥ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {args.input_dir}")
        sys.exit(1)

    # ì²˜ë¦¬ ì‹¤í–‰
    process_all_missions(
        input_dir=args.input_dir,
        output_dir=args.output_dir,
        chunk_size=args.chunk_size,
        chunk_overlap=args.chunk_overlap,
        incremental=not args.recreate,
        dry_run=args.dry_run,
        verbose=not args.quiet,
    )


if __name__ == "__main__":
    main()
