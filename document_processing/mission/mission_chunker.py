"""
ì£¼ê°„ ë¯¸ì…˜ ì²­í‚¹ ëª¨ë“ˆ.

ë¬¸ì œ íŒŒì¼ì—ì„œ í•™ìŠµ ëª©í‘œ, ë¬¸ì œ ì„¤ëª…, íŒíŠ¸ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
âš ï¸ ì •ë‹µ ì½”ë“œëŠ” ì œì™¸í•˜ì—¬ íŒíŠ¸ í˜•íƒœë¡œë§Œ ì œê³µí•©ë‹ˆë‹¤.
"""

import hashlib
import re
from dataclasses import dataclass, field
from typing import Any

from langchain_text_splitters import RecursiveCharacterTextSplitter

from .mission_loader import ParsedMission, MissionType
from ..common.versioning import create_chunk_version_metadata


@dataclass
class MissionChunk:
    """
    ë¯¸ì…˜ì—ì„œ ì¶”ì¶œí•œ ì²­í¬.

    Attributes:
        id: ê³ ìœ  ì‹ë³„ì
        content: ì²­í¬ ë‚´ìš©
        metadata: ë©”íƒ€ë°ì´í„°
    """

    id: str
    content: str
    metadata: dict[str, Any] = field(default_factory=dict)

    @property
    def token_estimate(self) -> int:
        """í† í° ìˆ˜ ì¶”ì •."""
        korean_chars = len(re.findall(r"[ê°€-í£]", self.content))
        other_chars = len(self.content) - korean_chars
        return int(korean_chars / 1.5 + other_chars / 4)

    @property
    def char_count(self) -> int:
        """ë¬¸ì ìˆ˜."""
        return len(self.content)

    def to_dict(self) -> dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜."""
        return {
            "id": self.id,
            "content": self.content,
            "metadata": self.metadata,
            "token_estimate": self.token_estimate,
            "char_count": self.char_count,
        }


class MissionChunker:
    """
    ë¯¸ì…˜ì„ RAGìš© ì²­í¬ë¡œ ë¶„í• í•˜ëŠ” í´ë˜ìŠ¤.

    ë¬¸ì œ íŒŒì¼ì—ì„œëŠ” ë§ˆí¬ë‹¤ìš´(ì„¤ëª…/íŒíŠ¸)ë§Œ ì¶”ì¶œí•˜ê³ ,
    ì½”ë“œëŠ” ì œì™¸í•˜ì—¬ ì •ë‹µ ìœ ì¶œì„ ë°©ì§€í•©ë‹ˆë‹¤.

    ì˜ˆì‹œ:
        ```python
        chunker = MissionChunker(chunk_size=1000)
        chunks = chunker.chunk_mission(parsed_mission)

        for chunk in chunks:
            print(f"[{chunk.id}] {chunk.content[:100]}...")
        ```
    """

    # í•œêµ­ì–´ì— ì í•©í•œ êµ¬ë¶„ì
    DEFAULT_SEPARATORS = [
        "\n\n\n",
        "\n\n",
        "\n",
        ". ",
        "ã€‚",
        "? ",
        "! ",
        ", ",
        " ",
        "",
    ]

    # base64 ì´ë¯¸ì§€ íŒ¨í„´ (ë§ˆí¬ë‹¤ìš´ ì´ë¯¸ì§€ ë° ì¸ë¼ì¸ base64)
    BASE64_IMAGE_PATTERNS = [
        # ë§ˆí¬ë‹¤ìš´ ì´ë¯¸ì§€: ![alt](data:image/...;base64,...)
        r"!\[[^\]]*\]\(data:image\/[^;]+;base64,[A-Za-z0-9+/=\s]+\)",
        # HTML ì´ë¯¸ì§€ íƒœê·¸: <img src="data:image/...;base64,...">
        r"<img[^>]*src=['\"]data:image\/[^;]+;base64,[A-Za-z0-9+/=\s]+['\"][^>]*>",
        # ìˆœìˆ˜ base64 ë°ì´í„° ë¸”ë¡ (100ì ì´ìƒ ì—°ì†)
        r"(?<![A-Za-z0-9+/])[A-Za-z0-9+/]{100,}={0,2}(?![A-Za-z0-9+/])",
    ]

    def __init__(
        self,
        chunk_size: int = 1000,
        chunk_overlap: int = 100,
        include_code_hints: bool = True,
    ) -> None:
        """
        MissionChunker ì´ˆê¸°í™”.

        Args:
            chunk_size: ì²­í¬ ìµœëŒ€ í† í° ìˆ˜
            chunk_overlap: ì²­í¬ ê°„ ì˜¤ë²„ë© í† í° ìˆ˜
            include_code_hints: ì½”ë“œ ì£¼ì„/TODOë¥¼ íŒíŠ¸ë¡œ í¬í•¨í• ì§€ ì—¬ë¶€
        """
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap
        self.include_code_hints = include_code_hints

        # í† í° â†’ ë¬¸ì ë³€í™˜ (í‰ê·  2.5ì/í† í°)
        char_size = int(chunk_size * 2.5)
        char_overlap = int(chunk_overlap * 2.5)

        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=char_size,
            chunk_overlap=char_overlap,
            separators=self.DEFAULT_SEPARATORS,
            length_function=len,
        )

    def chunk_mission(self, mission: ParsedMission) -> list[MissionChunk]:
        """
        ë¯¸ì…˜ì„ ì²­í¬ë¡œ ë¶„í• í•©ë‹ˆë‹¤.

        Args:
            mission: íŒŒì‹±ëœ ë¯¸ì…˜

        Returns:
            MissionChunk ë¦¬ìŠ¤íŠ¸
        """
        if mission.mission_type == MissionType.PROBLEM:
            return self._chunk_problem(mission)
        elif mission.mission_type == MissionType.RUBRIC:
            return self._chunk_rubric(mission)
        else:
            # ì •ë‹µ íŒŒì¼ì€ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
            return []

    def chunk_missions(self, missions: list[ParsedMission]) -> list[MissionChunk]:
        """ì—¬ëŸ¬ ë¯¸ì…˜ì„ ì¼ê´„ ì²­í‚¹í•©ë‹ˆë‹¤."""
        all_chunks: list[MissionChunk] = []

        for mission in missions:
            chunks = self.chunk_mission(mission)
            all_chunks.extend(chunks)

        return all_chunks

    def _chunk_problem(self, mission: ParsedMission) -> list[MissionChunk]:
        """
        ë¬¸ì œ ë…¸íŠ¸ë¶ì„ ì²­í‚¹í•©ë‹ˆë‹¤.

        ë§ˆí¬ë‹¤ìš´ ì…€(ì„¤ëª…/íŒíŠ¸)ë§Œ ì¶”ì¶œí•˜ê³  ì½”ë“œëŠ” ì œì™¸í•©ë‹ˆë‹¤.
        """
        if not mission.notebook:
            return []

        notebook = mission.notebook

        # ë§ˆí¬ë‹¤ìš´ ì…€ë§Œ ì¶”ì¶œ
        markdown_texts: list[str] = []

        for cell in notebook.cells:
            if cell.cell_type.value == "markdown" and not cell.is_empty:
                # base64 ì´ë¯¸ì§€ ì œê±°
                cleaned_source = self._remove_base64_images(cell.source)
                if cleaned_source.strip():
                    markdown_texts.append(cleaned_source)

            # ì½”ë“œ ì…€ì—ì„œ íŒíŠ¸ ì¶”ì¶œ (ì„ íƒì )
            elif self.include_code_hints and cell.cell_type.value == "code":
                hints = self._extract_code_hints(cell.source)
                if hints:
                    markdown_texts.append(hints)

        if not markdown_texts:
            return []

        # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©
        full_text = "\n\n".join(markdown_texts)

        # ë©”íƒ€ë°ì´í„° í—¤ë” ì¶”ê°€
        header = self._create_header(mission)
        full_text = f"{header}\n\n{full_text}"

        # RecursiveCharacterTextSplitterë¡œ ë¶„í• 
        text_chunks = self.text_splitter.split_text(full_text)

        # MissionChunk ê°ì²´ë¡œ ë³€í™˜
        chunks: list[MissionChunk] = []
        for idx, text in enumerate(text_chunks):
            chunk = self._create_chunk(
                mission=mission,
                content=text,
                chunk_idx=idx,
                total_chunks=len(text_chunks),
                chunk_type="problem",
            )
            chunks.append(chunk)

        return chunks

    def _chunk_rubric(self, mission: ParsedMission) -> list[MissionChunk]:
        """ì±„ì  ê¸°ì¤€í‘œë¥¼ ì²­í‚¹í•©ë‹ˆë‹¤."""
        if not mission.raw_text:
            return []

        # ë©”íƒ€ë°ì´í„° í—¤ë” ì¶”ê°€
        header = f"[ì±„ì  ê¸°ì¤€í‘œ] {mission.course} - {mission.mission_name}"
        full_text = f"{header}\n\n{mission.raw_text}"

        # ë¶„í• 
        text_chunks = self.text_splitter.split_text(full_text)

        # ì²­í¬ ìƒì„±
        chunks: list[MissionChunk] = []
        for idx, text in enumerate(text_chunks):
            chunk = self._create_chunk(
                mission=mission,
                content=text,
                chunk_idx=idx,
                total_chunks=len(text_chunks),
                chunk_type="rubric",
            )
            chunks.append(chunk)

        return chunks

    def _remove_base64_images(self, text: str) -> str:
        """
        í…ìŠ¤íŠ¸ì—ì„œ base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ì œê±°í•©ë‹ˆë‹¤.

        ì œê±° ëŒ€ìƒ:
        - ë§ˆí¬ë‹¤ìš´ ì´ë¯¸ì§€: ![alt](data:image/png;base64,...)
        - HTML ì´ë¯¸ì§€: <img src="data:image/png;base64,...">
        - ìˆœìˆ˜ base64 ë°ì´í„° ë¸”ë¡
        """
        result = text

        for pattern in self.BASE64_IMAGE_PATTERNS:
            result = re.sub(pattern, "[Image]", result, flags=re.DOTALL)

        return result

    def _extract_code_hints(self, code: str) -> str:
        """
        ì½”ë“œ ì…€ì—ì„œ íŒíŠ¸(ì£¼ì„, TODO)ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.

        ì •ë‹µ ì½”ë“œëŠ” ì œì™¸í•˜ê³  íŒíŠ¸ì„± ì£¼ì„ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
        """
        hints: list[str] = []

        for line in code.split("\n"):
            line = line.strip()

            # TODO ì£¼ì„
            if re.match(r"^#\s*TODO", line, re.IGNORECASE):
                hints.append(f"ğŸ’¡ íŒíŠ¸: {line[1:].strip()}")

            # íŒíŠ¸/ê°€ì´ë“œ ì£¼ì„
            elif re.match(r"^#\s*(íŒíŠ¸|Hint|ê°€ì´ë“œ|Guide)", line, re.IGNORECASE):
                hints.append(f"ğŸ’¡ {line[1:].strip()}")

            # ì„¤ëª… ì£¼ì„ (ê¸´ ì£¼ì„)
            elif line.startswith("#") and len(line) > 20:
                # ë‹¨ìˆœ ì½”ë“œ ì£¼ì„ ì œì™¸ (import, ë³€ìˆ˜ëª… ë“±)
                comment = line[1:].strip()
                if not re.match(r"^(import|from|def|class|\w+\s*=)", comment):
                    hints.append(f"ğŸ“ {comment}")

        return "\n".join(hints) if hints else ""

    def _create_header(self, mission: ParsedMission) -> str:
        """ë¯¸ì…˜ ë©”íƒ€ë°ì´í„° í—¤ë”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        parts = []

        if mission.course:
            parts.append(f"ê³¼ëª©: {mission.course}")
        if mission.week:
            parts.append(f"ì£¼ì°¨: {mission.week}")
        if mission.mission_name:
            parts.append(f"ë¯¸ì…˜: {mission.mission_name}")
        if mission.instructor:
            parts.append(f"ë§ˆìŠ¤í„°: {mission.instructor}")

        if parts:
            return f"[ì£¼ê°„ ë¯¸ì…˜] {' | '.join(parts)}"
        return "[ì£¼ê°„ ë¯¸ì…˜]"

    def _create_chunk(
        self,
        mission: ParsedMission,
        content: str,
        chunk_idx: int,
        total_chunks: int,
        chunk_type: str,
    ) -> MissionChunk:
        """ì²­í¬ ê°ì²´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        chunk_id = self._generate_chunk_id(mission, chunk_idx, chunk_type)

        metadata = {
            "source_file": str(mission.file_path),
            "file_name": mission.file_path.name,
            "course": mission.course,
            "week": mission.week,
            "mission_name": mission.mission_name,
            "instructor": mission.instructor,
            "chunk_idx": chunk_idx,
            "total_chunks": total_chunks,
            "chunk_type": chunk_type,
            "doc_type": "weekly_mission",
        }

        # ë²„ì „ ë©”íƒ€ë°ì´í„° ì¶”ê°€
        version_meta = create_chunk_version_metadata(
            source_file=mission.file_path,
            include_hash=True,
        )
        metadata.update(version_meta)

        return MissionChunk(
            id=chunk_id,
            content=content,
            metadata=metadata,
        )

    def _generate_chunk_id(
        self,
        mission: ParsedMission,
        chunk_idx: int,
        chunk_type: str,
    ) -> str:
        """ì²­í¬ IDë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        course_slug = mission.course.lower().replace(" ", "_").replace("-", "_")
        if not course_slug:
            course_slug = "unknown"

        week_str = mission.week if mission.week else "w0"

        hash_input = f"{mission.file_path}_{chunk_idx}".encode()
        short_hash = hashlib.md5(hash_input).hexdigest()[:6]

        return f"mission_{course_slug}_{week_str}_{chunk_type}_c{chunk_idx:03d}_{short_hash}"


# =============================================================================
# CLI í…ŒìŠ¤íŠ¸
# =============================================================================

if __name__ == "__main__":
    import sys
    from .mission_loader import MissionLoader

    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python -m mission.mission_chunker <directory>")
        sys.exit(1)

    directory = sys.argv[1]

    loader = MissionLoader(verbose=True)
    missions = loader.load_from_directory(directory)

    chunker = MissionChunker(chunk_size=1000, chunk_overlap=100)

    print(f"\n{'=' * 60}")
    print(f"ğŸ“‚ {len(missions)}ê°œ ë¯¸ì…˜ ë¡œë“œ")

    all_chunks = chunker.chunk_missions(missions)
    print(f"ğŸ§© {len(all_chunks)}ê°œ ì²­í¬ ìƒì„±")
    print("=" * 60)

    # ë¯¸ë¦¬ë³´ê¸°
    for chunk in all_chunks[:3]:
        print(f"\n--- {chunk.id} ({chunk.token_estimate}t) ---")
        print(chunk.content[:400])
        if len(chunk.content) > 400:
            print("...")
