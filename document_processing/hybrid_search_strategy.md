# Hybrid Search ì „ëµ: ë²¡í„° ê²€ìƒ‰ + BM25

## ê°œìš”

ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰(Vector)ê³¼ í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰(BM25)ì„ ê²°í•©í•œ Hybrid Search ì „ëµì…ë‹ˆë‹¤.

## ì™œ Hybrid Searchì¸ê°€?

### ë²¡í„° ê²€ìƒ‰ì˜ ì¥ì ê³¼ í•œê³„

**ì¥ì :**
- âœ… ì˜ë¯¸ì  ìœ ì‚¬ë„ íŒŒì•… ("GPU ë¶€ì¡±" â‰ˆ "ë©”ëª¨ë¦¬ ì—ëŸ¬")
- âœ… ë™ì˜ì–´ ì²˜ë¦¬ ê°€ëŠ¥
- âœ… ë¬¸ë§¥ ì´í•´

**í•œê³„:**
- âŒ ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­ ì•½í•¨ (ì˜ˆ: íŠ¹ì • í•¨ìˆ˜ëª…, ì—ëŸ¬ ì½”ë“œ)
- âŒ í¬ê·€í•œ ì „ë¬¸ ìš©ì–´ ê²€ìƒ‰ ì–´ë ¤ì›€

### BM25 ê²€ìƒ‰ì˜ ì¥ì ê³¼ í•œê³„

**ì¥ì :**
- âœ… ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­ (ì˜ˆ: "torch.cuda.OutOfMemoryError")
- âœ… ì „ë¬¸ ìš©ì–´ ê²€ìƒ‰ ìš°ìˆ˜
- âœ… ë¹ ë¥¸ ì†ë„

**í•œê³„:**
- âŒ ë™ì˜ì–´ ì²˜ë¦¬ ì•ˆ ë¨
- âŒ ì˜ë¯¸ ì´í•´ ë¶ˆê°€

### Hybrid = ë‘˜ì˜ ì¥ì  ê²°í•©

```
Vector Search: "GPU ë©”ëª¨ë¦¬ ë¶€ì¡±" â†’ "CUDA out of memory" ì°¾ê¸° âœ…
BM25 Search:   "OutOfMemoryError" â†’ ì •í™•í•œ ì—ëŸ¬ëª… ì°¾ê¸° âœ…
```

## ë¬¸ì„œ êµ¬ì¡° ì„¤ê³„

### í•„ë“œ ë¶„ë¦¬ ì „ëµ

ê° ë¬¸ì„œì— ì§ˆë¬¸ê³¼ ë‹µë³€ì„ **ë¶„ë¦¬ëœ í•„ë“œ**ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

```python
{
    # === Qdrant Vector (ì˜ë¯¸ ê²€ìƒ‰ìš©) ===
    "vector": [0.1, 0.2, ...],  # 768ì°¨ì› ì„ë² ë”©
    
    # === Payload (ë©”íƒ€ë°ì´í„° + í…ìŠ¤íŠ¸) ===
    "payload": {
        # ì›ë³¸ í…ìŠ¤íŠ¸ (BM25 ê²€ìƒ‰ ëŒ€ìƒ)
        "question_text": "GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ë¬¸ì œ í•´ê²° ë°©ë²•ì€?",
        "answer_text": "ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì´ê±°ë‚˜ gradient checkpointingì„ ì‚¬ìš©í•˜ì„¸ìš”.",
        
        # í† í°í™”ëœ í…ìŠ¤íŠ¸ (BM25 ì¸ë±ì‹±ìš©)
        "question_tokens": ["GPU", "ë©”ëª¨ë¦¬", "ë¶€ì¡±", "ë¬¸ì œ", "í•´ê²°", "ë°©ë²•"],
        "answer_tokens": ["ë°°ì¹˜", "í¬ê¸°", "ì¤„ì´ë‹¤", "gradient", "checkpointing", "ì‚¬ìš©"],
        
        # ë©”íƒ€ë°ì´í„° (í•„í„°ë§ìš©)
        "course": "level2_cv",
        "generation": "4",
        ...
    }
}
```

### í† í°í™” ì „ëµ

**í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ê¸° ì‚¬ìš©:**
- **Kiwi** (ì¶”ì²œ): ë¹ ë¥´ê³  ì •í™•, ì„¤ì¹˜ ê°„ë‹¨
- Mecab: ì „í†µì , ì •í™•ë„ ë†’ìŒ
- KoNLPy: ë‹¤ì–‘í•œ ë¶„ì„ê¸° ì§€ì›

**í† í°í™” ì˜ˆì‹œ:**
```python
from kiwipiepy import Kiwi

kiwi = Kiwi()

text = "GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë°©ë²•ì€?"
tokens = [token.form for token in kiwi.tokenize(text)]
# ["GPU", "ë©”ëª¨ë¦¬", "ë¶€ì¡±", "ë¬¸ì œ", "ë¥¼", "í•´ê²°", "í•˜ë‹¤", "ë°©ë²•", "ì€"]
```

## BM25 ì¸ë±ìŠ¤ êµ¬ì¡°

### ë³„ë„ ì¸ë±ìŠ¤ ê´€ë¦¬

Qdrantì™€ ë³„ë„ë¡œ BM25 ì¸ë±ìŠ¤ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.

```python
from rank_bm25 import BM25Okapi

# ì¸ë±ìŠ¤ êµ¬ì¡°
bm25_indices = {
    "question": BM25Okapi([
        doc1_question_tokens,
        doc2_question_tokens,
        ...
    ]),
    "answer": BM25Okapi([
        doc1_answer_tokens,
        doc2_answer_tokens,
        ...
    ]),
    "combined": BM25Okapi([
        doc1_question_tokens + doc1_answer_tokens,
        doc2_question_tokens + doc2_answer_tokens,
        ...
    ])
}

# ë¬¸ì„œ ID ë§¤í•‘ (ê²€ìƒ‰ ê²°ê³¼ ì—°ê²°ìš©)
doc_id_mapping = [
    "doc_id_1",
    "doc_id_2",
    ...
]
```

### ì¸ë±ìŠ¤ ì €ì¥ ë° ë¡œë“œ

```python
import pickle

# ì €ì¥
with open("bm25_index.pkl", "wb") as f:
    pickle.dump({
        "indices": bm25_indices,
        "doc_ids": doc_id_mapping
    }, f)

# ë¡œë“œ
with open("bm25_index.pkl", "rb") as f:
    data = pickle.load(f)
    bm25_indices = data["indices"]
    doc_id_mapping = data["doc_ids"]
```

## Hybrid Search í”„ë¡œì„¸ìŠ¤

### 1. ë²¡í„° ê²€ìƒ‰ (Qdrant)

```python
# ì¿¼ë¦¬ ì„ë² ë”©
query_vector = embedding_model.encode(query)

# Qdrant ê²€ìƒ‰
vector_results = qdrant_client.search(
    collection_name="slack_qa",
    query_vector=query_vector,
    limit=50,  # í›„ë³´ ë§ì´ ê°€ì ¸ì˜¤ê¸°
    query_filter=course_filter  # í•„í„° ì ìš©
)
```

### 2. BM25 ê²€ìƒ‰

```python
# ì¿¼ë¦¬ í† í°í™”
query_tokens = kiwi.tokenize(query)

# BM25 ê²€ìƒ‰ (ì§ˆë¬¸ + ë‹µë³€ ê°€ì¤‘ì¹˜)
question_scores = bm25_indices["question"].get_scores(query_tokens)
answer_scores = bm25_indices["answer"].get_scores(query_tokens)

# ê°€ì¤‘ì¹˜ ì¡°í•© (ì§ˆë¬¸ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜)
bm25_scores = 0.7 * question_scores + 0.3 * answer_scores

# ìƒìœ„ 50ê°œ ì„ íƒ
top_indices = np.argsort(bm25_scores)[::-1][:50]
bm25_results = [doc_id_mapping[i] for i in top_indices]
```

### 3. ê²°ê³¼ ë³‘í•©: Reciprocal Rank Fusion (RRF)

```python
def reciprocal_rank_fusion(
    vector_results: list,
    bm25_results: list,
    k: int = 60
) -> list:
    """
    RRFë¡œ ë‘ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë³‘í•©í•©ë‹ˆë‹¤.
    
    RRF ê³µì‹: score(d) = Î£ 1 / (k + rank(d))
    """
    scores = {}
    
    # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼
    for rank, doc in enumerate(vector_results, 1):
        doc_id = doc.id
        scores[doc_id] = scores.get(doc_id, 0) + 1 / (k + rank)
    
    # BM25 ê²€ìƒ‰ ê²°ê³¼
    for rank, doc_id in enumerate(bm25_results, 1):
        scores[doc_id] = scores.get(doc_id, 0) + 1 / (k + rank)
    
    # ì ìˆ˜ ìˆœ ì •ë ¬
    ranked_docs = sorted(scores.items(), key=lambda x: x[1], reverse=True)
    
    return ranked_docs
```

### 4. ê°€ì¤‘ì¹˜ ì¡°ì ˆ (Alpha Blending)

```python
def weighted_hybrid_search(
    vector_results: list,
    bm25_results: list,
    alpha: float = 0.7  # ë²¡í„° ê°€ì¤‘ì¹˜
) -> list:
    """
    alpha: ë²¡í„° ê²€ìƒ‰ ê°€ì¤‘ì¹˜ (0~1)
    1-alpha: BM25 ê°€ì¤‘ì¹˜
    
    alpha=0.7: ë²¡í„° 70%, BM25 30%
    alpha=0.5: ë²¡í„° 50%, BM25 50%
    """
    scores = {}
    
    # ì •ê·œí™”ëœ ì ìˆ˜ ê³„ì‚°
    for rank, doc in enumerate(vector_results, 1):
        normalized_score = 1 / rank
        scores[doc.id] = alpha * normalized_score
    
    for rank, doc_id in enumerate(bm25_results, 1):
        normalized_score = 1 / rank
        scores[doc_id] = scores.get(doc_id, 0) + (1 - alpha) * normalized_score
    
    return sorted(scores.items(), key=lambda x: x[1], reverse=True)
```

## í•„ë“œë³„ BM25 ê²€ìƒ‰ ì „ëµ

### ì „ëµ 1: ì§ˆë¬¸ ìš°ì„  ê²€ìƒ‰

ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ë¹„ìŠ·í•œ ì§ˆë¬¸ì„ ì°¾ëŠ” ê²ƒì´ ìš°ì„ ì…ë‹ˆë‹¤.

```python
# ì§ˆë¬¸ í•„ë“œì— ë†’ì€ ê°€ì¤‘ì¹˜
bm25_score = 0.8 * question_bm25 + 0.2 * answer_bm25
```

**ì í•©í•œ ê²½ìš°:**
- ì¤‘ë³µ ì§ˆë¬¸ íƒì§€
- "ë¹„ìŠ·í•œ ì§ˆë¬¸ ìˆë‚˜ìš”?" ê¸°ëŠ¥

### ì „ëµ 2: ë‹µë³€ ìš°ì„  ê²€ìƒ‰

ë‹µë³€ ë‚´ìš©ì—ì„œ í‚¤ì›Œë“œë¥¼ ì°¾ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.

```python
# ë‹µë³€ í•„ë“œì— ë†’ì€ ê°€ì¤‘ì¹˜
bm25_score = 0.2 * question_bm25 + 0.8 * answer_bm25
```

**ì í•©í•œ ê²½ìš°:**
- íŠ¹ì • í•´ê²° ë°©ë²• ê²€ìƒ‰ (ì˜ˆ: "gradient checkpointing")
- ì½”ë“œ ìŠ¤ë‹ˆí« ê²€ìƒ‰

### ì „ëµ 3: ê· í˜• ê²€ìƒ‰ (ì¶”ì²œ)

ì§ˆë¬¸ê³¼ ë‹µë³€ ëª¨ë‘ ê³ ë ¤í•©ë‹ˆë‹¤.

```python
# ê· í˜• ê°€ì¤‘ì¹˜
bm25_score = 0.6 * question_bm25 + 0.4 * answer_bm25
```

**ì í•©í•œ ê²½ìš°:**
- ì¼ë°˜ì ì¸ Q&A ê²€ìƒ‰
- í¬ê´„ì ì¸ ì •ë³´ ê²€ìƒ‰

## ì„±ëŠ¥ ìµœì í™”

### 1. ì¸ë±ìŠ¤ ì‚¬ì „ ë¡œë“œ

```python
class HybridRetriever:
    def __init__(self):
        # ì‹œì‘ ì‹œ ì¸ë±ìŠ¤ ë¡œë“œ (ëŠë¦¼)
        self.bm25_indices = self._load_bm25_index()
        self.qdrant_client = QdrantClient()
        
    def search(self, query):
        # ê²€ìƒ‰ì€ ë¹ ë¦„
        pass
```

### 2. ìºì‹±

```python
from functools import lru_cache

@lru_cache(maxsize=100)
def hybrid_search_cached(query: str, course: str):
    return hybrid_search(query, course)
```

### 3. ë¹„ë™ê¸° ê²€ìƒ‰

```python
import asyncio

async def async_hybrid_search(query):
    # ë²¡í„° ê²€ìƒ‰ê³¼ BM25 ê²€ìƒ‰ì„ ë³‘ë ¬ë¡œ
    vector_task = asyncio.create_task(vector_search(query))
    bm25_task = asyncio.create_task(bm25_search(query))
    
    vector_results, bm25_results = await asyncio.gather(
        vector_task,
        bm25_task
    )
    
    return merge_results(vector_results, bm25_results)
```

## ê²€ìƒ‰ í’ˆì§ˆ í‰ê°€

### ë©”íŠ¸ë¦­

1. **Precision@K**: ìƒìœ„ Kê°œ ì¤‘ ê´€ë ¨ ë¬¸ì„œ ë¹„ìœ¨
2. **Recall@K**: ì „ì²´ ê´€ë ¨ ë¬¸ì„œ ì¤‘ ìƒìœ„ Kê°œì— í¬í•¨ëœ ë¹„ìœ¨
3. **MRR (Mean Reciprocal Rank)**: ì²« ê´€ë ¨ ë¬¸ì„œì˜ ìˆœìœ„

### A/B í…ŒìŠ¤íŠ¸

```python
# ë²¡í„°ë§Œ
vector_only = search_vector(query)

# BM25ë§Œ
bm25_only = search_bm25(query)

# í•˜ì´ë¸Œë¦¬ë“œ
hybrid = hybrid_search(query, alpha=0.7)

# í‰ê°€
evaluate_results(vector_only, bm25_only, hybrid, ground_truth)
```

## ì‹¤ì „ ì‚¬ìš© ì˜ˆì‹œ

### ì˜ˆì‹œ 1: ì¼ë°˜ ê²€ìƒ‰

```python
retriever = HybridRetriever()

results = retriever.search(
    query="GPU ë©”ëª¨ë¦¬ ë¶€ì¡± í•´ê²°",
    course="level2_cv",
    alpha=0.7,  # ë²¡í„° 70%, BM25 30%
    limit=10
)
```

### ì˜ˆì‹œ 2: í‚¤ì›Œë“œ ì¤‘ì‹¬ ê²€ìƒ‰

```python
# íŠ¹ì • ì—ëŸ¬ ì½”ë“œ ê²€ìƒ‰
results = retriever.search(
    query="torch.cuda.OutOfMemoryError",
    alpha=0.3,  # BM25 ë¹„ì¤‘ ì¦ê°€
    limit=10
)
```

### ì˜ˆì‹œ 3: ì˜ë¯¸ ì¤‘ì‹¬ ê²€ìƒ‰

```python
# ì¶”ìƒì ì¸ ê°œë… ê²€ìƒ‰
results = retriever.search(
    query="ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒ ë°©ë²•",
    alpha=0.9,  # ë²¡í„° ë¹„ì¤‘ ì¦ê°€
    limit=10
)
```

## ì¥ë‹¨ì  ë¶„ì„

### Hybrid Searchì˜ ì¥ì 

âœ… **í¬ê´„ì  ê²€ìƒ‰**: ì˜ë¯¸ì™€ í‚¤ì›Œë“œ ëª¨ë‘ ì»¤ë²„
âœ… **ë†’ì€ ì •í™•ë„**: ë‘ ë°©ì‹ì˜ ì•½ì  ë³´ì™„
âœ… **ìœ ì—°ì„±**: ê°€ì¤‘ì¹˜ ì¡°ì ˆë¡œ ìƒí™©ë³„ ìµœì í™”
âœ… **ê°•ê±´ì„±**: í•œ ë°©ì‹ì´ ì‹¤íŒ¨í•´ë„ ë‹¤ë¥¸ ë°©ì‹ì´ ì»¤ë²„

### ê³ ë ¤ì‚¬í•­

âš ï¸ **ì¸ë±ìŠ¤ ê´€ë¦¬**: ë‘ ê°œì˜ ì¸ë±ìŠ¤ ìœ ì§€ í•„ìš”
âš ï¸ **ë©”ëª¨ë¦¬**: BM25 ì¸ë±ìŠ¤ê°€ ë©”ëª¨ë¦¬ì— ìƒì£¼
âš ï¸ **ë³µì¡ë„**: êµ¬í˜„ ë° ë””ë²„ê¹… ë³µì¡
âš ï¸ **íŒŒë¼ë¯¸í„° íŠœë‹**: alpha ê°’ ìµœì í™” í•„ìš”

## ë‹¤ìŒ ë‹¨ê³„

1. âœ… ì „ëµ ì„¤ê³„ ì™„ë£Œ
2. ğŸ”„ BM25 ì¸ë±ìŠ¤ ìƒì„± ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
3. ğŸ”„ Hybrid Retriever í´ë˜ìŠ¤ êµ¬í˜„
4. ğŸ”„ ì„±ëŠ¥ í‰ê°€ ë° íŠœë‹
5. ğŸ”„ í”„ë¡œë•ì…˜ ë°°í¬

## ì°¸ê³  ìë£Œ

- [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf)
- [Qdrant Hybrid Search](https://qdrant.tech/documentation/tutorials/hybrid-search/)
- [rank_bm25 ë¼ì´ë¸ŒëŸ¬ë¦¬](https://github.com/dorianbrown/rank_bm25)

