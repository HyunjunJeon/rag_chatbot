"""
ì „ì²´ PDF ì¼ê´„ ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸.

lecture_content/ í´ë”ì˜ ëª¨ë“  PDFë¥¼ ë¡œë“œí•˜ê³  ì²­í‚¹í•˜ì—¬
document_chunks/pdf_chunks/ ì— ì €ì¥í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    # ì¦ë¶„ ì—…ë°ì´íŠ¸ (ê¸°ë³¸)
    python process_all_pdfs.py

    # ì „ì²´ ì¬ì²˜ë¦¬
    python process_all_pdfs.py --recreate

    # ë³€ê²½ì‚¬í•­ë§Œ í™•ì¸ (dry-run)
    python process_all_pdfs.py --dry-run
"""

import argparse
import json
import sys
from collections import defaultdict
from datetime import datetime
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT / "document_processing"))

from pdf.pdf_loader import PDFLoader
from pdf.pdf_chunker import PDFChunker
from common.versioning import VersionInfo, save_version_file, load_version_file


def process_all_pdfs(
    input_dir: Path,
    output_dir: Path,
    chunk_size: int = 1000,
    chunk_overlap: int = 100,
    verbose: bool = True,
    incremental: bool = True,
    dry_run: bool = False,
) -> dict:
    """
    ëª¨ë“  PDFë¥¼ ì²˜ë¦¬í•˜ê³  ì²­í¬ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        input_dir: PDF íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬
        output_dir: ì²­í¬ ì €ì¥ ë””ë ‰í† ë¦¬
        chunk_size: ì²­í¬ ìµœëŒ€ í† í° ìˆ˜
        chunk_overlap: ì²­í¬ ê°„ ì˜¤ë²„ë© í† í° ìˆ˜
        verbose: ìƒì„¸ ë¡œê·¸ ì¶œë ¥
        incremental: Trueë©´ ë³€ê²½ëœ íŒŒì¼ë§Œ ì²˜ë¦¬
        dry_run: Trueë©´ ë³€ê²½ì‚¬í•­ë§Œ í™•ì¸ (ì‹¤ì œ ì²˜ë¦¬ ì•ˆí•¨)

    Returns:
        ì²˜ë¦¬ í†µê³„ ë”•ì…”ë„ˆë¦¬
    """
    print("=" * 60)
    print("ğŸ“„ PDF ì¼ê´„ ì²˜ë¦¬ ì‹œì‘")
    print("=" * 60)
    print(f"ğŸ“‚ ì…ë ¥: {input_dir}")
    print(f"ğŸ“ ì¶œë ¥: {output_dir}")
    print(f"ğŸ”§ ì²­í¬ í¬ê¸°: {chunk_size} tokens (overlap: {chunk_overlap})")
    mode_str = "ğŸ”„ ì¦ë¶„ ì—…ë°ì´íŠ¸" if incremental else "ğŸ” ì „ì²´ ì¬ì²˜ë¦¬"
    if dry_run:
        mode_str += " (DRY-RUN)"
    print(f"ğŸ“Œ ëª¨ë“œ: {mode_str}")
    print()

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir.mkdir(parents=True, exist_ok=True)

    # ê¸°ì¡´ ë²„ì „ ì •ë³´ ë¡œë“œ (ì¦ë¶„ ì—…ë°ì´íŠ¸ìš©)
    version_file = output_dir / "_version.json"
    existing_version = load_version_file(version_file) if incremental else None

    # ë¡œë” ë° ì²­ì»¤ ì´ˆê¸°í™”
    loader = PDFLoader(verbose=verbose)
    chunker = PDFChunker(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        length_function="tokens",
    )

    # PDF íŒŒì¼ ë¡œë“œ
    print("ğŸ“¥ PDF íŒŒì¼ ë¡œë“œ ì¤‘...")
    all_pdfs = loader.load_from_directory(input_dir, recursive=True)
    print(f"   ë¡œë“œ ì™„ë£Œ: {len(all_pdfs)}ê°œ PDF")

    # ì¦ë¶„ ì—…ë°ì´íŠ¸: ë³€ê²½ëœ íŒŒì¼ë§Œ í•„í„°ë§
    if existing_version and incremental:
        current_files = {pdf.file_path.name: pdf.file_path for pdf in all_pdfs}
        new_files, changed_files, deleted_files = existing_version.get_changed_files(current_files)

        print(f"\nğŸ“Š ë³€ê²½ ê°ì§€ ê²°ê³¼:")
        print(f"   ğŸ†• ìƒˆ íŒŒì¼: {len(new_files)}ê°œ")
        print(f"   âœï¸  ë³€ê²½ë¨: {len(changed_files)}ê°œ")
        print(f"   ğŸ—‘ï¸  ì‚­ì œë¨: {len(deleted_files)}ê°œ")

        if dry_run:
            if new_files:
                print(f"\n   ìƒˆ íŒŒì¼: {new_files[:5]}{'...' if len(new_files) > 5 else ''}")
            if changed_files:
                print(f"   ë³€ê²½ íŒŒì¼: {changed_files[:5]}{'...' if len(changed_files) > 5 else ''}")
            print("\nâœ… DRY-RUN ì™„ë£Œ. ì‹¤ì œ ì²˜ë¦¬ëŠ” ìˆ˜í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return {
                "mode": "dry_run",
                "new": len(new_files),
                "changed": len(changed_files),
                "deleted": len(deleted_files),
            }

        # ë³€ê²½ëœ íŒŒì¼ë§Œ ì²˜ë¦¬ ëŒ€ìƒìœ¼ë¡œ í•„í„°ë§
        files_to_process = set(new_files + changed_files)
        if not files_to_process:
            print("\nâœ… ë³€ê²½ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì²˜ë¦¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return {"mode": "incremental", "changes": 0}

        pdfs = [pdf for pdf in all_pdfs if pdf.file_path.name in files_to_process]
        print(f"\n   â†’ ì²˜ë¦¬ ëŒ€ìƒ: {len(pdfs)}ê°œ íŒŒì¼")
    else:
        pdfs = all_pdfs
    print()

    if not pdfs:
        print("âš ï¸ ì²˜ë¦¬í•  PDFê°€ ì—†ìŠµë‹ˆë‹¤.")
        return {}

    # ê³¼ëª©ë³„ë¡œ ê·¸ë£¹í™”
    pdfs_by_course: dict[str, list] = defaultdict(list)
    for pdf in pdfs:
        course = pdf.course if pdf.course else "Unknown"
        pdfs_by_course[course].append(pdf)

    # í†µê³„
    stats = {
        "processed_at": datetime.now().isoformat(),
        "input_dir": str(input_dir),
        "output_dir": str(output_dir),
        "chunk_size": chunk_size,
        "chunk_overlap": chunk_overlap,
        "total_pdfs": len(pdfs),
        "total_pages": sum(pdf.total_pages for pdf in pdfs),
        "total_chunks": 0,
        "by_course": {},
    }

    all_chunks: list[dict] = []

    # ê³¼ëª©ë³„ ì²˜ë¦¬
    for course, course_pdfs in sorted(pdfs_by_course.items()):
        print(f"ğŸ“š {course} ({len(course_pdfs)}ê°œ PDF)")

        course_chunks: list[dict] = []

        for pdf in sorted(course_pdfs, key=lambda p: p.lecture_num):
            # ì²­í‚¹
            chunks = chunker.chunk_pdf(pdf)

            # ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            chunk_dicts = [c.to_dict() for c in chunks]
            course_chunks.extend(chunk_dicts)

            if verbose:
                print(
                    f"   ğŸ“– {pdf.lecture_num}ê°• {pdf.topic}: {pdf.total_pages}p â†’ {len(chunks)} chunks"
                )

        # ê³¼ëª©ë³„ ì €ì¥
        course_slug = course.lower().replace(" ", "_").replace("-", "_")
        course_file = output_dir / f"{course_slug}_chunks.json"

        course_data = {
            "course": course,
            "pdf_count": len(course_pdfs),
            "chunk_count": len(course_chunks),
            "chunks": course_chunks,
        }

        with open(course_file, "w", encoding="utf-8") as f:
            json.dump(course_data, f, ensure_ascii=False, indent=2)

        print(f"   âœ… ì €ì¥: {course_file.name} ({len(course_chunks)} chunks)")
        print()

        # í†µê³„ ì—…ë°ì´íŠ¸
        stats["by_course"][course] = {
            "pdf_count": len(course_pdfs),
            "chunk_count": len(course_chunks),
        }
        stats["total_chunks"] += len(course_chunks)
        all_chunks.extend(course_chunks)

    # ì „ì²´ ì²­í¬ ì €ì¥
    all_chunks_file = output_dir / "all_pdf_chunks.json"
    with open(all_chunks_file, "w", encoding="utf-8") as f:
        json.dump(
            {
                "total_chunks": len(all_chunks),
                "chunks": all_chunks,
            },
            f,
            ensure_ascii=False,
            indent=2,
        )
    print(f"ğŸ“¦ ì „ì²´ ì €ì¥: {all_chunks_file.name} ({len(all_chunks)} chunks)")

    # ìš”ì•½ ì €ì¥
    summary_file = output_dir / "_summary.json"
    with open(summary_file, "w", encoding="utf-8") as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)

    # ë²„ì „ ì •ë³´ ì €ì¥
    save_version_info_pdf(pdfs, all_chunks, output_dir)

    # ê²°ê³¼ ì¶œë ¥
    print()
    print("=" * 60)
    print("âœ… ì²˜ë¦¬ ì™„ë£Œ")
    print("=" * 60)
    print(f"ğŸ“„ PDF íŒŒì¼: {stats['total_pdfs']}ê°œ")
    print(f"ğŸ“ƒ ì´ í˜ì´ì§€: {stats['total_pages']}ê°œ")
    print(f"ğŸ§© ì´ ì²­í¬: {stats['total_chunks']}ê°œ")
    print()
    print("ğŸ“Š ê³¼ëª©ë³„ í†µê³„:")
    for course, course_stats in stats["by_course"].items():
        print(
            f"   â€¢ {course}: {course_stats['pdf_count']} PDFs â†’ {course_stats['chunk_count']} chunks"
        )
    print()

    return stats


def save_version_info_pdf(pdfs: list, all_chunks: list[dict], output_dir: Path) -> None:
    """
    ë²„ì „ ì •ë³´ë¥¼ _version.jsonì— ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        pdfs: ì²˜ë¦¬ëœ PDF ë¦¬ìŠ¤íŠ¸
        all_chunks: ìƒì„±ëœ ì²­í¬ ë¦¬ìŠ¤íŠ¸ (dict)
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
    """
    version_info = VersionInfo(
        total_chunks=len(all_chunks),
    )

    # ê° PDFì˜ ì²­í¬ ìˆ˜ ê³„ì‚°
    chunks_by_file: dict[str, int] = {}
    for chunk in all_chunks:
        source_file = chunk.get("metadata", {}).get("source_file", "")
        if source_file:
            file_name = Path(source_file).name
            chunks_by_file[file_name] = chunks_by_file.get(file_name, 0) + 1

    # ì›ë³¸ íŒŒì¼ ì •ë³´ ì¶”ê°€
    for pdf in pdfs:
        file_name = pdf.file_path.name
        chunk_count = chunks_by_file.get(file_name, 0)
        if chunk_count > 0:
            version_info.add_source_file(
                file_name=file_name,
                file_path=pdf.file_path,
                chunk_count=chunk_count,
            )

    # ì €ì¥
    version_file = output_dir / "_version.json"
    save_version_file(version_file, version_info)
    print(f"\nğŸ“ ë²„ì „ ì •ë³´ ì €ì¥: {version_file.name}")


def main():
    """ë©”ì¸ í•¨ìˆ˜."""
    parser = argparse.ArgumentParser(
        description="PDF ê°•ì˜ ìë£Œë¥¼ ì²­í‚¹í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    parser.add_argument(
        "--input-dir",
        type=Path,
        default=PROJECT_ROOT / "original_documents" / "lecture_content",
        help="PDF íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬",
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=PROJECT_ROOT / "document_chunks" / "pdf_chunks",
        help="ì²­í¬ ì €ì¥ ë””ë ‰í† ë¦¬",
    )
    parser.add_argument(
        "--chunk-size",
        type=int,
        default=1000,
        help="ì²­í¬ ìµœëŒ€ í† í° ìˆ˜ (ê¸°ë³¸: 1000)",
    )
    parser.add_argument(
        "--chunk-overlap",
        type=int,
        default=100,
        help="ì²­í¬ ê°„ ì˜¤ë²„ë© í† í° ìˆ˜ (ê¸°ë³¸: 100)",
    )
    parser.add_argument(
        "-q",
        "--quiet",
        action="store_true",
        help="ê°„ëµí•œ ì¶œë ¥",
    )
    parser.add_argument(
        "--recreate",
        action="store_true",
        help="ì „ì²´ ì¬ì²˜ë¦¬ (ê¸°ì¡´ ì²­í¬ ë¬´ì‹œ)",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="ë³€ê²½ì‚¬í•­ë§Œ í™•ì¸ (ì‹¤ì œ ì²˜ë¦¬ ì•ˆí•¨)",
    )

    args = parser.parse_args()

    # ì…ë ¥ ë””ë ‰í† ë¦¬ í™•ì¸
    if not args.input_dir.exists():
        print(f"âŒ ì…ë ¥ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {args.input_dir}")
        sys.exit(1)

    # ì²˜ë¦¬ ì‹¤í–‰
    process_all_pdfs(
        input_dir=args.input_dir,
        output_dir=args.output_dir,
        chunk_size=args.chunk_size,
        chunk_overlap=args.chunk_overlap,
        verbose=not args.quiet,
        incremental=not args.recreate,
        dry_run=args.dry_run,
    )


if __name__ == "__main__":
    main()
