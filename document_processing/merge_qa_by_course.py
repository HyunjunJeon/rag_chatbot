"""
ê³¼ì •ë³„ë¡œ ëª¨ë“  ê¸°ìˆ˜ì˜ Q&Aë¥¼ í•˜ë‚˜ì˜ JSON íŒŒì¼ë¡œ ë³‘í•©í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸.

ê° ê³¼ì •(level2_cv, level2_nlp ë“±)ë³„ë¡œ ëª¨ë“  ê¸°ìˆ˜ì˜ Q&Aë¥¼ ìˆ˜ì§‘í•˜ê³ ,
ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ í•˜ë‚˜ì˜ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
"""

import json
from collections import defaultdict
from datetime import datetime
from pathlib import Path
from typing import Any


def extract_date_from_filename(filename: str) -> str | None:
    """
    íŒŒì¼ëª…ì—ì„œ ë‚ ì§œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

    ë§¤ê°œë³€ìˆ˜:
        filename: íŒŒì¼ëª… (ì˜ˆ: "2021-09-06_qa.json")

    ë°˜í™˜ê°’:
        ë‚ ì§œ ë¬¸ìì—´ (ì˜ˆ: "2021-09-06") ë˜ëŠ” None
    """
    try:
        # _qa.json ì œê±°í•˜ê³  ë‚ ì§œ ë¶€ë¶„ë§Œ ì¶”ì¶œ
        date_str = filename.replace("_qa.json", "")
        # ë‚ ì§œ í˜•ì‹ ê²€ì¦
        datetime.strptime(date_str, "%Y-%m-%d")
        return date_str
    except ValueError:
        return None


def load_qa_file(file_path: Path) -> dict[str, Any]:
    """
    Q&A JSON íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.

    ë§¤ê°œë³€ìˆ˜:
        file_path: JSON íŒŒì¼ ê²½ë¡œ

    ë°˜í™˜ê°’:
        íŒŒì‹±ëœ JSON ë°ì´í„°
    """
    with open(file_path, encoding="utf-8") as f:
        return json.load(f)


def collect_qa_by_course(
    processed_dir: Path | str,
) -> dict[str, dict[str, Any]]:
    """
    ê³¼ì •ë³„ë¡œ ëª¨ë“  Q&Aë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

    ë§¤ê°œë³€ìˆ˜:
        processed_dir: ì²˜ë¦¬ëœ Q&A ë””ë ‰í† ë¦¬ ê²½ë¡œ

    ë°˜í™˜ê°’:
        ê³¼ì •ëª…ì„ í‚¤ë¡œ, Q&A ë°ì´í„°ì™€ ë©”íƒ€ë°ì´í„°ë¥¼ ê°’ìœ¼ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
    """
    processed_dir = Path(processed_dir)
    course_data: dict[str, dict[str, Any]] = defaultdict(
        lambda: {
            "qa_pairs": [],
            "generations": set(),
            "dates": [],
            "gen_stats": defaultdict(int),
            "source_files": [],
        }
    )

    print("=" * 80)
    print("ğŸ“š ê³¼ì •ë³„ Q&A ìˆ˜ì§‘ ì‹œì‘")
    print("=" * 80)

    # ê¸°ìˆ˜ë³„ ë””ë ‰í† ë¦¬ ìˆœíšŒ
    for gen_dir in sorted(processed_dir.iterdir()):
        if not gen_dir.is_dir():
            continue

        generation = gen_dir.name
        print(f"\nğŸ“ ê¸°ìˆ˜ {generation} ì²˜ë¦¬ ì¤‘...")

        # ê³¼ì •ë³„ ë””ë ‰í† ë¦¬ ìˆœíšŒ
        for course_dir in sorted(gen_dir.iterdir()):
            if not course_dir.is_dir():
                continue

            course_name = course_dir.name
            print(f"  ğŸ“‚ {course_name}")

            # JSON íŒŒì¼ ì²˜ë¦¬
            qa_files = sorted(course_dir.glob("*_qa.json"))
            file_count = 0

            for qa_file in qa_files:
                try:
                    data = load_qa_file(qa_file)
                    qa_pairs = data.get("qa_pairs", [])

                    if not qa_pairs:
                        continue

                    # ë‚ ì§œ ì¶”ì¶œ
                    date = extract_date_from_filename(qa_file.name)

                    # ê° Q&A ìŒì— ë©”íƒ€ë°ì´í„° ì¶”ê°€
                    for qa_pair in qa_pairs:
                        enriched_qa = {
                            "generation": generation,
                            "date": date,
                            "source_file": qa_file.name,
                            "course": course_name,
                            "question": qa_pair["question"],
                            "answers": qa_pair["answers"],
                        }
                        course_data[course_name]["qa_pairs"].append(enriched_qa)

                    # í†µê³„ ì—…ë°ì´íŠ¸
                    course_data[course_name]["generations"].add(generation)
                    if date:
                        course_data[course_name]["dates"].append(date)
                    course_data[course_name]["gen_stats"][generation] += len(qa_pairs)
                    course_data[course_name]["source_files"].append(
                        {
                            "generation": generation,
                            "filename": qa_file.name,
                            "qa_count": len(qa_pairs),
                        }
                    )

                    file_count += 1

                except Exception as e:
                    print(f"    âœ— {qa_file.name}: {e}")
                    continue

            if file_count > 0:
                print(f"    âœ“ {file_count}ê°œ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ")

    return dict(course_data)


def create_metadata(course_data: dict[str, Any]) -> dict[str, Any]:
    """
    ê³¼ì •ë³„ ë©”íƒ€ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    ë§¤ê°œë³€ìˆ˜:
        course_data: ìˆ˜ì§‘ëœ ê³¼ì • ë°ì´í„°

    ë°˜í™˜ê°’:
        ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬
    """
    qa_pairs = course_data["qa_pairs"]
    dates = sorted(course_data["dates"]) if course_data["dates"] else []

    metadata = {
        "total_qa_pairs": len(qa_pairs),
        "generations": sorted(course_data["generations"]),
        "generation_count": len(course_data["generations"]),
        "statistics": {
            "by_generation": dict(
                sorted(course_data["gen_stats"].items(), key=lambda x: x[0])
            )
        },
    }

    # ë‚ ì§œ ë²”ìœ„ ì¶”ê°€
    if dates:
        metadata["date_range"] = {"start": dates[0], "end": dates[-1]}

    # íŒŒì¼ í†µê³„ ì¶”ê°€
    metadata["source_files"] = {
        "count": len(course_data["source_files"]),
        "files": course_data["source_files"],
    }

    return metadata


def sort_qa_pairs(qa_pairs: list[dict[str, Any]]) -> list[dict[str, Any]]:
    """
    Q&A ìŒì„ ë‚ ì§œì™€ ê¸°ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬í•©ë‹ˆë‹¤.

    ë§¤ê°œë³€ìˆ˜:
        qa_pairs: Q&A ìŒ ë¦¬ìŠ¤íŠ¸

    ë°˜í™˜ê°’:
        ì •ë ¬ëœ Q&A ìŒ ë¦¬ìŠ¤íŠ¸
    """

    def sort_key(qa: dict[str, Any]) -> tuple:
        date = qa.get("date") or "9999-99-99"
        generation = qa.get("generation", "0")
        return (date, generation)

    return sorted(qa_pairs, key=sort_key)


def merge_qa_by_course(
    processed_dir: Path | str, output_dir: Path | str
) -> dict[str, int]:
    """
    ê³¼ì •ë³„ë¡œ Q&Aë¥¼ ë³‘í•©í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.

    ë§¤ê°œë³€ìˆ˜:
        processed_dir: ì²˜ë¦¬ëœ Q&A ë””ë ‰í† ë¦¬ ê²½ë¡œ
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ

    ë°˜í™˜ê°’:
        ê³¼ì •ëª…ê³¼ Q&A ê°œìˆ˜ë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬
    """
    processed_dir = Path(processed_dir)
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # ê³¼ì •ë³„ ë°ì´í„° ìˆ˜ì§‘
    course_data = collect_qa_by_course(processed_dir)

    print("\n" + "=" * 80)
    print("ğŸ’¾ ê³¼ì •ë³„ JSON íŒŒì¼ ìƒì„± ì¤‘...")
    print("=" * 80)

    stats: dict[str, int] = {}

    for course_name, data in sorted(course_data.items()):
        # Q&A ì •ë ¬
        sorted_qa = sort_qa_pairs(data["qa_pairs"])

        # ë©”íƒ€ë°ì´í„° ìƒì„±
        metadata = create_metadata(data)

        # ìµœì¢… ë°ì´í„° êµ¬ì¡°
        output_data = {
            "course": course_name,
            "metadata": metadata,
            "qa_pairs": sorted_qa,
        }

        # JSON íŒŒì¼ë¡œ ì €ì¥
        output_file = output_dir / f"{course_name}_merged.json"
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)

        qa_count = len(sorted_qa)
        stats[course_name] = qa_count

        print(f"\nâœ“ {course_name}_merged.json")
        print(f"  - Q&A ìŒ: {qa_count}ê°œ")
        print(f"  - ê¸°ìˆ˜: {metadata['generation_count']}ê°œ ({', '.join(metadata['generations'])})")
        if "date_range" in metadata:
            print(
                f"  - ê¸°ê°„: {metadata['date_range']['start']} ~ {metadata['date_range']['end']}"
            )
        print(f"  - íŒŒì¼ í¬ê¸°: {output_file.stat().st_size / 1024:.1f} KB")

    return stats


def generate_summary(stats: dict[str, int], output_dir: Path) -> None:
    """
    ì „ì²´ í†µê³„ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.

    ë§¤ê°œë³€ìˆ˜:
        stats: ê³¼ì •ë³„ Q&A ê°œìˆ˜
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
    """
    total_qa = sum(stats.values())
    total_courses = len(stats)

    summary = {
        "generated_at": datetime.now().isoformat(),
        "total_courses": total_courses,
        "total_qa_pairs": total_qa,
        "by_course": stats,
    }

    summary_file = output_dir / "_summary.json"
    with open(summary_file, "w", encoding="utf-8") as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)

    print("\n" + "=" * 80)
    print("ğŸ“Š ì „ì²´ í†µê³„")
    print("=" * 80)
    print(f"ì´ ê³¼ì • ìˆ˜: {total_courses}ê°œ")
    print(f"ì´ Q&A ìŒ: {total_qa}ê°œ")
    print(f"\nìš”ì•½ íŒŒì¼: {summary_file}")


def main() -> None:
    """ë©”ì¸ í•¨ìˆ˜."""
    # ê²½ë¡œ ì„¤ì •
    processed_dir = Path(
        "/Users/jhj/Desktop/personal/naver_connect_chatbot/document_chunks/slack_qa_processed"
    )
    output_dir = Path(
        "/Users/jhj/Desktop/personal/naver_connect_chatbot/document_chunks/slack_qa_merged"
    )

    print("\nğŸš€ ê³¼ì •ë³„ Q&A ë³‘í•© ì‹œì‘\n")
    print(f"ì…ë ¥: {processed_dir}")
    print(f"ì¶œë ¥: {output_dir}\n")

    # ë³‘í•© ì‹¤í–‰
    stats = merge_qa_by_course(processed_dir, output_dir)

    # ìš”ì•½ ìƒì„±
    generate_summary(stats, output_dir)

    print("\n" + "=" * 80)
    print("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
    print("=" * 80)


if __name__ == "__main__":
    main()

