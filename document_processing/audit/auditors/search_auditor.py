"""
ê²€ìƒ‰ ì„±ëŠ¥ ì ê²€ ëª¨ë“ˆ.

ì ê²€ ëŒ€ìƒ:
- BM25 ê²€ìƒ‰ ì„±ëŠ¥
- í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„±ëŠ¥ (ì„ íƒì )

ì ê²€ í•­ëª©:
- ìƒ˜í”Œ ì¿¼ë¦¬ ì‘ë‹µ ì‹œê°„
- ê²€ìƒ‰ ê²°ê³¼ ì¡´ì¬ ì—¬ë¶€
- ê²°ê³¼ ê°œìˆ˜ ì ì ˆì„±

ì£¼ì˜:
- ì´ ëª¨ë“ˆì€ ì‹¤ì œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ë¯€ë¡œ BM25 ì¸ë±ìŠ¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.
- ì „ì²´ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì€ Qdrant ì„œë²„ì™€ LLM APIê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì‚¬ìš© ì˜ˆ:
    ```python
    from document_processing.audit.auditors.search_auditor import SearchAuditor

    auditor = SearchAuditor(verbose=True)
    result = await auditor.audit()
    print(result.model_dump_json(indent=2))
    ```
"""

import logging
import time
from pathlib import Path
from typing import Any

from document_processing.audit.auditors.base import BaseAuditor
from document_processing.audit.models.audit_result import LayerResult, LayerStats, Severity

logger = logging.getLogger(__name__)


class SearchAuditor(BaseAuditor):
    """ê²€ìƒ‰ ì„±ëŠ¥ ì ê²€ê¸°."""

    layer_name = "search"

    # BM25 ì¸ë±ìŠ¤ ê²½ë¡œ
    BM25_INDEX_DIR = "sparse_index/unified_bm25"

    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ (ë‹¤ì–‘í•œ ìœ í˜•)
    TEST_QUERIES = [
        # ì¼ë°˜ ì§ˆë¬¸
        {"query": "PyTorch í…ì„œ ì—°ì‚°", "expected_doc_type": "lecture_transcript"},
        {"query": "Transformer ëª¨ë¸ êµ¬ì¡°", "expected_doc_type": "lecture_transcript"},
        {"query": "í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬", "expected_doc_type": "lecture_transcript"},
        # ì½”ë“œ ê´€ë ¨
        {"query": "loss function êµ¬í˜„", "expected_doc_type": "lecture_transcript"},
        {"query": "DataLoader ì‚¬ìš©ë²•", "expected_doc_type": "lecture_transcript"},
        # Slack Q&A ìŠ¤íƒ€ì¼
        {"query": "GPU ë©”ëª¨ë¦¬ ë¶€ì¡± í•´ê²°", "expected_doc_type": "slack_qa"},
        {"query": "ëª¨ë¸ ì €ì¥ ë°©ë²•", "expected_doc_type": "slack_qa"},
    ]

    # ì„±ëŠ¥ ì„ê³„ê°’
    MAX_SEARCH_TIME_MS = 1000  # 1ì´ˆ ì´ë‚´
    MIN_RESULTS = 1  # ìµœì†Œ 1ê°œ ê²°ê³¼

    async def audit(self) -> LayerResult:
        """ê²€ìƒ‰ ì„±ëŠ¥ ì ê²€ ì‹¤í–‰."""
        result = self.create_result()
        self.start_timer()

        stats_extra: dict[str, Any] = {
            "bm25_available": False,
            "queries_tested": 0,
            "queries_passed": 0,
            "avg_search_time_ms": 0,
            "query_results": [],
        }

        # BM25 ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        bm25_retriever = await self._load_bm25_retriever()

        if bm25_retriever is None:
            self.add_issue(
                severity=Severity.WARNING,
                category="search",
                message="BM25 ì¸ë±ìŠ¤ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ì–´ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤",
            )
            result.total_items = 0
            result.stats = LayerStats(extra=stats_extra)
            return self.finalize_result()

        stats_extra["bm25_available"] = True

        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì‹¤í–‰
        total_time_ms = 0
        passed = 0

        for test in self.TEST_QUERIES:
            query = test["query"]
            self.log_progress(
                stats_extra["queries_tested"] + 1,
                len(self.TEST_QUERIES),
                query[:30],
            )

            query_result = await self._test_search(bm25_retriever, query)
            stats_extra["query_results"].append(query_result)
            stats_extra["queries_tested"] += 1

            total_time_ms += query_result.get("time_ms", 0)

            if query_result.get("passed"):
                passed += 1
            else:
                self.add_issue(
                    severity=Severity.INFO,
                    category="search",
                    message=f"ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: '{query[:30]}...' - {query_result.get('reason')}",
                    details=query_result,
                )

        stats_extra["queries_passed"] = passed

        if stats_extra["queries_tested"] > 0:
            stats_extra["avg_search_time_ms"] = round(
                total_time_ms / stats_extra["queries_tested"], 2
            )

        # ì „ì²´ ì„±ëŠ¥ í‰ê°€
        if passed < len(self.TEST_QUERIES) * 0.7:  # 70% ë¯¸ë§Œ í†µê³¼ ì‹œ ê²½ê³ 
            self.add_issue(
                severity=Severity.WARNING,
                category="search",
                message=f"ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ í†µê³¼ìœ¨ ë‚®ìŒ: {passed}/{len(self.TEST_QUERIES)} ({passed / len(self.TEST_QUERIES) * 100:.1f}%)",
            )

        if stats_extra["avg_search_time_ms"] > self.MAX_SEARCH_TIME_MS:
            self.add_issue(
                severity=Severity.WARNING,
                category="performance",
                message=f"í‰ê·  ê²€ìƒ‰ ì‹œê°„ì´ ëŠë¦¼: {stats_extra['avg_search_time_ms']}ms (ì„ê³„ê°’: {self.MAX_SEARCH_TIME_MS}ms)",
            )

        # í†µê³„ ì—…ë°ì´íŠ¸
        result.total_items = len(self.TEST_QUERIES)
        result.stats = LayerStats(
            total_items=len(self.TEST_QUERIES),
            checked_items=stats_extra["queries_tested"],
            passed_items=passed,
            failed_items=stats_extra["queries_tested"] - passed,
            extra=stats_extra,
        )

        return self.finalize_result()

    async def _load_bm25_retriever(self) -> Any:
        """BM25 ê²€ìƒ‰ê¸° ë¡œë“œ."""
        import pickle

        index_dir = self.resolve_path(self.BM25_INDEX_DIR)
        index_file = index_dir / "bm25_index.pkl"

        if not index_file.exists():
            return None

        def load() -> Any:
            try:
                with open(index_file, "rb") as f:
                    data = pickle.load(f)

                # KiwiBM25Retriever í˜•ì‹ í™•ì¸
                if isinstance(data, dict):
                    return data
                return {"bm25": data, "docs": [], "doc_ids": []}

            except Exception as e:
                logger.warning(f"BM25 ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
                return None

        return await self.run_in_executor(load)

    async def _test_search(
        self,
        retriever_data: dict[str, Any],
        query: str,
    ) -> dict[str, Any]:
        """ê°œë³„ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤í–‰."""

        def search() -> dict[str, Any]:
            result: dict[str, Any] = {
                "query": query,
                "passed": False,
                "time_ms": 0,
                "num_results": 0,
                "reason": "",
            }

            try:
                bm25 = retriever_data.get("bm25")
                docs = retriever_data.get("docs", [])

                if bm25 is None:
                    result["reason"] = "BM25 ê°ì²´ ì—†ìŒ"
                    return result

                # Kiwi í† í¬ë‚˜ì´ì €ë¡œ ì¿¼ë¦¬ í† í°í™”
                try:
                    from kiwipiepy import Kiwi

                    kiwi = Kiwi()
                    tokens = [
                        token.form
                        for token in kiwi.tokenize(query)
                        if token.tag.startswith(("N", "V", "MA"))
                    ]
                except ImportError:
                    # Kiwi ì—†ìœ¼ë©´ ë‹¨ìˆœ ë¶„ë¦¬
                    tokens = query.split()

                if not tokens:
                    result["reason"] = "í† í°í™” ê²°ê³¼ ì—†ìŒ"
                    return result

                # ê²€ìƒ‰ ì‹¤í–‰
                start = time.perf_counter()
                scores = bm25.get_scores(tokens)
                elapsed_ms = (time.perf_counter() - start) * 1000

                result["time_ms"] = round(elapsed_ms, 2)

                # ìƒìœ„ ê²°ê³¼ ì¹´ìš´íŠ¸ (ì ìˆ˜ > 0)
                num_results = sum(1 for s in scores if s > 0)
                result["num_results"] = min(num_results, 10)  # ìƒìœ„ 10ê°œê¹Œì§€ë§Œ í‘œì‹œ

                # í‰ê°€
                if num_results >= self.MIN_RESULTS:
                    result["passed"] = True
                else:
                    result["reason"] = f"ê²°ê³¼ ë¶€ì¡± ({num_results}ê°œ)"

                if elapsed_ms > self.MAX_SEARCH_TIME_MS:
                    result["passed"] = False
                    result["reason"] = f"ê²€ìƒ‰ ì‹œê°„ ì´ˆê³¼ ({elapsed_ms:.0f}ms)"

            except Exception as e:
                result["reason"] = f"ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}"

            return result

        return await self.run_in_executor(search)


# =============================================================================
# CLI í…ŒìŠ¤íŠ¸
# =============================================================================

if __name__ == "__main__":
    import asyncio

    logging.basicConfig(level=logging.INFO)

    async def main():
        auditor = SearchAuditor(verbose=True)
        result = await auditor.audit()

        print("\n" + "=" * 60)
        print("ê²€ìƒ‰ ì„±ëŠ¥ ì ê²€ ê²°ê³¼")
        print("=" * 60)
        print(f"ìƒíƒœ: {result.status}")
        print(f"í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: {result.total_items}ê°œ")
        print(f"í†µê³¼: {result.stats.passed_items}ê°œ")
        print(f"í‰ê·  ê²€ìƒ‰ ì‹œê°„: {result.stats.extra.get('avg_search_time_ms', 0)}ms")
        print(f"ì†Œìš” ì‹œê°„: {result.duration_seconds:.2f}ì´ˆ")

        print("\nğŸ“Š ì¿¼ë¦¬ë³„ ê²°ê³¼:")
        for qr in result.stats.extra.get("query_results", []):
            status = "âœ“" if qr.get("passed") else "âœ—"
            print(
                f"  {status} '{qr['query'][:25]}...' "
                f"- {qr['num_results']}ê°œ ê²°ê³¼, {qr['time_ms']}ms"
            )

        if result.issues:
            print("\nâš ï¸ ë°œê²¬ëœ ì´ìŠˆ:")
            for issue in result.issues:
                print(f"  {issue}")

    asyncio.run(main())
