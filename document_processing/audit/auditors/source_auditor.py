"""
ì›ë³¸ ë°ì´í„° ì†ŒìŠ¤ ì ê²€ ëª¨ë“ˆ.

ì ê²€ ëŒ€ìƒ:
- PDF íŒŒì¼ (original_documents/lecture_content/)
- Slack Q&A JSON (original_documents/qa_dataset_from_slack/)
- ê°•ì˜ ë…¹ìŒ ì²­í¬ (document_chunks/lecture_transcript_chunks/)

ì ê²€ í•­ëª©:
- íŒŒì¼ ì¡´ì¬ ë° ì½ê¸° ê°€ëŠ¥ ì—¬ë¶€
- íŒŒì¼ í¬ê¸° ë° í˜ì´ì§€ ìˆ˜ í†µê³„
- ì†ìƒëœ íŒŒì¼ íƒì§€
- JSON íŒŒì‹± ë° í•„ìˆ˜ í•„ë“œ ê²€ì¦

ì‚¬ìš© ì˜ˆ:
    ```python
    from document_processing.audit.auditors.source_auditor import SourceAuditor

    auditor = SourceAuditor(verbose=True)
    result = await auditor.audit()
    print(result.model_dump_json(indent=2))
    ```
"""

import json
import logging
from pathlib import Path
from typing import Any

from document_processing.audit.auditors.base import BaseAuditor
from document_processing.audit.models.audit_result import LayerResult, LayerStats, Severity

logger = logging.getLogger(__name__)


class SourceAuditor(BaseAuditor):
    """ì›ë³¸ ë°ì´í„° ì†ŒìŠ¤ ì ê²€ê¸°."""

    layer_name = "sources"

    # ì ê²€ ëŒ€ìƒ ë””ë ‰í† ë¦¬ (base_path ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ)
    PDF_DIR = "original_documents/lecture_content"
    SLACK_QA_DIR = "original_documents/qa_dataset_from_slack"
    TRANSCRIPT_DIR = "document_chunks/lecture_transcript_chunks"

    # ê¸°ëŒ€í•˜ëŠ” ìµœì†Œ íŒŒì¼ ìˆ˜ (ì´ ìˆ˜ë³´ë‹¤ ì ìœ¼ë©´ ê²½ê³ )
    MIN_PDF_COUNT = 100
    MIN_SLACK_JSON_COUNT = 500
    MIN_TRANSCRIPT_COUNT = 50

    async def audit(self) -> LayerResult:
        """ì›ë³¸ ë°ì´í„° ì†ŒìŠ¤ ì ê²€ ì‹¤í–‰."""
        result = self.create_result()
        self.start_timer()

        stats_extra: dict[str, Any] = {}
        total_items = 0
        checked_items = 0
        passed_items = 0
        failed_items = 0

        # 1. PDF íŒŒì¼ ì ê²€
        pdf_stats = await self._audit_pdf_files()
        stats_extra["pdf"] = pdf_stats
        total_items += pdf_stats.get("total", 0)
        checked_items += pdf_stats.get("checked", 0)
        passed_items += pdf_stats.get("passed", 0)
        failed_items += pdf_stats.get("failed", 0)

        # 2. Slack Q&A JSON ì ê²€
        slack_stats = await self._audit_slack_json()
        stats_extra["slack_qa"] = slack_stats
        total_items += slack_stats.get("total", 0)
        checked_items += slack_stats.get("checked", 0)
        passed_items += slack_stats.get("passed", 0)
        failed_items += slack_stats.get("failed", 0)

        # 3. ê°•ì˜ ë…¹ìŒ ì²­í¬ ì ê²€
        transcript_stats = await self._audit_transcript_chunks()
        stats_extra["lecture_transcript"] = transcript_stats
        total_items += transcript_stats.get("total", 0)
        checked_items += transcript_stats.get("checked", 0)
        passed_items += transcript_stats.get("passed", 0)
        failed_items += transcript_stats.get("failed", 0)

        # í†µê³„ ì—…ë°ì´íŠ¸
        result.total_items = total_items
        result.stats = LayerStats(
            total_items=total_items,
            checked_items=checked_items,
            passed_items=passed_items,
            failed_items=failed_items,
            extra=stats_extra,
        )

        return self.finalize_result()

    async def _audit_pdf_files(self) -> dict[str, Any]:
        """PDF íŒŒì¼ ì ê²€."""
        pdf_dir = self.resolve_path(self.PDF_DIR)
        stats: dict[str, Any] = {
            "total": 0,
            "checked": 0,
            "passed": 0,
            "failed": 0,
            "total_size_bytes": 0,
            "by_course": {},
        }

        if not pdf_dir.exists():
            self.add_issue(
                severity=Severity.CRITICAL,
                category="directory",
                message=f"PDF ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {pdf_dir}",
            )
            return stats

        # PDF íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘
        pdf_files = list(pdf_dir.rglob("*.pdf"))
        stats["total"] = len(pdf_files)

        if len(pdf_files) < self.MIN_PDF_COUNT:
            self.add_issue(
                severity=Severity.WARNING,
                category="count",
                message=f"PDF íŒŒì¼ ìˆ˜ê°€ ì˜ˆìƒë³´ë‹¤ ì ìŠµë‹ˆë‹¤: {len(pdf_files)}ê°œ (ìµœì†Œ {self.MIN_PDF_COUNT}ê°œ ê¸°ëŒ€)",
            )

        # ê° PDF íŒŒì¼ ì ê²€
        for i, pdf_path in enumerate(pdf_files):
            self.log_progress(i + 1, len(pdf_files), pdf_path.name)

            stats["checked"] += 1

            # íŒŒì¼ í¬ê¸° í™•ì¸
            try:
                file_size = pdf_path.stat().st_size
                stats["total_size_bytes"] += file_size

                if file_size == 0:
                    self.add_issue(
                        severity=Severity.CRITICAL,
                        category="content",
                        message="ë¹ˆ PDF íŒŒì¼",
                        file_path=str(pdf_path),
                    )
                    stats["failed"] += 1
                    continue

                # ì½”ìŠ¤ë³„ í†µê³„
                course = pdf_path.parent.name
                if course not in stats["by_course"]:
                    stats["by_course"][course] = {"count": 0, "size_bytes": 0}
                stats["by_course"][course]["count"] += 1
                stats["by_course"][course]["size_bytes"] += file_size

                # PDF í—¤ë” ê²€ì¦ (ê°„ë‹¨í•œ ë¬´ê²°ì„± ì²´í¬)
                is_valid = await self._validate_pdf_header(pdf_path)
                if not is_valid:
                    self.add_issue(
                        severity=Severity.WARNING,
                        category="content",
                        message="ì†ìƒëœ PDF íŒŒì¼ (í—¤ë” ê²€ì¦ ì‹¤íŒ¨)",
                        file_path=str(pdf_path),
                    )
                    stats["failed"] += 1
                else:
                    stats["passed"] += 1

            except OSError as e:
                self.add_issue(
                    severity=Severity.CRITICAL,
                    category="access",
                    message=f"íŒŒì¼ ì ‘ê·¼ ì˜¤ë¥˜: {e}",
                    file_path=str(pdf_path),
                )
                stats["failed"] += 1

        stats["total_size_mb"] = round(stats["total_size_bytes"] / (1024 * 1024), 2)
        return stats

    async def _validate_pdf_header(self, pdf_path: Path) -> bool:
        """PDF íŒŒì¼ í—¤ë” ê²€ì¦ (ê°„ë‹¨í•œ ë¬´ê²°ì„± ì²´í¬)."""

        def check_header() -> bool:
            try:
                with open(pdf_path, "rb") as f:
                    header = f.read(8)
                    # PDF íŒŒì¼ì€ %PDF-ë¡œ ì‹œì‘
                    return header.startswith(b"%PDF-")
            except Exception:
                return False

        return await self.run_in_executor(check_header)

    async def _audit_slack_json(self) -> dict[str, Any]:
        """Slack Q&A JSON íŒŒì¼ ì ê²€."""
        slack_dir = self.resolve_path(self.SLACK_QA_DIR)
        stats: dict[str, Any] = {
            "total": 0,
            "checked": 0,
            "passed": 0,
            "failed": 0,
            "total_qa_pairs": 0,
            "by_course": {},
            "by_generation": {},
        }

        if not slack_dir.exists():
            self.add_issue(
                severity=Severity.CRITICAL,
                category="directory",
                message=f"Slack Q&A ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {slack_dir}",
            )
            return stats

        # JSON íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘
        json_files = list(slack_dir.rglob("*.json"))
        stats["total"] = len(json_files)

        if len(json_files) < self.MIN_SLACK_JSON_COUNT:
            self.add_issue(
                severity=Severity.WARNING,
                category="count",
                message=f"Slack JSON íŒŒì¼ ìˆ˜ê°€ ì˜ˆìƒë³´ë‹¤ ì ìŠµë‹ˆë‹¤: {len(json_files)}ê°œ (ìµœì†Œ {self.MIN_SLACK_JSON_COUNT}ê°œ ê¸°ëŒ€)",
            )

        # ê° JSON íŒŒì¼ ì ê²€
        for i, json_path in enumerate(json_files):
            self.log_progress(i + 1, len(json_files), json_path.name)

            stats["checked"] += 1

            validation_result = await self._validate_slack_json(json_path)
            if validation_result["valid"]:
                stats["passed"] += 1
                stats["total_qa_pairs"] += validation_result.get("qa_pairs", 0)

                # ì½”ìŠ¤ë³„/ê¸°ìˆ˜ë³„ í†µê³„
                course = validation_result.get("course", "unknown")
                generation = validation_result.get("generation", "unknown")

                stats["by_course"][course] = stats["by_course"].get(course, 0) + 1
                stats["by_generation"][generation] = stats["by_generation"].get(generation, 0) + 1
            else:
                stats["failed"] += 1
                self.add_issue(
                    severity=validation_result.get("severity", Severity.WARNING),
                    category="content",
                    message=validation_result.get("error", "Unknown error"),
                    file_path=str(json_path),
                )

        return stats

    async def _validate_slack_json(self, json_path: Path) -> dict[str, Any]:
        """Slack Q&A JSON íŒŒì¼ ê²€ì¦."""

        def validate() -> dict[str, Any]:
            try:
                with open(json_path, "r", encoding="utf-8") as f:
                    data = json.load(f)

                # ê¸°ë³¸ êµ¬ì¡° ê²€ì¦
                if not isinstance(data, dict):
                    return {
                        "valid": False,
                        "error": "JSONì´ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹˜",
                        "severity": Severity.WARNING,
                    }

                # í•„ìˆ˜ í•„ë“œ ê²€ì¦ (ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›)
                qa_pairs = 0

                # í˜•ì‹ 1: qa_pairs ë°°ì—´
                if "qa_pairs" in data:
                    qa_pairs = len(data["qa_pairs"])
                    for qa in data["qa_pairs"]:
                        if "question" not in qa:
                            return {
                                "valid": False,
                                "error": "Q&Aì— question í•„ë“œ ëˆ„ë½",
                                "severity": Severity.WARNING,
                            }

                # í˜•ì‹ 2: ì§ì ‘ question/answers
                elif "question" in data:
                    qa_pairs = 1

                # í˜•ì‹ 3: messages ë°°ì—´ (ì›ë³¸ Slack í˜•ì‹)
                elif "messages" in data:
                    qa_pairs = len(data.get("messages", []))

                # ì½”ìŠ¤ ë° ê¸°ìˆ˜ ì¶”ì¶œ (ê²½ë¡œì—ì„œ)
                parts = json_path.parts
                course = "unknown"
                generation = "unknown"

                for part in parts:
                    if part.startswith("level") or part in ["bot_common", "general"]:
                        course = part
                    elif part.isdigit():
                        generation = part

                return {
                    "valid": True,
                    "qa_pairs": qa_pairs,
                    "course": course,
                    "generation": generation,
                }

            except json.JSONDecodeError as e:
                return {
                    "valid": False,
                    "error": f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}",
                    "severity": Severity.CRITICAL,
                }
            except Exception as e:
                return {
                    "valid": False,
                    "error": f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}",
                    "severity": Severity.CRITICAL,
                }

        return await self.run_in_executor(validate)

    async def _audit_transcript_chunks(self) -> dict[str, Any]:
        """ê°•ì˜ ë…¹ìŒ ì²­í¬ íŒŒì¼ ì ê²€."""
        transcript_dir = self.resolve_path(self.TRANSCRIPT_DIR)
        stats: dict[str, Any] = {
            "total": 0,
            "checked": 0,
            "passed": 0,
            "failed": 0,
            "total_chunks": 0,
            "by_course": {},
        }

        if not transcript_dir.exists():
            self.add_issue(
                severity=Severity.WARNING,
                category="directory",
                message=f"ê°•ì˜ ë…¹ìŒ ì²­í¬ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {transcript_dir}",
            )
            return stats

        # JSON íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘
        json_files = list(transcript_dir.glob("*_chunks.json"))
        stats["total"] = len(json_files)

        if len(json_files) < self.MIN_TRANSCRIPT_COUNT:
            self.add_issue(
                severity=Severity.WARNING,
                category="count",
                message=f"ê°•ì˜ ë…¹ìŒ ì²­í¬ íŒŒì¼ ìˆ˜ê°€ ì˜ˆìƒë³´ë‹¤ ì ìŠµë‹ˆë‹¤: {len(json_files)}ê°œ (ìµœì†Œ {self.MIN_TRANSCRIPT_COUNT}ê°œ ê¸°ëŒ€)",
            )

        # ê° ì²­í¬ íŒŒì¼ ì ê²€
        for i, json_path in enumerate(json_files):
            self.log_progress(i + 1, len(json_files), json_path.name)

            stats["checked"] += 1

            validation_result = await self._validate_transcript_chunk(json_path)
            if validation_result["valid"]:
                stats["passed"] += 1
                stats["total_chunks"] += validation_result.get("chunk_count", 0)

                # ì½”ìŠ¤ë³„ í†µê³„ (íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ)
                course = self._extract_course_from_filename(json_path.stem)
                stats["by_course"][course] = stats["by_course"].get(course, 0) + 1
            else:
                stats["failed"] += 1
                self.add_issue(
                    severity=validation_result.get("severity", Severity.WARNING),
                    category="content",
                    message=validation_result.get("error", "Unknown error"),
                    file_path=str(json_path),
                )

        return stats

    async def _validate_transcript_chunk(self, json_path: Path) -> dict[str, Any]:
        """ê°•ì˜ ë…¹ìŒ ì²­í¬ íŒŒì¼ ê²€ì¦."""

        def validate() -> dict[str, Any]:
            try:
                with open(json_path, "r", encoding="utf-8") as f:
                    data = json.load(f)

                # ë°°ì—´ ë˜ëŠ” chunks í•„ë“œ í™•ì¸
                chunks = data if isinstance(data, list) else data.get("chunks", [])

                if not chunks:
                    return {
                        "valid": False,
                        "error": "ì²­í¬ê°€ ë¹„ì–´ìˆìŒ",
                        "severity": Severity.WARNING,
                    }

                # ì²­í¬ ë‚´ìš© ê²€ì¦
                for chunk in chunks[:5]:  # ì²˜ìŒ 5ê°œë§Œ ìƒ˜í”Œ ê²€ì¦
                    if isinstance(chunk, dict):
                        if not chunk.get("page_content") and not chunk.get("content"):
                            return {
                                "valid": False,
                                "error": "ì²­í¬ì— ì½˜í…ì¸ ê°€ ì—†ìŒ",
                                "severity": Severity.WARNING,
                            }

                return {
                    "valid": True,
                    "chunk_count": len(chunks),
                }

            except json.JSONDecodeError as e:
                return {
                    "valid": False,
                    "error": f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}",
                    "severity": Severity.CRITICAL,
                }
            except Exception as e:
                return {
                    "valid": False,
                    "error": f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}",
                    "severity": Severity.CRITICAL,
                }

        return await self.run_in_executor(validate)

    def _extract_course_from_filename(self, filename: str) -> str:
        """íŒŒì¼ëª…ì—ì„œ ì½”ìŠ¤ëª… ì¶”ì¶œ."""
        # ì˜ˆ: "[NLP ì´ë¡ ] (8ê°•) Transformer 2_chunks" -> "NLP ì´ë¡ "
        if filename.startswith("["):
            end_bracket = filename.find("]")
            if end_bracket > 0:
                return filename[1:end_bracket]

        # ì˜ˆ: "(1ê°•) PyTorch Intro_chunks" -> "general"
        return "general"


# =============================================================================
# CLI í…ŒìŠ¤íŠ¸
# =============================================================================

if __name__ == "__main__":
    import asyncio

    logging.basicConfig(level=logging.INFO)

    async def main():
        auditor = SourceAuditor(verbose=True)
        result = await auditor.audit()

        print("\n" + "=" * 60)
        print("ì›ë³¸ ë°ì´í„° ì†ŒìŠ¤ ì ê²€ ê²°ê³¼")
        print("=" * 60)
        print(f"ìƒíƒœ: {result.status}")
        print(f"ì „ì²´ í•­ëª©: {result.total_items}")
        print(f"ì´ìŠˆ: {len(result.issues)}ê°œ")
        print(f"ì†Œìš” ì‹œê°„: {result.duration_seconds:.2f}ì´ˆ")

        print("\nğŸ“Š í†µê³„:")
        for key, value in result.stats.extra.items():
            print(f"  {key}: {value}")

        if result.issues:
            print("\nâš ï¸ ë°œê²¬ëœ ì´ìŠˆ:")
            for issue in result.issues[:10]:  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥
                print(f"  {issue}")

    asyncio.run(main())
