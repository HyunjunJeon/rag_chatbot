# ğŸ““ Notebook Processing Module

Jupyter Notebook (.ipynb) íŒŒì¼ì—ì„œ RAG ì‹œìŠ¤í…œì„ ìœ„í•œ ì˜ë¯¸ìˆëŠ” ì²­í¬ë¥¼ ì¶”ì¶œí•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.

## ê°œìš”

ì´ ëª¨ë“ˆì€ `practice/` ë° `home_work/` í´ë”ì˜ ë…¸íŠ¸ë¶ íŒŒì¼ì„ ë¶„ì„í•˜ì—¬:
- âœ… ë§ˆí¬ë‹¤ìš´ ì…€ì—ì„œ ê°œë… ì„¤ëª… ì¶”ì¶œ
- âœ… ì½”ë“œ ì…€ì—ì„œ êµ¬í˜„ ì˜ˆì‹œ ì¶”ì¶œ (ì •ë‹µ íŒŒì¼ë§Œ)
- âœ… ì„¹ì…˜ ë‹¨ìœ„ ì²­í‚¹ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€
- âœ… ë©”íƒ€ë°ì´í„° ìë™ ì¶”ì¶œ (ê³¼ëª©, ì£¼ì œ, ë‚œì´ë„)

## ëª¨ë“ˆ êµ¬ì¡°

```
notebooks/
â”œâ”€â”€ __init__.py              # íŒ¨í‚¤ì§€ ì´ˆê¸°í™”
â”œâ”€â”€ notebook_loader.py       # NotebookLoader í´ë˜ìŠ¤
â”œâ”€â”€ notebook_chunker.py      # NotebookChunker í´ë˜ìŠ¤
â”œâ”€â”€ process_all_notebooks.py # ì¼ê´„ ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ README.md                # ì´ ë¬¸ì„œ
```

## ë¹ ë¥¸ ì‹œì‘

### 1. ë‹¨ì¼ ë…¸íŠ¸ë¶ ì²˜ë¦¬

```python
from document_processing.notebooks import NotebookLoader, NotebookChunker

# ë¡œë”ì™€ ì²­ì»¤ ì´ˆê¸°í™”
loader = NotebookLoader()
chunker = NotebookChunker(max_tokens=500)

# ë…¸íŠ¸ë¶ ë¡œë“œ
notebook = loader.load_from_file("path/to/notebook.ipynb")

print(f"ê³¼ëª©: {notebook.course}")
print(f"ì£¼ì œ: {notebook.topic}")
print(f"íƒ€ì…: {notebook.file_type.value}")

# ì²­í‚¹
chunks = chunker.chunk_notebook(notebook)

for chunk in chunks:
    print(f"[{chunk.id}] {chunk.content[:100]}...")
```

### 2. ì „ì²´ ë°ì´í„°ì…‹ ì²˜ë¦¬

```bash
cd document_processing/notebooks
python process_all_notebooks.py
```

### 3. ë¬¸ì œ íŒŒì¼ ì½”ë“œë„ í¬í•¨

```bash
python process_all_notebooks.py --include-problems
```

## í´ë˜ìŠ¤ ì„¤ëª…

### NotebookLoader

ë…¸íŠ¸ë¶ íŒŒì¼ì„ ë¡œë“œí•˜ê³  íŒŒì‹±í•©ë‹ˆë‹¤.

```python
loader = NotebookLoader()

# ë‹¨ì¼ íŒŒì¼
notebook = loader.load_from_file("notebook.ipynb")

# ë””ë ‰í† ë¦¬ ì „ì²´ (ì¬ê·€)
notebooks = loader.load_from_directory("path/to/dir", recursive=True)

# ì •ë‹µ íŒŒì¼ë§Œ
notebooks = loader.load_from_directory("path/to/dir", solution_only=True)
```

#### ParsedNotebook ì†ì„±

| ì†ì„± | íƒ€ì… | ì„¤ëª… |
|------|------|------|
| `file_path` | Path | íŒŒì¼ ê²½ë¡œ |
| `cells` | list[NotebookCell] | íŒŒì‹±ëœ ì…€ ë¦¬ìŠ¤íŠ¸ |
| `file_type` | FileType | ë¬¸ì œ/ì •ë‹µ/ì•Œìˆ˜ì—†ìŒ |
| `difficulty` | Difficulty | ê¸°ë³¸/ì‹¬í™”/ì•Œìˆ˜ì—†ìŒ |
| `course` | str | ê³¼ëª©ëª… (ì˜ˆ: "PyTorch") |
| `topic` | str | ì£¼ì œëª… (ì˜ˆ: "Linear Regression") |

### NotebookChunker

ë…¸íŠ¸ë¶ì„ RAGìš© ì²­í¬ë¡œ ë¶„í• í•©ë‹ˆë‹¤.

```python
chunker = NotebookChunker(
    max_tokens=500,      # ì²­í¬ ìµœëŒ€ í† í° ìˆ˜
    min_tokens=50,       # ì²­í¬ ìµœì†Œ í† í° ìˆ˜
    include_outputs=True, # ì½”ë“œ ì¶œë ¥ í¬í•¨
    max_output_lines=30,  # ì¶œë ¥ ìµœëŒ€ ë¼ì¸ ìˆ˜
    solution_only=True,   # ì •ë‹µ íŒŒì¼ë§Œ ì½”ë“œ í¬í•¨
)

chunks = chunker.chunk_notebook(notebook)

# ì—¬ëŸ¬ ë…¸íŠ¸ë¶ ì¼ê´„ ì²˜ë¦¬
all_chunks = chunker.chunk_notebooks(notebooks)
```

#### NotebookChunk ì†ì„±

| ì†ì„± | íƒ€ì… | ì„¤ëª… |
|------|------|------|
| `id` | str | ê³ ìœ  ì‹ë³„ì |
| `content` | str | ì²­í¬ ë‚´ìš© |
| `metadata` | dict | ë©”íƒ€ë°ì´í„° |
| `token_estimate` | int | ì¶”ì • í† í° ìˆ˜ |

## ì²­í‚¹ ì „ëµ

### 1. ì„¹ì…˜ ê¸°ë°˜ ë¶„í• 

H1, H2, H3 í—¤ë”©ì„ ê¸°ì¤€ìœ¼ë¡œ ë…¸íŠ¸ë¶ì„ ì„¹ì…˜ìœ¼ë¡œ ë¶„í• í•©ë‹ˆë‹¤.

```
## 1. ë°ì´í„° ë¡œë“œ        â† ìƒˆ ì„¹ì…˜ ì‹œì‘
ì„¤ëª… ë§ˆí¬ë‹¤ìš´...
ì½”ë“œ ì…€...

## 2. ëª¨ë¸ ì •ì˜          â† ìƒˆ ì„¹ì…˜ ì‹œì‘
ì„¤ëª… ë§ˆí¬ë‹¤ìš´...
ì½”ë“œ ì…€...
```

### 2. ì…€ ê·¸ë£¹í™”

ê´€ë ¨ëœ ë§ˆí¬ë‹¤ìš´, ì½”ë“œ, ì¶œë ¥ì„ í•˜ë‚˜ì˜ ì²­í¬ë¡œ ë¬¶ìŠµë‹ˆë‹¤.

```
ì²­í¬ 1:
â”œâ”€â”€ [Markdown] ì„¹ì…˜ ì œëª© + ì„¤ëª…
â”œâ”€â”€ [Code] ê´€ë ¨ ì½”ë“œ
â””â”€â”€ [Output] ì‹¤í–‰ ê²°ê³¼ (ì„ íƒ)
```

### 3. í† í° ì œí•œ

`max_tokens`ë¥¼ ì´ˆê³¼í•˜ë©´ ì²­í¬ë¥¼ ë¶„í• í•©ë‹ˆë‹¤.

### 4. ì½”ë“œ í•„í„°ë§

ë¬¸ì œ íŒŒì¼ì˜ ë¹ˆ ì½”ë“œëŠ” ì œì™¸í•©ë‹ˆë‹¤:
- `# TODO: ì½”ë“œ ì‘ì„±`
- `pass`
- `...`
- importë§Œ ìˆëŠ” ì…€

## ì¶œë ¥ í˜•ì‹

### ì²­í¬ JSON

```json
{
  "id": "pytorch_linear_regression_s01_c00_abc123",
  "content": "## Linear Regression\n\nì„ í˜• íšŒê·€ ëª¨ë¸ì„...\n\n```python\nclass Model...",
  "metadata": {
    "source_file": "practice/01. AI Core/01. PyTorch/.../ì •ë‹µ.ipynb",
    "course": "PyTorch",
    "topic": "Linear Regression",
    "difficulty": "ê¸°ë³¸",
    "file_type": "ì •ë‹µ",
    "section_idx": 1,
    "chunk_idx": 0,
    "cell_range": [3, 7],
    "cell_types": ["markdown", "code"],
    "title": "PyTorch ê¸°ì´ˆ ì‹¤ìŠµ"
  },
  "token_estimate": 320
}
```

### ì¶œë ¥ ë””ë ‰í† ë¦¬

```
document_chunks/notebook_chunks/
â”œâ”€â”€ _summary.json              # ì „ì²´ í†µê³„
â”œâ”€â”€ all_notebook_chunks.json   # ì „ì²´ ì²­í¬
â”œâ”€â”€ PyTorch_chunks.json        # ê³¼ëª©ë³„ ì²­í¬
â”œâ”€â”€ AI_Math_chunks.json
â”œâ”€â”€ ML_LifeCycle_chunks.json
â””â”€â”€ MRC_chunks.json
```

## ë©”íƒ€ë°ì´í„° ì¶”ì¶œ

### íŒŒì¼ëª… íŒ¨í„´

| íŒ¨í„´ | ì˜ë¯¸ |
|------|------|
| `(ì •ë‹µ)`, `_ì •ë‹µ`, `(í•´ì„¤)` | ì •ë‹µ íŒŒì¼ |
| `(ë¬¸ì œ)`, `_ë¬¸ì œ` | ë¬¸ì œ íŒŒì¼ |
| `(ê¸°ë³¸-`, `ê¸°ë³¸_` | ê¸°ë³¸ ë‚œì´ë„ |
| `(ì‹¬í™”-`, `ì‹¬í™”_` | ì‹¬í™” ë‚œì´ë„ |

### ê²½ë¡œ ê¸°ë°˜ ì¶”ì¶œ

```
practice/01. AI Core/01. PyTorch/(ê¸°ë³¸-2) Linear Regression/(ì •ë‹µ).ipynb
         â†“          â†“                    â†“                      â†“
       (ë¬´ì‹œ)     ê³¼ëª©ëª…              ì£¼ì œëª…                 íŒŒì¼íƒ€ì…
```

## ì²˜ë¦¬ ëŒ€ìƒ

### practice/ (ì‹¤ìŠµ ìë£Œ)

| ê³¼ëª© | íŒŒì¼ ìˆ˜ | ë‚´ìš© |
|------|--------|------|
| PyTorch | 8ê°œ | Tensor, Linear Regression, Classification |
| AI Math | 6ê°œ | í–‰ë ¬, einsum, í™•ë¥ ë¡  |
| ML LifeCycle | 6ê°œ | NumPy, Back Propagation, Self-Attention |

### home_work/ (ê³¼ì œ)

| ê³¼ëª© | íŒŒì¼ ìˆ˜ | ë‚´ìš© |
|------|--------|------|
| AI ê°œë°œ ê¸°ì´ˆ | 1ê°œ | Shell script (ë¡œê·¸ ì²˜ë¦¬) |
| MRC | 10ê°œ | KorQuAD, TF-IDF, Dense Retrieval, FAISS |

## ë‹¤ìŒ ë‹¨ê³„

ì²­í¬ê°€ ìƒì„±ë˜ë©´ ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ì„ í™œìš©í•˜ì—¬:

1. **BM25 ì¸ë±ìŠ¤ ìƒì„±**
   ```bash
   python rebuild_bm25_for_chatbot.py --input-dir document_chunks/notebook_chunks
   ```

2. **Qdrant ì ì¬**
   ```bash
   python ingest_to_vectordb.py --input-dir document_chunks/notebook_chunks
   ```

## ê´€ë ¨ ë¬¸ì„œ

- [ì „ì²´ ì²˜ë¦¬ ê³„íš](../PROCESSING_PLAN.md)
- [Slack Q&A ì²˜ë¦¬](../README.md)
- [VectorDB ê°€ì´ë“œ](../VECTORDB_USAGE.md)
