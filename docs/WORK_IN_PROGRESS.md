# Pre-Retriever ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ ê¸°ëŠ¥ - ì‘ì—… ì§„í–‰ ìƒí™©

> ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: 2025-12-09

## ì™„ë£Œëœ ì‘ì—…

### 1. VectorDB Payload ì¸ë±ìŠ¤ ìƒì„± âœ…
- `scripts/create_payload_indexes.py` ìƒì„±
- ìƒì„±ëœ ì¸ë±ìŠ¤:
  - `course` (Tenant Index, is_tenant=true)
  - `doc_type`
  - `difficulty`
  - `instructor`
  - `file_type`
  - `topic`

### 2. Pre-Retriever ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ êµ¬í˜„ âœ…
- `app/naver_connect_chatbot/rag/schema_registry.py` ìƒì„±
- ì„œë²„ ì‹œì‘ ì‹œ VectorDBì—ì„œ ë°ì´í„° ë¶„í¬ ìë™ ë¡œë“œ
- Query Analyzer í”„ë¡¬í”„íŠ¸ì— ì‹¤ì œ ë°ì´í„° ì†ŒìŠ¤ ì •ë³´ ì£¼ì…

### 3. ì• ë§¤í•œ ì§ˆì˜ ì²˜ë¦¬ ê¸°ëŠ¥ êµ¬í˜„ âœ… (2025-12-09)

#### Priority 1: `course` ë‹¤ì¤‘ê°’ ì§€ì›
- `course` í•„ë“œë¥¼ `str` â†’ `list[str]`ë¡œ ë³€ê²½
- OR ì¡°ê±´ í•„í„°ë§ ì§€ì› (ì˜ˆ: `["CV ì´ë¡ ", "level2_cv"]`)
- í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€ (str ì…ë ¥ ì‹œ listë¡œ ìë™ ë³€í™˜)

#### Priority 2: Alias ë§¤í•‘ (VectorDB ê¸°ë°˜ ë™ì  ìƒì„±)
- `KEYWORD_PATTERNS` ì •ì˜: CV, NLP, RecSys, MRC, PyTorch ë“± 10ê°œ í‚¤ì›Œë“œ
- `_build_course_aliases()`: VectorDB ê³¼ì • ëª©ë¡ì—ì„œ ìë™ alias ìƒì„±
- `resolve_course_aliases()`: í‚¤ì›Œë“œ â†’ ì‹¤ì œ ê³¼ì • ì´ë¦„ ëª©ë¡ ë³€í™˜
- `get_alias_context_for_prompt()`: LLM í”„ë¡¬í”„íŠ¸ì— alias ì •ë³´ ì£¼ì…

#### Priority 3: Fuzzy Matching
- `find_matching_courses()`: difflib.SequenceMatcher ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰
- `resolve_course_with_fuzzy()`: Alias + Fuzzy ê²°í•© í•´ì„
- ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹˜ ì‹œ ìœ ì‚¬ë„ ë³´ë„ˆìŠ¤ ì ìš© (0.8)

#### Priority 4: Clarification
- `filter_confidence` í•„ë“œ ì¶”ê°€ (0.0 ~ 1.0)
- `clarify_node`: ì‹ ë¢°ë„ ë‚®ì„ ë•Œ ì‚¬ìš©ìì—ê²Œ ì„ íƒì§€ ì œì‹œ
- `should_clarify()` ë¼ìš°íŒ… í•¨ìˆ˜
- `enable_clarification`, `clarification_threshold` ì„¤ì • ì¶”ê°€

### ìˆ˜ì •ëœ íŒŒì¼
| íŒŒì¼ | ë³€ê²½ ë‚´ìš© |
|------|----------|
| `rag/schema_registry.py` | ì‹ ê·œ - ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ + Alias/Fuzzy ë§¤í•‘ |
| `rag/__init__.py` | schema_registry export ì¶”ê°€ |
| `server.py` | lifespanì— ìŠ¤í‚¤ë§ˆ ë¡œë“œ ì¶”ê°€ |
| `prompts/templates/query_analysis.yaml` | v5.1 - ë‹¤ì¤‘ course, alias ê°€ì´ë“œ |
| `service/agents/query_analyzer.py` | course: list[str], filter_confidence ì¶”ê°€ |
| `service/graph/types.py` | course: list[str] ë³€ê²½ |
| `service/graph/state.py` | filter_confidence í•„ë“œ ì¶”ê°€ |
| `service/graph/nodes.py` | alias context ì£¼ì…, fuzzy í›„ì²˜ë¦¬, clarify_node |
| `service/graph/workflow.py` | clarify ë…¸ë“œ ë° ì¡°ê±´ë¶€ ë¼ìš°íŒ… |
| `service/tool/retrieval_tool.py` | course OR ì¡°ê±´ í•„í„°ë§, TYPE_CHECKING |
| `config/settings/rag_settings.py` | enable_clarification ì„¤ì • ì¶”ê°€ |

---

## ì‚¬ìš© ë°©ë²•

### Clarification ê¸°ëŠ¥ í™œì„±í™”

```python
# ì›Œí¬í”Œë¡œìš° ë¹Œë“œ ì‹œ
graph = build_adaptive_rag_graph(
    retriever=retriever,
    llm=llm,
    enable_clarification=True,  # ê¸°ë³¸ê°’: False
    clarification_threshold=0.5,  # ê¸°ë³¸ê°’: 0.5
)
```

ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜:
```bash
ADAPTIVE_RAG_ENABLE_CLARIFICATION=true
ADAPTIVE_RAG_CLARIFICATION_THRESHOLD=0.5
```

### KEYWORD_PATTERNS í™•ì¥

```python
# schema_registry.pyì—ì„œ ìˆ˜ì •
KEYWORD_PATTERNS = {
    "CV": ["CV", "cv", "Computer Vision", "ì»´í“¨í„°ë¹„ì „"],
    # ìƒˆ í‚¤ì›Œë“œ ì¶”ê°€...
}
```

---

## ì™„ë£Œë¨ (ì´ì „ "ë‹¤ìŒ ì‘ì—…" ì„¹ì…˜)

### ë¬¸ì œ ìƒí™©

ì‚¬ìš©ì ì§ˆì˜ê°€ ì• ë§¤í•œ ê²½ìš° ì •í™•í•œ í•„í„° ì¶”ì¶œì´ ì–´ë ¤ì›€:

```
ì˜ˆì‹œ 1: "CV ê´€ë ¨ ì§ˆë¬¸"
- doc_type ë¶ˆëª…í™•: pdf? slack_qa? lecture_transcript?

ì˜ˆì‹œ 2: "ì¶”ì²œì‹œìŠ¤í…œ ê°•ì˜"
- course ë§¤ì¹­ ì–´ë ¤ì›€:
  - "RecSys" (lecture_transcript)
  - "RecSys ì´ë¡ " (lecture_transcript)
  - "level2_recsys" (slack_qa)
  - "MLforRecSys" (pdf, lecture_transcript)
  - "RecSys ê¸°ì´ˆ í”„ë¡œì íŠ¸" (pdf)

ì˜ˆì‹œ 3: "ê°•ì˜ ë‚´ìš©ì—ì„œ Transformer"
- pdf (ìŠ¬ë¼ì´ë“œ)? lecture_transcript (ë…¹ì·¨ë¡)?
```

### í•´ê²° ë°©ì•ˆ í›„ë³´

#### ë°©ì•ˆ 1: Fuzzy Course Matching
```python
# schema_registry.pyì— ì¶”ê°€
def find_matching_courses(self, query: str, threshold: float = 0.6) -> list[str]:
    """ì‚¬ìš©ì ì…ë ¥ê³¼ ìœ ì‚¬í•œ course ì´ë¦„ë“¤ì„ ë°˜í™˜"""
    from difflib import SequenceMatcher

    matches = []
    for ds in self._schema.data_sources:
        for course in ds.courses:
            ratio = SequenceMatcher(None, query.lower(), course.name.lower()).ratio()
            if ratio >= threshold:
                matches.append({
                    "course": course.name,
                    "doc_type": ds.doc_type,
                    "similarity": ratio,
                    "count": course.count
                })
    return sorted(matches, key=lambda x: -x["similarity"])
```

#### ë°©ì•ˆ 2: Multi-Source Retrieval
```python
# retrieval_filtersì—ì„œ ì—¬ëŸ¬ doc_type/course ì§€ì›
retrieval_filters = {
    "doc_type": ["pdf", "lecture_transcript"],  # ì• ë§¤í•˜ë©´ ì—¬ëŸ¬ ì†ŒìŠ¤
    "course": ["RecSys ì´ë¡ ", "level2_recsys", "MLforRecSys"]  # OR ì¡°ê±´
}
```

#### ë°©ì•ˆ 3: í”„ë¡¬í”„íŠ¸ì— ì• ë§¤í•¨ ì²˜ë¦¬ ê°€ì´ë“œ ì¶”ê°€
```yaml
# query_analysis.yamlì— ì¶”ê°€
### Handling Ambiguous Queries:
- If doc_type is unclear, include multiple relevant types: ["pdf", "lecture_transcript"]
- If course name is ambiguous, include all matching variants
- Example: "RecSys ê°•ì˜" â†’ course: ["RecSys ì´ë¡ ", "MLforRecSys", "RecSys ê¸°ì´ˆ í”„ë¡œì íŠ¸"]
```

#### ë°©ì•ˆ 4: Course Alias ë§¤í•‘ í…Œì´ë¸”
```python
COURSE_ALIASES = {
    "CV": ["CV ì´ë¡ ", "level2_cv", "Computer Vision"],
    "NLP": ["NLP", "NLP ì´ë¡ ", "level2_nlp"],
    "RecSys": ["RecSys", "RecSys ì´ë¡ ", "level2_recsys", "MLforRecSys"],
    "ì¶”ì²œì‹œìŠ¤í…œ": ["RecSys", "RecSys ì´ë¡ ", "level2_recsys", "MLforRecSys"],
    ...
}
```

### ê¶Œì¥ êµ¬í˜„ ìˆœì„œ

1. **ì¦‰ì‹œ ì ìš© (í”„ë¡¬í”„íŠ¸ ê°œì„ )**
   - query_analysis.yamlì— ì• ë§¤í•¨ ì²˜ë¦¬ ê°€ì´ë“œ ì¶”ê°€
   - ì—¬ëŸ¬ doc_type/courseë¥¼ ë°°ì—´ë¡œ ë°˜í™˜í•˜ë„ë¡ ê¶Œì¥

2. **ë‹¨ê¸° (Alias ë§¤í•‘)**
   - ìì£¼ ì‚¬ìš©ë˜ëŠ” í‚¤ì›Œë“œ â†’ ì‹¤ì œ course ë§¤í•‘ í…Œì´ë¸”
   - schema_registryì— alias ì¡°íšŒ ê¸°ëŠ¥ ì¶”ê°€

3. **ì¤‘ê¸° (Fuzzy Matching)**
   - ì‚¬ìš©ì ì…ë ¥ê³¼ ìœ ì‚¬í•œ course ìë™ íƒìƒ‰
   - ìœ ì‚¬ë„ ê¸°ë°˜ ë‹¤ì¤‘ ë§¤ì¹­

4. **ì¥ê¸° (Clarification)**
   - í™•ì‹ ë„ ë‚®ìœ¼ë©´ ì‚¬ìš©ìì—ê²Œ ì„ íƒì§€ ì œê³µ
   - "ì–´ë–¤ ìë£Œì—ì„œ ì°¾ì„ê¹Œìš”? [ê°•ì˜ìë£Œ] [ì‹¤ìŠµë…¸íŠ¸ë¶] [ìŠ¬ë™Q&A]"

---

## í˜„ì¬ VectorDB ë°ì´í„° ë¶„í¬

```
ğŸ“Š ì´ ë¬¸ì„œ: ~15,950ê°œ (ì „ì²´), 10,000ê°œ (ìƒ˜í”Œ)

doc_typeë³„ ë¶„í¬:
â”œâ”€â”€ pdf (3,287ê°œ, 32.9%)
â”‚   â””â”€â”€ top courses: Semantic Seg(1127), CV ì´ë¡ (255), Object Det(192)...
â”œâ”€â”€ notebook (2,987ê°œ, 29.9%)
â”‚   â””â”€â”€ courses: AI Core(2083), AI Production(875), MRC(29)
â”œâ”€â”€ lecture_transcript (1,804ê°œ, 18.0%)
â”‚   â””â”€â”€ top courses: NLP(313), MLforRecSys(228), AI Math(192)...
â”œâ”€â”€ slack_qa (1,773ê°œ, 17.7%)
â”‚   â””â”€â”€ top courses: level2_cv(436), level3_common(330), core_common(273)...
â””â”€â”€ weekly_mission (149ê°œ, 1.5%)
    â””â”€â”€ top courses: MRC(22), RecSys ê¸°ì´ˆ í”„ë¡œì íŠ¸(17), Object Detection(17)...
```

---

## í…ŒìŠ¤íŠ¸ ë°©ë²•

### ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ í…ŒìŠ¤íŠ¸
```bash
uv run python3 -c "
from naver_connect_chatbot.rag.schema_registry import SchemaRegistry, get_data_source_context
from qdrant_client import QdrantClient

client = QdrantClient(url='http://localhost:6333')
registry = SchemaRegistry.get_instance()
schema = registry.load_from_qdrant(client, 'naver_connect_docs')

print(get_data_source_context(max_courses=5))
"
```

### ì„œë²„ ì‹œì‘ í…ŒìŠ¤íŠ¸
```bash
python -m naver_connect_chatbot.server
# ë¡œê·¸ì—ì„œ "VectorDB ìŠ¤í‚¤ë§ˆ ë¡œë“œ ì™„ë£Œ" í™•ì¸
```

---

## ê´€ë ¨ íŒŒì¼ ê²½ë¡œ

```
app/naver_connect_chatbot/
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ __init__.py                    # schema_registry export
â”‚   â””â”€â”€ schema_registry.py             # ìŠ¤í‚¤ë§ˆ ë ˆì§€ìŠ¤íŠ¸ë¦¬ (ì‹ ê·œ)
â”œâ”€â”€ prompts/templates/
â”‚   â””â”€â”€ query_analysis.yaml            # v5.0 - ë™ì  ë°ì´í„° ì†ŒìŠ¤
â”œâ”€â”€ service/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â””â”€â”€ query_analyzer.py          # data_source_context íŒŒë¼ë¯¸í„°
â”‚   â””â”€â”€ graph/
â”‚       â””â”€â”€ nodes.py                   # analyze_query_node ìŠ¤í‚¤ë§ˆ ì£¼ì…
â””â”€â”€ server.py                          # lifespan ìŠ¤í‚¤ë§ˆ ë¡œë“œ

scripts/
â””â”€â”€ create_payload_indexes.py          # Qdrant ì¸ë±ìŠ¤ ìƒì„±
```

---

## ì°¸ê³  ìë£Œ

- [Qdrant Filtering Guide](https://qdrant.tech/articles/vector-search-filtering/)
- [Qdrant Payload Indexing](https://qdrant.tech/documentation/concepts/indexing/)
- [Qdrant Tenant Indexing](https://qdrant.tech/documentation/guides/multiple-partitions/)
